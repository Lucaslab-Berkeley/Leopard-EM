{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Leopard-EM","text":"<p>Welcome to the Location &amp; oriEntatiOn of PARticles found using two-Dimensional tEmplate Matching (Leopard-EM) online documentation! Leopard-EM is a Python implementation of Two-Dimensional Template Matching (2DTM) which itself is a data processing method in cryo-EM for locating and orienting particles using a reference structure. This package currently reflects the functionality described in Lucas, et al. (2021)<sup>1</sup> with additional programs to maximize the usefulness of 2DTM as well as other user-friendly features for integrating into broader data science workflows.</p> <p>Citing this work</p> <p>If you use Leopard-EM in your research, please cite (coming soon!).</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#requirements","title":"Requirements","text":"<p>The general system requirements for Leopard-EM are</p> <ul> <li>Python version 3.10 or above</li> <li>PyTorch 2.4.0 or above</li> <li>Linux operating system</li> </ul> <p>The package config contains a complete set of requirements which are automatically downloaded and checked during the installation process. We also recommend using a virtual environment manager (such as conda) to avoid conflicts with other installed software on your system. Please open a open up a bug report on the GitHub page if you experience major issues during the installation process.</p> <p>MacOS and Windows support</p> <p>Leopard-EM should theoretically work on MacOS and Windows operating systems, but we cannot guarantee compatibility with platforms other than Linux nor do we distribute pre-built wheels for these platforms.</p> <p>Tested GPU support</p> <p>Leopard-EM has only been tested against NVIDIA GPUs but should run on most modern GPU hardware (supported by PyTorch). If you've experienced a compatibility issue, create an issue on GitHub.</p>"},{"location":"#pre-packaged-releases","title":"Pre-packaged releases","text":"<p>Pre-packaged versions of Leopard-EM are released on the Python Package Index (PyPI). To install the latest pre-packaged release of Leopard-EM, run the following:</p> <pre><code>pip install leopard-em\n</code></pre> <p>From there, you are ready to start running 2DTM workflows or exploring some of our examples.</p>"},{"location":"#installing-from-source","title":"Installing from Source","text":"<p>If you want to install Leopard-EM from source, first clone the repository and install the package using pip:</p> <pre><code>git clone https://github.com/Lucaslab-Berkeley/Leopard-EM.git\ncd Leopard-EM\npip install .\n</code></pre>"},{"location":"#for-developers","title":"For Developers","text":"<p>Developers who are interested in contributing to Leopard-EM should fork the repository into their own GitHub account. Navigate to the Leopard-EM GitHub landing page and click on fork in the top right-hand corner. Then clone your fork and add the Lucaslab-Berkeley remote as an upstream:</p> <pre><code>git clone https://github.com/YOUR_USERNAME/Leopard-EM.git\ncd Leopard-EM\ngit remote add upstream https://github.com/Lucaslab-Berkeley/Leopard-EM\n</code></pre> <p>Check that the remote has been properly added (<code>git remote -v</code>) then run the following to install the package along with the optional development dependencies.</p> <pre><code>pip install -e '.[dev,test,docs]'\n</code></pre> <p>See the Contributing page for detailed guidelines on contributing to the package.</p>"},{"location":"#basic-usage","title":"Basic Usage","text":""},{"location":"#built-in-programs","title":"Built-in programs","text":"<p>Leopard-EM is runnable through a set of pre-built Python scripts and easily modifiable YAML configurations. There are currently five main programs (located under <code>programs/</code> folder) each with their own configuration files. Detailed documentation for each program can be found on the Program Documentation Overview, but the five main programs are as follows:</p> <ol> <li><code>match_template</code> - Runs a whole orientation search for a given reference structure on a single micrograph.</li> <li><code>refine_template</code> - Takes particles identified from match template and refines their location, orientation, and defocus parameters.</li> <li><code>optimize_template</code> - Optimizes the pixel size of the micrograph and template structure model using a set of identified particles.</li> <li><code>constrained_search</code> - Uses the location and orientation of identified particles to constrain the search parameters of a second particle.</li> <li><code>optimize_b_factor.py</code> - Script to optimize the b-factor added to a model (using 2DTM) for a set of metrics.</li> </ol>"},{"location":"#minimal-match-template-example","title":"Minimal match template example","text":"<p>The following Python script will run a basic match template program using only the built-in Pydantic models. See the programs documentation page for more details on running each program.</p> <pre><code>from leopard_em.pydantic_models.config import DefocusSearchConfig\nfrom leopard_em.pydantic_models.config import OrientationSearchConfig\nfrom leopard_em.pydantic_models.config import ComputationalConfig\nfrom leopard_em.pydantic_models.config import PreprocessingFilters\nfrom leopard_em.pydantic_models.data_structures import OpticsGroup\nfrom leopard_em.pydantic_models.managers import MatchTemplateManager\nfrom leopard_em.pydantic_models.results import MatchTemplateResult\n\n\ndef setup_match_template_manager():\n    \"\"\"Helper function to set up MatchTemplateManager Pydantic model.\"\"\"\n    # Microscope imaging parameters\n    my_optics_group = OpticsGroup(\n        label=\"my_optics_group\",\n        pixel_size=1.2,    # In Angstroms\n        voltage=300,       # In kV\n        defocus_u=5100.0,  # In Angstroms\n        defocus_v=4900.0,  # In Angstroms\n        astigmatism_angle=0.0,  # In degrees\n    )\n\n    # Relative defocus planes to search across\n    df_search_config = DefocusSearchConfig(\n        defocus_min=-1000,  # In Angstroms, relative to defocus_{u,v}\n        defocus_max=1000,   # In Angstroms, relative to defocus_{u,v}\n        defocus_step=200.0,    # In Angstroms\n    )\n\n    # Orientation sampling of SO(3) space, using default\n    orientation_search_config = OrientationSearchConfig()\n\n    # Where to save the output results\n    mt_result = MatchTemplateResult(\n        allow_file_overwrite=True,\n        mip_path=\"some/path/to/output_mip.mrc\",\n        scaled_mip_path=\"some/path/to/output_scaled_mip.mrc\",\n        correlation_average_path=\"some/path/to/output_correlation_average.mrc\",\n        correlation_variance_path=\"some/path/to/output_correlation_variance.mrc\",\n        orientation_psi_path=\"some/path/to/output_orientation_psi.mrc\",\n        orientation_theta_path=\"some/path/to/output_orientation_theta.mrc\",\n        orientation_phi_path=\"some/path/to/output_orientation_phi.mrc\",\n        relative_defocus_path=\"some/path/to/output_relative_defocus.mrc\",\n    )\n\n    # What Fourier pre-processing filters to apply to image/template\n    # This uses the default filter parameters which work in most cases\n    pre_filters = PreprocessingFilters()\n\n    # Which GPUs to run template matching on (here the first 2 GPUs)\n    comp_config = ComputationalConfig(gpu_ids=[0, 1])\n\n    # Bring all the other configs together in the manager\n    mt_manager = MatchTemplateManager(\n        micrograph_path=\"some_path/to/image.mrc\",\n        template_volume_path=\"some_path/to/volume.mrc\",\n        optics_group=my_optics_group,\n        defocus_search_config=df_search_config,\n        orientation_search_config=orientation_search_config,\n        match_template_result=mt_result,\n        computational_config=comp_config,\n        preprocessing_filters=pre_filters,\n    )\n\n    return mt_manager\n\n\ndef main():\n    \"\"\"Run the match_template program.\"\"\"\n    mt_manager = setup_match_template_manager()\n    mt_manager.run_match_template(\n        orientation_batch_size=1,  # Change this based on GPU memory\n        do_result_export=True,  # Saves the statistics immediately upon completion\n    )\n\n    # Construct and export the dataframe of picked peaks\n    df = mt_manager.results_to_dataframe()\n    df.to_csv(\"my_match_template_results.csv\", index=True)\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"#documentation-and-examples","title":"Documentation and Examples","text":"<p>See the left-hand menu for examples of using the Leopard-EM package and other package documentation.</p>"},{"location":"#theory","title":"Theory","text":"<p>\ud83d\udea7 Under Construction \ud83d\udea7</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We encourage contributions to this package from the broader cryo-EM/ET and structural biology communities. See contributing for guidelines. Leopard-EM is configured with a set of development dependencies to help contributors maintain code quality and consistency. See the Installation -- For Developers section for instructions on how to install these dependencies.</p>"},{"location":"#license","title":"License","text":"<p>The code in this repository is licensed under the BSD 3-Clause License. See the LICENSE file for full details.</p>"},{"location":"#references","title":"References","text":"<ol> <li> <p>Lucas BA, Himes BA, Xue L, Grant T, Mahamid J, Grigorieff N. Locating macromolecular assemblies in cells by 2D template matching with cisTEM. Elife. 2021 Jun 11;10:e68946. doi: 10.7554/eLife.68946. PMID: 34114559; PMCID: PMC8219381.\u00a0\u21a9</p> </li> </ol>"},{"location":"contributing/","title":"Contributing to the Leopard-EM Package","text":"<p>Welcome to the contributing section of the documentation. There are multiple ways to contribute to the Leopard-EM codebase ranging from reporting &amp; fixing a bug to adding new features into the package. While we strive to make 2DTM accessible and to promote open-source science, we are only a handful of researchers managing this package. To ensure a streamlined development cycle, we\u2019ve put together a set of contribution guidelines for the Leopard-EM package.</p> <p>The tl;dr of the contributing guidelines:</p> <ul> <li>Follow the bug report template so we can help fix bugs!  </li> <li>Create feature requests before adding new features to the library; community suggestions and contributions are encouraged, but we want to keep the scope narrow for Leopard-EM.  </li> <li>Open pull requests to the proper branches, and pull requests must be reviewed by a maintainer before merging.</li> </ul>"},{"location":"contributing/#using-github-issues","title":"Using GitHub Issues","text":""},{"location":"contributing/#opening-a-bug-report","title":"Opening a bug report","text":"<p>We\u2019ve included bug report/issue templates in our GitHub page which detail the necessary information to include when opening a new bug or issue report. This helps us track down the bug/issue and find a fix. We reserve the right to close bug reports that don\u2019t include this necessary information.</p>"},{"location":"contributing/#making-feature-requests","title":"Making feature requests","text":"<p>We encourage users to make applicable feature requests, but we also want to prevent feature creep. If you are thinking about adding new functionality or features to the package, please open a feature request before opening a pull request so we can discuss if that feature fits within the scope of Leopard-EM. For example, the following would fall outside the scope:</p> <ul> <li>Generating 3D reconstructions from 2DTM results</li> <li>Adding a GUI for processing data using 2DTM (this could be a new package!)</li> </ul> <p>For major feature requests, we ask contributors to take initiative for implementing the feature.</p>"},{"location":"contributing/#making-contributions-to-the-leopard-em-package","title":"Making contributions to the Leopard-EM package","text":""},{"location":"contributing/#setting-up-leopard-em-on-your-machine-as-a-developer","title":"Setting up Leopard-EM on your machine as a developer","text":"<p>Leopard-EM is installable as a PyPI package, but we include additional development and testing dependencies. Please follow the developer installation instructions to properly configure these additional dependencies.</p> <p>Also, make sure you\u2019ve forked the repo when installing from source. Your local repository should be tracking the forked copy as \u201corigin\u201d and the Lucaslab-Berkekely/Leopard-EM repo as \u201cupstream\u201d. Commits should be pushed to your fork, and changes should only come into the main Leopard-EM repository through pull requests.</p>"},{"location":"contributing/#pull-requests-and-branches","title":"Pull requests and branches","text":"<p>As mentioned before, new code should only be added to the main Leopard-EM repository through a pull request. This ensures all the necessary changes adhere to the style and testing standards defined in the package and that maintainers can review newly added code. The process for successfully creating and merging pull request is:</p> <ol> <li>Committing and pushing the changes to your fork of the repository (\u201corigin\u201d upstream).</li> <li>Creating a PR from a fork branch to one of the branches (listed below) depending on the kind of addition/change.</li> <li>Ensuring the PR passes all the CI checks and tests.</li> <li>Getting the PR reviewed and approved by one of the Leopard-EM maintainers.</li> <li>Asking one of the maintainers to merge the PR.</li> </ol> <p>We also have a pull request template in the repository listing all the components and steps for a successful pull request. Please follow these carefully!</p> <p>Pull requests should be made to one of the following branches to ensure the main branch stays stable:</p> <ul> <li>dev \u2013 Intended for testing out new features or other development changes; code may be unstable.</li> <li>feature_{abcd} \u2013 Branch specifically for a larger feature named \u201cabcd\u201d which may require many changes over a significant period of time</li> <li>docs_main \u2013 Updates to the online documentation site to be made immediately. For example, updating URLs of hosted data or correcting minor errors not specific to the source code.</li> <li>docs_dev \u2013 Development branch for documentation which may be unstable or include pages/statements which don\u2019t directly correspond to the current main branch.</li> <li>prerelease_v{x.y.z}  \u2013 Code for final cleanup and staging before releasing version \u201cx.y.z\u201d of  Leopard-EM.</li> </ul>"},{"location":"contributing/#building-documentation","title":"Building Documentation","text":"<p>The documentation for Leopard-EM is built using MkDocs and Material for MkDocs for generating the documentation site. If you've installed the package with the optional <code>docs</code> dependencies, you can build the documentation site with the following command:</p> <pre><code>mkdocs build\nmkdocs serve\n</code></pre> <p>The first command will construct the HTML files for the documentation site, and the second command will start a local server (at <code>127.0.0.1:8000</code>) to view the site.</p>"},{"location":"contributing/#code-style-guidelines","title":"Code style guidelines","text":"<p>The package is already configured with code formatting standards which aim to reduce complexity and increase readability. Please make sure your code changes are properly type-hinted, include docstrings, and pass the formatting checks.</p>"},{"location":"contributing/#configuring-pre-commit-hooks","title":"Configuring pre-commit hooks","text":"<p>The pre-commit package is used to run a set of code quality checks and auto-formatters on the codebase. The pre-commit hooks need installed and configured once after a fresh installation.</p> <pre><code>pre-commit install --install-hooks\n</code></pre> <p>Now, the pre-commit tool can be run on staged files before making a commit by running the following.</p> <pre><code>pre-commit run\n</code></pre>"},{"location":"contributing/#running-pylint","title":"Running pylint","text":"<p>Pylint is another tool to ensure consistent code quality. The pylint tool can be run on all files in the source directory by running:</p> <pre><code>pylint src/\n</code></pre> <p>Please make sure new code passes the pylint tests.</p>"},{"location":"contributing/#running-unit-tests","title":"Running unit tests","text":"<p>Leopard-EM uses the pytest package for running tests. To run the tests, simply run the following command from the root directory of the repository:</p> <pre><code>pytest\n</code></pre> <p>Note that we are still working on expanding the unit tests to cover more of the package.</p>"},{"location":"data_formats/","title":"Description of Data Formats","text":"<p>To increase interoperability between external packages, we herein describe the different data formats used as input to and export from programs. Orientations on a per-particle bases are currently stored as Euler angles in ZYZ format with angles ordered as .</p> <p>Note</p> <p>Leopard-Em is still undergoing development, and the exact way the data is represented might change in the future. We will document any data format changes between versions.</p>"},{"location":"data_formats/#data-from-the-match-template-program","title":"Data from the match template program","text":"<p>The match template program collates statistics from a large number of cross-correlograms taken over an orientation and defocus search space. See the API on the <code>MatchTemplateResult</code> object for further information on how these data are stored in memory, but here we provide an overview of what files get written to disk.</p>"},{"location":"data_formats/#best-statistic-maps","title":"Best statistic maps","text":"<p>Each of the \"best\" statistics (i.e. orientation, defocus) is stored on a per-position basis in what we dub \"statistics maps\" saved as <code>.mrc</code> files. We have the following tracked statistics for each valid (x, y) position:</p> <ul> <li>Maximum Intensity Projection (MIP): Maximum attained cross-correlation value over the entire search space.</li> <li>Scaled MIP (z-score or 2DTM SNR): The MIP value normalized by the mean and variance of the cross-correlation over the entire search space.</li> <li>Correlation Mean: The mean of the cross-correlation values over the entire search space. Used to calculate the scaled MIP.</li> <li>Correlation Variance: The variance of the cross-correlation values over the entire search space. Used to calculate the scaled MIP.</li> <li>Phi: The  angle (in degrees) which produced the MIP value.</li> <li>Theta: The  angle (in degrees) which produced the MIP value.</li> <li>Psi: The  angle (in degrees) which produced the MIP value.</li> <li>Defocus: The relative defocus value (in Angstroms, relative to CTF defocus of micrograph) which produced the MIP value.</li> </ul> <p>Each of these statistics maps are saved to disk in the MRC format based on paths provided in the <code>MatchTemplateResult</code> object.</p>"},{"location":"data_formats/#a-note-on-correlation-modes-and-output-shapes","title":"A note on correlation modes and output shapes","text":"<p>Three general modes for convolution/correlation exist in digital signal processing: \"full\", \"same\", and \"valid\". This chapter of Digital Signals Theory provides a good overview of these modes.</p> <p>We use the the \"valid\" mode by default when saving these statistics maps, but they are initially stored in their \"same\" modes. The <code>MatchTemplateResult.apply_valid_cropping</code> method does this \"same\" to \"valid\" cropping. For an image with shape  and template , the modes will output statistics maps with the following shapes:</p> <ul> <li>same:  </li> <li>valid:  </li> </ul> <p>Note that same mode pads the image with zeros along the edges and does not increase the number of particles detectable; values along the padded portions of the edge do not hold significance in the context of the particle detection. In each case, the position in the map at  corresponds to the top-left corner of the template projection at that position, not the center of the template.</p> <p>There are, however, the <code>pos_{x,y}_img</code> columns in the exported DataFrame after match template whose values do correspond to the center of the particle.</p>"},{"location":"data_formats/#match-template-dataframe","title":"Match template DataFrame","text":"<p>Since not all positions  contain a particle from the match template search, using full statistics maps for downstream analysis can be inefficient in terms of speed, memory requirements, and code overhead. The match template manager class has the method <code>MatchTemplateManager.results_to_dataframe()</code> which automatically picks peaks within the scaled MIP map and stores the peak locations, orientations, and defocus values in a pandas DataFrame. This is automatically called when using the provided match template program script.</p> <p>We take a verbose approach to constructing this DataFrame where some columns store similar information about each particle. Additional columns besides locations and orientations are included in the DataFrame to increase the utility of the data, namely the construction of <code>ParticleStack</code> objects. The columns and corresponding descriptions are as follows:</p> Column Name Type Description <code>particle_index</code> int An integer descriptor for ordering picked particles. Useful when operating on multiple dataframes. <code>mip</code> float Maximum cross-correlation value over all search orientations and relative defocus values. <code>scaled_mip</code> float Scaled MIP value (z-score) normalized by cross-correlation mean and variance. <code>correlation_mean</code> float Mean of the cross-correlation values over the entire search space. <code>correlation_variance</code> float Variance of the cross-correlation values over the entire search space. <code>total_correlations</code> int Total number of cross-correlations performs in the search space (number of defocus planes times number of orientations). <code>pos_x</code> int Particle x position (units of pixels) in the statistics maps. Corresponds to the top-left corner of the template. <code>pos_y</code> int Particle y position (units of pixels) in the statistics maps. Corresponds to the top-left corner of the template. <code>pos_x_img</code> int Center of of the particle (x position, units of pixels) in the micrograph. <code>pos_y_img</code> int Center of of the particle (y position, units of pixels) in the micrograph. <code>pos_x_img_angstrom</code> float Center of the particle (x position, in Angstroms) in the micrograph. <code>pos_y_img_angstrom</code> float Center of the particle (y position, in Angstroms) in the micrograph. <code>phi</code> float The  angle which (in degrees) produced the MIP value. Orientation angles are in the ZYZ format. <code>theta</code> float The  angle (in degrees) which produced the MIP value. Orientation angles are in the ZYZ format. <code>psi</code> float The  angle (in degrees) which produced the MIP value. Orientation angles are in the ZYZ format. <code>relative_defocus</code> float The relative defocus value (in Angstroms) which produced the MIP value. Relative to <code>defocus_u</code> and <code>defocus_v</code>. <code>defocus_u</code> float Defocus value along the major axis for the micrograph (in Angstroms). <code>defocus_v</code> float Defocus value along the minor axis for the micrograph (in Angstroms). <code>astigmatism_angle</code> float Angle of the astigmatism (in degrees) for defocus. <code>pixel_size</code> float Pixel size of the micrograph (in Angstroms). <code>voltage</code> float Voltage of the microscope (in kV). <code>spherical_aberration</code> float Spherical aberration of the microscope (in mm). <code>amplitude_contrast_ratio</code> float Amplitude contrast ratio of the microscope. <code>phase_shift</code> float Phase shift of the microscope (in degrees). <code>ctf_B_factor</code> float B-factor of the CTF, in Angstroms^2. <code>micrograph_path</code> str Path to the micrograph searched over in the match template program. Can be used to identify where particles came from when data frames from multiple match template runs are merged. <code>template_path</code> str Path to the template used for the search. <code>mip_path</code> str Path to the saved MIP map. <code>scaled_mip_path</code> str Path to the saved scaled MIP map. <code>psi_path</code> str Path to the saved psi map. <code>theta_path</code> str Path to the saved theta map. <code>phi_path</code> str Path to the saved phi map. <code>defocus_path</code> str Path to the saved defocus map. <code>correlation_average_path</code> str Path to the saved correlation mean map. <code>correlation_variance_path</code> str Path to the saved correlation variance map."},{"location":"data_formats/#data-from-the-refine-template-program","title":"Data from the refine template program","text":"<p>The refine template program takes in the DataFrame from the match template program and refines the orientation &amp; defocus values of each particle. Each of the refined parameters are stored in new columns prefixed with the <code>refined_</code> string. Note that refined results can be re-refined, for example with a slightly different template, and the already refined parameters will be used. When using the results from a refine template run, say to construct a particle stack, columns with the <code>refined_</code> prefix will be used by default, if they are present.</p>"},{"location":"data_formats/#refine-template-dataframe","title":"Refine template DataFrame","text":"<p>The program outputs another DataFrame with additional columns for the refined orientations, defocus values, and positions. New columns with descriptions are listed below:</p> Column Name Type Description <code>refined_mip</code> float New maximum cross-correlation over refinement search space. <code>refined_scaled_mip</code> float New scaled MIP value (z-score) normalized by cross-correlation mean and variance. <code>refined_pos_x</code> int The refined x position of the particle, top-left corner of the template. <code>refined_pos_y</code> int The refined y position of the particle, top-left corner of the template. <code>refined_pos_x_img</code> int The refined x position of the particle, center of the particle in the micrograph. <code>refined_pos_y_img</code> int The refined y position of the particle, center of the particle in the micrograph. <code>refined_pos_x_img_angstrom</code> float The refined x position of the particle, center of the particle in the micrograph (in Angstroms). <code>refined_pos_y_img_angstrom</code> float The refined y position of the particle, center of the particle in the micrograph (in Angstroms). <code>refined_phi</code> float The refined  angle (in degrees). <code>refined_theta</code> float The refined  angle (in degrees). <code>refined_psi</code> float The refined  angle (in degrees). <code>refined_relative_defocus</code> float The refined relative defocus value (in Angstroms)."},{"location":"autoapi/summary/","title":"Summary","text":"<ul> <li>leopard_em<ul> <li>analysis<ul> <li>gev_fit_metric</li> <li>match_template_peaks</li> <li>pvalue_metric</li> <li>utils</li> <li>zscore_metric</li> </ul> </li> <li>backend<ul> <li>core_match_template</li> <li>core_refine_template</li> <li>cross_correlation</li> <li>process_results</li> <li>utils</li> </ul> </li> <li>pydantic_models<ul> <li>config<ul> <li>computational_config</li> <li>correlation_filters</li> <li>defocus_search</li> <li>orientation_search</li> <li>pixel_size_search</li> </ul> </li> <li>custom_types</li> <li>data_structures<ul> <li>optics_group</li> <li>particle_stack</li> </ul> </li> <li>formats</li> <li>managers<ul> <li>constrained_search_manager</li> <li>match_template_manager</li> <li>optimize_template_manager</li> <li>refine_template_manager</li> </ul> </li> <li>results<ul> <li>match_template_result</li> </ul> </li> <li>utils</li> </ul> </li> <li>utils<ul> <li>cross_correlation</li> <li>data_io</li> <li>fourier_slice</li> </ul> </li> </ul> </li> </ul>"},{"location":"autoapi/leopard_em/","title":"leopard_em","text":"<p>Two-Dimensional Template Matching (2DTM) written in Python.</p>"},{"location":"autoapi/leopard_em/analysis/","title":"analysis","text":"<p>Submodule for analyzing results during the template matching pipeline.</p>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.MatchTemplatePeaks","title":"<code>MatchTemplatePeaks</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Helper class for return value of extract_peaks_and_statistics.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>class MatchTemplatePeaks(NamedTuple):\n    \"\"\"Helper class for return value of extract_peaks_and_statistics.\"\"\"\n\n    pos_y: torch.Tensor\n    pos_x: torch.Tensor\n    mip: torch.Tensor\n    scaled_mip: torch.Tensor\n    psi: torch.Tensor\n    theta: torch.Tensor\n    phi: torch.Tensor\n    relative_defocus: torch.Tensor\n    correlation_mean: torch.Tensor\n    correlation_variance: torch.Tensor\n    total_correlations: int\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.extract_peaks_and_statistics_p_value","title":"<code>extract_peaks_and_statistics_p_value(mip, scaled_mip, best_psi, best_theta, best_phi, best_defocus, correlation_average, correlation_variance, total_correlation_positions, p_value_cutoff=0.01, mask_radius=5.0)</code>","text":"<p>Returns peak locations, stats, etc. using the pvalue metric.</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the match template results.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>Scaled maximum intensity projection of the match template results.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angles for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angles for each pixel.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angles for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best relative defocus values for each pixel.</p> required <code>correlation_average</code> <code>Tensor</code> <p>Average correlation value for each pixel.</p> required <code>correlation_variance</code> <code>Tensor</code> <p>Variance of the correlation values for each pixel.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number of correlation positions calculated during template matching. Must be provided if <code>z_score_cutoff</code> is not provided (needed for the noise model).</p> required <code>p_value_cutoff</code> <code>float</code> <p>P-value cutoff value for peak detection. Default is 0.01.</p> <code>0.01</code> <code>mask_radius</code> <code>float</code> <p>Radius for the mask used to filter peaks. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>A named tuple containing the peak locations, statistics, and other relevant data.</p> Source code in <code>src/leopard_em/analysis/pvalue_metric.py</code> <pre><code>def extract_peaks_and_statistics_p_value(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    correlation_average: torch.Tensor,\n    correlation_variance: torch.Tensor,\n    total_correlation_positions: int,\n    p_value_cutoff: float = 0.01,\n    mask_radius: float = 5.0,\n) -&gt; MatchTemplatePeaks:\n    \"\"\"Returns peak locations, stats, etc. using the pvalue metric.\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        Maximum intensity projection of the match template results.\n    scaled_mip : torch.Tensor\n        Scaled maximum intensity projection of the match template results.\n    best_psi : torch.Tensor\n        Best psi angles for each pixel.\n    best_theta : torch.Tensor\n        Best theta angles for each pixel.\n    best_phi : torch.Tensor\n        Best phi angles for each pixel.\n    best_defocus : torch.Tensor\n        Best relative defocus values for each pixel.\n    correlation_average : torch.Tensor\n        Average correlation value for each pixel.\n    correlation_variance : torch.Tensor\n        Variance of the correlation values for each pixel.\n    total_correlation_positions : int\n        Total number of correlation positions calculated during template matching. Must\n        be provided if `z_score_cutoff` is not provided (needed for the noise model).\n    p_value_cutoff : float, optional\n        P-value cutoff value for peak detection. Default is 0.01.\n    mask_radius : float, optional\n        Radius for the mask used to filter peaks. Default is 5.0.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        A named tuple containing the peak locations, statistics, and other relevant\n        data.\n    \"\"\"\n    pos_y, pos_x = find_peaks_from_pvalue(\n        mip=mip,\n        scaled_mip=scaled_mip,\n        p_value_cutoff=p_value_cutoff,\n        mask_radius=mask_radius,\n    )\n\n    # Raise warning if no peaks are found\n    if len(pos_y) == 0:\n        warnings.warn(\"No peaks found using p-value metric.\", stacklevel=2)\n\n    # Extract peak heights, orientations, etc. from other maps\n    return MatchTemplatePeaks(\n        pos_y=pos_y,\n        pos_x=pos_x,\n        mip=mip[pos_y, pos_x],\n        scaled_mip=scaled_mip[pos_y, pos_x],\n        psi=best_psi[pos_y, pos_x],\n        theta=best_theta[pos_y, pos_x],\n        phi=best_phi[pos_y, pos_x],\n        relative_defocus=best_defocus[pos_y, pos_x],\n        correlation_mean=correlation_average[pos_y, pos_x],\n        correlation_variance=correlation_variance[pos_y, pos_x],\n        total_correlations=total_correlation_positions,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.extract_peaks_and_statistics_zscore","title":"<code>extract_peaks_and_statistics_zscore(mip, scaled_mip, best_psi, best_theta, best_phi, best_defocus, correlation_average, correlation_variance, total_correlation_positions, false_positives=1.0, z_score_cutoff=None, mask_radius=5.0)</code>","text":"<p>Returns peak locations, heights, and pose stats from match template results.</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the match template results.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>Scaled maximum intensity projection of the match template results.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angles for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angles for each pixel.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angles for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best relative defocus values for each pixel.</p> required <code>correlation_average</code> <code>Tensor</code> <p>Average correlation value for each pixel.</p> required <code>correlation_variance</code> <code>Tensor</code> <p>Variance of the correlation values for each pixel.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number of correlation positions calculated during template matching. Must be provided if <code>z_score_cutoff</code> is not provided (needed for the noise model).</p> required <code>false_positives</code> <code>float</code> <p>Number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <code>z_score_cutoff</code> <code>float</code> <p>Z-score cutoff value for peak detection. If not provided, it is calculated using the Gaussian noise model. Default is None.</p> <code>None</code> <code>mask_radius</code> <code>float</code> <p>Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>Named tuple containing the peak locations, heights, and pose statistics.</p> Source code in <code>src/leopard_em/analysis/zscore_metric.py</code> <pre><code>def extract_peaks_and_statistics_zscore(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    correlation_average: torch.Tensor,\n    correlation_variance: torch.Tensor,\n    total_correlation_positions: int,\n    false_positives: float = 1.0,\n    z_score_cutoff: Optional[float] = None,\n    mask_radius: float = 5.0,\n) -&gt; MatchTemplatePeaks:\n    \"\"\"Returns peak locations, heights, and pose stats from match template results.\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        Maximum intensity projection of the match template results.\n    scaled_mip : torch.Tensor\n        Scaled maximum intensity projection of the match template results.\n    best_psi : torch.Tensor\n        Best psi angles for each pixel.\n    best_theta : torch.Tensor\n        Best theta angles for each pixel.\n    best_phi : torch.Tensor\n        Best phi angles for each pixel.\n    best_defocus : torch.Tensor\n        Best relative defocus values for each pixel.\n    correlation_average : torch.Tensor\n        Average correlation value for each pixel.\n    correlation_variance : torch.Tensor\n        Variance of the correlation values for each pixel.\n    total_correlation_positions : int\n        Total number of correlation positions calculated during template matching. Must\n        be provided if `z_score_cutoff` is not provided (needed for the noise model).\n    false_positives : float, optional\n        Number of false positives to allow in the image (over all pixels). Default is\n        1.0 which corresponds to a single false-positive.\n    z_score_cutoff : float, optional\n        Z-score cutoff value for peak detection. If not provided, it is calculated using\n        the Gaussian noise model. Default is None.\n    mask_radius : float, optional\n        Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        Named tuple containing the peak locations, heights, and pose statistics.\n    \"\"\"\n    if z_score_cutoff is None:\n        z_score_cutoff = gaussian_noise_zscore_cutoff(\n            num_ccg=mip.numel() * total_correlation_positions,\n            false_positives=false_positives,\n        )\n\n    # Find the peak locations only in the scaled MIP\n    pos_y, pos_x = find_peaks_from_zscore(scaled_mip, z_score_cutoff, mask_radius)\n\n    # Raise warning if no peaks are found\n    if len(pos_y) == 0:\n        warnings.warn(\"No peaks found using z-score metric.\", stacklevel=2)\n\n    # Extract peak heights, orientations, etc. from other maps\n    return MatchTemplatePeaks(\n        pos_y=pos_y,\n        pos_x=pos_x,\n        mip=mip[pos_y, pos_x],\n        scaled_mip=scaled_mip[pos_y, pos_x],\n        psi=best_psi[pos_y, pos_x],\n        theta=best_theta[pos_y, pos_x],\n        phi=best_phi[pos_y, pos_x],\n        relative_defocus=best_defocus[pos_y, pos_x],\n        correlation_mean=correlation_average[pos_y, pos_x],\n        correlation_variance=correlation_variance[pos_y, pos_x],\n        total_correlations=total_correlation_positions,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.gaussian_noise_zscore_cutoff","title":"<code>gaussian_noise_zscore_cutoff(num_ccg, false_positives=1.0)</code>","text":"<p>Determines the z-score cutoff based on Gaussian noise model and number of pixels.</p> <p>NOTE: This procedure assumes that the z-scores (normalized maximum intensity projections) are distributed according to a standard normal distribution. Here, this model is used to find the cutoff value such that there is at most 'false_positives' number of false positives in all of the pixels.</p> <p>Parameters:</p> Name Type Description Default <code>num_ccg</code> <code>int</code> <p>Total number of cross-correlograms calculated during template matching. Product of the number of pixels, number of defocus values, and number of orientations.</p> required <code>false_positives</code> <code>float</code> <p>Number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Z-score cutoff.</p> Source code in <code>src/leopard_em/analysis/zscore_metric.py</code> <pre><code>def gaussian_noise_zscore_cutoff(num_ccg: int, false_positives: float = 1.0) -&gt; float:\n    \"\"\"Determines the z-score cutoff based on Gaussian noise model and number of pixels.\n\n    NOTE: This procedure assumes that the z-scores (normalized maximum intensity\n    projections) are distributed according to a standard normal distribution. Here,\n    this model is used to find the cutoff value such that there is at most\n    'false_positives' number of false positives in all of the pixels.\n\n    Parameters\n    ----------\n    num_ccg : int\n        Total number of cross-correlograms calculated during template matching. Product\n        of the number of pixels, number of defocus values, and number of orientations.\n    false_positives : float, optional\n        Number of false positives to allow in the image (over all pixels). Default is\n        1.0 which corresponds to a single false-positive.\n\n    Returns\n    -------\n    float\n        Z-score cutoff.\n    \"\"\"\n    tmp = erfcinv(2.0 * false_positives / num_ccg)\n    tmp *= np.sqrt(2.0)\n\n    return float(tmp)\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.match_template_peaks_to_dataframe","title":"<code>match_template_peaks_to_dataframe(peaks)</code>","text":"<p>Convert MatchTemplatePeaks object to a pandas DataFrame.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>def match_template_peaks_to_dataframe(peaks: MatchTemplatePeaks) -&gt; pd.DataFrame:\n    \"\"\"Convert MatchTemplatePeaks object to a pandas DataFrame.\"\"\"\n    return pd.DataFrame(peaks._asdict())\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/#leopard_em.analysis.match_template_peaks_to_dict","title":"<code>match_template_peaks_to_dict(peaks)</code>","text":"<p>Convert MatchTemplatePeaks object to a dictionary.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>def match_template_peaks_to_dict(peaks: MatchTemplatePeaks) -&gt; dict:\n    \"\"\"Convert MatchTemplatePeaks object to a dictionary.\"\"\"\n    return peaks._asdict()\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/gev_fit_metric/","title":"gev_fit_metric","text":"<p>Fit a General Extreme Value (GEV) distribution to calculate cutoff value.</p>"},{"location":"autoapi/leopard_em/analysis/gev_fit_metric/#leopard_em.analysis.gev_fit_metric.extract_peaks_and_statistics_gev","title":"<code>extract_peaks_and_statistics_gev(mip, scaled_mip, best_psi, best_theta, best_phi, best_defocus, correlation_average, correlation_variance, total_correlation_positions, false_positives=1.0, mask_radius=5.0)</code>","text":"<p>Returns peak locations, heights, and pose stats from match template results.</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the match template results.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>Scaled maximum intensity projection of the match template results.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angles for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angles for each pixel.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angles for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best relative defocus values for each pixel.</p> required <code>correlation_average</code> <code>Tensor</code> <p>Average correlation value for each pixel.</p> required <code>correlation_variance</code> <code>Tensor</code> <p>Variance of the correlation values for each pixel.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number of correlation positions calculated during template matching. Must be provided if <code>z_score_cutoff</code> is not provided (needed for the noise model).</p> required <code>false_positives</code> <code>float</code> <p>Number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <code>mask_radius</code> <code>float</code> <p>Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>Named tuple containing the peak locations, heights, and pose statistics.</p> Source code in <code>src/leopard_em/analysis/gev_fit_metric.py</code> <pre><code>def extract_peaks_and_statistics_gev(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    correlation_average: torch.Tensor,\n    correlation_variance: torch.Tensor,\n    total_correlation_positions: int,\n    false_positives: float = 1.0,\n    mask_radius: float = 5.0,\n) -&gt; MatchTemplatePeaks:\n    \"\"\"Returns peak locations, heights, and pose stats from match template results.\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        Maximum intensity projection of the match template results.\n    scaled_mip : torch.Tensor\n        Scaled maximum intensity projection of the match template results.\n    best_psi : torch.Tensor\n        Best psi angles for each pixel.\n    best_theta : torch.Tensor\n        Best theta angles for each pixel.\n    best_phi : torch.Tensor\n        Best phi angles for each pixel.\n    best_defocus : torch.Tensor\n        Best relative defocus values for each pixel.\n    correlation_average : torch.Tensor\n        Average correlation value for each pixel.\n    correlation_variance : torch.Tensor\n        Variance of the correlation values for each pixel.\n    total_correlation_positions : int\n        Total number of correlation positions calculated during template matching. Must\n        be provided if `z_score_cutoff` is not provided (needed for the noise model).\n    false_positives : float, optional\n        Number of false positives to allow in the image (over all pixels). Default is\n        1.0 which corresponds to a single false-positive.\n    mask_radius : float, optional\n        Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        Named tuple containing the peak locations, heights, and pose statistics.\n    \"\"\"\n    z_score_cutoff = gev_zscore_cutoff(scaled_mip, false_positives=false_positives)\n\n    # Find the peak locations only in the scaled MIP\n    pos_y, pos_x = find_peaks_from_zscore(scaled_mip, z_score_cutoff, mask_radius)\n\n    # Raise warning if no peaks are found\n    if len(pos_y) == 0:\n        warnings.warn(\"No peaks found using z-score metric.\", stacklevel=2)\n\n    # Raise warning if a very large number of peaks are found\n    if len(pos_y) &gt; LARGE_PEAK_WARNING_VALUE:\n        warnings.warn(\n            f\"Found {len(pos_y)} peaks using the fitted GEV distribution. This is a \"\n            \"lot and could indicate a poor fit to the data. You should inspect the fit \"\n            \"before using these results. See the online documentation for details.\",\n            stacklevel=2,\n        )\n\n    # Extract peak heights, orientations, etc. from other maps\n    return MatchTemplatePeaks(\n        pos_y=pos_y,\n        pos_x=pos_x,\n        mip=mip[pos_y, pos_x],\n        scaled_mip=scaled_mip[pos_y, pos_x],\n        psi=best_psi[pos_y, pos_x],\n        theta=best_theta[pos_y, pos_x],\n        phi=best_phi[pos_y, pos_x],\n        relative_defocus=best_defocus[pos_y, pos_x],\n        correlation_mean=correlation_average[pos_y, pos_x],\n        correlation_variance=correlation_variance[pos_y, pos_x],\n        total_correlations=total_correlation_positions,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/gev_fit_metric/#leopard_em.analysis.gev_fit_metric.fit_gev_to_zscore","title":"<code>fit_gev_to_zscore(zscore_map, min_zscore_value=None, max_zscore_value=8.5, num_samples=1000000)</code>","text":"<p>Helper function to fit a GEV distribution to the z-score map.</p> <p>See <code>gev_zscore_cutoff</code> for more details.</p> Source code in <code>src/leopard_em/analysis/gev_fit_metric.py</code> <pre><code>def fit_gev_to_zscore(\n    zscore_map: torch.Tensor,\n    min_zscore_value: Optional[float] = None,\n    max_zscore_value: Optional[float] = 8.5,\n    num_samples: Optional[int] = 1_000_000,\n) -&gt; tuple[rv_frozen, tuple[float, float, float]]:\n    \"\"\"Helper function to fit a GEV distribution to the z-score map.\n\n    See `gev_zscore_cutoff` for more details.\n    \"\"\"\n    if isinstance(zscore_map, torch.Tensor):\n        zscore_map = zscore_map.cpu().numpy()\n\n    # Logic for handling optional parameters\n    if min_zscore_value is None:\n        min_zscore_value = zscore_map.min().item()\n    if max_zscore_value is None:\n        max_zscore_value = zscore_map.max().item()\n    if num_samples is None or num_samples &gt; zscore_map.size:\n        num_samples = zscore_map.size\n\n    # Get flattened and filtered data to fit the GEV distribution\n    data = zscore_map.flatten()\n    data = data[(data &gt;= min_zscore_value) &amp; (data &lt;= max_zscore_value)]\n    if len(data) &gt; num_samples:  # type: ignore\n        data = np.random.choice(data, num_samples, replace=False)\n\n    # Fit the parameters of the GEV distribution\n    shape, loc, scale = genextreme.fit(data)\n\n    return genextreme(shape, loc=loc, scale=scale), (shape, loc, scale)\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/gev_fit_metric/#leopard_em.analysis.gev_fit_metric.gev_zscore_cutoff","title":"<code>gev_zscore_cutoff(zscore_map, false_positives=1.0, min_zscore_value=None, max_zscore_value=8.5, num_samples=1000000)</code>","text":"<p>Calculate the z-score cutoff value by fitting a GEV distn to the z-score map.</p> <p>NOTE: This function can take on the order of 10s to 100s of seconds to run when there are a large number of pixels in the z-score map. The 'num_samples' parameter can be set to fit only using a random subset of the z-score map.</p> <p>NOTE: Fitting with ~1,000,000 points seems to sufficiently capture the GEV behavior. Your fit results may vary depending on the data; inspecting the quality of your fit is recommended.</p> <p>NOTE: The 'max_zscore_value' parameter is set to 8.5 by default which performs well for a full orientation search (1.5 degrees in-plane and 2.5 degrees out-of-plane). Adjusting the search space parameters will require adjustment from the default value.</p> <p>Parameters:</p> Name Type Description Default <code>zscore_map</code> <code>Tensor</code> <p>The z-score map to fit the GEV distribution to.</p> required <code>false_positives</code> <code>Optional[float]</code> <p>The number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <code>min_zscore_value</code> <code>Optional[float]</code> <p>The minimum z-score value to consider for fitting the GEV distribution. If None, the minimum value in the z-score map is used.</p> <code>None</code> <code>max_zscore_value</code> <code>Optional[float]</code> <p>The maximum z-score value to consider for fitting the GEV distribution. If None, the maximum value in the z-score map is used. Default is 8.5 and all values above this are ignored.</p> <code>8.5</code> <code>num_samples</code> <code>Optional[int]</code> <p>The number of samples to use for fitting the GEV distribution. If None, the number of samples is set to the number of pixels in the z-score map. The default is 1,000,000, and 1 million random pixels are sampled from the z-score map.</p> <code>1000000</code> <p>Returns:</p> Type Description <code>float</code> <p>The z-score cutoff value for the GEV distribution.</p> Source code in <code>src/leopard_em/analysis/gev_fit_metric.py</code> <pre><code>def gev_zscore_cutoff(\n    zscore_map: torch.Tensor,\n    false_positives: Optional[float] = 1.0,\n    min_zscore_value: Optional[float] = None,\n    max_zscore_value: Optional[float] = 8.5,\n    num_samples: Optional[int] = 1_000_000,\n) -&gt; float:\n    \"\"\"Calculate the z-score cutoff value by fitting a GEV distn to the z-score map.\n\n    NOTE: This function can take on the order of 10s to 100s of seconds to run when\n    there are a large number of pixels in the z-score map. The 'num_samples' parameter\n    can be set to fit only using a random subset of the z-score map.\n\n    NOTE: Fitting with ~1,000,000 points seems to sufficiently capture the GEV behavior.\n    Your fit results may vary depending on the data; inspecting the quality of your fit\n    is recommended.\n\n    NOTE: The 'max_zscore_value' parameter is set to 8.5 by default which performs well\n    for a full orientation search (1.5 degrees in-plane and 2.5 degrees out-of-plane).\n    Adjusting the search space parameters will require adjustment from the default\n    value.\n\n    Parameters\n    ----------\n    zscore_map: torch.Tensor\n        The z-score map to fit the GEV distribution to.\n    false_positives: float, optional\n        The number of false positives to allow in the image (over all pixels). Default\n        is 1.0 which corresponds to a single false-positive.\n    min_zscore_value: float, optional\n        The minimum z-score value to consider for fitting the GEV distribution. If\n        None, the minimum value in the z-score map is used.\n    max_zscore_value: float, optional\n        The maximum z-score value to consider for fitting the GEV distribution. If\n        None, the maximum value in the z-score map is used. Default is 8.5 and all\n        values above this are ignored.\n    num_samples: int, optional\n        The number of samples to use for fitting the GEV distribution. If None, the\n        number of samples is set to the number of pixels in the z-score map. The default\n        is 1,000,000, and 1 million random pixels are sampled from the z-score map.\n\n    Returns\n    -------\n    float\n        The z-score cutoff value for the GEV distribution.\n    \"\"\"\n    if isinstance(zscore_map, torch.Tensor):\n        zscore_map = zscore_map.cpu().numpy()\n\n    gev_opt, _ = fit_gev_to_zscore(\n        zscore_map,\n        min_zscore_value=min_zscore_value,\n        max_zscore_value=max_zscore_value,\n        num_samples=num_samples,\n    )\n\n    # False positive rate of the survival function\n    false_positive_density = false_positives / zscore_map.size\n    tmp = gev_opt.isf(false_positive_density)\n\n    return float(tmp)\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/match_template_peaks/","title":"match_template_peaks","text":"<p>Data class and helper functions for match template peaks and statistics.</p>"},{"location":"autoapi/leopard_em/analysis/match_template_peaks/#leopard_em.analysis.match_template_peaks.MatchTemplatePeaks","title":"<code>MatchTemplatePeaks</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Helper class for return value of extract_peaks_and_statistics.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>class MatchTemplatePeaks(NamedTuple):\n    \"\"\"Helper class for return value of extract_peaks_and_statistics.\"\"\"\n\n    pos_y: torch.Tensor\n    pos_x: torch.Tensor\n    mip: torch.Tensor\n    scaled_mip: torch.Tensor\n    psi: torch.Tensor\n    theta: torch.Tensor\n    phi: torch.Tensor\n    relative_defocus: torch.Tensor\n    correlation_mean: torch.Tensor\n    correlation_variance: torch.Tensor\n    total_correlations: int\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/match_template_peaks/#leopard_em.analysis.match_template_peaks.match_template_peaks_to_dataframe","title":"<code>match_template_peaks_to_dataframe(peaks)</code>","text":"<p>Convert MatchTemplatePeaks object to a pandas DataFrame.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>def match_template_peaks_to_dataframe(peaks: MatchTemplatePeaks) -&gt; pd.DataFrame:\n    \"\"\"Convert MatchTemplatePeaks object to a pandas DataFrame.\"\"\"\n    return pd.DataFrame(peaks._asdict())\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/match_template_peaks/#leopard_em.analysis.match_template_peaks.match_template_peaks_to_dict","title":"<code>match_template_peaks_to_dict(peaks)</code>","text":"<p>Convert MatchTemplatePeaks object to a dictionary.</p> Source code in <code>src/leopard_em/analysis/match_template_peaks.py</code> <pre><code>def match_template_peaks_to_dict(peaks: MatchTemplatePeaks) -&gt; dict:\n    \"\"\"Convert MatchTemplatePeaks object to a dictionary.\"\"\"\n    return peaks._asdict()\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/pvalue_metric/","title":"pvalue_metric","text":"<p>Module for calling true/false positives using the p-value metric.</p>"},{"location":"autoapi/leopard_em/analysis/pvalue_metric/#leopard_em.analysis.pvalue_metric.extract_peaks_and_statistics_p_value","title":"<code>extract_peaks_and_statistics_p_value(mip, scaled_mip, best_psi, best_theta, best_phi, best_defocus, correlation_average, correlation_variance, total_correlation_positions, p_value_cutoff=0.01, mask_radius=5.0)</code>","text":"<p>Returns peak locations, stats, etc. using the pvalue metric.</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the match template results.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>Scaled maximum intensity projection of the match template results.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angles for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angles for each pixel.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angles for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best relative defocus values for each pixel.</p> required <code>correlation_average</code> <code>Tensor</code> <p>Average correlation value for each pixel.</p> required <code>correlation_variance</code> <code>Tensor</code> <p>Variance of the correlation values for each pixel.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number of correlation positions calculated during template matching. Must be provided if <code>z_score_cutoff</code> is not provided (needed for the noise model).</p> required <code>p_value_cutoff</code> <code>float</code> <p>P-value cutoff value for peak detection. Default is 0.01.</p> <code>0.01</code> <code>mask_radius</code> <code>float</code> <p>Radius for the mask used to filter peaks. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>A named tuple containing the peak locations, statistics, and other relevant data.</p> Source code in <code>src/leopard_em/analysis/pvalue_metric.py</code> <pre><code>def extract_peaks_and_statistics_p_value(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    correlation_average: torch.Tensor,\n    correlation_variance: torch.Tensor,\n    total_correlation_positions: int,\n    p_value_cutoff: float = 0.01,\n    mask_radius: float = 5.0,\n) -&gt; MatchTemplatePeaks:\n    \"\"\"Returns peak locations, stats, etc. using the pvalue metric.\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        Maximum intensity projection of the match template results.\n    scaled_mip : torch.Tensor\n        Scaled maximum intensity projection of the match template results.\n    best_psi : torch.Tensor\n        Best psi angles for each pixel.\n    best_theta : torch.Tensor\n        Best theta angles for each pixel.\n    best_phi : torch.Tensor\n        Best phi angles for each pixel.\n    best_defocus : torch.Tensor\n        Best relative defocus values for each pixel.\n    correlation_average : torch.Tensor\n        Average correlation value for each pixel.\n    correlation_variance : torch.Tensor\n        Variance of the correlation values for each pixel.\n    total_correlation_positions : int\n        Total number of correlation positions calculated during template matching. Must\n        be provided if `z_score_cutoff` is not provided (needed for the noise model).\n    p_value_cutoff : float, optional\n        P-value cutoff value for peak detection. Default is 0.01.\n    mask_radius : float, optional\n        Radius for the mask used to filter peaks. Default is 5.0.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        A named tuple containing the peak locations, statistics, and other relevant\n        data.\n    \"\"\"\n    pos_y, pos_x = find_peaks_from_pvalue(\n        mip=mip,\n        scaled_mip=scaled_mip,\n        p_value_cutoff=p_value_cutoff,\n        mask_radius=mask_radius,\n    )\n\n    # Raise warning if no peaks are found\n    if len(pos_y) == 0:\n        warnings.warn(\"No peaks found using p-value metric.\", stacklevel=2)\n\n    # Extract peak heights, orientations, etc. from other maps\n    return MatchTemplatePeaks(\n        pos_y=pos_y,\n        pos_x=pos_x,\n        mip=mip[pos_y, pos_x],\n        scaled_mip=scaled_mip[pos_y, pos_x],\n        psi=best_psi[pos_y, pos_x],\n        theta=best_theta[pos_y, pos_x],\n        phi=best_phi[pos_y, pos_x],\n        relative_defocus=best_defocus[pos_y, pos_x],\n        correlation_mean=correlation_average[pos_y, pos_x],\n        correlation_variance=correlation_variance[pos_y, pos_x],\n        total_correlations=total_correlation_positions,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/pvalue_metric/#leopard_em.analysis.pvalue_metric.find_peaks_from_pvalue","title":"<code>find_peaks_from_pvalue(mip, scaled_mip, p_value_cutoff=0.01, mask_radius=5.0)</code>","text":"<p>Finds the peak locations based on the p-value metric using mip and scaled mip.</p> <p>See the following for a reference on the p-value metric:     https://journals.iucr.org/m/issues/2025/02/00/eh5020/eh5020.pdf</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>The maximum intensity projection (MIP) tensor from match template program.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>The z-score scaled MIP tensor from match template program.</p> required <code>p_value_cutoff</code> <code>float</code> <p>The p-value cutoff for peak detection. Default is 0.01.</p> <code>0.01</code> <code>mask_radius</code> <code>float</code> <p>The radius of the mask used to filter peaks. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>The y and x coordinates of the detected peaks.</p> Source code in <code>src/leopard_em/analysis/pvalue_metric.py</code> <pre><code>def find_peaks_from_pvalue(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    p_value_cutoff: float = 0.01,\n    mask_radius: float = 5.0,\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Finds the peak locations based on the p-value metric using mip and scaled mip.\n\n    See the following for a reference on the p-value metric:\n        https://journals.iucr.org/m/issues/2025/02/00/eh5020/eh5020.pdf\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        The maximum intensity projection (MIP) tensor from match template program.\n    scaled_mip : torch.Tensor\n        The z-score scaled MIP tensor from match template program.\n    p_value_cutoff : float, optional\n        The p-value cutoff for peak detection. Default is 0.01.\n    mask_radius : float, optional\n        The radius of the mask used to filter peaks. Default is 5.0.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        The y and x coordinates of the detected peaks.\n    \"\"\"\n    device = mip.device\n\n    # Convert mip and scaled_mip tensors into numpy arrays\n    scaled_mip = scaled_mip.cpu().numpy()\n    mip = mip.cpu().numpy()\n\n    # Apply the probit transformation to the quantiles of each of the data\n    probit_zscore = probit_transform(scaled_mip.flatten())\n    probit_mip = probit_transform(mip.flatten())\n\n    # Dimensions for the data inferred from min/max values\n    # NOTE: fixing the number of points used for the histogram here, could expose\n    # options for fitting to the user...\n    x_dim = np.linspace(\n        start=probit_zscore.min(),\n        stop=probit_zscore.max(),\n        num=100,\n    )\n    y_dim = np.linspace(\n        start=probit_mip.min(),\n        stop=probit_mip.max(),\n        num=100,\n    )\n\n    hist, _, _ = np.histogram2d(\n        probit_zscore,\n        probit_mip,\n        # bins=(x_dim, y_dim),\n        bins=(100, 100),\n    )\n    hist = np.ma.masked_array(hist, mask=hist == 0)\n\n    # Fit the full covariance 2D Gaussian to the log transformed histogram\n    # hist = np.masked_array(hist, mask=hist == 0)\n    result = fit_full_cov_gaussian_2d(\n        data=hist,\n        x_dim=x_dim,\n        y_dim=y_dim,\n    )\n    rv = _params_to_multivariate_normal(\n        mu_x=result.params[\"mu_x\"].value,\n        mu_y=result.params[\"mu_y\"].value,\n        sigma_x=result.params[\"sigma_x\"].value,\n        sigma_y=result.params[\"sigma_y\"].value,\n        rho=result.params[\"rho\"].value,\n    )\n\n    # Use numpy's masked array to only operate on points in the first quadrant\n    points = np.column_stack((probit_zscore, probit_mip))\n    # mask = (points[:, 0] &lt; 0) | (points[:, 1] &lt; 0)\n    # points = np.ma.masked_array(points, mask=np.array([mask, mask]))\n\n    # NOTE: This is a relatively slow step (~20-80s) since the cdf needs calculated for\n    # large numbers of points. There are potential speedups like pre-filtering points\n    # based on a less expensive bounds estimate, but that is left for future work.\n    p_values = 1.0 - rv.cdf(points)\n\n    p_values = p_values.reshape(mip.shape)\n\n    # Convert back to Torch tensor and use the peak filtering utility function\n    p_values = torch.from_numpy(p_values).to(device)\n    peaks = torch.nonzero(p_values &lt; p_value_cutoff, as_tuple=False)\n    p_values = p_values[tuple(peaks.t())]\n\n    if peaks.shape[0] == 0:\n        return torch.tensor([], dtype=torch.long), torch.tensor([], dtype=torch.long)\n\n    peaks = filter_peaks_by_distance(\n        peak_values=p_values,\n        peak_locations=peaks,\n        distance_threshold=mask_radius,\n    )\n\n    return peaks[:, 0], peaks[:, 1]\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/pvalue_metric/#leopard_em.analysis.pvalue_metric.fit_full_cov_gaussian_2d","title":"<code>fit_full_cov_gaussian_2d(data, x_dim, y_dim)</code>","text":"<p>Fit the full covariance 2D Gaussian to the data using the LMFit package.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>2D array of data to fit.</p> required <code>x_dim</code> <code>ndarray</code> <p>1D array of x-coordinates.</p> required <code>y_dim</code> <code>ndarray</code> <p>1D array of y-coordinates.</p> required <p>Returns:</p> Type Description <code>ModelResult</code> <p>The result of the fit.</p> Source code in <code>src/leopard_em/analysis/pvalue_metric.py</code> <pre><code>def fit_full_cov_gaussian_2d(\n    data: np.ndarray,\n    x_dim: np.ndarray,\n    y_dim: np.ndarray,\n) -&gt; ModelResult:\n    \"\"\"Fit the full covariance 2D Gaussian to the data using the LMFit package.\n\n    Parameters\n    ----------\n    data : np.ndarray\n        2D array of data to fit.\n    x_dim : np.ndarray\n        1D array of x-coordinates.\n    y_dim : np.ndarray\n        1D array of y-coordinates.\n\n    Returns\n    -------\n    ModelResult\n        The result of the fit.\n    \"\"\"\n    assert data.ndim == 2, \"Data must be a 2D array.\"\n    assert x_dim.ndim == 1, \"x_dim must be a 1D array.\"\n    assert y_dim.ndim == 1, \"y_dim must be a 1D array.\"\n    expected_shape = (len(y_dim), len(x_dim))\n    error_msg = (\n        f\"Data shape does not match dimensions. \"\n        f\"Expected {expected_shape}, got data.shape={data.shape}.\"\n    )\n    assert data.shape == expected_shape, error_msg\n\n    def gaussian_pdf_2d(\n        coords_flat: np.ndarray,\n        amplitude: float,\n        mu_x: float,\n        mu_y: float,\n        sigma_x: float,\n        sigma_y: float,\n        rho: float,\n    ) -&gt; np.ndarray:\n        \"\"\"Helper function to calculate the 2D Gaussian PDF for a set of parameters.\"\"\"\n        rv = _params_to_multivariate_normal(mu_x, mu_y, sigma_x, sigma_y, rho)\n        coords = coords_flat.reshape(-1, 2)\n\n        return amplitude * rv.pdf(coords)\n\n    # Setup the grid coordinates\n    xx, yy = np.meshgrid(x_dim, y_dim)\n    coords_flat = np.column_stack((xx.ravel(), yy.ravel()))\n    z = data.ravel()\n\n    # Setup a LMFit model object for the Gaussian PDF\n    model = Model(gaussian_pdf_2d, independent_vars=[\"coords_flat\"])\n\n    params = Parameters()\n    params.add(\"amplitude\", value=np.max(z), min=0)\n    params.add(\"mu_x\", value=np.mean(x_dim))  # Initial guess for x mean\n    params.add(\"mu_y\", value=np.mean(y_dim))  # Initial guess for y mean\n    params.add(\"sigma_x\", value=1.0, min=0)\n    params.add(\"sigma_y\", value=1.0, min=0)\n    params.add(\"rho\", value=0.0, min=-1, max=1)  # Correlation coefficient\n\n    # Fit the model to the data\n    result = model.fit(z, params, coords_flat=coords_flat)\n\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/pvalue_metric/#leopard_em.analysis.pvalue_metric.probit_transform","title":"<code>probit_transform(x)</code>","text":"<p>Apply the probit transform to the quantiles of input data x.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Transformed array.</p> Source code in <code>src/leopard_em/analysis/pvalue_metric.py</code> <pre><code>def probit_transform(x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Apply the probit transform to the quantiles of input data x.\n\n    Parameters\n    ----------\n    x : np.ndarray\n        Input array.\n\n    Returns\n    -------\n    np.ndarray\n        Transformed array.\n    \"\"\"\n    assert x.ndim == 1, \"Input array must be 1-dimensional.\"\n\n    n = x.size\n\n    # Get the sorted indices of the input array\n    sorted_indices = np.argsort(x)\n\n    # Create an array of ranks based on the sorted indices\n    ranks = np.empty_like(sorted_indices)\n    ranks[sorted_indices] = np.arange(1, n + 1)  # ranks start from 1\n\n    # Calculate the probit transform\n    rank_tmp = (ranks - 0.5) / n\n    # pylint: disable=no-member\n    probit = np.sqrt(2.0) * special.erfinv(2.0 * rank_tmp - 1.0)\n\n    return probit\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/utils/","title":"utils","text":"<p>Utility function associated with the analysis submodule.</p>"},{"location":"autoapi/leopard_em/analysis/utils/#leopard_em.analysis.utils.filter_peaks_by_distance","title":"<code>filter_peaks_by_distance(peak_values, peak_locations, distance_threshold)</code>","text":"<p>Filters peaks in descending order with a distance threshold.</p> <p>If any peaks are within a distance threshold of an already picked peak, they are suppressed. Precedence is given to peaks with the highest value.</p> <p>NOTE: This function operates on 2D data only and distance metrics are measured in pixels.</p> <p>Parameters:</p> Name Type Description Default <code>peak_values</code> <code>Tensor</code> <p>Tensor of peak values.</p> required <code>peak_locations</code> <code>Tensor</code> <p>Tensor of peak locations, shape (N, 2) where N is the number of peaks.</p> required <code>distance_threshold</code> <code>float</code> <p>Minimum distance between peaks to be considered separate peaks.</p> required Source code in <code>src/leopard_em/analysis/utils.py</code> <pre><code>def filter_peaks_by_distance(\n    peak_values: torch.Tensor,\n    peak_locations: torch.Tensor,\n    distance_threshold: float,\n) -&gt; torch.Tensor:\n    \"\"\"Filters peaks in descending order with a distance threshold.\n\n    If any peaks are within a distance threshold of an already picked peak, they are\n    suppressed. Precedence is given to peaks with the highest value.\n\n    NOTE: This function operates on 2D data only and distance metrics are measured in\n    pixels.\n\n    Parameters\n    ----------\n    peak_values : torch.Tensor\n        Tensor of peak values.\n    peak_locations : torch.Tensor\n        Tensor of peak locations, shape (N, 2) where N is the number of peaks.\n    distance_threshold : float\n        Minimum distance between peaks to be considered separate peaks.\n    \"\"\"\n    # Sort the peaks in descending order based on their values\n    peak_values, sort_indices = torch.sort(peak_values, descending=True)\n    peak_locations = peak_locations[sort_indices]\n\n    # Create a boolean mask to record which peaks are taken\n    taken_mask = torch.zeros(\n        peak_values.size(0), dtype=torch.bool, device=peak_values.device\n    )\n    picked_peaks = torch.tensor([], dtype=torch.long, device=peak_values.device)\n\n    for i in range(peak_values.size(0)):\n        if taken_mask[i]:\n            continue\n\n        picked_peaks = torch.cat((picked_peaks, peak_locations[i].unsqueeze(0)), dim=0)\n\n        # Compute distances between current peak and all peaks\n        distances = torch.norm(peak_locations - peak_locations[i].float(), dim=1)\n\n        # Mark all peaks closer than distance_threshold as taken\n        taken_mask |= distances &lt; distance_threshold\n\n    return picked_peaks\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/zscore_metric/","title":"zscore_metric","text":"<p>Locates peaks in the scaled mip from a match template result.</p>"},{"location":"autoapi/leopard_em/analysis/zscore_metric/#leopard_em.analysis.zscore_metric.extract_peaks_and_statistics_zscore","title":"<code>extract_peaks_and_statistics_zscore(mip, scaled_mip, best_psi, best_theta, best_phi, best_defocus, correlation_average, correlation_variance, total_correlation_positions, false_positives=1.0, z_score_cutoff=None, mask_radius=5.0)</code>","text":"<p>Returns peak locations, heights, and pose stats from match template results.</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the match template results.</p> required <code>scaled_mip</code> <code>Tensor</code> <p>Scaled maximum intensity projection of the match template results.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angles for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angles for each pixel.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angles for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best relative defocus values for each pixel.</p> required <code>correlation_average</code> <code>Tensor</code> <p>Average correlation value for each pixel.</p> required <code>correlation_variance</code> <code>Tensor</code> <p>Variance of the correlation values for each pixel.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number of correlation positions calculated during template matching. Must be provided if <code>z_score_cutoff</code> is not provided (needed for the noise model).</p> required <code>false_positives</code> <code>float</code> <p>Number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <code>z_score_cutoff</code> <code>float</code> <p>Z-score cutoff value for peak detection. If not provided, it is calculated using the Gaussian noise model. Default is None.</p> <code>None</code> <code>mask_radius</code> <code>float</code> <p>Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>Named tuple containing the peak locations, heights, and pose statistics.</p> Source code in <code>src/leopard_em/analysis/zscore_metric.py</code> <pre><code>def extract_peaks_and_statistics_zscore(\n    mip: torch.Tensor,\n    scaled_mip: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    correlation_average: torch.Tensor,\n    correlation_variance: torch.Tensor,\n    total_correlation_positions: int,\n    false_positives: float = 1.0,\n    z_score_cutoff: Optional[float] = None,\n    mask_radius: float = 5.0,\n) -&gt; MatchTemplatePeaks:\n    \"\"\"Returns peak locations, heights, and pose stats from match template results.\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        Maximum intensity projection of the match template results.\n    scaled_mip : torch.Tensor\n        Scaled maximum intensity projection of the match template results.\n    best_psi : torch.Tensor\n        Best psi angles for each pixel.\n    best_theta : torch.Tensor\n        Best theta angles for each pixel.\n    best_phi : torch.Tensor\n        Best phi angles for each pixel.\n    best_defocus : torch.Tensor\n        Best relative defocus values for each pixel.\n    correlation_average : torch.Tensor\n        Average correlation value for each pixel.\n    correlation_variance : torch.Tensor\n        Variance of the correlation values for each pixel.\n    total_correlation_positions : int\n        Total number of correlation positions calculated during template matching. Must\n        be provided if `z_score_cutoff` is not provided (needed for the noise model).\n    false_positives : float, optional\n        Number of false positives to allow in the image (over all pixels). Default is\n        1.0 which corresponds to a single false-positive.\n    z_score_cutoff : float, optional\n        Z-score cutoff value for peak detection. If not provided, it is calculated using\n        the Gaussian noise model. Default is None.\n    mask_radius : float, optional\n        Radius of the mask to apply around the peak, in units of pixels. Default is 5.0.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        Named tuple containing the peak locations, heights, and pose statistics.\n    \"\"\"\n    if z_score_cutoff is None:\n        z_score_cutoff = gaussian_noise_zscore_cutoff(\n            num_ccg=mip.numel() * total_correlation_positions,\n            false_positives=false_positives,\n        )\n\n    # Find the peak locations only in the scaled MIP\n    pos_y, pos_x = find_peaks_from_zscore(scaled_mip, z_score_cutoff, mask_radius)\n\n    # Raise warning if no peaks are found\n    if len(pos_y) == 0:\n        warnings.warn(\"No peaks found using z-score metric.\", stacklevel=2)\n\n    # Extract peak heights, orientations, etc. from other maps\n    return MatchTemplatePeaks(\n        pos_y=pos_y,\n        pos_x=pos_x,\n        mip=mip[pos_y, pos_x],\n        scaled_mip=scaled_mip[pos_y, pos_x],\n        psi=best_psi[pos_y, pos_x],\n        theta=best_theta[pos_y, pos_x],\n        phi=best_phi[pos_y, pos_x],\n        relative_defocus=best_defocus[pos_y, pos_x],\n        correlation_mean=correlation_average[pos_y, pos_x],\n        correlation_variance=correlation_variance[pos_y, pos_x],\n        total_correlations=total_correlation_positions,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/zscore_metric/#leopard_em.analysis.zscore_metric.find_peaks_from_zscore","title":"<code>find_peaks_from_zscore(zscore_map, zscore_cutoff, mask_radius=5.0)</code>","text":"<p>Find peaks in a z-score map above a cutoff threshold using torch.</p> <p>The function returns a tensor of peak indices sorted in descending order by their z-score values. Peaks closer than mask_radius to an already picked peak are suppressed.</p> <p>Parameters:</p> Name Type Description Default <code>zscore_map</code> <code>Tensor</code> <p>Input tensor containing z-score values.</p> required <code>zscore_cutoff</code> <code>float</code> <p>Minimum z-score value to consider as a peak.</p> required <code>mask_radius</code> <code>float</code> <p>Minimum allowed distance between peaks, default is 5.0.</p> <code>5.0</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Two tensors containing the y and x coordinates of the peaks.</p> Source code in <code>src/leopard_em/analysis/zscore_metric.py</code> <pre><code>def find_peaks_from_zscore(\n    zscore_map: torch.Tensor,\n    zscore_cutoff: float,\n    mask_radius: float = 5.0,\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Find peaks in a z-score map above a cutoff threshold using torch.\n\n    The function returns a tensor of peak indices sorted in descending order by\n    their z-score values. Peaks closer than mask_radius to an already picked peak\n    are suppressed.\n\n    Parameters\n    ----------\n    zscore_map : torch.Tensor\n        Input tensor containing z-score values.\n    zscore_cutoff : float\n        Minimum z-score value to consider as a peak.\n    mask_radius : float, optional\n        Minimum allowed distance between peaks, default is 5.0.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        Two tensors containing the y and x coordinates of the peaks.\n    \"\"\"\n    # Find indices where zscore_map is above the cutoff\n    peaks = torch.nonzero(zscore_map &gt; zscore_cutoff, as_tuple=False)\n\n    if peaks.shape[0] == 0:\n        return torch.tensor([], dtype=torch.long), torch.tensor([], dtype=torch.long)\n\n    # Retrieve the zscore values for these indices and sort descending\n    peak_values = zscore_map[tuple(peaks.t())]\n\n    picked_peaks = filter_peaks_by_distance(\n        peak_values=peak_values,\n        peak_locations=peaks,\n        distance_threshold=mask_radius,\n    )\n\n    return picked_peaks[:, 0], picked_peaks[:, 1]\n</code></pre>"},{"location":"autoapi/leopard_em/analysis/zscore_metric/#leopard_em.analysis.zscore_metric.gaussian_noise_zscore_cutoff","title":"<code>gaussian_noise_zscore_cutoff(num_ccg, false_positives=1.0)</code>","text":"<p>Determines the z-score cutoff based on Gaussian noise model and number of pixels.</p> <p>NOTE: This procedure assumes that the z-scores (normalized maximum intensity projections) are distributed according to a standard normal distribution. Here, this model is used to find the cutoff value such that there is at most 'false_positives' number of false positives in all of the pixels.</p> <p>Parameters:</p> Name Type Description Default <code>num_ccg</code> <code>int</code> <p>Total number of cross-correlograms calculated during template matching. Product of the number of pixels, number of defocus values, and number of orientations.</p> required <code>false_positives</code> <code>float</code> <p>Number of false positives to allow in the image (over all pixels). Default is 1.0 which corresponds to a single false-positive.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>float</code> <p>Z-score cutoff.</p> Source code in <code>src/leopard_em/analysis/zscore_metric.py</code> <pre><code>def gaussian_noise_zscore_cutoff(num_ccg: int, false_positives: float = 1.0) -&gt; float:\n    \"\"\"Determines the z-score cutoff based on Gaussian noise model and number of pixels.\n\n    NOTE: This procedure assumes that the z-scores (normalized maximum intensity\n    projections) are distributed according to a standard normal distribution. Here,\n    this model is used to find the cutoff value such that there is at most\n    'false_positives' number of false positives in all of the pixels.\n\n    Parameters\n    ----------\n    num_ccg : int\n        Total number of cross-correlograms calculated during template matching. Product\n        of the number of pixels, number of defocus values, and number of orientations.\n    false_positives : float, optional\n        Number of false positives to allow in the image (over all pixels). Default is\n        1.0 which corresponds to a single false-positive.\n\n    Returns\n    -------\n    float\n        Z-score cutoff.\n    \"\"\"\n    tmp = erfcinv(2.0 * false_positives / num_ccg)\n    tmp *= np.sqrt(2.0)\n\n    return float(tmp)\n</code></pre>"},{"location":"autoapi/leopard_em/backend/","title":"backend","text":"<p>Submodule for computationally intensive backend functions.</p>"},{"location":"autoapi/leopard_em/backend/#leopard_em.backend.cross_correlate_particle_stack","title":"<code>cross_correlate_particle_stack(particle_stack_dft, template_dft, rotation_matrices, projective_filters, mode='valid', batch_size=1024)</code>","text":"<p>Cross-correlate a stack of particle images against a template.</p> <p>Here, the argument 'particle_stack_dft' is a set of RFFT-ed particle images with necessary filtering already applied. The zeroth dimension corresponds to unique particles.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack_dft</code> <code>Tensor</code> <p>The stack of particle real-Fourier transformed and un-fftshifted images. Shape of (N, H, W).</p> required <code>template_dft</code> <code>Tensor</code> <p>The template volume to extract central slices from. Real-Fourier transformed and fftshifted.</p> required <code>rotation_matrices</code> <code>Tensor</code> <p>The orientations of the particles to take the Fourier slices of, as a long list of rotation matrices. Shape of (N, 3, 3).</p> required <code>projective_filters</code> <code>Tensor</code> <p>Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).</p> required <code>mode</code> <code>Literal['valid', 'same']</code> <p>Correlation mode to use, by default \"valid\". If \"valid\", the output will be the valid cross-correlation of the inputs. If \"same\", the output will be the same shape as the input particle stack.</p> <code>'valid'</code> <code>batch_size</code> <code>int</code> <p>The number of particle images to cross-correlate at once. Default is 1024. Larger sizes will consume more memory. If -1, then the entire stack will be cross-correlated at once.</p> <code>1024</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The cross-correlation of the particle stack with the template. Shape will depend on the mode used. If \"valid\", the output will be (N, H-h+1, W-w+1). If \"same\", the output will be (N, H, W).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the mode is not \"valid\" or \"same\".</p> Source code in <code>src/leopard_em/backend/core_refine_template.py</code> <pre><code>def cross_correlate_particle_stack(\n    particle_stack_dft: torch.Tensor,  # (N, H, W)\n    template_dft: torch.Tensor,  # (d, h, w)\n    rotation_matrices: torch.Tensor,  # (N, 3, 3)\n    projective_filters: torch.Tensor,  # (N, h, w)\n    mode: Literal[\"valid\", \"same\"] = \"valid\",\n    batch_size: int = 1024,\n) -&gt; torch.Tensor:\n    \"\"\"Cross-correlate a stack of particle images against a template.\n\n    Here, the argument 'particle_stack_dft' is a set of RFFT-ed particle images with\n    necessary filtering already applied. The zeroth dimension corresponds to unique\n    particles.\n\n    Parameters\n    ----------\n    particle_stack_dft : torch.Tensor\n        The stack of particle real-Fourier transformed and un-fftshifted images.\n        Shape of (N, H, W).\n    template_dft : torch.Tensor\n        The template volume to extract central slices from. Real-Fourier transformed\n        and fftshifted.\n    rotation_matrices : torch.Tensor\n        The orientations of the particles to take the Fourier slices of, as a long\n        list of rotation matrices. Shape of (N, 3, 3).\n    projective_filters : torch.Tensor\n        Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).\n    mode : Literal[\"valid\", \"same\"], optional\n        Correlation mode to use, by default \"valid\". If \"valid\", the output will be\n        the valid cross-correlation of the inputs. If \"same\", the output will be the\n        same shape as the input particle stack.\n    batch_size : int, optional\n        The number of particle images to cross-correlate at once. Default is 1024.\n        Larger sizes will consume more memory. If -1, then the entire stack will be\n        cross-correlated at once.\n\n    Returns\n    -------\n    torch.Tensor\n        The cross-correlation of the particle stack with the template. Shape will depend\n        on the mode used. If \"valid\", the output will be (N, H-h+1, W-w+1). If \"same\",\n        the output will be (N, H, W).\n\n    Raises\n    ------\n    ValueError\n        If the mode is not \"valid\" or \"same\".\n    \"\"\"\n    # Helpful constants for later use\n    device = particle_stack_dft.device\n    num_particles, image_h, image_w = particle_stack_dft.shape\n    _, template_h, template_w = template_dft.shape\n    # account for RFFT\n    image_w = 2 * (image_w - 1)\n    template_w = 2 * (template_w - 1)\n\n    if batch_size == -1:\n        batch_size = num_particles\n\n    if mode == \"valid\":\n        output_shape = (\n            num_particles,\n            image_h - template_h + 1,\n            image_w - template_w + 1,\n        )\n    elif mode == \"same\":\n        output_shape = (num_particles, image_h, image_w)\n    else:\n        raise ValueError(f\"Invalid mode: {mode}. Must be 'valid' or 'same'.\")\n\n    out_correlation = torch.zeros(output_shape, device=device)\n\n    # Loop over the particle stack in batches\n    for i in range(0, num_particles, batch_size):\n        batch_particles_dft = particle_stack_dft[i : i + batch_size]\n        batch_rotation_matrices = rotation_matrices[i : i + batch_size]\n        batch_projective_filters = projective_filters[i : i + batch_size]\n\n        # Extract the Fourier slice and apply the projective filters\n        fourier_slice = extract_central_slices_rfft_3d(\n            volume_rfft=template_dft,\n            image_shape=(template_h,) * 3,\n            rotation_matrices=batch_rotation_matrices,\n        )\n        fourier_slice = torch.fft.ifftshift(fourier_slice, dim=(-2,))\n        fourier_slice[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n        fourier_slice *= -1  # flip contrast\n        fourier_slice *= batch_projective_filters\n\n        # Inverse Fourier transform and normalize the projection\n        projections = torch.fft.irfftn(fourier_slice, dim=(-2, -1))\n        projections = torch.fft.ifftshift(projections, dim=(-2, -1))\n        projections = normalize_template_projection(\n            projections, (template_h, template_w), (image_h, image_w)\n        )\n\n        # Padded forward FFT and cross-correlate\n        projections_dft = torch.fft.rfftn(\n            projections, dim=(-2, -1), s=(image_h, image_w)\n        )\n        projections_dft = batch_particles_dft * projections_dft.conj()\n        cross_correlation = torch.fft.irfftn(projections_dft, dim=(-2, -1))\n\n        # Handle the output shape\n        cross_correlation = handle_correlation_mode(\n            cross_correlation, output_shape, mode\n        )\n\n        out_correlation[i : i + batch_size] = cross_correlation\n\n    return out_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_match_template/","title":"core_match_template","text":"<p>Pure PyTorch implementation of whole orientation search backend.</p>"},{"location":"autoapi/leopard_em/backend/core_match_template/#leopard_em.backend.core_match_template.construct_multi_gpu_match_template_kwargs","title":"<code>construct_multi_gpu_match_template_kwargs(image_dft, template_dft, euler_angles, projective_filters, defocus_values, pixel_values, orientation_batch_size, num_cuda_streams, devices)</code>","text":"<p>Split orientations between requested devices.</p> <p>See the <code>core_match_template</code> function for further descriptions of the input parameters.</p> <p>Parameters:</p> Name Type Description Default <code>image_dft</code> <code>Tensor</code> <p>dft of image</p> required <code>template_dft</code> <code>Tensor</code> <p>dft of template</p> required <code>euler_angles</code> <code>Tensor</code> <p>euler angles to search</p> required <code>projective_filters</code> <code>Tensor</code> <p>filters to apply to each projection</p> required <code>defocus_values</code> <code>Tensor</code> <p>corresponding defocus values for each filter</p> required <code>pixel_values</code> <code>Tensor</code> <p>corresponding pixel size values for each filter</p> required <code>orientation_batch_size</code> <code>int</code> <p>number of projections to calculate at once</p> required <code>num_cuda_streams</code> <code>int</code> <p>number of CUDA streams to use for parallelizing cross-correlation computation</p> required <code>devices</code> <code>list[device]</code> <p>list of devices to split the orientations across</p> required <p>Returns:</p> Type Description <code>list[dict[str, Tensor | int]]</code> <p>List of dictionaries containing the kwargs to call the single-GPU function. Each index in the list corresponds to a different device, and all tensors in the dictionary have been allocated to that device.</p> Source code in <code>src/leopard_em/backend/core_match_template.py</code> <pre><code>def construct_multi_gpu_match_template_kwargs(\n    image_dft: torch.Tensor,\n    template_dft: torch.Tensor,\n    euler_angles: torch.Tensor,\n    projective_filters: torch.Tensor,\n    defocus_values: torch.Tensor,\n    pixel_values: torch.Tensor,\n    orientation_batch_size: int,\n    num_cuda_streams: int,\n    devices: list[torch.device],\n) -&gt; list[dict[str, torch.Tensor | torch.device | int]]:\n    \"\"\"Split orientations between requested devices.\n\n    See the `core_match_template` function for further descriptions of the\n    input parameters.\n\n    Parameters\n    ----------\n    image_dft : torch.Tensor\n        dft of image\n    template_dft : torch.Tensor\n        dft of template\n    euler_angles : torch.Tensor\n        euler angles to search\n    projective_filters : torch.Tensor\n        filters to apply to each projection\n    defocus_values : torch.Tensor\n        corresponding defocus values for each filter\n    pixel_values : torch.Tensor\n        corresponding pixel size values for each filter\n    orientation_batch_size : int\n        number of projections to calculate at once\n    num_cuda_streams : int\n        number of CUDA streams to use for parallelizing cross-correlation computation\n    devices : list[torch.device]\n        list of devices to split the orientations across\n\n    Returns\n    -------\n    list[dict[str, torch.Tensor | int]]\n        List of dictionaries containing the kwargs to call the single-GPU\n        function. Each index in the list corresponds to a different device,\n        and all tensors in the dictionary have been allocated to that device.\n    \"\"\"\n    kwargs_per_device = []\n\n    # Split the euler angles across devices\n    euler_angles_split = euler_angles.chunk(len(devices))\n\n    for device, euler_angles_device in zip(devices, euler_angles_split):\n        # Allocate and construct the kwargs for this device\n        kwargs = {\n            \"image_dft\": image_dft,\n            \"template_dft\": template_dft,\n            \"euler_angles\": euler_angles_device,\n            \"projective_filters\": projective_filters,\n            \"defocus_values\": defocus_values,\n            \"pixel_values\": pixel_values,\n            \"orientation_batch_size\": orientation_batch_size,\n            \"num_cuda_streams\": num_cuda_streams,\n            \"device\": device,\n        }\n\n        kwargs_per_device.append(kwargs)\n\n    return kwargs_per_device\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_match_template/#leopard_em.backend.core_match_template.core_match_template","title":"<code>core_match_template(image_dft, template_dft, ctf_filters, whitening_filter_template, defocus_values, pixel_values, euler_angles, device, orientation_batch_size=1, num_cuda_streams=1)</code>","text":"<p>Core function for performing the whole-orientation search.</p> <p>With the RFFT, the last dimension (fastest dimension) is half the width of the input, hence the shape of W // 2 + 1 instead of W for some of the input parameters.</p> <p>Parameters:</p> Name Type Description Default <code>image_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the image with large image filters already applied. Has shape (H, W // 2 + 1).</p> required <code>template_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the template volume to take Fourier slices from. Has shape (l, h, w // 2 + 1) with the last dimension being the half-dimension for real-FFT transformation. NOTE: The original template volume should be a cubic volume, i.e. h == w == l.</p> required <code>ctf_filters</code> <code>Tensor</code> <p>Stack of CTF filters at different pixel size (Cs) and  defocus values to use in the search. Has shape (num_Cs, num_defocus, h, w // 2 + 1) where num_Cs are the number of pixel sizes searched over, and num_defocus are the number of defocus values searched over.</p> required <code>whitening_filter_template</code> <code>Tensor</code> <p>Whitening filter for the template volume. Has shape (h, w // 2 + 1). Gets multiplied with the ctf filters to create a filter stack applied to each orientation projection.</p> required <code>euler_angles</code> <code>Tensor</code> <p>Euler angles (in 'ZYZ' convention) to search over. Has shape (num_orientations, 3).</p> required <code>defocus_values</code> <code>Tensor</code> <p>What defoucs values correspond with the CTF filters, in units of Angstroms. Has shape (num_defocus,).</p> required <code>pixel_values</code> <code>Tensor</code> <p>What pixel size values correspond with the CTF filters, in units of Angstroms. Has shape (num_Cs,).</p> required <code>device</code> <code>device | list[device]</code> <p>Device or devices to split computation across.</p> required <code>orientation_batch_size</code> <code>int</code> <p>Number of projections, at different orientations, to calculate simultaneously. Larger values will use more memory, but can help amortize the cost of Fourier slice extraction. The default is 1, but generally values larger than 1 should be used for performance.</p> <code>1</code> <code>num_cuda_streams</code> <code>int</code> <p>Number of CUDA streams to use for parallelizing cross-correlation computation. More streams can lead to better performance, especially for high-end GPUs, but the performance will degrade if too many streams are used. The default is 1 which performs well in most cases, but high-end GPUs can benefit from increasing this value. NOTE: If the number of streams is greater than the number of cross-correlations to compute per batch, then the number of streams will be reduced to the number of cross-correlations per batch. This is done to avoid unnecessary overhead and performance degradation.</p> <code>1</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>Dictionary containing the following key, value pairs:</p> <pre><code>- \"mip\": Maximum intensity projection of the cross-correlation values across\n  orientation and defocus search space.\n- \"scaled_mip\": Z-score scaled MIP of the cross-correlation values.\n- \"best_phi\": Best phi angle for each pixel.\n- \"best_theta\": Best theta angle for each pixel.\n- \"best_psi\": Best psi angle for each pixel.\n- \"best_defocus\": Best defocus value for each pixel.\n- \"best_pixel_size\": Best pixel size value for each pixel.\n- \"correlation_sum\": Sum of cross-correlation values for each pixel.\n- \"correlation_squared_sum\": Sum of squared cross-correlation values for\n  each pixel.\n- \"total_projections\": Total number of projections calculated.\n- \"total_orientations\": Total number of orientations searched.\n- \"total_defocus\": Total number of defocus values searched.\n</code></pre> Source code in <code>src/leopard_em/backend/core_match_template.py</code> <pre><code>def core_match_template(\n    image_dft: torch.Tensor,\n    template_dft: torch.Tensor,  # already fftshifted\n    ctf_filters: torch.Tensor,\n    whitening_filter_template: torch.Tensor,\n    defocus_values: torch.Tensor,\n    pixel_values: torch.Tensor,\n    euler_angles: torch.Tensor,\n    device: torch.device | list[torch.device],\n    orientation_batch_size: int = 1,\n    num_cuda_streams: int = 1,\n) -&gt; dict[str, torch.Tensor]:\n    \"\"\"Core function for performing the whole-orientation search.\n\n    With the RFFT, the last dimension (fastest dimension) is half the width\n    of the input, hence the shape of W // 2 + 1 instead of W for some of the\n    input parameters.\n\n    Parameters\n    ----------\n    image_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the image with large image filters\n        already applied. Has shape (H, W // 2 + 1).\n    template_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the template volume to take Fourier\n        slices from. Has shape (l, h, w // 2 + 1) with the last dimension being the\n        half-dimension for real-FFT transformation. NOTE: The original template volume\n        should be a cubic volume, i.e. h == w == l.\n    ctf_filters : torch.Tensor\n        Stack of CTF filters at different pixel size (Cs) and  defocus values to use in\n        the search. Has shape (num_Cs, num_defocus, h, w // 2 + 1) where num_Cs are the\n        number of pixel sizes searched over, and num_defocus are the number of\n        defocus values searched over.\n    whitening_filter_template : torch.Tensor\n        Whitening filter for the template volume. Has shape (h, w // 2 + 1).\n        Gets multiplied with the ctf filters to create a filter stack applied to each\n        orientation projection.\n    euler_angles : torch.Tensor\n        Euler angles (in 'ZYZ' convention) to search over. Has shape\n        (num_orientations, 3).\n    defocus_values : torch.Tensor\n        What defoucs values correspond with the CTF filters, in units of Angstroms. Has\n        shape (num_defocus,).\n    pixel_values : torch.Tensor\n        What pixel size values correspond with the CTF filters, in units of Angstroms.\n        Has shape (num_Cs,).\n    device : torch.device | list[torch.device]\n        Device or devices to split computation across.\n    orientation_batch_size : int, optional\n        Number of projections, at different orientations, to calculate simultaneously.\n        Larger values will use more memory, but can help amortize the cost of Fourier\n        slice extraction. The default is 1, but generally values larger than 1 should\n        be used for performance.\n    num_cuda_streams : int, optional\n        Number of CUDA streams to use for parallelizing cross-correlation computation.\n        More streams can lead to better performance, especially for high-end GPUs, but\n        the performance will degrade if too many streams are used. The default is 1\n        which performs well in most cases, but high-end GPUs can benefit from\n        increasing this value. NOTE: If the number of streams is greater than the\n        number of cross-correlations to compute per batch, then the number of streams\n        will be reduced to the number of cross-correlations per batch. This is done to\n        avoid unnecessary overhead and performance degradation.\n\n    Returns\n    -------\n    dict[str, torch.Tensor]\n        Dictionary containing the following key, value pairs:\n\n            - \"mip\": Maximum intensity projection of the cross-correlation values across\n              orientation and defocus search space.\n            - \"scaled_mip\": Z-score scaled MIP of the cross-correlation values.\n            - \"best_phi\": Best phi angle for each pixel.\n            - \"best_theta\": Best theta angle for each pixel.\n            - \"best_psi\": Best psi angle for each pixel.\n            - \"best_defocus\": Best defocus value for each pixel.\n            - \"best_pixel_size\": Best pixel size value for each pixel.\n            - \"correlation_sum\": Sum of cross-correlation values for each pixel.\n            - \"correlation_squared_sum\": Sum of squared cross-correlation values for\n              each pixel.\n            - \"total_projections\": Total number of projections calculated.\n            - \"total_orientations\": Total number of orientations searched.\n            - \"total_defocus\": Total number of defocus values searched.\n    \"\"\"\n    ################################################################\n    ### Initial checks for input parameters plus and adjustments ###\n    ################################################################\n    # If there are more streams than cross-correlations to compute per batch, then\n    # reduce the number of streams to the number of cross-correlations per batch.\n    total_cc_per_batch = (\n        orientation_batch_size * defocus_values.shape[0] * pixel_values.shape[0]\n    )\n    if num_cuda_streams &gt; total_cc_per_batch:\n        warnings.warn(\n            f\"Number of CUDA streams ({num_cuda_streams}) is greater than the \"\n            f\"number of cross-correlations per batch ({total_cc_per_batch}). \"\n            f\"The total cross-correlations per batch is number of pixel sizes \"\n            f\"({pixel_values.shape[0]}) * number of defocus values \"\n            f\"({defocus_values.shape[0]}) * orientation batch size \"\n            f\"({orientation_batch_size}). \"\n            f\"Reducing number of streams to {total_cc_per_batch} for performance.\",\n            stacklevel=2,\n        )\n        num_cuda_streams = total_cc_per_batch\n\n    # Ensure the tensors are all on the CPU. The _core_match_template_single_gpu\n    # function will move them onto the correct device.\n    image_dft = image_dft.cpu()\n    template_dft = template_dft.cpu()\n    ctf_filters = ctf_filters.cpu()\n    whitening_filter_template = whitening_filter_template.cpu()\n    defocus_values = defocus_values.cpu()\n    pixel_values = pixel_values.cpu()\n    euler_angles = euler_angles.cpu()\n\n    ##############################################################\n    ### Pre-multiply the whitening filter with the CTF filters ###\n    ##############################################################\n\n    projective_filters = ctf_filters * whitening_filter_template[None, None, ...]\n\n    #########################################\n    ### Split orientations across devices ###\n    #########################################\n\n    if isinstance(device, torch.device):\n        device = [device]\n\n    kwargs_per_device = construct_multi_gpu_match_template_kwargs(\n        image_dft=image_dft,\n        template_dft=template_dft,\n        euler_angles=euler_angles,\n        projective_filters=projective_filters,\n        defocus_values=defocus_values,\n        pixel_values=pixel_values,\n        orientation_batch_size=orientation_batch_size,\n        num_cuda_streams=num_cuda_streams,\n        devices=device,\n    )\n\n    result_dict = run_multiprocess_jobs(\n        target=_core_match_template_single_gpu,\n        kwargs_list=kwargs_per_device,\n    )\n\n    # Get the aggregated results\n    partial_results = [result_dict[i] for i in range(len(kwargs_per_device))]\n    aggregated_results = aggregate_distributed_results(partial_results)\n    mip = aggregated_results[\"mip\"]\n    best_phi = aggregated_results[\"best_phi\"]\n    best_theta = aggregated_results[\"best_theta\"]\n    best_psi = aggregated_results[\"best_psi\"]\n    best_defocus = aggregated_results[\"best_defocus\"]\n    correlation_sum = aggregated_results[\"correlation_sum\"]\n    correlation_squared_sum = aggregated_results[\"correlation_squared_sum\"]\n    total_projections = aggregated_results[\"total_projections\"]\n\n    mip_scaled = torch.empty_like(mip)\n    mip, mip_scaled, correlation_mean, correlation_variance = scale_mip(\n        mip=mip,\n        mip_scaled=mip_scaled,\n        correlation_sum=correlation_sum,\n        correlation_squared_sum=correlation_squared_sum,\n        total_correlation_positions=total_projections,\n    )\n\n    return {\n        \"mip\": mip,\n        \"scaled_mip\": mip_scaled,\n        \"best_phi\": best_phi,\n        \"best_theta\": best_theta,\n        \"best_psi\": best_psi,\n        \"best_defocus\": best_defocus,\n        \"correlation_mean\": correlation_mean,\n        \"correlation_variance\": correlation_variance,\n        \"total_projections\": total_projections,\n        \"total_orientations\": euler_angles.shape[0],\n        \"total_defocus\": defocus_values.shape[0],\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_refine_template/","title":"core_refine_template","text":"<p>Backend functions related to correlating and refining particle stacks.</p>"},{"location":"autoapi/leopard_em/backend/core_refine_template/#leopard_em.backend.core_refine_template.combine_euler_angles","title":"<code>combine_euler_angles(angle_a, angle_b)</code>","text":"<p>Helper function for composing rotations defined by two sets of Euler angles.</p> Source code in <code>src/leopard_em/backend/core_refine_template.py</code> <pre><code>def combine_euler_angles(angle_a: torch.Tensor, angle_b: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Helper function for composing rotations defined by two sets of Euler angles.\"\"\"\n    rotmat_a = roma.euler_to_rotmat(\n        EULER_ANGLE_FMT, angle_a, degrees=True, device=angle_a.device\n    )\n    rotmat_b = roma.euler_to_rotmat(\n        EULER_ANGLE_FMT, angle_b, degrees=True, device=angle_b.device\n    )\n    rotmat_c = roma.rotmat_composition((rotmat_a, rotmat_b))\n    euler_angles_c = roma.rotmat_to_euler(EULER_ANGLE_FMT, rotmat_c, degrees=True)\n\n    return euler_angles_c\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_refine_template/#leopard_em.backend.core_refine_template.construct_multi_gpu_refine_template_kwargs","title":"<code>construct_multi_gpu_refine_template_kwargs(particle_stack_dft, template_dft, euler_angles, euler_angle_offsets, defocus_u, defocus_v, defocus_angle, defocus_offsets, pixel_size_offsets, corr_mean, corr_std, ctf_kwargs, projective_filters, batch_size, devices, num_cuda_streams)</code>","text":"<p>Split particle stack between requested devices.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack_dft</code> <code>Tensor</code> <p>Particle stack to split.</p> required <code>template_dft</code> <code>Tensor</code> <p>Template volume.</p> required <code>euler_angles</code> <code>Tensor</code> <p>Euler angles for each particle.</p> required <code>euler_angle_offsets</code> <code>Tensor</code> <p>Euler angle offsets to search over.</p> required <code>defocus_u</code> <code>Tensor</code> <p>Defocus U values for each particle.</p> required <code>defocus_v</code> <code>Tensor</code> <p>Defocus V values for each particle.</p> required <code>defocus_angle</code> <code>Tensor</code> <p>Defocus angle values for each particle.</p> required <code>defocus_offsets</code> <code>Tensor</code> <p>Defocus offsets to search over.</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>Pixel size offsets to search over.</p> required <code>corr_mean</code> <code>Tensor</code> <p>Mean of the cross-correlation</p> required <code>corr_std</code> <code>Tensor</code> <p>Standard deviation of the cross-correlation</p> required <code>ctf_kwargs</code> <code>dict</code> <p>CTF calculation parameters.</p> required <code>projective_filters</code> <code>Tensor</code> <p>Projective filters for each particle.</p> required <code>batch_size</code> <code>int</code> <p>Batch size for orientation processing.</p> required <code>devices</code> <code>list[device]</code> <p>List of devices to split across.</p> required <code>num_cuda_streams</code> <code>int</code> <p>Number of CUDA streams to use per device.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>List of dictionaries containing the kwargs to call the single-GPU function.</p> Source code in <code>src/leopard_em/backend/core_refine_template.py</code> <pre><code>def construct_multi_gpu_refine_template_kwargs(\n    particle_stack_dft: torch.Tensor,\n    template_dft: torch.Tensor,\n    euler_angles: torch.Tensor,\n    euler_angle_offsets: torch.Tensor,\n    defocus_u: torch.Tensor,\n    defocus_v: torch.Tensor,\n    defocus_angle: torch.Tensor,\n    defocus_offsets: torch.Tensor,\n    pixel_size_offsets: torch.Tensor,\n    corr_mean: torch.Tensor,\n    corr_std: torch.Tensor,\n    ctf_kwargs: dict,\n    projective_filters: torch.Tensor,\n    batch_size: int,\n    devices: list[torch.device],\n    num_cuda_streams: int,\n) -&gt; list[dict]:\n    \"\"\"Split particle stack between requested devices.\n\n    Parameters\n    ----------\n    particle_stack_dft : torch.Tensor\n        Particle stack to split.\n    template_dft : torch.Tensor\n        Template volume.\n    euler_angles : torch.Tensor\n        Euler angles for each particle.\n    euler_angle_offsets : torch.Tensor\n        Euler angle offsets to search over.\n    defocus_u : torch.Tensor\n        Defocus U values for each particle.\n    defocus_v : torch.Tensor\n        Defocus V values for each particle.\n    defocus_angle : torch.Tensor\n        Defocus angle values for each particle.\n    defocus_offsets : torch.Tensor\n        Defocus offsets to search over.\n    pixel_size_offsets : torch.Tensor\n        Pixel size offsets to search over.\n    corr_mean : torch.Tensor\n        Mean of the cross-correlation\n    corr_std : torch.Tensor\n        Standard deviation of the cross-correlation\n    ctf_kwargs : dict\n        CTF calculation parameters.\n    projective_filters : torch.Tensor\n        Projective filters for each particle.\n    batch_size : int\n        Batch size for orientation processing.\n    devices : list[torch.device]\n        List of devices to split across.\n    num_cuda_streams : int\n        Number of CUDA streams to use per device.\n\n    Returns\n    -------\n    list[dict]\n        List of dictionaries containing the kwargs to call the single-GPU function.\n    \"\"\"\n    num_devices = len(devices)\n    kwargs_per_device = []\n    num_particles = particle_stack_dft.shape[0]\n\n    # Calculate how many particles to assign to each device\n    particles_per_device = [num_particles // num_devices] * num_devices\n    # Distribute remaining particles\n    for i in range(num_particles % num_devices):\n        particles_per_device[i] += 1\n\n    # Split the particle stack across devices\n    start_idx = 0\n    for device_idx, num_device_particles in enumerate(particles_per_device):\n        if num_device_particles == 0:\n            continue\n\n        end_idx = start_idx + num_device_particles\n        device = devices[device_idx]\n\n        # Get particle indices for this device\n        particle_indices = torch.arange(start_idx, end_idx)\n\n        # Split tensors for this device. All these tensors are per-particle, that is\n        # the i-th element in each tensor corresponds to the i-th particle in the stack.\n        device_particle_stack_dft = particle_stack_dft[start_idx:end_idx]\n        device_euler_angles = euler_angles[start_idx:end_idx]\n        device_defocus_u = defocus_u[start_idx:end_idx]\n        device_defocus_v = defocus_v[start_idx:end_idx]\n        device_defocus_angle = defocus_angle[start_idx:end_idx]\n        device_projective_filters = projective_filters[start_idx:end_idx]\n\n        kwargs = {\n            \"particle_stack_dft\": device_particle_stack_dft,\n            \"particle_indices\": particle_indices,\n            \"template_dft\": template_dft,\n            \"euler_angles\": device_euler_angles,\n            \"euler_angle_offsets\": euler_angle_offsets,\n            \"defocus_u\": device_defocus_u,\n            \"defocus_v\": device_defocus_v,\n            \"defocus_angle\": device_defocus_angle,\n            \"defocus_offsets\": defocus_offsets,\n            \"pixel_size_offsets\": pixel_size_offsets,\n            \"corr_mean\": corr_mean,\n            \"corr_std\": corr_std,\n            \"projective_filters\": device_projective_filters,\n            \"ctf_kwargs\": ctf_kwargs,\n            \"batch_size\": batch_size,\n            \"num_cuda_streams\": num_cuda_streams,\n            \"device\": device,\n        }\n\n        kwargs_per_device.append(kwargs)\n        start_idx = end_idx\n\n    return kwargs_per_device\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_refine_template/#leopard_em.backend.core_refine_template.core_refine_template","title":"<code>core_refine_template(particle_stack_dft, template_dft, euler_angles, euler_angle_offsets, defocus_offsets, defocus_u, defocus_v, defocus_angle, pixel_size_offsets, corr_mean, corr_std, ctf_kwargs, projective_filters, device, batch_size=32, num_cuda_streams=1)</code>","text":"<p>Core function to refine orientations and defoci of a set of particles.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack_dft</code> <code>Tensor</code> <p>The stack of particle real-Fourier transformed and un-fftshifted images. Shape of (N, H, W).</p> required <code>template_dft</code> <code>Tensor</code> <p>The template volume to extract central slices from. Real-Fourier transformed and fftshifted.</p> required <code>euler_angles</code> <code>Tensor</code> <p>The Euler angles for each particle in the stack. Shape of (N, 3).</p> required <code>euler_angle_offsets</code> <code>Tensor</code> <p>The Euler angle offsets to apply to each particle. Shape of (k, 3).</p> required <code>defocus_u</code> <code>Tensor</code> <p>The defocus along the major axis for each particle in the stack. Shape of (N,).</p> required <code>defocus_v</code> <code>Tensor</code> <p>The defocus along the minor for each particle in the stack. Shape of (N,).</p> required <code>defocus_angle</code> <code>Tensor</code> <p>The defocus astigmatism angle for each particle in the stack. Shape of (N,). Is the same as the defocus for the micrograph the particle came from.</p> required <code>defocus_offsets</code> <code>Tensor</code> <p>The defocus offsets to search over for each particle. Shape of (l,).</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>The pixel size offsets to search over for each particle. Shape of (m,).</p> required <code>corr_mean</code> <code>Tensor</code> <p>The mean of the cross-correlation values from the full orientation search for the pixels around the center of the particle. Shape of (H - h + 1, W - w + 1).</p> required <code>corr_std</code> <code>Tensor</code> <p>The standard deviation of the cross-correlation values from the full orientation search for the pixels around the center of the particle. Shape of (H - h + 1, W - w + 1).</p> required <code>ctf_kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the CTF calculation function.</p> required <code>projective_filters</code> <code>Tensor</code> <p>Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).</p> required <code>device</code> <code>device | list[device]</code> <p>Device or list of devices to use for processing.</p> required <code>batch_size</code> <code>int</code> <p>The number of cross-correlations to process in one batch, defaults to 32.</p> <code>32</code> <code>num_cuda_streams</code> <code>int</code> <p>Number of CUDA streams to use for parallel processing. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>dict[str, Tensor]</code> <p>Dictionary containing the refined parameters for all particles.</p> Source code in <code>src/leopard_em/backend/core_refine_template.py</code> <pre><code>def core_refine_template(\n    particle_stack_dft: torch.Tensor,  # (N, H, W)\n    template_dft: torch.Tensor,  # (d, h, w)\n    euler_angles: torch.Tensor,  # (N, 3)\n    euler_angle_offsets: torch.Tensor,  # (k, 3)\n    defocus_offsets: torch.Tensor,  # (l,)\n    defocus_u: torch.Tensor,  # (N,)\n    defocus_v: torch.Tensor,  # (N,)\n    defocus_angle: torch.Tensor,  # (N,)\n    pixel_size_offsets: torch.Tensor,  # (m,)\n    corr_mean: torch.Tensor,  # (N, H - h + 1, W - w + 1)\n    corr_std: torch.Tensor,  # (N, H - h + 1, W - w + 1)\n    ctf_kwargs: dict,\n    projective_filters: torch.Tensor,  # (N, h, w)\n    device: torch.device | list[torch.device],\n    batch_size: int = 32,\n    num_cuda_streams: int = 1,\n) -&gt; dict[str, torch.Tensor]:\n    \"\"\"Core function to refine orientations and defoci of a set of particles.\n\n    Parameters\n    ----------\n    particle_stack_dft : torch.Tensor\n        The stack of particle real-Fourier transformed and un-fftshifted images.\n        Shape of (N, H, W).\n    template_dft : torch.Tensor\n        The template volume to extract central slices from. Real-Fourier transformed\n        and fftshifted.\n    euler_angles : torch.Tensor\n        The Euler angles for each particle in the stack. Shape of (N, 3).\n    euler_angle_offsets : torch.Tensor\n        The Euler angle offsets to apply to each particle. Shape of (k, 3).\n    defocus_u : torch.Tensor\n        The defocus along the major axis for each particle in the stack. Shape of (N,).\n    defocus_v : torch.Tensor\n        The defocus along the minor for each particle in the stack. Shape of (N,).\n    defocus_angle : torch.Tensor\n        The defocus astigmatism angle for each particle in the stack. Shape of (N,).\n        Is the same as the defocus for the micrograph the particle came from.\n    defocus_offsets : torch.Tensor\n        The defocus offsets to search over for each particle. Shape of (l,).\n    pixel_size_offsets : torch.Tensor\n        The pixel size offsets to search over for each particle. Shape of (m,).\n    corr_mean : torch.Tensor\n        The mean of the cross-correlation values from the full orientation search\n        for the pixels around the center of the particle.\n        Shape of (H - h + 1, W - w + 1).\n    corr_std : torch.Tensor\n        The standard deviation of the cross-correlation values from the full\n        orientation search for the pixels around the center of the particle.\n        Shape of (H - h + 1, W - w + 1).\n    ctf_kwargs : dict\n        Keyword arguments to pass to the CTF calculation function.\n    projective_filters : torch.Tensor\n        Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).\n    device : torch.device | list[torch.device]\n        Device or list of devices to use for processing.\n    batch_size : int, optional\n        The number of cross-correlations to process in one batch, defaults to 32.\n    num_cuda_streams : int, optional\n        Number of CUDA streams to use for parallel processing. Defaults to 1.\n\n    Returns\n    -------\n    dict[str, torch.Tensor]\n        Dictionary containing the refined parameters for all particles.\n    \"\"\"\n    # Convert single device to list for consistent handling\n    if isinstance(device, torch.device):\n        device = [device]\n\n    ###########################################\n    ### Split particle stack across devices ###\n    ###########################################\n\n    kwargs_per_device = construct_multi_gpu_refine_template_kwargs(\n        particle_stack_dft=particle_stack_dft,\n        template_dft=template_dft,\n        euler_angles=euler_angles,\n        euler_angle_offsets=euler_angle_offsets,\n        defocus_u=defocus_u,\n        defocus_v=defocus_v,\n        defocus_angle=defocus_angle,\n        defocus_offsets=defocus_offsets,\n        pixel_size_offsets=pixel_size_offsets,\n        corr_mean=corr_mean,\n        corr_std=corr_std,\n        ctf_kwargs=ctf_kwargs,\n        projective_filters=projective_filters,\n        batch_size=batch_size,\n        devices=device,\n        num_cuda_streams=num_cuda_streams,\n    )\n\n    results = run_multiprocess_jobs(\n        target=_core_refine_template_single_gpu,\n        kwargs_list=kwargs_per_device,\n    )\n\n    # Synchronize all devices to ensure all computations are complete\n    for dev in device:\n        if dev.type == \"cuda\":\n            torch.cuda.synchronize(dev)\n\n    # Shape information for offset calculations\n    _, img_h, img_w = particle_stack_dft.shape\n    _, template_h, template_w = template_dft.shape\n    # account for RFFT\n    img_w = 2 * (img_w - 1)\n    template_w = 2 * (template_w - 1)\n\n    # Concatenate results from all devices\n    refined_cross_correlation = torch.cat(\n        [torch.from_numpy(r[\"refined_cross_correlation\"]) for r in results.values()]\n    )\n    refined_z_score = torch.cat(\n        [torch.from_numpy(r[\"refined_z_score\"]) for r in results.values()]\n    )\n    refined_euler_angles = torch.cat(\n        [torch.from_numpy(r[\"refined_euler_angles\"]) for r in results.values()]\n    )\n    refined_defocus_offset = torch.cat(\n        [torch.from_numpy(r[\"refined_defocus_offset\"]) for r in results.values()]\n    )\n    refined_pixel_size_offset = torch.cat(\n        [torch.from_numpy(r[\"refined_pixel_size_offset\"]) for r in results.values()]\n    )\n    refined_pos_y = torch.cat(\n        [torch.from_numpy(r[\"refined_pos_y\"]) for r in results.values()]\n    )\n    refined_pos_x = torch.cat(\n        [torch.from_numpy(r[\"refined_pos_x\"]) for r in results.values()]\n    )\n\n    # Ensure the results are sorted back to the original particle order\n    # (If particles were split across devices, we need to reorder the results)\n    particle_indices = torch.cat(\n        [torch.from_numpy(r[\"particle_indices\"]) for r in results.values()]\n    )\n    angle_idx = torch.cat([torch.from_numpy(r[\"angle_idx\"]) for r in results.values()])\n    sort_indices = torch.argsort(particle_indices)\n\n    refined_cross_correlation = refined_cross_correlation[sort_indices]\n    refined_z_score = refined_z_score[sort_indices]\n    refined_euler_angles = refined_euler_angles[sort_indices]\n    refined_defocus_offset = refined_defocus_offset[sort_indices]\n    refined_pixel_size_offset = refined_pixel_size_offset[sort_indices]\n    refined_pos_y = refined_pos_y[sort_indices]\n    refined_pos_x = refined_pos_x[sort_indices]\n    angle_idx = angle_idx[sort_indices]\n\n    # Offset refined_pos_{x,y} by the extracted box size (same as original)\n    refined_pos_y -= (img_h - template_h + 1) // 2\n    refined_pos_x -= (img_w - template_w + 1) // 2\n\n    return {\n        \"refined_cross_correlation\": refined_cross_correlation,\n        \"refined_z_score\": refined_z_score,\n        \"refined_euler_angles\": refined_euler_angles,\n        \"refined_defocus_offset\": refined_defocus_offset,\n        \"refined_pixel_size_offset\": refined_pixel_size_offset,\n        \"refined_pos_y\": refined_pos_y,\n        \"refined_pos_x\": refined_pos_x,\n        \"angle_idx\": angle_idx,\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/backend/core_refine_template/#leopard_em.backend.core_refine_template.cross_correlate_particle_stack","title":"<code>cross_correlate_particle_stack(particle_stack_dft, template_dft, rotation_matrices, projective_filters, mode='valid', batch_size=1024)</code>","text":"<p>Cross-correlate a stack of particle images against a template.</p> <p>Here, the argument 'particle_stack_dft' is a set of RFFT-ed particle images with necessary filtering already applied. The zeroth dimension corresponds to unique particles.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack_dft</code> <code>Tensor</code> <p>The stack of particle real-Fourier transformed and un-fftshifted images. Shape of (N, H, W).</p> required <code>template_dft</code> <code>Tensor</code> <p>The template volume to extract central slices from. Real-Fourier transformed and fftshifted.</p> required <code>rotation_matrices</code> <code>Tensor</code> <p>The orientations of the particles to take the Fourier slices of, as a long list of rotation matrices. Shape of (N, 3, 3).</p> required <code>projective_filters</code> <code>Tensor</code> <p>Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).</p> required <code>mode</code> <code>Literal['valid', 'same']</code> <p>Correlation mode to use, by default \"valid\". If \"valid\", the output will be the valid cross-correlation of the inputs. If \"same\", the output will be the same shape as the input particle stack.</p> <code>'valid'</code> <code>batch_size</code> <code>int</code> <p>The number of particle images to cross-correlate at once. Default is 1024. Larger sizes will consume more memory. If -1, then the entire stack will be cross-correlated at once.</p> <code>1024</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The cross-correlation of the particle stack with the template. Shape will depend on the mode used. If \"valid\", the output will be (N, H-h+1, W-w+1). If \"same\", the output will be (N, H, W).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the mode is not \"valid\" or \"same\".</p> Source code in <code>src/leopard_em/backend/core_refine_template.py</code> <pre><code>def cross_correlate_particle_stack(\n    particle_stack_dft: torch.Tensor,  # (N, H, W)\n    template_dft: torch.Tensor,  # (d, h, w)\n    rotation_matrices: torch.Tensor,  # (N, 3, 3)\n    projective_filters: torch.Tensor,  # (N, h, w)\n    mode: Literal[\"valid\", \"same\"] = \"valid\",\n    batch_size: int = 1024,\n) -&gt; torch.Tensor:\n    \"\"\"Cross-correlate a stack of particle images against a template.\n\n    Here, the argument 'particle_stack_dft' is a set of RFFT-ed particle images with\n    necessary filtering already applied. The zeroth dimension corresponds to unique\n    particles.\n\n    Parameters\n    ----------\n    particle_stack_dft : torch.Tensor\n        The stack of particle real-Fourier transformed and un-fftshifted images.\n        Shape of (N, H, W).\n    template_dft : torch.Tensor\n        The template volume to extract central slices from. Real-Fourier transformed\n        and fftshifted.\n    rotation_matrices : torch.Tensor\n        The orientations of the particles to take the Fourier slices of, as a long\n        list of rotation matrices. Shape of (N, 3, 3).\n    projective_filters : torch.Tensor\n        Projective filters to apply to each Fourier slice particle. Shape of (N, h, w).\n    mode : Literal[\"valid\", \"same\"], optional\n        Correlation mode to use, by default \"valid\". If \"valid\", the output will be\n        the valid cross-correlation of the inputs. If \"same\", the output will be the\n        same shape as the input particle stack.\n    batch_size : int, optional\n        The number of particle images to cross-correlate at once. Default is 1024.\n        Larger sizes will consume more memory. If -1, then the entire stack will be\n        cross-correlated at once.\n\n    Returns\n    -------\n    torch.Tensor\n        The cross-correlation of the particle stack with the template. Shape will depend\n        on the mode used. If \"valid\", the output will be (N, H-h+1, W-w+1). If \"same\",\n        the output will be (N, H, W).\n\n    Raises\n    ------\n    ValueError\n        If the mode is not \"valid\" or \"same\".\n    \"\"\"\n    # Helpful constants for later use\n    device = particle_stack_dft.device\n    num_particles, image_h, image_w = particle_stack_dft.shape\n    _, template_h, template_w = template_dft.shape\n    # account for RFFT\n    image_w = 2 * (image_w - 1)\n    template_w = 2 * (template_w - 1)\n\n    if batch_size == -1:\n        batch_size = num_particles\n\n    if mode == \"valid\":\n        output_shape = (\n            num_particles,\n            image_h - template_h + 1,\n            image_w - template_w + 1,\n        )\n    elif mode == \"same\":\n        output_shape = (num_particles, image_h, image_w)\n    else:\n        raise ValueError(f\"Invalid mode: {mode}. Must be 'valid' or 'same'.\")\n\n    out_correlation = torch.zeros(output_shape, device=device)\n\n    # Loop over the particle stack in batches\n    for i in range(0, num_particles, batch_size):\n        batch_particles_dft = particle_stack_dft[i : i + batch_size]\n        batch_rotation_matrices = rotation_matrices[i : i + batch_size]\n        batch_projective_filters = projective_filters[i : i + batch_size]\n\n        # Extract the Fourier slice and apply the projective filters\n        fourier_slice = extract_central_slices_rfft_3d(\n            volume_rfft=template_dft,\n            image_shape=(template_h,) * 3,\n            rotation_matrices=batch_rotation_matrices,\n        )\n        fourier_slice = torch.fft.ifftshift(fourier_slice, dim=(-2,))\n        fourier_slice[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n        fourier_slice *= -1  # flip contrast\n        fourier_slice *= batch_projective_filters\n\n        # Inverse Fourier transform and normalize the projection\n        projections = torch.fft.irfftn(fourier_slice, dim=(-2, -1))\n        projections = torch.fft.ifftshift(projections, dim=(-2, -1))\n        projections = normalize_template_projection(\n            projections, (template_h, template_w), (image_h, image_w)\n        )\n\n        # Padded forward FFT and cross-correlate\n        projections_dft = torch.fft.rfftn(\n            projections, dim=(-2, -1), s=(image_h, image_w)\n        )\n        projections_dft = batch_particles_dft * projections_dft.conj()\n        cross_correlation = torch.fft.irfftn(projections_dft, dim=(-2, -1))\n\n        # Handle the output shape\n        cross_correlation = handle_correlation_mode(\n            cross_correlation, output_shape, mode\n        )\n\n        out_correlation[i : i + batch_size] = cross_correlation\n\n    return out_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/backend/cross_correlation/","title":"cross_correlation","text":"<p>File containing Fourier-slice based cross-correlation functions for 2DTM.</p>"},{"location":"autoapi/leopard_em/backend/cross_correlation/#leopard_em.backend.cross_correlation.do_batched_orientation_cross_correlate","title":"<code>do_batched_orientation_cross_correlate(image_dft, template_dft, rotation_matrices, projective_filters)</code>","text":"<p>Batched projection and cross-correlation with fixed (batched) filters.</p> <p>NOTE: This function is similar to <code>do_streamed_orientation_cross_correlate</code> but it computes cross-correlation batches over the orientation space. For example, if there are 32 orientations to process and 10 different defocus values, then there would be a total of 10 batched-32 cross-correlations computed.</p> <p>NOTE: that this function returns a cross-correlogram with \"same\" mode (i.e. the same size as the input image). See numpy correlate docs for more information.</p> <p>Parameters:</p> Name Type Description Default <code>image_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the image with large image filters already applied. Has shape (H, W // 2 + 1).</p> required <code>template_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the template volume to take Fourier slices from. Has shape (l, h, w // 2 + 1) where (l, h, w) is the original real-space shape of the template volume.</p> required <code>rotation_matrices</code> <code>Tensor</code> <p>Rotation matrices to apply to the template volume. Has shape (num_orientations, 3, 3).</p> required <code>projective_filters</code> <code>Tensor</code> <p>Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape (num_Cs, num_defocus, h, w // 2 + 1). Is RFFT and not fftshifted.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Cross-correlation of the image with the template volume for each orientation and defocus value. Will have shape (num_Cs, num_defocus, num_orientations, H, W).</p> Source code in <code>src/leopard_em/backend/cross_correlation.py</code> <pre><code>def do_batched_orientation_cross_correlate(\n    image_dft: torch.Tensor,\n    template_dft: torch.Tensor,\n    rotation_matrices: torch.Tensor,\n    projective_filters: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Batched projection and cross-correlation with fixed (batched) filters.\n\n    NOTE: This function is similar to `do_streamed_orientation_cross_correlate` but\n    it computes cross-correlation batches over the orientation space. For example, if\n    there are 32 orientations to process and 10 different defocus values, then there\n    would be a total of 10 batched-32 cross-correlations computed.\n\n    NOTE: that this function returns a cross-correlogram with \"same\" mode (i.e. the\n    same size as the input image). See numpy correlate docs for more information.\n\n    Parameters\n    ----------\n    image_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the image with large image filters\n        already applied. Has shape (H, W // 2 + 1).\n    template_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the template volume to take Fourier\n        slices from. Has shape (l, h, w // 2 + 1) where (l, h, w) is the original\n        real-space shape of the template volume.\n    rotation_matrices : torch.Tensor\n        Rotation matrices to apply to the template volume. Has shape\n        (num_orientations, 3, 3).\n    projective_filters : torch.Tensor\n        Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape\n        (num_Cs, num_defocus, h, w // 2 + 1). Is RFFT and not fftshifted.\n\n    Returns\n    -------\n    torch.Tensor\n        Cross-correlation of the image with the template volume for each\n        orientation and defocus value. Will have shape\n        (num_Cs, num_defocus, num_orientations, H, W).\n    \"\"\"\n    # Accounting for RFFT shape\n    projection_shape_real = (template_dft.shape[1], template_dft.shape[2] * 2 - 2)\n    image_shape_real = (image_dft.shape[0], image_dft.shape[1] * 2 - 2)\n\n    num_Cs = projective_filters.shape[0]  # pylint: disable=invalid-name\n    num_defocus = projective_filters.shape[1]\n\n    cross_correlation = torch.empty(\n        size=(\n            num_Cs,\n            num_defocus,\n            rotation_matrices.shape[0],\n            *image_shape_real,\n        ),\n        dtype=image_dft.real.dtype,  # Deduce the real dtype from complex DFT\n        device=image_dft.device,\n    )\n\n    # Extract central slice(s) from the template volume\n    fourier_slice = extract_central_slices_rfft_3d(\n        volume_rfft=template_dft,\n        image_shape=(projection_shape_real[0],) * 3,  # NOTE: requires cubic template\n        rotation_matrices=rotation_matrices,\n    )\n    fourier_slice = torch.fft.ifftshift(fourier_slice, dim=(-2,))\n    fourier_slice[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n    fourier_slice *= -1  # flip contrast\n\n    # Apply the projective filters on a new batch dimension\n    fourier_slice = fourier_slice[None, None, ...] * projective_filters[:, :, None, ...]\n\n    # Inverse Fourier transform into real space and normalize\n    projections = torch.fft.irfftn(fourier_slice, dim=(-2, -1))\n    projections = torch.fft.ifftshift(projections, dim=(-2, -1))\n    projections = normalize_template_projection_compiled(\n        projections,\n        projection_shape_real,\n        image_shape_real,\n    )\n\n    for j in range(num_defocus):\n        for k in range(num_Cs):\n            projections_dft = torch.fft.rfftn(\n                projections[k, j, ...], dim=(-2, -1), s=image_shape_real\n            )\n            projections_dft[..., 0, 0] = 0 + 0j\n\n            # Cross correlation step by element-wise multiplication\n            projections_dft = image_dft[None, ...] * projections_dft.conj()\n            torch.fft.irfftn(\n                projections_dft, dim=(-2, -1), out=cross_correlation[k, j, ...]\n            )\n\n    return cross_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/backend/cross_correlation/#leopard_em.backend.cross_correlation.do_batched_orientation_cross_correlate_cpu","title":"<code>do_batched_orientation_cross_correlate_cpu(image_dft, template_dft, rotation_matrices, projective_filters)</code>","text":"<p>Same as <code>do_streamed_orientation_cross_correlate</code> but on the CPU.</p> <p>The only difference is that this function does not call into a compiled torch function for normalization.</p> <p>TODO: Figure out a better way to split up CPU/GPU functions while remaining performant and not duplicating code.</p> <p>Parameters:</p> Name Type Description Default <code>image_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the image with large image filters already applied. Has shape (H, W // 2 + 1).</p> required <code>template_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the template volume to take Fourier slices from. Has shape (l, h, w // 2 + 1).</p> required <code>rotation_matrices</code> <code>Tensor</code> <p>Rotation matrices to apply to the template volume. Has shape (orientations, 3, 3).</p> required <code>projective_filters</code> <code>Tensor</code> <p>Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape (defocus_batch, h, w // 2 + 1). Is RFFT and not fftshifted.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Cross-correlation for the batch of orientations and defocus values.s</p> Source code in <code>src/leopard_em/backend/cross_correlation.py</code> <pre><code>def do_batched_orientation_cross_correlate_cpu(\n    image_dft: torch.Tensor,\n    template_dft: torch.Tensor,\n    rotation_matrices: torch.Tensor,\n    projective_filters: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Same as `do_streamed_orientation_cross_correlate` but on the CPU.\n\n    The only difference is that this function does not call into a compiled torch\n    function for normalization.\n\n    TODO: Figure out a better way to split up CPU/GPU functions while remaining\n    performant and not duplicating code.\n\n    Parameters\n    ----------\n    image_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the image with large image filters\n        already applied. Has shape (H, W // 2 + 1).\n    template_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the template volume to take Fourier\n        slices from. Has shape (l, h, w // 2 + 1).\n    rotation_matrices : torch.Tensor\n        Rotation matrices to apply to the template volume. Has shape\n        (orientations, 3, 3).\n    projective_filters : torch.Tensor\n        Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape\n        (defocus_batch, h, w // 2 + 1). Is RFFT and not fftshifted.\n\n    Returns\n    -------\n    torch.Tensor\n        Cross-correlation for the batch of orientations and defocus values.s\n    \"\"\"\n    # Accounting for RFFT shape\n    projection_shape_real = (template_dft.shape[1], template_dft.shape[2] * 2 - 2)\n    image_shape_real = (image_dft.shape[0], image_dft.shape[1] * 2 - 2)\n\n    # Extract central slice(s) from the template volume\n    fourier_slice = extract_central_slices_rfft_3d(\n        volume_rfft=template_dft,\n        image_shape=(projection_shape_real[0],) * 3,  # NOTE: requires cubic template\n        rotation_matrices=rotation_matrices,\n    )\n    fourier_slice = torch.fft.ifftshift(fourier_slice, dim=(-2,))\n    fourier_slice[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n    fourier_slice *= -1  # flip contrast\n\n    # Apply the projective filters on a new batch dimension\n    fourier_slice = fourier_slice[None, None, ...] * projective_filters[:, :, None, ...]\n\n    # Inverse Fourier transform into real space and normalize\n    projections = torch.fft.irfftn(fourier_slice, dim=(-2, -1))\n    projections = torch.fft.ifftshift(projections, dim=(-2, -1))\n    projections = normalize_template_projection(\n        projections,\n        projection_shape_real,\n        image_shape_real,\n    )\n\n    # Padded forward Fourier transform for cross-correlation\n    projections_dft = torch.fft.rfftn(projections, dim=(-2, -1), s=image_shape_real)\n    projections_dft[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n\n    # Cross correlation step by element-wise multiplication\n    projections_dft = image_dft[None, None, None, ...] * projections_dft.conj()\n    cross_correlation = torch.fft.irfftn(projections_dft, dim=(-2, -1))\n\n    return cross_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/backend/cross_correlation/#leopard_em.backend.cross_correlation.do_streamed_orientation_cross_correlate","title":"<code>do_streamed_orientation_cross_correlate(image_dft, template_dft, rotation_matrices, projective_filters, streams)</code>","text":"<p>Calculates a grid of 2D cross-correlations over multiple CUDA streams.</p> <p>NOTE: This function is more performant than a batched 2D cross-correlation with shape (N, H, W) when the kernel (template) is much smaller than the image (e.g. kernel is 512x512 and image is 4096x4096). Each cross-correlation is computed individually and stored in a batched tensor for the grid of orientations, defoci, and pixel size values.</p> <p>NOTE: this function returns a cross-correlogram with \"same\" mode (i.e. the same size as the input image). See numpy correlate docs for more information.</p> <p>Parameters:</p> Name Type Description Default <code>image_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the image with large image filters already applied. Has shape (H, W // 2 + 1).</p> required <code>template_dft</code> <code>Tensor</code> <p>Real-fourier transform (RFFT) of the template volume to take Fourier slices from. Has shape (l, h, w // 2 + 1) where (l, h, w) is the original real-space shape of the template volume.</p> required <code>rotation_matrices</code> <code>Tensor</code> <p>Rotation matrices to apply to the template volume. Has shape (num_orientations, 3, 3).</p> required <code>projective_filters</code> <code>Tensor</code> <p>Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape (num_Cs, num_defocus, h, w // 2 + 1). Is RFFT and not fftshifted.</p> required <code>streams</code> <code>list[Stream]</code> <p>List of CUDA streams to use for parallel computation. Each stream will handle a separate cross-correlation.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Cross-correlation of the image with the template volume for each orientation and defocus value. Will have shape (num_Cs, num_defocus, num_orientations, H, W).</p> Source code in <code>src/leopard_em/backend/cross_correlation.py</code> <pre><code>def do_streamed_orientation_cross_correlate(\n    image_dft: torch.Tensor,\n    template_dft: torch.Tensor,\n    rotation_matrices: torch.Tensor,\n    projective_filters: torch.Tensor,\n    streams: list[torch.cuda.Stream],\n) -&gt; torch.Tensor:\n    \"\"\"Calculates a grid of 2D cross-correlations over multiple CUDA streams.\n\n    NOTE: This function is more performant than a batched 2D cross-correlation with\n    shape (N, H, W) when the kernel (template) is much smaller than the image (e.g.\n    kernel is 512x512 and image is 4096x4096). Each cross-correlation is computed\n    individually and stored in a batched tensor for the grid of orientations, defoci,\n    and pixel size values.\n\n    NOTE: this function returns a cross-correlogram with \"same\" mode (i.e. the\n    same size as the input image). See numpy correlate docs for more information.\n\n    Parameters\n    ----------\n    image_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the image with large image filters\n        already applied. Has shape (H, W // 2 + 1).\n    template_dft : torch.Tensor\n        Real-fourier transform (RFFT) of the template volume to take Fourier\n        slices from. Has shape (l, h, w // 2 + 1) where (l, h, w) is the original\n        real-space shape of the template volume.\n    rotation_matrices : torch.Tensor\n        Rotation matrices to apply to the template volume. Has shape\n        (num_orientations, 3, 3).\n    projective_filters : torch.Tensor\n        Multiplied 'ctf_filters' with 'whitening_filter_template'. Has shape\n        (num_Cs, num_defocus, h, w // 2 + 1). Is RFFT and not fftshifted.\n    streams : list[torch.cuda.Stream]\n        List of CUDA streams to use for parallel computation. Each stream will\n        handle a separate cross-correlation.\n\n    Returns\n    -------\n    torch.Tensor\n        Cross-correlation of the image with the template volume for each\n        orientation and defocus value. Will have shape\n        (num_Cs, num_defocus, num_orientations, H, W).\n    \"\"\"\n    # Accounting for RFFT shape\n    projection_shape_real = (template_dft.shape[1], template_dft.shape[2] * 2 - 2)\n    image_shape_real = (image_dft.shape[0], image_dft.shape[1] * 2 - 2)\n\n    num_orientations = rotation_matrices.shape[0]\n    num_Cs = projective_filters.shape[0]  # pylint: disable=invalid-name\n    num_defocus = projective_filters.shape[1]\n\n    cross_correlation = torch.empty(\n        size=(num_Cs, num_defocus, num_orientations, *image_shape_real),\n        dtype=image_dft.real.dtype,  # Deduce the real dtype from complex DFT\n        device=image_dft.device,\n    )\n\n    # Do a batched Fourier slice extraction for all the orientations at once.\n    fourier_slices = extract_central_slices_rfft_3d(\n        volume_rfft=template_dft,\n        image_shape=(projection_shape_real[0],) * 3,\n        rotation_matrices=rotation_matrices,\n    )\n    fourier_slices = torch.fft.ifftshift(fourier_slices, dim=(-2,))\n    fourier_slices[..., 0, 0] = 0 + 0j  # zero out the DC component (mean zero)\n    fourier_slices *= -1  # flip contrast\n\n    # Barrier to ensure Fourier slice computation on default stream is done before\n    # continuing computation in parallel on non-default streams.\n    default_stream = torch.cuda.default_stream(image_dft.device)\n    for s in streams:\n        s.wait_stream(default_stream)\n\n    # Iterate over the orientations\n    for i in range(num_orientations):\n        fourier_slice = fourier_slices[i]\n\n        # Iterate over the different pixel sizes (Cs) and defocus values for this\n        # particular orientation\n        for j in range(num_defocus):\n            for k in range(num_Cs):\n                # Use a round-robin scheduling for the streams\n                job_idx = (i * num_defocus * num_Cs) + (j * num_Cs) + k\n                stream_idx = job_idx % len(streams)\n                stream = streams[stream_idx]\n\n                with torch.cuda.stream(stream):\n                    # Apply the projective filter and do template normalization\n                    fourier_slice_filtered = fourier_slice * projective_filters[k, j]\n                    projection = torch.fft.irfft2(fourier_slice_filtered)\n                    projection = torch.fft.ifftshift(projection, dim=(-2, -1))\n                    projection = normalize_template_projection_compiled(\n                        projection,\n                        projection_shape_real,\n                        image_shape_real,\n                    )\n\n                    # Padded forward Fourier transform for cross-correlation\n                    projection_dft = torch.fft.rfft2(projection, s=image_shape_real)\n                    projection_dft[0, 0] = 0 + 0j\n\n                    # Cross correlation step by element-wise multiplication\n                    projection_dft = image_dft * projection_dft.conj()\n                    torch.fft.irfft2(\n                        projection_dft,\n                        s=image_shape_real,\n                        out=cross_correlation[k, j, i],\n                    )\n\n    # Record 'fourier_slices' on each stream to ensure it's not deallocated before all\n    # streams are finished processing.\n    for s in streams:\n        fourier_slices.record_stream(s)\n\n    # Wait for all streams to finish\n    for stream in streams:\n        stream.synchronize()\n\n    # shape is (num_Cs, num_defocus, num_orientations, H, W)\n    return cross_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/backend/process_results/","title":"process_results","text":"<p>Functions related to result processing after backend functions.</p>"},{"location":"autoapi/leopard_em/backend/process_results/#leopard_em.backend.process_results.aggregate_distributed_results","title":"<code>aggregate_distributed_results(results)</code>","text":"<p>Combine the 2DTM results from multiple devices.</p> <p>NOTE: This assumes that all tensors have been passed back to the CPU and are in the form of numpy arrays.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>list[dict[str, ndarray]]</code> <p>List of dictionaries containing the results from each device. Each dictionary contains the following keys:     - \"mip\": Maximum intensity projection of the cross-correlation values.     - \"best_phi\": Best phi angle for each pixel.     - \"best_theta\": Best theta angle for each pixel.     - \"best_psi\": Best psi angle for each pixel.     - \"best_defocus\": Best defocus value for each pixel.     - \"best_pixel_size\": Best pixel size value for each pixel.     - \"correlation_sum\": Sum of cross-correlation values for each pixel.     - \"correlation_squared_sum\": Sum of squared cross-correlation values for       each pixel.     - \"total_projections\": Total number of projections calculated.</p> required Source code in <code>src/leopard_em/backend/process_results.py</code> <pre><code>def aggregate_distributed_results(\n    results: list[dict[str, torch.Tensor | np.ndarray]],\n) -&gt; dict[str, torch.Tensor]:\n    \"\"\"Combine the 2DTM results from multiple devices.\n\n    NOTE: This assumes that all tensors have been passed back to the CPU and are in\n    the form of numpy arrays.\n\n    Parameters\n    ----------\n    results : list[dict[str, np.ndarray]]\n        List of dictionaries containing the results from each device. Each dictionary\n        contains the following keys:\n            - \"mip\": Maximum intensity projection of the cross-correlation values.\n            - \"best_phi\": Best phi angle for each pixel.\n            - \"best_theta\": Best theta angle for each pixel.\n            - \"best_psi\": Best psi angle for each pixel.\n            - \"best_defocus\": Best defocus value for each pixel.\n            - \"best_pixel_size\": Best pixel size value for each pixel.\n            - \"correlation_sum\": Sum of cross-correlation values for each pixel.\n            - \"correlation_squared_sum\": Sum of squared cross-correlation values for\n              each pixel.\n            - \"total_projections\": Total number of projections calculated.\n    \"\"\"\n    # Ensure all the tensors are passed back to CPU as numpy arrays\n    # Not sure why cannot sync across devices, but this is a workaround\n    results = [\n        {\n            key: value.cpu().numpy() if isinstance(value, torch.Tensor) else value\n            for key, value in result.items()\n        }\n        for result in results\n    ]\n\n    # Find which device had the highest MIP for each pixel and index stats accordingly.\n    # Results after 'take_along_axis' have extra dimension at idx 0.\n    mips = np.stack([result[\"mip\"] for result in results], axis=0)\n    best_phi = np.stack([result[\"best_phi\"] for result in results], axis=0)\n    best_theta = np.stack([result[\"best_theta\"] for result in results], axis=0)\n    best_psi = np.stack([result[\"best_psi\"] for result in results], axis=0)\n    best_defocus = np.stack([result[\"best_defocus\"] for result in results], axis=0)\n    best_pixel_size = np.stack(\n        [result[\"best_pixel_size\"] for result in results], axis=0\n    )\n    mip_max = mips.max(axis=0)\n    mip_argmax = mips.argmax(axis=0)\n\n    best_phi = np.take_along_axis(best_phi, mip_argmax[None, ...], axis=0)\n    best_theta = np.take_along_axis(best_theta, mip_argmax[None, ...], axis=0)\n    best_psi = np.take_along_axis(best_psi, mip_argmax[None, ...], axis=0)\n    best_defocus = np.take_along_axis(best_defocus, mip_argmax[None, ...], axis=0)\n    best_pixel_size = np.take_along_axis(best_pixel_size, mip_argmax[None, ...], axis=0)\n    best_phi = best_phi[0]\n    best_theta = best_theta[0]\n    best_psi = best_psi[0]\n    best_defocus = best_defocus[0]\n    best_pixel_size = best_pixel_size[0]\n    # Sum the sums and squared sums of the cross-correlation values\n    correlation_sum = np.stack(\n        [result[\"correlation_sum\"] for result in results], axis=0\n    ).sum(axis=0)\n    correlation_squared_sum = np.stack(\n        [result[\"correlation_squared_sum\"] for result in results], axis=0\n    ).sum(axis=0)\n\n    # NOTE: Currently only tracking total number of projections for statistics,\n    # but could be future case where number of projections calculated on each\n    # device is necessary for some statistical computation.\n    total_projections = sum(result[\"total_projections\"] for result in results)\n\n    # Cast back to torch tensors on the CPU\n    mip_max = torch.from_numpy(mip_max)\n    best_phi = torch.from_numpy(best_phi)\n    best_theta = torch.from_numpy(best_theta)\n    best_psi = torch.from_numpy(best_psi)\n    best_defocus = torch.from_numpy(best_defocus)\n    best_pixel_size = torch.from_numpy(best_pixel_size)\n    correlation_sum = torch.from_numpy(correlation_sum)\n    correlation_squared_sum = torch.from_numpy(correlation_squared_sum)\n\n    return {\n        \"mip\": mip_max,\n        \"best_phi\": best_phi,\n        \"best_theta\": best_theta,\n        \"best_psi\": best_psi,\n        \"best_defocus\": best_defocus,\n        \"correlation_sum\": correlation_sum,\n        \"correlation_squared_sum\": correlation_squared_sum,\n        \"total_projections\": total_projections,\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/backend/process_results/#leopard_em.backend.process_results.correlation_sum_and_squared_sum_to_mean_and_variance","title":"<code>correlation_sum_and_squared_sum_to_mean_and_variance(correlation_sum, correlation_squared_sum, total_correlation_positions)</code>","text":"<p>Convert the sum and squared sum of the correlation values to mean and variance.</p> <p>Parameters:</p> Name Type Description Default <code>correlation_sum</code> <code>Tensor</code> <p>Sum of the correlation values.</p> required <code>correlation_squared_sum</code> <code>Tensor</code> <p>Sum of the squared correlation values.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number cross-correlograms calculated.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple containing the mean and variance of the correlation values.</p> Source code in <code>src/leopard_em/backend/process_results.py</code> <pre><code>def correlation_sum_and_squared_sum_to_mean_and_variance(\n    correlation_sum: torch.Tensor,\n    correlation_squared_sum: torch.Tensor,\n    total_correlation_positions: int,\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Convert the sum and squared sum of the correlation values to mean and variance.\n\n    Parameters\n    ----------\n    correlation_sum : torch.Tensor\n        Sum of the correlation values.\n    correlation_squared_sum : torch.Tensor\n        Sum of the squared correlation values.\n    total_correlation_positions : int\n        Total number cross-correlograms calculated.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        Tuple containing the mean and variance of the correlation values.\n    \"\"\"\n    correlation_mean = correlation_sum / total_correlation_positions\n    correlation_variance = correlation_squared_sum / total_correlation_positions\n    correlation_variance -= correlation_mean**2\n    correlation_variance = torch.sqrt(torch.clamp(correlation_variance, min=0))\n    return correlation_mean, correlation_variance\n</code></pre>"},{"location":"autoapi/leopard_em/backend/process_results/#leopard_em.backend.process_results.scale_mip","title":"<code>scale_mip(mip, mip_scaled, correlation_sum, correlation_squared_sum, total_correlation_positions)</code>","text":"<p>Scale the MIP to Z-score map by the mean and variance of the correlation values.</p> <p>Z-score is accounting for the variation in image intensity and spurious correlations by subtracting the mean and dividing by the standard deviation pixel-wise. Since cross-correlation values are roughly normally distributed for pure noise, Z-score effectively becomes a measure of how unexpected (highly correlated to the reference template) a region is in the image. Note that we are looking at maxima of millions of Gaussian distributions, so Z-score has to be compared with a generalized extreme value distribution (GEV) to determine significance (done elsewhere).</p> <p>NOTE: This method also updates the correlation_sum and correlation_squared_sum tensors in-place into the mean and variance, respectively. Likely should reflect conversions in variable names...</p> <p>Parameters:</p> Name Type Description Default <code>mip</code> <code>Tensor</code> <p>MIP of the correlation values.</p> required <code>mip_scaled</code> <code>Tensor</code> <p>Scaled MIP of the correlation values.</p> required <code>correlation_sum</code> <code>Tensor</code> <p>Sum of the correlation values. Updated to mean of the correlation values.</p> required <code>correlation_squared_sum</code> <code>Tensor</code> <p>Sum of the squared correlation values. Updated to variance of the correlation.</p> required <code>total_correlation_positions</code> <code>int</code> <p>Total number cross-correlograms calculated.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple containing, in order, the MIP, scaled MIP, correlation mean, and correlation variance.</p> Source code in <code>src/leopard_em/backend/process_results.py</code> <pre><code>def scale_mip(\n    mip: torch.Tensor,\n    mip_scaled: torch.Tensor,\n    correlation_sum: torch.Tensor,\n    correlation_squared_sum: torch.Tensor,\n    total_correlation_positions: int,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Scale the MIP to Z-score map by the mean and variance of the correlation values.\n\n    Z-score is accounting for the variation in image intensity and spurious correlations\n    by subtracting the mean and dividing by the standard deviation pixel-wise. Since\n    cross-correlation values are roughly normally distributed for pure noise, Z-score\n    effectively becomes a measure of how unexpected (highly correlated to the reference\n    template) a region is in the image. Note that we are looking at maxima of millions\n    of Gaussian distributions, so Z-score has to be compared with a generalized extreme\n    value distribution (GEV) to determine significance (done elsewhere).\n\n    NOTE: This method also updates the correlation_sum and correlation_squared_sum\n    tensors in-place into the mean and variance, respectively. Likely should reflect\n    conversions in variable names...\n\n    Parameters\n    ----------\n    mip : torch.Tensor\n        MIP of the correlation values.\n    mip_scaled : torch.Tensor\n        Scaled MIP of the correlation values.\n    correlation_sum : torch.Tensor\n        Sum of the correlation values. Updated to mean of the correlation values.\n    correlation_squared_sum : torch.Tensor\n        Sum of the squared correlation values. Updated to variance of the correlation.\n    total_correlation_positions : int\n        Total number cross-correlograms calculated.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        Tuple containing, in order, the MIP, scaled MIP, correlation mean, and\n        correlation variance.\n    \"\"\"\n    corr_mean, corr_variance = correlation_sum_and_squared_sum_to_mean_and_variance(\n        correlation_sum, correlation_squared_sum, total_correlation_positions\n    )\n\n    # Calculate normalized MIP\n    mip_scaled = mip - corr_mean\n    torch.where(\n        corr_variance != 0,  # preventing zero division error, albeit unlikely\n        mip_scaled / corr_variance,\n        torch.zeros_like(mip_scaled),\n        out=mip_scaled,\n    )\n\n    # # Update correlation_sum and correlation_squared_sum to mean and variance\n    # correlation_sum.copy_(corr_mean)\n    # correlation_squared_sum.copy_(corr_variance)\n\n    return mip, mip_scaled, corr_mean, corr_variance\n</code></pre>"},{"location":"autoapi/leopard_em/backend/utils/","title":"utils","text":"<p>Utility and helper functions associated with the backend of Leopard-EM.</p>"},{"location":"autoapi/leopard_em/backend/utils/#leopard_em.backend.utils.attempt_torch_compilation","title":"<code>attempt_torch_compilation(target_func, backend='inductor')</code>","text":"<p>Compile a function using Torch's compilation utilities.</p> <p>NOTE: This function will fall back onto the original function if compilation fails or is not supported. Under these circumstances, a warning is issued to inform the user of the failure, but the program will continue to run with the original function.</p> <p>Parameters:</p> Name Type Description Default <code>target_func</code> <code>Callable</code> <p>The function to compile.</p> required <code>backend</code> <code>str</code> <p>The backend to use for compilation (default is \"inductor\").</p> <code>'inductor'</code> <p>Returns:</p> Type Description <code>Callable</code> <p>The potentially compiled function.</p> Warning <p>If compilation fails, the original function is returned without modification which is useful for program consistency. If compilation is not supported, then a warning is generated, and the original function is returned.</p> Source code in <code>src/leopard_em/backend/utils.py</code> <pre><code>def attempt_torch_compilation(target_func: F, backend: str = \"inductor\") -&gt; F:\n    \"\"\"Compile a function using Torch's compilation utilities.\n\n    NOTE: This function will fall back onto the original function if compilation fails\n    or is not supported. Under these circumstances, a warning is issued to inform the\n    user of the failure, but the program will continue to run with the original\n    function.\n\n    Parameters\n    ----------\n    target_func : Callable\n        The function to compile.\n    backend : str, optional\n        The backend to use for compilation (default is \"inductor\").\n\n    Returns\n    -------\n    Callable\n        The potentially compiled function.\n\n    Warning\n    -------\n    If compilation fails, the original function is returned without modification which\n    is useful for program consistency. If compilation is not supported, then a\n    warning is generated, and the original function is returned.\n    \"\"\"\n    try:\n        compiled_func = torch.compile(target_func, backend=backend)\n        return compiled_func  # type: ignore[no-any-return]\n    except (RuntimeError, NotImplementedError) as e:\n        warnings.warn(\n            f\"Failed to compile function {target_func.__name__} with\"\n            f\"backend {backend}: {e}. \"\n            \"Returning the original function instead and continuing...\",\n            UserWarning,\n            stacklevel=2,\n        )\n        return target_func\n</code></pre>"},{"location":"autoapi/leopard_em/backend/utils/#leopard_em.backend.utils.do_iteration_statistics_updates","title":"<code>do_iteration_statistics_updates(cross_correlation, euler_angles, defocus_values, pixel_values, mip, best_phi, best_theta, best_psi, best_defocus, best_pixel_size, correlation_sum, correlation_squared_sum, img_h, img_w)</code>","text":"<p>Helper function for updating maxima and tracked statistics.</p> <p>NOTE: The batch dimensions are effectively unraveled since taking the maximum over a single batch dimensions is much faster than multi-dimensional maxima.</p> <p>NOTE: Updating the maxima was found to be fastest and least memory impactful when using torch.where directly. Other methods tested were boolean masking and torch.where with tuples of tensor indexes.</p> <p>Parameters:</p> Name Type Description Default <code>cross_correlation</code> <code>Tensor</code> <p>Cross-correlation values for the current iteration. Has either shape (batch, H, W) or (defocus, orientations, H, W).</p> required <code>euler_angles</code> <code>Tensor</code> <p>Euler angles for the current iteration. Has shape (orientations, 3).</p> required <code>defocus_values</code> <code>Tensor</code> <p>Defocus values for the current iteration. Has shape (defocus,).</p> required <code>pixel_values</code> <code>Tensor</code> <p>Pixel size values for the current iteration. Has shape (pixel_size_batch,).</p> required <code>mip</code> <code>Tensor</code> <p>Maximum intensity projection of the cross-correlation values.</p> required <code>best_phi</code> <code>Tensor</code> <p>Best phi angle for each pixel.</p> required <code>best_theta</code> <code>Tensor</code> <p>Best theta angle for each pixel.</p> required <code>best_psi</code> <code>Tensor</code> <p>Best psi angle for each pixel.</p> required <code>best_defocus</code> <code>Tensor</code> <p>Best defocus value for each pixel.</p> required <code>best_pixel_size</code> <code>Tensor</code> <p>Best pixel size value for each pixel.</p> required <code>correlation_sum</code> <code>Tensor</code> <p>Sum of cross-correlation values for each pixel.</p> required <code>correlation_squared_sum</code> <code>Tensor</code> <p>Sum of squared cross-correlation values for each pixel.</p> required <code>img_h</code> <code>int</code> <p>Height of the cross-correlation values.</p> required <code>img_w</code> <code>int</code> <p>Width of the cross-correlation values.</p> required Source code in <code>src/leopard_em/backend/utils.py</code> <pre><code>def do_iteration_statistics_updates(\n    cross_correlation: torch.Tensor,\n    euler_angles: torch.Tensor,\n    defocus_values: torch.Tensor,\n    pixel_values: torch.Tensor,\n    mip: torch.Tensor,\n    best_phi: torch.Tensor,\n    best_theta: torch.Tensor,\n    best_psi: torch.Tensor,\n    best_defocus: torch.Tensor,\n    best_pixel_size: torch.Tensor,\n    correlation_sum: torch.Tensor,\n    correlation_squared_sum: torch.Tensor,\n    img_h: int,\n    img_w: int,\n) -&gt; None:\n    \"\"\"Helper function for updating maxima and tracked statistics.\n\n    NOTE: The batch dimensions are effectively unraveled since taking the\n    maximum over a single batch dimensions is much faster than\n    multi-dimensional maxima.\n\n    NOTE: Updating the maxima was found to be fastest and least memory\n    impactful when using torch.where directly. Other methods tested were\n    boolean masking and torch.where with tuples of tensor indexes.\n\n    Parameters\n    ----------\n    cross_correlation : torch.Tensor\n        Cross-correlation values for the current iteration. Has either shape\n        (batch, H, W) or (defocus, orientations, H, W).\n    euler_angles : torch.Tensor\n        Euler angles for the current iteration. Has shape (orientations, 3).\n    defocus_values : torch.Tensor\n        Defocus values for the current iteration. Has shape (defocus,).\n    pixel_values : torch.Tensor\n        Pixel size values for the current iteration. Has shape (pixel_size_batch,).\n    mip : torch.Tensor\n        Maximum intensity projection of the cross-correlation values.\n    best_phi : torch.Tensor\n        Best phi angle for each pixel.\n    best_theta : torch.Tensor\n        Best theta angle for each pixel.\n    best_psi : torch.Tensor\n        Best psi angle for each pixel.\n    best_defocus : torch.Tensor\n        Best defocus value for each pixel.\n    best_pixel_size : torch.Tensor\n        Best pixel size value for each pixel.\n    correlation_sum : torch.Tensor\n        Sum of cross-correlation values for each pixel.\n    correlation_squared_sum : torch.Tensor\n        Sum of squared cross-correlation values for each pixel.\n    img_h : int\n        Height of the cross-correlation values.\n    img_w : int\n        Width of the cross-correlation values.\n    \"\"\"\n    num_cs, num_defocs, num_orientations = cross_correlation.shape[0:3]\n    max_values, max_indices = torch.max(cross_correlation.view(-1, img_h, img_w), dim=0)\n    max_cs_idx = (max_indices // (num_defocs * num_orientations)) % num_cs\n    max_defocus_idx = (max_indices // num_orientations) % num_defocs\n    max_orientation_idx = max_indices % num_orientations\n\n    # using torch.where directly\n    update_mask = max_values &gt; mip\n\n    torch.where(update_mask, max_values, mip, out=mip)\n    torch.where(\n        update_mask, euler_angles[max_orientation_idx, 0], best_phi, out=best_phi\n    )\n    torch.where(\n        update_mask, euler_angles[max_orientation_idx, 1], best_theta, out=best_theta\n    )\n    torch.where(\n        update_mask, euler_angles[max_orientation_idx, 2], best_psi, out=best_psi\n    )\n    torch.where(\n        update_mask, defocus_values[max_defocus_idx], best_defocus, out=best_defocus\n    )\n    torch.where(\n        update_mask, pixel_values[max_cs_idx], best_pixel_size, out=best_pixel_size\n    )\n\n    correlation_sum += cross_correlation.view(-1, img_h, img_w).sum(dim=0)\n    correlation_squared_sum += (cross_correlation.view(-1, img_h, img_w) ** 2).sum(\n        dim=0\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/backend/utils/#leopard_em.backend.utils.normalize_template_projection","title":"<code>normalize_template_projection(projections, small_shape, large_shape)</code>","text":"<p>Subtract mean of edge values and set variance to 1 (in large shape).</p> <p>This function uses the fact that variance of a sequence, Var(X), is scaled by the relative size of the small (unpadded) and large (padded with zeros) space. Some negligible error is introduced into the variance (~1e-4) due to this routine.</p> <p>Let $X$ be the large, zero-padded projection and $x$ the small projection each with sizes $(H, W)$ and $(h, w)$, respectively. The mean of the zero-padded projection in terms of the small projection is: .. math::      The variance of the zero-padded projection in terms of the small projection can be obtained by: .. math::      </p> <p>Parameters:</p> Name Type Description Default <code>projections</code> <code>Tensor</code> <p>Real-space projections of the template (in small space).</p> required <code>small_shape</code> <code>tuple[int, int]</code> <p>Shape of the template.</p> required <code>large_shape</code> <code>tuple[int, int]</code> <p>Shape of the image (in large space).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Edge-mean subtracted projections, still in small space, but normalized so variance of zero-padded projection is 1.</p> Source code in <code>src/leopard_em/backend/utils.py</code> <pre><code>def normalize_template_projection(\n    projections: torch.Tensor,  # shape (batch, h, w)\n    small_shape: tuple[int, int],  # (h, w)\n    large_shape: tuple[int, int],  # (H, W)\n) -&gt; torch.Tensor:\n    r\"\"\"Subtract mean of edge values and set variance to 1 (in large shape).\n\n    This function uses the fact that variance of a sequence, Var(X), is scaled by the\n    relative size of the small (unpadded) and large (padded with zeros) space. Some\n    negligible error is introduced into the variance (~1e-4) due to this routine.\n\n    Let $X$ be the large, zero-padded projection and $x$ the small projection each\n    with sizes $(H, W)$ and $(h, w)$, respectively. The mean of the zero-padded\n    projection in terms of the small projection is:\n    .. math::\n        \\begin{align}\n            \\mu(X) &amp;= \\frac{1}{H \\cdot W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} X_{ij} \\\\\n            \\mu(X) &amp;= \\frac{1}{H \\cdot W} \\sum_{i=1}^{h} \\sum_{j=1}^{w} X_{ij} + 0 \\\\\n            \\mu(X) &amp;= \\frac{h \\cdot w}{H \\cdot W} \\mu(x)\n        \\end{align}\n    The variance of the zero-padded projection in terms of the small projection can be\n    obtained by:\n    .. math::\n        \\begin{align}\n            Var(X) &amp;= \\frac{1}{H \\cdot W} \\sum_{i=1}^{H} \\sum_{j=1}^{W} (X_{ij} -\n                \\mu(X))^2 \\\\\n            Var(X) &amp;= \\frac{1}{H \\cdot W} \\left(\\sum_{i=1}^{h}\n                \\sum_{j=1}^{w} (X_{ij} - \\mu(X))^2 +\n                \\sum_{i=h+1}^{H}\\sum_{i=w+1}^{W} \\mu(X)^2 \\right) \\\\\n            Var(X) &amp;= \\frac{1}{H \\cdot W} \\sum_{i=1}^{h} \\sum_{j=1}^{w} (X_{ij} -\n                \\mu(X))^2 + (H-h)(W-w)\\mu(X)^2\n        \\end{align}\n\n    Parameters\n    ----------\n    projections : torch.Tensor\n        Real-space projections of the template (in small space).\n    small_shape : tuple[int, int]\n        Shape of the template.\n    large_shape : tuple[int, int]\n        Shape of the image (in large space).\n\n    Returns\n    -------\n    torch.Tensor\n        Edge-mean subtracted projections, still in small space, but normalized\n        so variance of zero-padded projection is 1.\n    \"\"\"\n    # Extract edges while preserving batch dimensions\n    top_edge = projections[..., 0, :]  # shape: (..., w)\n    bottom_edge = projections[..., -1, :]  # shape: (..., w)\n    left_edge = projections[..., 1:-1, 0]  # shape: (..., h-2)\n    right_edge = projections[..., 1:-1, -1]  # shape: (..., h-2)\n    edge_pixels = torch.concatenate(\n        [top_edge, bottom_edge, left_edge, right_edge], dim=-1\n    )\n\n    # Subtract the edge pixel mean and calculate variance of small, unpadded projection\n    projections -= edge_pixels.mean(dim=-1)[..., None, None]\n\n    # # Calculate variance like cisTEM (does not match desired results...)\n    # variance = (projections**2).sum(dim=(-1, -2), keepdim=True) * relative_size - (\n    #     projections.mean(dim=(-1, -2), keepdim=True) * relative_size\n    # ) ** 2\n\n    # Fast calculation of mean/var using Torch + appropriate scaling.\n    large_size_sqrt = (large_shape[0] * large_shape[1]) ** 0.5\n    relative_size = (small_shape[0] * small_shape[1]) / (\n        large_shape[0] * large_shape[1]\n    )\n\n    mean = torch.mean(projections, dim=(-2, -1), keepdim=True) * relative_size\n    mean *= relative_size\n\n    # First term of the variance calculation\n    variance = torch.sum((projections - mean) ** 2, dim=(-2, -1), keepdim=True)\n    # Add the second term of the variance calculation\n    variance += (\n        (large_shape[0] - small_shape[0]) * (large_shape[1] - small_shape[1]) * mean**2\n    )\n\n    projections = (projections * large_size_sqrt) / torch.sqrt(variance.clamp_min(1e-8))\n    return projections\n</code></pre>"},{"location":"autoapi/leopard_em/backend/utils/#leopard_em.backend.utils.run_multiprocess_jobs","title":"<code>run_multiprocess_jobs(target, kwargs_list, extra_args=(), extra_kwargs=None)</code>","text":"<p>Helper function for running multiple processes on the same target function.</p> <p>Spawns multiple processes to run the same target function with different keyword arguments, aggregates results in a shared dictionary, and returns them.</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>Callable</code> <p>The function that each process will execute. It must accept at least two positional arguments: a shared dict and a unique index.</p> required <code>kwargs_list</code> <code>list[dict[str, Any]]</code> <p>A list of dictionaries containing keyword arguments for each process.</p> required <code>extra_args</code> <code>tuple[Any, ...]</code> <p>Additional positional arguments to pass to the target (prepending the shared parameters).</p> <code>()</code> <code>extra_kwargs</code> <code>Optional[dict[str, Any]]</code> <p>Additional common keyword arguments for all processes.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[Any, Any]</code> <p>Aggregated results stored in the shared dictionary.</p> Example <pre><code>def worker_fn(result_dict, idx, param1, param2):\n    result_dict[idx] = param1 + param2\n\n\nkwargs_per_process = [\n    {\"param1\": 1, \"param2\": 2},\n    {\"param1\": 3, \"param2\": 4},\n]\nresults = run_multiprocess_jobs(worker_fn, kwargs_per_process)\nprint(results)\n# {0: 3, 1: 7}\n</code></pre> Source code in <code>src/leopard_em/backend/utils.py</code> <pre><code>def run_multiprocess_jobs(\n    target: Callable,\n    kwargs_list: list[dict[str, Any]],\n    extra_args: tuple[Any, ...] = (),\n    extra_kwargs: Optional[dict[str, Any]] = None,\n) -&gt; dict[Any, Any]:\n    \"\"\"Helper function for running multiple processes on the same target function.\n\n    Spawns multiple processes to run the same target function with different keyword\n    arguments, aggregates results in a shared dictionary, and returns them.\n\n    Parameters\n    ----------\n    target : Callable\n        The function that each process will execute. It must accept at least two\n        positional arguments: a shared dict and a unique index.\n    kwargs_list : list[dict[str, Any]]\n        A list of dictionaries containing keyword arguments for each process.\n    extra_args : tuple[Any, ...], optional\n        Additional positional arguments to pass to the target (prepending the shared\n        parameters).\n    extra_kwargs : Optional[dict[str, Any]], optional\n        Additional common keyword arguments for all processes.\n\n    Returns\n    -------\n    dict[Any, Any]\n        Aggregated results stored in the shared dictionary.\n\n    Example\n    -------\n    ```\n    def worker_fn(result_dict, idx, param1, param2):\n        result_dict[idx] = param1 + param2\n\n\n    kwargs_per_process = [\n        {\"param1\": 1, \"param2\": 2},\n        {\"param1\": 3, \"param2\": 4},\n    ]\n    results = run_multiprocess_jobs(worker_fn, kwargs_per_process)\n    print(results)\n    # {0: 3, 1: 7}\n    ```\n    \"\"\"\n    if extra_kwargs is None:\n        extra_kwargs = {}\n\n    # Manager object for shared result data as a dictionary\n    manager = Manager()\n    result_dict = manager.dict()\n    processes: list[Process] = []\n\n    for i, kwargs in enumerate(kwargs_list):\n        args = (*extra_args, result_dict, i)\n\n        # Merge per-process kwargs with common kwargs.\n        proc_kwargs = {**extra_kwargs, **kwargs}\n        p = Process(target=target, args=args, kwargs=proc_kwargs)\n        processes.append(p)\n        p.start()\n\n    for p in processes:\n        p.join()\n\n    return dict(result_dict)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/","title":"pydantic_models","text":"<p>Pydantic models for the Leopard-EM package.</p>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/","title":"custom_types","text":"<p>Additional type definitions and hints for Pydantic models.</p>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/#leopard_em.pydantic_models.custom_types.BaseModel2DTM","title":"<code>BaseModel2DTM</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Implementation of a Pydantic BaseModel with additional, useful methods.</p> <p>Currently, only additional import/export methods are implemented and this class can effectively be treated as the <code>pydantic.BaseModel</code> class.</p> <p>Attributes:</p> Name Type Description <code>None</code> <p>Methods:</p> Name Description <code>from_json</code> <p>Load a BaseModel2DTM subclass from a serialized JSON file.</p> <code>from_yaml</code> <p>Load a BaseModel2DTM subclass from a serialized YAML file.</p> <code>to_json</code> <p>Serialize the BaseModel2DTM subclass to a JSON file.</p> <code>to_yaml</code> <p>Serialize the BaseModel2DTM subclass to a YAML file.</p> Source code in <code>src/leopard_em/pydantic_models/custom_types.py</code> <pre><code>class BaseModel2DTM(BaseModel):\n    \"\"\"Implementation of a Pydantic BaseModel with additional, useful methods.\n\n    Currently, only additional import/export methods are implemented and this\n    class can effectively be treated as the `pydantic.BaseModel` class.\n\n    Attributes\n    ----------\n    None\n\n    Methods\n    -------\n    from_json(json_path: str | os.PathLike) -&gt; BaseModel2DTM\n        Load a BaseModel2DTM subclass from a serialized JSON file.\n    from_yaml(yaml_path: str | os.PathLike) -&gt; BaseModel2DTM\n        Load a BaseModel2DTM subclass from a serialized YAML file.\n    to_json(json_path: str | os.PathLike) -&gt; None\n        Serialize the BaseModel2DTM subclass to a JSON file.\n    to_yaml(yaml_path: str | os.PathLike) -&gt; None\n        Serialize the BaseModel2DTM subclass to a YAML file.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(extra=\"forbid\")\n\n    #####################################\n    ### Import/instantiation methods ###\n    #####################################\n\n    @classmethod\n    def from_json(cls, json_path: str | os.PathLike) -&gt; \"BaseModel2DTM\":\n        \"\"\"Load a MatchTemplateManager from a serialized JSON file.\n\n        Parameters\n        ----------\n        json_path : str | os.PathLike\n            Path to the JSON file to load.\n\n        Returns\n        -------\n        BaseModel2DTM\n            Instance of the BaseModel2DTM subclass loaded from the JSON file.\n        \"\"\"\n        with open(json_path, encoding=\"utf-8\") as f:\n            data = json.load(f)\n\n        return cls(**data)\n\n    @classmethod\n    def from_yaml(cls, yaml_path: str | os.PathLike) -&gt; \"BaseModel2DTM\":\n        \"\"\"Load a MatchTemplateManager from a serialized YAML file.\n\n        Parameters\n        ----------\n        yaml_path : str | os.PathLike\n            Path to the YAML file to load.\n\n        Returns\n        -------\n        BaseModel2DTM\n            Instance of the BaseModel2DTM subclass loaded from the YAML file.\n        \"\"\"\n        with open(yaml_path, encoding=\"utf-8\") as f:\n            data = yaml.safe_load(f)\n\n        return cls(**data)\n\n    ####################################\n    ### Export/serialization methods ###\n    ####################################\n\n    def to_json(self, json_path: str | os.PathLike) -&gt; None:\n        \"\"\"Serialize the MatchTemplateManager to a JSON file.\n\n        Parameters\n        ----------\n        json_path : str | os.PathLike\n            Path to the JSON file to save.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with open(json_path, \"w\", encoding=\"utf-8\") as f:\n            json.dump(self.model_dump(), f)\n\n    def to_yaml(self, yaml_path: str | os.PathLike) -&gt; None:\n        \"\"\"Serialize the MatchTemplateManager to a YAML file.\n\n        Parameters\n        ----------\n        yaml_path : str | os.PathLike\n            Path to the YAML file to save.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n            yaml.dump(self.model_dump(), f)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/#leopard_em.pydantic_models.custom_types.BaseModel2DTM.from_json","title":"<code>from_json(json_path)</code>  <code>classmethod</code>","text":"<p>Load a MatchTemplateManager from a serialized JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str | PathLike</code> <p>Path to the JSON file to load.</p> required <p>Returns:</p> Type Description <code>BaseModel2DTM</code> <p>Instance of the BaseModel2DTM subclass loaded from the JSON file.</p> Source code in <code>src/leopard_em/pydantic_models/custom_types.py</code> <pre><code>@classmethod\ndef from_json(cls, json_path: str | os.PathLike) -&gt; \"BaseModel2DTM\":\n    \"\"\"Load a MatchTemplateManager from a serialized JSON file.\n\n    Parameters\n    ----------\n    json_path : str | os.PathLike\n        Path to the JSON file to load.\n\n    Returns\n    -------\n    BaseModel2DTM\n        Instance of the BaseModel2DTM subclass loaded from the JSON file.\n    \"\"\"\n    with open(json_path, encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    return cls(**data)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/#leopard_em.pydantic_models.custom_types.BaseModel2DTM.from_yaml","title":"<code>from_yaml(yaml_path)</code>  <code>classmethod</code>","text":"<p>Load a MatchTemplateManager from a serialized YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>yaml_path</code> <code>str | PathLike</code> <p>Path to the YAML file to load.</p> required <p>Returns:</p> Type Description <code>BaseModel2DTM</code> <p>Instance of the BaseModel2DTM subclass loaded from the YAML file.</p> Source code in <code>src/leopard_em/pydantic_models/custom_types.py</code> <pre><code>@classmethod\ndef from_yaml(cls, yaml_path: str | os.PathLike) -&gt; \"BaseModel2DTM\":\n    \"\"\"Load a MatchTemplateManager from a serialized YAML file.\n\n    Parameters\n    ----------\n    yaml_path : str | os.PathLike\n        Path to the YAML file to load.\n\n    Returns\n    -------\n    BaseModel2DTM\n        Instance of the BaseModel2DTM subclass loaded from the YAML file.\n    \"\"\"\n    with open(yaml_path, encoding=\"utf-8\") as f:\n        data = yaml.safe_load(f)\n\n    return cls(**data)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/#leopard_em.pydantic_models.custom_types.BaseModel2DTM.to_json","title":"<code>to_json(json_path)</code>","text":"<p>Serialize the MatchTemplateManager to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>json_path</code> <code>str | PathLike</code> <p>Path to the JSON file to save.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/custom_types.py</code> <pre><code>def to_json(self, json_path: str | os.PathLike) -&gt; None:\n    \"\"\"Serialize the MatchTemplateManager to a JSON file.\n\n    Parameters\n    ----------\n    json_path : str | os.PathLike\n        Path to the JSON file to save.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(self.model_dump(), f)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/custom_types/#leopard_em.pydantic_models.custom_types.BaseModel2DTM.to_yaml","title":"<code>to_yaml(yaml_path)</code>","text":"<p>Serialize the MatchTemplateManager to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>yaml_path</code> <code>str | PathLike</code> <p>Path to the YAML file to save.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/custom_types.py</code> <pre><code>def to_yaml(self, yaml_path: str | os.PathLike) -&gt; None:\n    \"\"\"Serialize the MatchTemplateManager to a YAML file.\n\n    Parameters\n    ----------\n    yaml_path : str | os.PathLike\n        Path to the YAML file to save.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n        yaml.dump(self.model_dump(), f)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/formats/","title":"formats","text":"<p>Submodule for shared formats used in pydantic models.</p>"},{"location":"autoapi/leopard_em/pydantic_models/utils/","title":"utils","text":"<p>Utility functions shared between pydantic models.</p>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.calculate_ctf_filter_stack","title":"<code>calculate_ctf_filter_stack(template_shape, optics_group, defocus_offsets, pixel_size_offsets)</code>","text":"<p>Calculate searched CTF filter values for a given shape and optics group.</p> <p>Parameters:</p> Name Type Description Default <code>template_shape</code> <code>tuple[int, int]</code> <p>Desired output shape for the filter, in real space.</p> required <code>optics_group</code> <code>OpticsGroup</code> <p>OpticsGroup object containing the optics defining the CTF parameters.</p> required <code>defocus_offsets</code> <code>Tensor</code> <p>Tensor of defocus offsets to search over, in Angstroms.</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>Tensor of pixel size offsets to search over, in Angstroms.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of CTF filter values for the specified shape and optics group. Will have shape (num_pixel_sizes, num_defocus_offsets, h, w // 2 + 1)</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def calculate_ctf_filter_stack(\n    template_shape: tuple[int, int],\n    optics_group: \"OpticsGroup\",\n    defocus_offsets: torch.Tensor,  # in Angstrom, relative\n    pixel_size_offsets: torch.Tensor,  # in Angstrom, relative\n) -&gt; torch.Tensor:\n    \"\"\"Calculate searched CTF filter values for a given shape and optics group.\n\n    Parameters\n    ----------\n    template_shape : tuple[int, int]\n        Desired output shape for the filter, in real space.\n    optics_group : OpticsGroup\n        OpticsGroup object containing the optics defining the CTF parameters.\n    defocus_offsets : torch.Tensor\n        Tensor of defocus offsets to search over, in Angstroms.\n    pixel_size_offsets : torch.Tensor\n        Tensor of pixel size offsets to search over, in Angstroms.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of CTF filter values for the specified shape and optics group. Will have\n        shape (num_pixel_sizes, num_defocus_offsets, h, w // 2 + 1)\n    \"\"\"\n    return calculate_ctf_filter_stack_full_args(\n        template_shape,\n        optics_group.defocus_u,\n        optics_group.defocus_v,\n        defocus_offsets,\n        pixel_size_offsets,\n        astigmatism_angle=optics_group.astigmatism_angle,\n        voltage=optics_group.voltage,\n        spherical_aberration=optics_group.spherical_aberration,\n        amplitude_contrast_ratio=optics_group.amplitude_contrast_ratio,\n        ctf_B_factor=optics_group.ctf_B_factor,\n        phase_shift=optics_group.phase_shift,\n        pixel_size=optics_group.pixel_size,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.calculate_ctf_filter_stack_full_args","title":"<code>calculate_ctf_filter_stack_full_args(template_shape, defocus_u, defocus_v, defocus_offsets, pixel_size_offsets, **kwargs)</code>","text":"<p>Calculate a CTF filter stack for a given set of parameters and search offsets.</p> <p>Parameters:</p> Name Type Description Default <code>template_shape</code> <code>tuple[int, int]</code> <p>Desired output shape for the filter, in real space.</p> required <code>defocus_u</code> <code>float</code> <p>Defocus along the major axis, in Angstroms.</p> required <code>defocus_v</code> <code>float</code> <p>Defocus along the minor axis, in Angstroms.</p> required <code>defocus_offsets</code> <code>Tensor</code> <p>Tensor of defocus offsets to search over, in Angstroms.</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>Tensor of pixel size offsets to search over, in Angstroms.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword to pass to the calculate_ctf_2d function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of CTF filter values for the specified shape and parameters. Will have shape (num_pixel_sizes, num_defocus_offsets, h, w // 2 + 1)</p> <code># Raises</code> <code># ------</code> <code># ValueError</code> <code>#     If not all the required parameters are passed as additional keyword arguments.</code> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def calculate_ctf_filter_stack_full_args(\n    template_shape: tuple[int, int],\n    defocus_u: float,  # in Angstrom\n    defocus_v: float,  # in Angstrom\n    defocus_offsets: torch.Tensor,  # in Angstrom, relative\n    pixel_size_offsets: torch.Tensor,  # in Angstrom, relative\n    **kwargs: Any,\n) -&gt; torch.Tensor:\n    \"\"\"Calculate a CTF filter stack for a given set of parameters and search offsets.\n\n    Parameters\n    ----------\n    template_shape : tuple[int, int]\n        Desired output shape for the filter, in real space.\n    defocus_u : float\n        Defocus along the major axis, in Angstroms.\n    defocus_v : float\n        Defocus along the minor axis, in Angstroms.\n    defocus_offsets : torch.Tensor\n        Tensor of defocus offsets to search over, in Angstroms.\n    pixel_size_offsets : torch.Tensor\n        Tensor of pixel size offsets to search over, in Angstroms.\n    **kwargs\n        Additional keyword to pass to the calculate_ctf_2d function.\n\n    Returns\n    -------\n    torch.Tensor\n        Tensor of CTF filter values for the specified shape and parameters. Will have\n        shape (num_pixel_sizes, num_defocus_offsets, h, w // 2 + 1)\n\n    # Raises\n    # ------\n    # ValueError\n    #     If not all the required parameters are passed as additional keyword arguments.\n    \"\"\"\n    # Calculate the defocus values + offsets in terms of Angstrom\n    defocus = defocus_offsets + ((defocus_u + defocus_v) / 2)\n    astigmatism = abs(defocus_u - defocus_v) / 2\n\n    # The different Cs values to search over as another dimension\n    cs_values = get_cs_range(\n        pixel_size=kwargs[\"pixel_size\"],\n        pixel_size_offsets=pixel_size_offsets,\n        cs=kwargs[\"spherical_aberration\"],\n    )\n\n    # Ensure defocus and astigmatism have a batch dimension so Cs and defocus can be\n    # interleaved correctly\n    if defocus.dim() == 0:\n        defocus = defocus.unsqueeze(0)\n\n    # Loop over spherical aberrations one at a time and collect results\n    ctf_list = []\n    for cs_val in cs_values:\n        tmp = calculate_ctf_2d(\n            defocus=defocus * 1e-4,  # Convert to um from Angstrom\n            astigmatism=astigmatism * 1e-4,  # Convert to um from Angstrom\n            astigmatism_angle=kwargs[\"astigmatism_angle\"],\n            voltage=kwargs[\"voltage\"],\n            spherical_aberration=cs_val,\n            amplitude_contrast=kwargs[\"amplitude_contrast_ratio\"],\n            phase_shift=kwargs[\"phase_shift\"],\n            pixel_size=kwargs[\"pixel_size\"],\n            image_shape=template_shape,\n            rfft=True,\n            fftshift=False,\n        )\n        # calc B-envelope and apply\n        b_envelope_tmp = b_envelope(\n            B=kwargs[\"ctf_B_factor\"],\n            image_shape=template_shape,\n            pixel_size=kwargs[\"pixel_size\"],\n            rfft=True,\n            fftshift=False,\n            device=tmp.device,\n        )\n        tmp *= b_envelope_tmp\n        ctf_list.append(tmp)\n\n    ctf = torch.stack(ctf_list, dim=0)\n\n    return ctf\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.cs_to_pixel_size","title":"<code>cs_to_pixel_size(cs_vals, nominal_pixel_size, nominal_cs=2.7)</code>","text":"<p>Convert Cs values to pixel sizes.</p> <p>Parameters:</p> Name Type Description Default <code>cs_vals</code> <code>Tensor</code> <p>The Cs (spherical aberration) values.</p> required <code>nominal_pixel_size</code> <code>float</code> <p>The nominal pixel size.</p> required <code>nominal_cs</code> <code>float</code> <p>The nominal Cs value, by default 2.7.</p> <code>2.7</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The pixel sizes.</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def cs_to_pixel_size(\n    cs_vals: torch.Tensor,\n    nominal_pixel_size: float,\n    nominal_cs: float = 2.7,\n) -&gt; torch.Tensor:\n    \"\"\"Convert Cs values to pixel sizes.\n\n    Parameters\n    ----------\n    cs_vals : torch.Tensor\n        The Cs (spherical aberration) values.\n    nominal_pixel_size : float\n        The nominal pixel size.\n    nominal_cs : float, optional\n        The nominal Cs value, by default 2.7.\n\n    Returns\n    -------\n    torch.Tensor\n        The pixel sizes.\n    \"\"\"\n    pixel_size = torch.pow(nominal_cs / cs_vals, 0.25) * nominal_pixel_size\n    return pixel_size\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.get_cs_range","title":"<code>get_cs_range(pixel_size, pixel_size_offsets, cs=2.7)</code>","text":"<p>Get the Cs values for a  range of pixel sizes.</p> <p>Parameters:</p> Name Type Description Default <code>pixel_size</code> <code>float</code> <p>The nominal pixel size.</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>The pixel size offsets.</p> required <code>cs</code> <code>float</code> <p>The Cs (spherical aberration) value, by default 2.7.</p> <code>2.7</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The Cs values for the range of pixel sizes.</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def get_cs_range(\n    pixel_size: float,\n    pixel_size_offsets: torch.Tensor,\n    cs: float = 2.7,\n) -&gt; torch.Tensor:\n    \"\"\"Get the Cs values for a  range of pixel sizes.\n\n    Parameters\n    ----------\n    pixel_size : float\n        The nominal pixel size.\n    pixel_size_offsets : torch.Tensor\n        The pixel size offsets.\n    cs : float, optional\n        The Cs (spherical aberration) value, by default 2.7.\n\n    Returns\n    -------\n    torch.Tensor\n        The Cs values for the range of pixel sizes.\n    \"\"\"\n    pixel_sizes = pixel_size + pixel_size_offsets\n    cs_values = cs / torch.pow(pixel_sizes / pixel_size, 4)\n    return cs_values\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.get_search_tensors","title":"<code>get_search_tensors(min_val, max_val, step_size, skip_enforce_zero=False)</code>","text":"<p>Get the search tensors (pixel or defocus) for a given range and step size.</p> <p>Parameters:</p> Name Type Description Default <code>min_val</code> <code>float</code> <p>The minimum value.</p> required <code>max_val</code> <code>float</code> <p>The maximum value.</p> required <code>step_size</code> <code>float</code> <p>The step size.</p> required <code>skip_enforce_zero</code> <code>bool</code> <p>Whether to skip enforcing a zero value, by default False.</p> <code>False</code> <p>Returns:</p> Type Description <code>tensor</code> <p>The search tensors.</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def get_search_tensors(\n    min_val: float,\n    max_val: float,\n    step_size: float,\n    skip_enforce_zero: bool = False,\n) -&gt; torch.tensor:\n    \"\"\"Get the search tensors (pixel or defocus) for a given range and step size.\n\n    Parameters\n    ----------\n    min_val : float\n        The minimum value.\n    max_val : float\n        The maximum value.\n    step_size : float\n        The step size.\n    skip_enforce_zero : bool, optional\n        Whether to skip enforcing a zero value, by default False.\n\n    Returns\n    -------\n    torch.tensor\n        The search tensors.\n    \"\"\"\n    vals = torch.arange(\n        min_val,\n        max_val + step_size,\n        step_size,\n        dtype=torch.float32,\n    )\n\n    if abs(torch.min(torch.abs(vals))) &gt; 1e-6 and not skip_enforce_zero:\n        vals = torch.cat([vals, torch.tensor([0.0])])\n        # Re-sort pixel sizes\n        vals = torch.sort(vals)[0]\n\n    return vals\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.preprocess_image","title":"<code>preprocess_image(image_rfft, cumulative_fourier_filters, bandpass_filter)</code>","text":"<p>Preprocesses and normalizes the image based on the given filters.</p> <p>Parameters:</p> Name Type Description Default <code>image_rfft</code> <code>Tensor</code> <p>The real Fourier-transformed image (unshifted).</p> required <code>cumulative_fourier_filters</code> <code>Tensor</code> <p>The cumulative Fourier filters. Multiplication of the whitening filter, phase randomization filter, bandpass filter, and arbitrary curve filter.</p> required <code>bandpass_filter</code> <code>Tensor</code> <p>The bandpass filter used for the image. Used for dimensionality normalization.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Preprocessed and normalized image in Fourier space</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def preprocess_image(\n    image_rfft: torch.Tensor,\n    cumulative_fourier_filters: torch.Tensor,\n    bandpass_filter: torch.Tensor,\n) -&gt; torch.Tensor:\n    \"\"\"Preprocesses and normalizes the image based on the given filters.\n\n    Parameters\n    ----------\n    image_rfft : torch.Tensor\n        The real Fourier-transformed image (unshifted).\n    cumulative_fourier_filters : torch.Tensor\n        The cumulative Fourier filters. Multiplication of the whitening filter, phase\n        randomization filter, bandpass filter, and arbitrary curve filter.\n    bandpass_filter : torch.Tensor\n        The bandpass filter used for the image. Used for dimensionality normalization.\n\n    Returns\n    -------\n    torch.Tensor\n        Preprocessed and normalized image in Fourier space\n    \"\"\"\n    image_rfft = image_rfft * cumulative_fourier_filters\n\n    # Normalize the image after filtering\n    squared_image_rfft = torch.abs(image_rfft) ** 2\n    squared_sum = torch.sum(squared_image_rfft, dim=(-2, -1), keepdim=True)\n    squared_sum += torch.sum(\n        squared_image_rfft[..., :, 1:-1], dim=(-2, -1), keepdim=True\n    )\n    image_rfft /= torch.sqrt(squared_sum)\n\n    # NOTE: For two Gaussian random variables in d-dimensional space --  A and B --\n    # each with mean 0 and variance 1 their correlation will have on average a\n    # variance of d.\n    # NOTE: Since we have the variance of the image and template projections each at\n    # 1, we need to multiply the image by the square root of the number of pixels\n    # so the cross-correlograms have a variance of 1 and not d.\n    # NOTE: When applying the Fourier filters to the image and template, any\n    # elements that get set to zero effectively reduce the dimensionality of our\n    # cross-correlation. Therefore, instead of multiplying by the number of pixels,\n    # we need to multiply tby the effective number of pixels that are non-zero.\n    # Below, we calculate the dimensionality of our cross-correlation and divide\n    # by the square root of that number to normalize the image.\n    dimensionality = bandpass_filter.sum() + bandpass_filter[:, 1:-1].sum()\n    image_rfft *= dimensionality**0.5\n\n    return image_rfft\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.setup_images_filters_particle_stack","title":"<code>setup_images_filters_particle_stack(particle_stack, preprocessing_filters, template)</code>","text":"<p>Extract and preprocess particle images and calculate filters.</p> <p>This function extracts particle images from a particle stack, performs FFT, applies filters, and prepares the template for further processing.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack</code> <code>ParticleStack</code> <p>The particle stack containing images to process.</p> required <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> required <code>template</code> <code>Tensor</code> <p>The 3D template volume.</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor, Tensor]</code> <p>A tuple containing: - particle_images_dft: The particle images in Fourier space - template_dft: The Fourier transformed template - projective_filters: Filters applied to the template</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def setup_images_filters_particle_stack(\n    particle_stack: \"ParticleStack\",\n    preprocessing_filters: \"PreprocessingFilters\",\n    template: torch.Tensor,\n) -&gt; tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Extract and preprocess particle images and calculate filters.\n\n    This function extracts particle images from a particle stack, performs FFT,\n    applies filters, and prepares the template for further processing.\n\n    Parameters\n    ----------\n    particle_stack : ParticleStack\n        The particle stack containing images to process.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    template : torch.Tensor\n        The 3D template volume.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n        A tuple containing:\n        - particle_images_dft: The particle images in Fourier space\n        - template_dft: The Fourier transformed template\n        - projective_filters: Filters applied to the template\n    \"\"\"\n    # Extract out the regions of interest (particles) based on the particle stack\n    particle_images = particle_stack.construct_image_stack(\n        pos_reference=\"top-left\",\n        padding_value=0.0,\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n    )\n\n    # FFT the particle images\n    # pylint: disable=E1102\n    particle_images_dft = torch.fft.rfftn(particle_images, dim=(-2, -1))\n    particle_images_dft[..., 0, 0] = 0.0 + 0.0j  # Zero out DC component\n\n    bandpass_filter = preprocessing_filters.bandpass_filter.calculate_bandpass_filter(\n        particle_images_dft.shape[-2:]\n    )\n\n    # Calculate and apply the filters for the particle image stack\n    filter_stack = particle_stack.construct_filter_stack(\n        preprocessing_filters, output_shape=particle_images_dft.shape[-2:]\n    )\n\n    particle_images_dft = preprocess_image(\n        image_rfft=particle_images_dft,\n        cumulative_fourier_filters=filter_stack,\n        bandpass_filter=bandpass_filter,\n    )\n\n    # Calculate the filters applied to each template (besides CTF)\n    projective_filters = particle_stack.construct_filter_stack(\n        preprocessing_filters,\n        output_shape=(template.shape[-2], template.shape[-1] // 2 + 1),\n    )\n\n    template_dft = volume_to_rfft_fourier_slice(template)\n\n    return (\n        particle_images_dft,\n        template_dft,\n        projective_filters,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.setup_particle_backend_kwargs","title":"<code>setup_particle_backend_kwargs(particle_stack, template, preprocessing_filters, euler_angles, euler_angle_offsets, defocus_offsets, pixel_size_offsets, device_list)</code>","text":"<p>Create common kwargs dictionary for template backend functions.</p> <p>This function extracts the common code between RefineTemplateManager and OptimizeTemplateManager's make_backend_core_function_kwargs methods.</p> <p>Parameters:</p> Name Type Description Default <code>particle_stack</code> <code>ParticleStack</code> <p>The particle stack containing images to process.</p> required <code>template</code> <code>Tensor</code> <p>The 3D template volume.</p> required <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> required <code>euler_angles</code> <code>Tensor</code> <p>The set of Euler angles to use.</p> required <code>euler_angle_offsets</code> <code>Tensor</code> <p>The relative Euler angle offsets to search over.</p> required <code>defocus_offsets</code> <code>Tensor</code> <p>The relative defocus values to search over.</p> required <code>pixel_size_offsets</code> <code>Tensor</code> <p>The relative pixel size values to search over.</p> required <code>device_list</code> <code>list</code> <p>List of computational devices to use.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary of keyword arguments for backend functions.</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def setup_particle_backend_kwargs(\n    particle_stack: \"ParticleStack\",\n    template: torch.Tensor,\n    preprocessing_filters: \"PreprocessingFilters\",\n    euler_angles: torch.Tensor,\n    euler_angle_offsets: torch.Tensor,\n    defocus_offsets: torch.Tensor,\n    pixel_size_offsets: torch.Tensor,\n    device_list: list,\n) -&gt; dict[str, Any]:\n    \"\"\"Create common kwargs dictionary for template backend functions.\n\n    This function extracts the common code between RefineTemplateManager and\n    OptimizeTemplateManager's make_backend_core_function_kwargs methods.\n\n    Parameters\n    ----------\n    particle_stack : ParticleStack\n        The particle stack containing images to process.\n    template : torch.Tensor\n        The 3D template volume.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    euler_angles : torch.Tensor\n        The set of Euler angles to use.\n    euler_angle_offsets : torch.Tensor\n        The relative Euler angle offsets to search over.\n    defocus_offsets : torch.Tensor\n        The relative defocus values to search over.\n    pixel_size_offsets : torch.Tensor\n        The relative pixel size values to search over.\n    device_list : list\n        List of computational devices to use.\n\n    Returns\n    -------\n    dict[str, Any]\n        Dictionary of keyword arguments for backend functions.\n    \"\"\"\n    # Get correlation statistics\n    corr_mean_stack = particle_stack.construct_cropped_statistic_stack(\n        stat=\"correlation_average\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=0.0,  # pad with zeros\n    )\n    corr_std_stack = particle_stack.construct_cropped_statistic_stack(\n        stat=\"correlation_variance\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=1e10,  # large to avoid out of bound pixels having inf z-score\n    )\n    corr_std_stack = corr_std_stack**0.5  # Convert variance to standard deviation\n\n    # Extract and preprocess images and filters\n    (\n        particle_images_dft,\n        template_dft,\n        projective_filters,\n    ) = setup_images_filters_particle_stack(\n        particle_stack, preprocessing_filters, template\n    )\n\n    # The best defocus values for each particle (+ astigmatism)\n    defocus_u, defocus_v = particle_stack.get_absolute_defocus()\n    defocus_angle = torch.tensor(particle_stack[\"astigmatism_angle\"])\n\n    ctf_kwargs = _setup_ctf_kwargs_from_particle_stack(\n        particle_stack, (template.shape[-2], template.shape[-1])\n    )\n\n    return {\n        \"particle_stack_dft\": particle_images_dft,\n        \"template_dft\": template_dft,\n        \"euler_angles\": euler_angles,\n        \"euler_angle_offsets\": euler_angle_offsets,\n        \"defocus_u\": defocus_u,\n        \"defocus_v\": defocus_v,\n        \"defocus_angle\": defocus_angle,\n        \"defocus_offsets\": defocus_offsets,\n        \"pixel_size_offsets\": pixel_size_offsets,\n        \"corr_mean\": corr_mean_stack,\n        \"corr_std\": corr_std_stack,\n        \"ctf_kwargs\": ctf_kwargs,\n        \"projective_filters\": projective_filters,\n        \"device\": device_list,\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/utils/#leopard_em.pydantic_models.utils.volume_to_rfft_fourier_slice","title":"<code>volume_to_rfft_fourier_slice(volume)</code>","text":"<p>Prepares a 3D volume for Fourier slice extraction.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Tensor</code> <p>The input volume.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The prepared volume in Fourier space ready for slice extraction.</p> Source code in <code>src/leopard_em/pydantic_models/utils.py</code> <pre><code>def volume_to_rfft_fourier_slice(volume: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Prepares a 3D volume for Fourier slice extraction.\n\n    Parameters\n    ----------\n    volume : torch.Tensor\n        The input volume.\n\n    Returns\n    -------\n    torch.Tensor\n        The prepared volume in Fourier space ready for slice extraction.\n    \"\"\"\n    assert volume.dim() == 3, \"Volume must be 3D\"\n\n    # NOTE: There is an extra FFTshift step before the RFFT since, for some reason,\n    # omitting this step will cause a 180 degree phase shift on odd (i, j, k)\n    # structure factors in the Fourier domain. This just requires an extra\n    # IFFTshift after converting a slice back to real-space (handled already).\n    volume = torch.fft.fftshift(volume, dim=(0, 1, 2))  # pylint: disable=E1102\n    volume_rfft = torch.fft.rfftn(volume, dim=(0, 1, 2))  # pylint: disable=E1102\n    volume_rfft = torch.fft.fftshift(volume_rfft, dim=(0, 1))  # pylint: disable=E1102\n\n    return volume_rfft\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/","title":"config","text":"<p>Pydantic models for search and refinement configurations in Leopard-EM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ArbitraryCurveFilterConfig","title":"<code>ArbitraryCurveFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Class holding frequency and amplitude values for arbitrary curve filter.</p> <p>Attributes:</p> Name Type Description <code>frequencies</code> <code>list[float]</code> <p>List of spatial frequencies (in terms of Nyquist) for the corresponding amplitudes.</p> <code>amplitudes</code> <code>list[float]</code> <p>List of amplitudes for the corresponding spatial frequencies.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class ArbitraryCurveFilterConfig(BaseModel2DTM):\n    \"\"\"Class holding frequency and amplitude values for arbitrary curve filter.\n\n    Attributes\n    ----------\n    frequencies : list[float]\n        List of spatial frequencies (in terms of Nyquist) for the corresponding\n        amplitudes.\n    amplitudes : list[float]\n        List of amplitudes for the corresponding spatial frequencies.\n    \"\"\"\n\n    enabled: bool = False\n    frequencies: Optional[list[float]] = None  # in terms of Nyquist frequency\n    amplitudes: Optional[list[float]] = None\n\n    def calculate_arbitrary_curve_filter(\n        self, output_shape: tuple[int, ...]\n    ) -&gt; torch.Tensor:\n        \"\"\"Calculates the curve filter for the desired output shape.\n\n        Parameters\n        ----------\n        output_shape : tuple[int, ...]\n            Desired output shape of the curve filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The curve filter for the desired output shape.\n        \"\"\"\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=torch.float32)\n\n        # Ensure that neither frequencies nor amplitudes are None\n        if self.frequencies is None or self.amplitudes is None:\n            raise ValueError(\n                \"When enabled, both 'frequencies' and 'amplitudes' must be provided.\"\n            )\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        freq_grid = fftfreq_grid(\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n            norm=True,\n        )\n\n        frequencies = torch.tensor(self.frequencies)\n        amplitudes = torch.tensor(self.amplitudes)\n        filter_ndim = curve_1dim_to_ndim(\n            frequency_1d=frequencies,\n            values_1d=amplitudes,\n            frequency_grid=freq_grid,\n            fill_lower=1.0,  # Fill oob areas with ones (no scaling)\n            fill_upper=1.0,\n        )\n\n        return filter_ndim\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ArbitraryCurveFilterConfig.calculate_arbitrary_curve_filter","title":"<code>calculate_arbitrary_curve_filter(output_shape)</code>","text":"<p>Calculates the curve filter for the desired output shape.</p> <p>Parameters:</p> Name Type Description Default <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the curve filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The curve filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_arbitrary_curve_filter(\n    self, output_shape: tuple[int, ...]\n) -&gt; torch.Tensor:\n    \"\"\"Calculates the curve filter for the desired output shape.\n\n    Parameters\n    ----------\n    output_shape : tuple[int, ...]\n        Desired output shape of the curve filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The curve filter for the desired output shape.\n    \"\"\"\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=torch.float32)\n\n    # Ensure that neither frequencies nor amplitudes are None\n    if self.frequencies is None or self.amplitudes is None:\n        raise ValueError(\n            \"When enabled, both 'frequencies' and 'amplitudes' must be provided.\"\n        )\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    freq_grid = fftfreq_grid(\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n        norm=True,\n    )\n\n    frequencies = torch.tensor(self.frequencies)\n    amplitudes = torch.tensor(self.amplitudes)\n    filter_ndim = curve_1dim_to_ndim(\n        frequency_1d=frequencies,\n        values_1d=amplitudes,\n        frequency_grid=freq_grid,\n        fill_lower=1.0,  # Fill oob areas with ones (no scaling)\n        fill_upper=1.0,\n    )\n\n    return filter_ndim\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.BandpassFilterConfig","title":"<code>BandpassFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for the bandpass filter.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a bandpass filter to correlation during template matching. Default is False.</p> <code>low_freq_cutoff</code> <code>Optional[float]</code> <p>Low pass filter cutoff frequency. Default is None, which is no low pass filter.</p> <code>high_freq_cutoff</code> <code>Optional[float]</code> <p>High pass filter cutoff frequency. Default is None, which is no high pass filter.</p> <code>falloff</code> <code>Optional[float]</code> <p>Falloff factor for bandpass filter. Default is 0.0, which is no falloff.</p> <p>Methods:</p> Name Description <code>from_spatial_resolution</code> <p>Helper method to instantiate a bandpass filter from spatial resolutions and a pixel size.</p> <code>calculate_bandpass_filter</code> <p>Helper function for bandpass filter based on the desired output shape. This method returns a filter for a RFFT'd and unshifted (zero-frequency component at the top-left corner) image.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class BandpassFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for the bandpass filter.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a bandpass filter to correlation during template\n        matching. Default is False.\n    low_freq_cutoff : Optional[float]\n        Low pass filter cutoff frequency. Default is None, which is no low\n        pass filter.\n    high_freq_cutoff : Optional[float]\n        High pass filter cutoff frequency. Default is None, which is no high\n        pass filter.\n    falloff : Optional[float]\n        Falloff factor for bandpass filter. Default is 0.0, which is no\n        falloff.\n\n    Methods\n    -------\n    from_spatial_resolution(low_resolution, high_resolution, pixel_size, **kwargs)\n        Helper method to instantiate a bandpass filter from spatial resolutions and\n        a pixel size.\n    calculate_bandpass_filter(output_shape)\n        Helper function for bandpass filter based on the desired output shape. This\n        method returns a filter for a RFFT'd and unshifted (zero-frequency component\n        at the top-left corner) image.\n    \"\"\"\n\n    enabled: bool = False\n    low_freq_cutoff: Optional[Annotated[float, Field(ge=0.0)]] = None\n    high_freq_cutoff: Optional[Annotated[float, Field(ge=0.0)]] = None\n    falloff: Optional[Annotated[float, Field(ge=0.0)]] = None\n\n    @classmethod\n    def from_spatial_resolution(\n        cls,\n        low_resolution: float,\n        high_resolution: float,\n        pixel_size: float,\n        **kwargs: dict[str, Any],\n    ) -&gt; \"BandpassFilterConfig\":\n        \"\"\"Helper method to instantiate a bandpass filter from spatial resolutions.\n\n        Parameters\n        ----------\n        low_resolution : float\n            Low resolution cutoff frequency in Angstroms.\n        high_resolution : float\n            High resolution cutoff frequency in Angstroms.\n        pixel_size : float\n            Pixel size in Angstroms.\n        **kwargs\n            Additional keyword arguments to pass to the constructor method.\n\n        Returns\n        -------\n        BandpassFilterConfig\n            Bandpass filter configuration object.\n        \"\"\"\n        low_freq_cutoff = pixel_size / low_resolution\n        high_freq_cutoff = pixel_size / high_resolution\n\n        return cls(\n            low_freq_cutoff=low_freq_cutoff,\n            high_freq_cutoff=high_freq_cutoff,\n            **kwargs,\n        )\n\n    def calculate_bandpass_filter(self, output_shape: tuple[int, ...]) -&gt; torch.Tensor:\n        \"\"\"Helper function for bandpass filter based on the desired output shape.\n\n        Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency\n        component at the top-left corner) image.\n\n        Parameters\n        ----------\n        output_shape : tuple[int, ...]\n            Desired output shape of the bandpass filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The bandpass filter for the desired output shape.\n        \"\"\"\n        # Handle case where bandpass filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=torch.float32)\n\n        # Account for None values\n        low = self.low_freq_cutoff if self.low_freq_cutoff is not None else 0.0\n        high = self.high_freq_cutoff if self.high_freq_cutoff is not None else 1.0\n        falloff = self.falloff if self.falloff is not None else 0.0\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return bandpass_filter(\n            low=low,\n            high=high,\n            falloff=falloff,\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.BandpassFilterConfig.calculate_bandpass_filter","title":"<code>calculate_bandpass_filter(output_shape)</code>","text":"<p>Helper function for bandpass filter based on the desired output shape.</p> <p>Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency component at the top-left corner) image.</p> <p>Parameters:</p> Name Type Description Default <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the bandpass filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The bandpass filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_bandpass_filter(self, output_shape: tuple[int, ...]) -&gt; torch.Tensor:\n    \"\"\"Helper function for bandpass filter based on the desired output shape.\n\n    Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency\n    component at the top-left corner) image.\n\n    Parameters\n    ----------\n    output_shape : tuple[int, ...]\n        Desired output shape of the bandpass filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The bandpass filter for the desired output shape.\n    \"\"\"\n    # Handle case where bandpass filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=torch.float32)\n\n    # Account for None values\n    low = self.low_freq_cutoff if self.low_freq_cutoff is not None else 0.0\n    high = self.high_freq_cutoff if self.high_freq_cutoff is not None else 1.0\n    falloff = self.falloff if self.falloff is not None else 0.0\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return bandpass_filter(\n        low=low,\n        high=high,\n        falloff=falloff,\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.BandpassFilterConfig.from_spatial_resolution","title":"<code>from_spatial_resolution(low_resolution, high_resolution, pixel_size, **kwargs)</code>  <code>classmethod</code>","text":"<p>Helper method to instantiate a bandpass filter from spatial resolutions.</p> <p>Parameters:</p> Name Type Description Default <code>low_resolution</code> <code>float</code> <p>Low resolution cutoff frequency in Angstroms.</p> required <code>high_resolution</code> <code>float</code> <p>High resolution cutoff frequency in Angstroms.</p> required <code>pixel_size</code> <code>float</code> <p>Pixel size in Angstroms.</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments to pass to the constructor method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BandpassFilterConfig</code> <p>Bandpass filter configuration object.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>@classmethod\ndef from_spatial_resolution(\n    cls,\n    low_resolution: float,\n    high_resolution: float,\n    pixel_size: float,\n    **kwargs: dict[str, Any],\n) -&gt; \"BandpassFilterConfig\":\n    \"\"\"Helper method to instantiate a bandpass filter from spatial resolutions.\n\n    Parameters\n    ----------\n    low_resolution : float\n        Low resolution cutoff frequency in Angstroms.\n    high_resolution : float\n        High resolution cutoff frequency in Angstroms.\n    pixel_size : float\n        Pixel size in Angstroms.\n    **kwargs\n        Additional keyword arguments to pass to the constructor method.\n\n    Returns\n    -------\n    BandpassFilterConfig\n        Bandpass filter configuration object.\n    \"\"\"\n    low_freq_cutoff = pixel_size / low_resolution\n    high_freq_cutoff = pixel_size / high_resolution\n\n    return cls(\n        low_freq_cutoff=low_freq_cutoff,\n        high_freq_cutoff=high_freq_cutoff,\n        **kwargs,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ComputationalConfig","title":"<code>ComputationalConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Serialization of computational resources allocated for 2DTM.</p> <p>NOTE: The field <code>gpu_ids</code> is not validated at instantiation past being one of the valid types. For example, if \"cuda:0\" is specified but no CUDA device is available, the instantiation will succeed, and only upon translating <code>gpu_ids</code> to a list of <code>torch.device</code> objects will an error be raised. This is done to allow for configuration files to be loaded without requiring the actual hardware to be present at the time of loading.</p> <p>Attributes:</p> Name Type Description <code>gpu_ids</code> <code>Optional[Union[int, list[int], str, list[str]]]</code> <p>Field which specifies which GPUs to use for computation. The following types of values are allowed: - A single integer, e.g. 0, which means to use GPU with ID 0. - A list of integers, e.g. [0, 2], which means to use GPUs with IDs 0 and 2. - A device specifier string, e.g. \"cuda:0\", which means to use GPU with ID 0. - A list of device specifier strings, e.g. [\"cuda:0\", \"cuda:1\"], which means to   use GPUs with IDs 0 and 1. - The specific string \"all\" which means to use all available GPUs identified   by torch.cuda.device_count(). - The specific string \"cpu\" which means to use CPU.</p> <code>num_cpus</code> <code>int</code> <p>Total number of CPUs to use, defaults to 1.</p> Source code in <code>src/leopard_em/pydantic_models/config/computational_config.py</code> <pre><code>class ComputationalConfig(BaseModel):\n    \"\"\"Serialization of computational resources allocated for 2DTM.\n\n    NOTE: The field `gpu_ids` is not validated at instantiation past being one of the\n    valid types. For example, if \"cuda:0\" is specified but no CUDA device is available,\n    the instantiation will succeed, and only upon translating `gpu_ids` to a list of\n    `torch.device` objects will an error be raised. This is done to allow for\n    configuration files to be loaded without requiring the actual hardware to be\n    present at the time of loading.\n\n    Attributes\n    ----------\n    gpu_ids : Optional[Union[int, list[int], str, list[str]]]\n        Field which specifies which GPUs to use for computation. The following types\n        of values are allowed:\n        - A single integer, e.g. 0, which means to use GPU with ID 0.\n        - A list of integers, e.g. [0, 2], which means to use GPUs with IDs 0 and 2.\n        - A device specifier string, e.g. \"cuda:0\", which means to use GPU with ID 0.\n        - A list of device specifier strings, e.g. [\"cuda:0\", \"cuda:1\"], which means to\n          use GPUs with IDs 0 and 1.\n        - The specific string \"all\" which means to use all available GPUs identified\n          by torch.cuda.device_count().\n        - The specific string \"cpu\" which means to use CPU.\n    num_cpus : int\n        Total number of CPUs to use, defaults to 1.\n    \"\"\"\n\n    # Type-hinting here is ensuring non-negative integers, and list of at least one\n    gpu_ids: Optional[\n        Union[\n            str,\n            NonNegativeInt,\n            Annotated[list[NonNegativeInt], Field(min_length=1)],\n            Annotated[list[str], Field(min_length=1)],\n        ]\n    ] = [0]\n    num_cpus: Annotated[int, Field(ge=1)] = 1\n\n    @property\n    def gpu_devices(self) -&gt; list[torch.device]:\n        \"\"\"Convert requested GPU IDs to torch device objects.\n\n        Returns\n        -------\n        list[torch.device]\n        \"\"\"\n        # Handle special string cases first\n        if self.gpu_ids == \"all\":\n            if not torch.cuda.is_available():\n                raise ValueError(\"No CUDA devices available.\")\n            return [torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n\n        if self.gpu_ids == \"cpu\":\n            return [torch.device(\"cpu\")]\n\n        # Normalize to list for uniform processing\n        gpu_list = self.gpu_ids if isinstance(self.gpu_ids, list) else [self.gpu_ids]\n\n        # Process each item in the normalized list\n        devices = []\n        for gpu_id in gpu_list:\n            if isinstance(gpu_id, int):\n                devices.append(torch.device(f\"cuda:{gpu_id}\"))\n            elif isinstance(gpu_id, str):\n                devices.append(torch.device(gpu_id))\n            else:\n                raise TypeError(\n                    f\"Invalid type for gpu_ids element: {type(gpu_id)}. \"\n                    \"Expected int or str.\"\n                )\n\n        return devices\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ComputationalConfig.gpu_devices","title":"<code>gpu_devices</code>  <code>property</code>","text":"<p>Convert requested GPU IDs to torch device objects.</p> <p>Returns:</p> Type Description <code>list[device]</code>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ConstrainedOrientationConfig","title":"<code>ConstrainedOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of constrained orientation parameters.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable constrained orientation search.</p> <code>phi_step</code> <code>float</code> <p>Angular step size for phi in degrees. Must be greater than or equal to 0.</p> <code>theta_step</code> <code>float</code> <p>Angular step size for theta in degrees. Must be greater than or equal to 0.</p> <code>psi_step</code> <code>float</code> <p>Angular step size for psi in degrees. Must be greater than or equal to 0.</p> <code>rotation_axis_euler_angles</code> <code>list[float]</code> <p>List of Euler angles (phi, theta, psi) for the rotation axis.</p> <code>phi_min</code> <code>float</code> <p>Minimum value for the phi angle in degrees.</p> <code>phi_max</code> <code>float</code> <p>Maximum value for the phi angle in degrees.</p> <code>theta_min</code> <code>float</code> <p>Minimum value for the theta angle in degrees.</p> <code>theta_max</code> <code>float</code> <p>Maximum value for the theta angle in degrees.</p> <code>psi_min</code> <code>float</code> <p>Minimum value for the psi angle in degrees.</p> <code>psi_max</code> <code>float</code> <p>Maximum value for the psi angle in degrees.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class ConstrainedOrientationConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of constrained orientation parameters.\n\n    Attributes\n    ----------\n    enabled: bool\n        Whether to enable constrained orientation search.\n    phi_step: float\n        Angular step size for phi in degrees.\n        Must be greater than or equal to 0.\n    theta_step: float\n        Angular step size for theta in degrees.\n        Must be greater than or equal to 0.\n    psi_step: float\n        Angular step size for psi in degrees.\n        Must be greater than or equal to 0.\n    rotation_axis_euler_angles: list[float]\n        List of Euler angles (phi, theta, psi) for the rotation axis.\n    phi_min: float\n        Minimum value for the phi angle in degrees.\n    phi_max: float\n        Maximum value for the phi angle in degrees.\n    theta_min: float\n        Minimum value for the theta angle in degrees.\n    theta_max: float\n        Maximum value for the theta angle in degrees.\n    psi_min: float\n        Minimum value for the psi angle in degrees.\n    psi_max: float\n        Maximum value for the psi angle in degrees.\n    \"\"\"\n\n    enabled: bool = True\n    phi_step: Optional[float] = None\n    theta_step: float = 2.5\n    psi_step: float = 1.5\n    rotation_axis_euler_angles: tuple[float, float, float] = Field(\n        default=[0.0, 0.0, 0.0]\n    )\n    phi_min: float = 0.0\n    phi_max: float = 360.0\n    theta_min: float = 0.0\n    theta_max: float = 180.0\n    psi_min: float = 0.0\n    psi_max: float = 360.0\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"basic\", \"roll\"] = \"uniform\"\n\n    search_roll_axis: bool = True\n    roll_axis: Optional[tuple[float, float]] = Field(default=[0, 1])\n    roll_step: float = 2.0\n\n    @property\n    def euler_angles_offsets(self) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Return the Euler angle offsets to search over.\n\n        Note that this method uses a uniform grid search which approximates SO(3) space\n        well when the angular ranges are small.\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n            A tuple of two tensors of shape (N, 3) where N is the number of\n            orientations to search over. The first tensor represents the Euler\n            angles of the rotated template, and the second tensor represents\n            the Euler angles of the rotation axis. The columns represent the\n            phi, theta, and psi angles, respectively, in the 'ZYZ' convention.\n        \"\"\"\n        if not self.enabled:\n            return torch.zeros((1, 3)), torch.zeros((1, 3))\n\n        if self.search_roll_axis:\n            self.roll_axis = None\n        roll_axis = None\n        if self.roll_axis is not None:\n            roll_axis = torch.tensor(self.roll_axis)\n\n        if self.base_grid_method == \"roll\":\n            euler_angles_offsets = get_roll_angles(\n                psi_step=self.psi_step,\n                psi_min=self.psi_min,\n                psi_max=self.psi_max,\n                theta_step=self.theta_step,\n                theta_min=self.theta_min,\n                theta_max=self.theta_max,\n                roll_axis=roll_axis,\n                roll_axis_step=self.roll_step,\n            )\n        else:\n            euler_angles_offsets = get_uniform_euler_angles(\n                phi_step=self.phi_step,\n                theta_step=self.theta_step,\n                psi_step=self.psi_step,\n                phi_min=self.phi_min,\n                phi_max=self.phi_max,\n                theta_min=self.theta_min,\n                theta_max=self.theta_max,\n                psi_min=self.psi_min,\n                psi_max=self.psi_max,\n                base_grid_method=self.base_grid_method,\n            )\n        # Convert to rotation matrix\n        rot_z_matrix = roma.euler_to_rotmat(\n            \"ZYZ\",\n            euler_angles_offsets,\n            degrees=True,\n            device=euler_angles_offsets.device,\n        ).to(torch.float32)\n        # Apply rotation to the template\n        rot_axis_matrix = roma.euler_to_rotmat(\n            \"ZYZ\",\n            torch.tensor(self.rotation_axis_euler_angles),\n            degrees=True,\n            device=euler_angles_offsets.device,\n        ).to(torch.float32)\n\n        rot_matrix_batch = roma.rotmat_composition(\n            sequence=(rot_axis_matrix, rot_z_matrix, rot_axis_matrix.transpose(-1, -2))\n        )\n\n        # Convert back to Euler angles\n        euler_angles_offsets_rotated = roma.rotmat_to_euler(\n            \"ZYZ\", rot_matrix_batch, degrees=True\n        ).to(torch.float32)\n        return euler_angles_offsets_rotated, euler_angles_offsets\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.ConstrainedOrientationConfig.euler_angles_offsets","title":"<code>euler_angles_offsets</code>  <code>property</code>","text":"<p>Return the Euler angle offsets to search over.</p> <p>Note that this method uses a uniform grid search which approximates SO(3) space well when the angular ranges are small.</p> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A tuple of two tensors of shape (N, 3) where N is the number of orientations to search over. The first tensor represents the Euler angles of the rotated template, and the second tensor represents the Euler angles of the rotation axis. The columns represent the phi, theta, and psi angles, respectively, in the 'ZYZ' convention.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.DefocusSearchConfig","title":"<code>DefocusSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of defocus search parameters for 2DTM.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable defocus search. Default is True.</p> <code>defocus_min</code> <code>float</code> <p>Minimum searched defocus relative to average defocus ('defocus_u' and 'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.</p> <code>defocus_max</code> <code>float</code> <p>Maximum searched defocus relative to average defocus ('defocus_u' and 'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.</p> <code>defocus_step</code> <code>float</code> <p>Step size for defocus search in units of Angstroms.</p> <code>skip_enforce_zero</code> <code>bool</code> <p>Whether to skip enforcing a zero value, by default False.</p> Properties <p>defocus_values : torch.Tensor     Tensor of relative defocus values to search over based on held params.</p> Source code in <code>src/leopard_em/pydantic_models/config/defocus_search.py</code> <pre><code>class DefocusSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of defocus search parameters for 2DTM.\n\n    Attributes\n    ----------\n    enabled : bool\n        Whether to enable defocus search. Default is True.\n    defocus_min : float\n        Minimum searched defocus relative to average defocus ('defocus_u' and\n        'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.\n    defocus_max : float\n        Maximum searched defocus relative to average defocus ('defocus_u' and\n        'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.\n    defocus_step : float\n        Step size for defocus search in units of Angstroms.\n    skip_enforce_zero : bool\n        Whether to skip enforcing a zero value, by default False.\n\n    Properties\n    ----------\n    defocus_values : torch.Tensor\n        Tensor of relative defocus values to search over based on held params.\n    \"\"\"\n\n    enabled: bool = True\n    defocus_min: float = -1000.0\n    defocus_max: float = 1000.0\n    defocus_step: Annotated[float, Field(..., gt=0.0)] = 200.0\n    skip_enforce_zero: bool = False\n\n    @property\n    def defocus_values(self) -&gt; torch.Tensor:\n        \"\"\"Relative defocus values to search over based on held params.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of relative defocus values to search over, in units of Angstroms.\n\n        Raises\n        ------\n        ValueError\n            If defocus search parameters result in no defocus values to search over.\n        \"\"\"\n        # Return a relative defocus of 0.0 if search is disabled.\n        if not self.enabled:\n            return torch.tensor([0.0])\n\n            # Check if parameters would result in valid range before calling arange\n        if self.defocus_max &lt; self.defocus_min:\n            raise ValueError(\n                \"Defocus search parameters result in no values to search over!\\n\"\n                f\"  self.defocus_min: {self.defocus_min}\\n\"\n                f\"  self.defocus_max: {self.defocus_max}\\n\"\n                f\"  self.defocus_step: {self.defocus_step}\\n\"\n            )\n\n        return get_search_tensors(\n            self.defocus_min,\n            self.defocus_max,\n            self.defocus_step,\n            self.skip_enforce_zero,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.DefocusSearchConfig.defocus_values","title":"<code>defocus_values</code>  <code>property</code>","text":"<p>Relative defocus values to search over based on held params.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of relative defocus values to search over, in units of Angstroms.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If defocus search parameters result in no defocus values to search over.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.MultipleOrientationConfig","title":"<code>MultipleOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for multiple orientation search ranges.</p> <p>This class allows specifying multiple complete orientation search configurations and concatenates their Euler angles.</p> <p>Attributes:</p> Name Type Description <code>orientation_configs</code> <code>list[OrientationSearchConfig]</code> <p>List of orientation search configurations to combine.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class MultipleOrientationConfig(BaseModel2DTM):\n    \"\"\"Configuration for multiple orientation search ranges.\n\n    This class allows specifying multiple complete orientation search\n    configurations and concatenates their Euler angles.\n\n    Attributes\n    ----------\n    orientation_configs : list[OrientationSearchConfig]\n        List of orientation search configurations to combine.\n    \"\"\"\n\n    orientation_configs: list[OrientationSearchConfig]\n\n    @property\n    def euler_angles(self) -&gt; torch.Tensor:\n        \"\"\"Returns the concatenated Euler angles from all orientation configs.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the total number of orientations\n            from all configurations. The columns represent the psi, theta, and phi\n            angles respectively.\n        \"\"\"\n        all_euler_angles = []\n        for config in self.orientation_configs:\n            all_euler_angles.append(config.euler_angles)\n\n        return torch.cat(all_euler_angles, dim=0)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.MultipleOrientationConfig.euler_angles","title":"<code>euler_angles</code>  <code>property</code>","text":"<p>Returns the concatenated Euler angles from all orientation configs.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the total number of orientations from all configurations. The columns represent the psi, theta, and phi angles respectively.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.OrientationSearchConfig","title":"<code>OrientationSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of orientation search parameters for 2DTM.</p> <p>The angles -- phi, theta, and psi -- represent Euler angles in the 'ZYZ' convention in units of degrees between 0 and 360 (for phi and psi) or between 0 and 180 (for theta).</p> <p>This model effectively acts as a connector into the <code>torch_so3.uniform_so3_sampling.get_uniform_euler_angles</code> function from the torch-so3 package.</p> <p>TODO: Implement indexing to get the i-th or range of orientations in the search space (need to be ordered).</p> <p>Attributes:</p> Name Type Description <code>psi_step</code> <code>float</code> <p>Angular step size for psi in degrees. Must be greater than 0.</p> <code>theta_step</code> <code>float</code> <p>Angular step size for theta in degrees. Must be greater than 0.</p> <code>phi_min</code> <code>float</code> <p>Minimum value for the phi angle in degrees.</p> <code>phi_max</code> <code>float</code> <p>Maximum value for the phi angle in degrees.</p> <code>theta_min</code> <code>float</code> <p>Minimum value for the theta angle in degrees.</p> <code>theta_max</code> <code>float</code> <p>Maximum value for the theta angle in degrees.</p> <code>psi_min</code> <code>float</code> <p>Minimum value for the psi angle in degrees.</p> <code>psi_max</code> <code>float</code> <p>Maximum value for the psi angle in degrees.</p> <code>base_grid_method</code> <code>str</code> <p>Method for sampling orientations. Default is 'uniform'. Currently only 'uniform' is supported.</p> <code>symmetry</code> <code>str</code> <p>Symmetry group of the template. Default is 'C1'. Note that if symmetry is provided, then the angle min/max values must be all set to None (validation will set these automatically based on the symmetry group).</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class OrientationSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of orientation search parameters for 2DTM.\n\n    The angles -- phi, theta, and psi -- represent Euler angles in the 'ZYZ'\n    convention in units of degrees between 0 and 360 (for phi and psi) or\n    between 0 and 180 (for theta).\n\n    This model effectively acts as a connector into the\n    `torch_so3.uniform_so3_sampling.get_uniform_euler_angles` function from the\n    [torch-so3](https://github.com/teamtomo/torch-so3) package.\n\n    TODO: Implement indexing to get the i-th or range of orientations in the\n    search space (need to be ordered).\n\n    Attributes\n    ----------\n    psi_step : float\n        Angular step size for psi in degrees. Must be greater\n        than 0.\n    theta_step : float\n        Angular step size for theta in degrees. Must be\n        greater than 0.\n    phi_min : float\n        Minimum value for the phi angle in degrees.\n    phi_max : float\n        Maximum value for the phi angle in degrees.\n    theta_min : float\n        Minimum value for the theta angle in degrees.\n    theta_max : float\n        Maximum value for the theta angle in degrees.\n    psi_min : float\n        Minimum value for the psi angle in degrees.\n    psi_max : float\n        Maximum value for the psi angle in degrees.\n    base_grid_method : str\n        Method for sampling orientations. Default is 'uniform'.\n        Currently only 'uniform' is supported.\n    symmetry : str\n        Symmetry group of the template. Default is 'C1'. Note that if symmetry is\n        provided, then the angle min/max values must be all set to None (validation\n        will set these automatically based on the symmetry group).\n    \"\"\"\n\n    psi_step: Annotated[float, Field(ge=0.0)] = 1.5\n    theta_step: Annotated[float, Field(ge=0.0)] = 2.5\n    phi_min: Optional[float] = None\n    phi_max: Optional[float] = None\n    theta_min: Optional[float] = None\n    theta_max: Optional[float] = None\n    psi_min: Optional[float] = None\n    psi_max: Optional[float] = None\n\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"cartesian\"] = \"uniform\"\n    symmetry: Optional[str] = \"C1\"\n\n    @model_validator(mode=\"after\")  # type: ignore\n    def validate_angle_ranges_and_symmetry(self) -&gt; Self:\n        \"\"\"Validate that angle ranges are consistent with symmetry.\n\n        There should be only two valid cases for combinations of manually defined\n        angle ranges and the symmetry group:\n        1. Symmetry argument is *not* None, and all angle min/max values\n           are set to None. In this case, the angle ranges will be set based on\n           the symmetry group.\n        2. Symmetry argument is None, and all angle min/max values are not None.\n\n        If any other combination is provided, a ValueError will be raised.\n        \"\"\"\n        _all_none = all(\n            x is None\n            for x in [\n                self.phi_min,\n                self.phi_max,\n                self.theta_min,\n                self.theta_max,\n                self.psi_min,\n                self.psi_max,\n            ]\n        )\n\n        # Check that both symmetry and angle ranges are not None\n        if not self.symmetry and _all_none:\n            raise ValueError(\n                \"Either a symmetry group must be provided, or all angle ranges must \"\n                \"not be None. Both symmetry and angle ranges were set to None.\"\n            )\n\n        # Case where both symmetry and angle ranges are provided\n        if self.symmetry and not _all_none:\n            raise ValueError(\n                \"Symmetry group is provided, but angle ranges are also set. \"\n                \"Please set all angle ranges to None when using symmetry.\"\n            )\n\n        # Case where symmetry group is provided, validate the symmetry\n        if self.symmetry:\n            match = re.match(r\"([A-Za-z]+)(\\d*)$\", self.symmetry)\n            if not match:\n                raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n        # If we reach here, it means that either symmetry is set or angle ranges are set\n        # but not both, so we can proceed.\n        return self\n\n    @property\n    def euler_angles(self) -&gt; torch.Tensor:\n        \"\"\"Returns the Euler angles ('ZYZ' convention) to search over.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of orientations to\n            search over. The columns represent the psi, theta, and phi angles\n            respectively.\n        \"\"\"\n        # If the symmetry used for the angular ranges, calculate the angular ranges\n        # based on the symmetry group.\n        if self.symmetry is not None:\n            match = re.match(r\"([A-Za-z]+)(\\d*)\", self.symmetry)\n            if match is None:\n                raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n            sym_group = match.group(1)\n            sym_order = int(match.group(2)) if match.group(2) else 1\n            (phi_min, phi_max, theta_min, theta_max, psi_min, psi_max) = (\n                get_symmetry_ranges(sym_group, sym_order)\n            )\n        # Otherwise, use the provided angular ranges replacing with default values if\n        # any are set to None.\n        else:\n            phi_min = self.phi_min if self.phi_min is not None else 0.0\n            phi_max = self.phi_max if self.phi_max is not None else 360.0\n            theta_min = self.theta_min if self.theta_min is not None else 0.0\n            theta_max = self.theta_max if self.theta_max is not None else 180.0\n            psi_min = self.psi_min if self.psi_min is not None else 0.0\n            psi_max = self.psi_max if self.psi_max is not None else 360.0\n\n        # Generate angles\n        return get_uniform_euler_angles(\n            psi_step=self.psi_step,\n            theta_step=self.theta_step,\n            phi_min=phi_min,\n            phi_max=phi_max,\n            theta_min=theta_min,\n            theta_max=theta_max,\n            psi_min=psi_min,\n            psi_max=psi_max,\n            base_grid_method=self.base_grid_method,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.OrientationSearchConfig.euler_angles","title":"<code>euler_angles</code>  <code>property</code>","text":"<p>Returns the Euler angles ('ZYZ' convention) to search over.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of orientations to search over. The columns represent the psi, theta, and phi angles respectively.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.OrientationSearchConfig.validate_angle_ranges_and_symmetry","title":"<code>validate_angle_ranges_and_symmetry()</code>","text":"<p>Validate that angle ranges are consistent with symmetry.</p> <p>There should be only two valid cases for combinations of manually defined angle ranges and the symmetry group: 1. Symmetry argument is not None, and all angle min/max values    are set to None. In this case, the angle ranges will be set based on    the symmetry group. 2. Symmetry argument is None, and all angle min/max values are not None.</p> <p>If any other combination is provided, a ValueError will be raised.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>@model_validator(mode=\"after\")  # type: ignore\ndef validate_angle_ranges_and_symmetry(self) -&gt; Self:\n    \"\"\"Validate that angle ranges are consistent with symmetry.\n\n    There should be only two valid cases for combinations of manually defined\n    angle ranges and the symmetry group:\n    1. Symmetry argument is *not* None, and all angle min/max values\n       are set to None. In this case, the angle ranges will be set based on\n       the symmetry group.\n    2. Symmetry argument is None, and all angle min/max values are not None.\n\n    If any other combination is provided, a ValueError will be raised.\n    \"\"\"\n    _all_none = all(\n        x is None\n        for x in [\n            self.phi_min,\n            self.phi_max,\n            self.theta_min,\n            self.theta_max,\n            self.psi_min,\n            self.psi_max,\n        ]\n    )\n\n    # Check that both symmetry and angle ranges are not None\n    if not self.symmetry and _all_none:\n        raise ValueError(\n            \"Either a symmetry group must be provided, or all angle ranges must \"\n            \"not be None. Both symmetry and angle ranges were set to None.\"\n        )\n\n    # Case where both symmetry and angle ranges are provided\n    if self.symmetry and not _all_none:\n        raise ValueError(\n            \"Symmetry group is provided, but angle ranges are also set. \"\n            \"Please set all angle ranges to None when using symmetry.\"\n        )\n\n    # Case where symmetry group is provided, validate the symmetry\n    if self.symmetry:\n        match = re.match(r\"([A-Za-z]+)(\\d*)$\", self.symmetry)\n        if not match:\n            raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n    # If we reach here, it means that either symmetry is set or angle ranges are set\n    # but not both, so we can proceed.\n    return self\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PhaseRandomizationFilterConfig","title":"<code>PhaseRandomizationFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for phase randomization filter.</p> <p>NOTE: Something is not working with the underlying torch_fourier_filter code for phase randomization.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a phase randomization filter to the input image. Default is False.</p> <code>cuton</code> <code>float</code> <p>Spatial resolution, in terms of Nyquist, above which to randomize the phase.</p> <p>Methods:</p> Name Description <code>calculate_phase_randomization_filter</code> <p>Helper function for the phase randomization filter based on the input reference image and held configuration parameters.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class PhaseRandomizationFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for phase randomization filter.\n\n    NOTE: Something is not working with the underlying torch_fourier_filter code\n    for phase randomization.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a phase randomization filter to the input image. Default\n        is False.\n    cuton : float\n        Spatial resolution, in terms of Nyquist, above which to randomize the phase.\n\n    Methods\n    -------\n    calculate_phase_randomization_filter(ref_img_rfft)\n        Helper function for the phase randomization filter based on the input reference\n        image and held configuration parameters.\n    \"\"\"\n\n    enabled: bool = False\n    cuton: Optional[Annotated[float, Field(ge=0.0)]] = None\n\n    def calculate_phase_randomization_filter(\n        self, ref_img_rfft: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"Helper function for phase randomization filter based on the reference image.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            The reference image to use as a template for phase randomization. This\n            should be RFFT'd and unshifted (zero-frequency component at the top-left\n            corner).\n        \"\"\"\n        output_shape = ref_img_rfft.shape\n\n        # Handle case where phase randomization filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n        # Fix for underlying shape bug in torch_fourier_filter\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return phase_randomize(\n            dft=ref_img_rfft,\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n            cuton=self.cuton,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PhaseRandomizationFilterConfig.calculate_phase_randomization_filter","title":"<code>calculate_phase_randomization_filter(ref_img_rfft)</code>","text":"<p>Helper function for phase randomization filter based on the reference image.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>The reference image to use as a template for phase randomization. This should be RFFT'd and unshifted (zero-frequency component at the top-left corner).</p> required Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_phase_randomization_filter(\n    self, ref_img_rfft: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"Helper function for phase randomization filter based on the reference image.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        The reference image to use as a template for phase randomization. This\n        should be RFFT'd and unshifted (zero-frequency component at the top-left\n        corner).\n    \"\"\"\n    output_shape = ref_img_rfft.shape\n\n    # Handle case where phase randomization filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n    # Fix for underlying shape bug in torch_fourier_filter\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return phase_randomize(\n        dft=ref_img_rfft,\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n        cuton=self.cuton,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PixelSizeSearchConfig","title":"<code>PixelSizeSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of pixel size search parameters for 2DTM.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable pixel size search. Default is False.</p> <code>pixel_size_min</code> <code>float</code> <p>Minimum searched pixel size in units of Angstroms.</p> <code>pixel_size_max</code> <code>float</code> <p>Maximum searched pixel size in units of Angstroms.</p> <code>pixel_size_step</code> <code>float</code> <p>Step size for pixel size search in units of Angstroms.</p> <code>skip_enforce_zero</code> <code>bool</code> <p>Whether to skip enforcing a zero value, by default False.</p> Properties <p>pixel_size_values : torch.Tensor     Tensor of pixel sizes to search over based on held params.</p> Source code in <code>src/leopard_em/pydantic_models/config/pixel_size_search.py</code> <pre><code>class PixelSizeSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of pixel size search parameters for 2DTM.\n\n    Attributes\n    ----------\n    enabled : bool\n        Whether to enable pixel size search. Default is False.\n    pixel_size_min : float\n        Minimum searched pixel size in units of Angstroms.\n    pixel_size_max : float\n        Maximum searched pixel size in units of Angstroms.\n    pixel_size_step : float\n        Step size for pixel size search in units of Angstroms.\n    skip_enforce_zero : bool\n        Whether to skip enforcing a zero value, by default False.\n\n    Properties\n    ----------\n    pixel_size_values : torch.Tensor\n        Tensor of pixel sizes to search over based on held params.\n    \"\"\"\n\n    enabled: bool = False\n    pixel_size_min: float = 0.0\n    pixel_size_max: float = 0.0\n    pixel_size_step: Annotated[float, Field(..., gt=0.0)] = 0.0\n    skip_enforce_zero: bool = False\n\n    @property\n    def pixel_size_values(self) -&gt; torch.Tensor:\n        \"\"\"Pixel sizes to search over based on held params.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of pixel sizes to search over, in units of Angstroms.\n\n        Raises\n        ------\n        ValueError\n            If pixel size search parameters result in no pixel sizes to search over.\n        \"\"\"\n        # Return a relative pixel size of 0.0 if search is disabled.\n        if not self.enabled:\n            return torch.tensor([0.0])\n\n        # Check if parameters would result in valid range before calling arange\n        if self.pixel_size_max &lt; self.pixel_size_min:\n            raise ValueError(\n                \"Pixel size search parameters result in no values to search over!\\n\"\n                f\"  self.pixel_size_min: {self.pixel_size_min}\\n\"\n                f\"  self.pixel_size_max: {self.pixel_size_max}\\n\"\n                f\"  self.pixel_size_step: {self.pixel_size_step}\\n\"\n            )\n\n        return get_search_tensors(\n            self.pixel_size_min,\n            self.pixel_size_max,\n            self.pixel_size_step,\n            self.skip_enforce_zero,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PixelSizeSearchConfig.pixel_size_values","title":"<code>pixel_size_values</code>  <code>property</code>","text":"<p>Pixel sizes to search over based on held params.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of pixel sizes to search over, in units of Angstroms.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pixel size search parameters result in no pixel sizes to search over.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PreprocessingFilters","title":"<code>PreprocessingFilters</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration class for all preprocessing filters.</p> <p>Attributes:</p> Name Type Description <code>whitening_filter_config</code> <code>WhiteningFilterConfig</code> <p>Configuration for the whitening filter.</p> <code>bandpass_filter_config</code> <code>BandpassFilterConfig</code> <p>Configuration for the bandpass filter.</p> <code>phase_randomization_filter_config</code> <code>PhaseRandomizationFilterConfig</code> <p>Configuration for the phase randomization filter.</p> <code>arbitrary_curve_filter_config</code> <code>ArbitraryCurveFilterConfig</code> <p>Configuration for the arbitrary curve filter.</p> <p>Methods:</p> Name Description <code>combined_filter</code> <p>Calculate and combine all Fourier filters into a single filter.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class PreprocessingFilters(BaseModel2DTM):\n    \"\"\"Configuration class for all preprocessing filters.\n\n    Attributes\n    ----------\n    whitening_filter_config : WhiteningFilterConfig\n        Configuration for the whitening filter.\n    bandpass_filter_config : BandpassFilterConfig\n        Configuration for the bandpass filter.\n    phase_randomization_filter_config : PhaseRandomizationFilterConfig\n        Configuration for the phase randomization filter.\n    arbitrary_curve_filter_config : ArbitraryCurveFilterConfig\n        Configuration for the arbitrary curve filter.\n\n    Methods\n    -------\n    combined_filter(ref_img_rfft, output_shape)\n        Calculate and combine all Fourier filters into a single filter.\n    \"\"\"\n\n    whitening_filter: WhiteningFilterConfig = WhiteningFilterConfig()\n    bandpass_filter: BandpassFilterConfig = BandpassFilterConfig()\n    phase_randomization_filter: PhaseRandomizationFilterConfig = (\n        PhaseRandomizationFilterConfig()\n    )\n    arbitrary_curve_filter: ArbitraryCurveFilterConfig = ArbitraryCurveFilterConfig()\n\n    def get_combined_filter(\n        self, ref_img_rfft: torch.Tensor, output_shape: tuple[int, ...]\n    ) -&gt; torch.Tensor:\n        \"\"\"Combine all filters into a single filter.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            Reference image to use for calculating the filters.\n        output_shape : tuple[int, ...]\n            Desired output shape of the combined filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The combined filter for the desired output shape.\n        \"\"\"\n        # NOTE: Phase randomization filter is not currently enabled\n        # pr_config = self.phase_randomization_filter\n        wf_config = self.whitening_filter\n        bf_config = self.bandpass_filter\n        ac_config = self.arbitrary_curve_filter\n\n        # Calculate each of the filters in turn\n        # phase_randomization_filter = pr_config.calculate_phase_randomization_filter(\n        #     ref_img_rfft=ref_img_rfft\n        # )\n        whitening_filter_tensor = wf_config.calculate_whitening_filter(\n            ref_img_rfft=ref_img_rfft, output_shape=output_shape\n        )\n        bandpass_filter_tensor = bf_config.calculate_bandpass_filter(\n            output_shape=output_shape\n        )\n        arbitrary_curve_filter_tensor = ac_config.calculate_arbitrary_curve_filter(\n            output_shape=output_shape\n        )\n\n        combined_filter = (\n            whitening_filter_tensor\n            * bandpass_filter_tensor\n            * arbitrary_curve_filter_tensor\n        )\n\n        return combined_filter\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.PreprocessingFilters.get_combined_filter","title":"<code>get_combined_filter(ref_img_rfft, output_shape)</code>","text":"<p>Combine all filters into a single filter.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>Reference image to use for calculating the filters.</p> required <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the combined filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The combined filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def get_combined_filter(\n    self, ref_img_rfft: torch.Tensor, output_shape: tuple[int, ...]\n) -&gt; torch.Tensor:\n    \"\"\"Combine all filters into a single filter.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        Reference image to use for calculating the filters.\n    output_shape : tuple[int, ...]\n        Desired output shape of the combined filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The combined filter for the desired output shape.\n    \"\"\"\n    # NOTE: Phase randomization filter is not currently enabled\n    # pr_config = self.phase_randomization_filter\n    wf_config = self.whitening_filter\n    bf_config = self.bandpass_filter\n    ac_config = self.arbitrary_curve_filter\n\n    # Calculate each of the filters in turn\n    # phase_randomization_filter = pr_config.calculate_phase_randomization_filter(\n    #     ref_img_rfft=ref_img_rfft\n    # )\n    whitening_filter_tensor = wf_config.calculate_whitening_filter(\n        ref_img_rfft=ref_img_rfft, output_shape=output_shape\n    )\n    bandpass_filter_tensor = bf_config.calculate_bandpass_filter(\n        output_shape=output_shape\n    )\n    arbitrary_curve_filter_tensor = ac_config.calculate_arbitrary_curve_filter(\n        output_shape=output_shape\n    )\n\n    combined_filter = (\n        whitening_filter_tensor\n        * bandpass_filter_tensor\n        * arbitrary_curve_filter_tensor\n    )\n\n    return combined_filter\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.RefineOrientationConfig","title":"<code>RefineOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of orientation refinement parameters.</p> <p>Angles will be sampled from [-coarse_step, coarse_step] in increments of 'fine_step' for the orientation refinement search.</p> <p>Attributes:</p> Name Type Description <code>orientation_sampling_method</code> <code>str</code> <p>Method for sampling orientations. Default is 'Hopf Fibration'. Currently only 'Hopf Fibration' is supported.</p> <code>template_symmetry</code> <code>str</code> <p>Symmetry group of the template. Default is 'C1'. Currently only 'C1' is supported.</p> <code>phi_step_coarse</code> <code>float</code> <p>Angular step size for phi in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.phi_step' value for the match template program. Must be greater than or equal to 0.</p> <code>phi_step_fine</code> <code>float</code> <p>Angular step size for phi in degrees for current, fine search. Must be greater than or equal to 0.</p> <code>theta_step_coarse</code> <code>float</code> <p>Angular step size for theta in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.theta_step' value for the match template program. Must be greater than or equal to 0.</p> <code>theta_step_fine</code> <code>float</code> <p>Angular step size for theta in degrees for current, fine search. Must be greater than or equal to 0.</p> <code>psi_step_coarse</code> <code>float</code> <p>Angular step size for psi in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.psi_step' value for the match template program. Must be greater than or equal to 0.</p> <code>psi_step_fine</code> <code>float</code> <p>Angular step size for psi in degrees for current, fine search. Must be greater than or equal to 0.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class RefineOrientationConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of orientation refinement parameters.\n\n    Angles will be sampled from [-coarse_step, coarse_step] in increments of\n    'fine_step' for the orientation refinement search.\n\n    Attributes\n    ----------\n    orientation_sampling_method : str\n        Method for sampling orientations. Default is 'Hopf Fibration'.\n        Currently only 'Hopf Fibration' is supported.\n    template_symmetry : str\n        Symmetry group of the template. Default is 'C1'.\n        Currently only 'C1' is supported.\n    phi_step_coarse : float\n        Angular step size for phi in degrees for previous, coarse search.\n        This corresponds to the 'OrientationSearchConfig.phi_step' value\n        for the match template program. Must be greater than or equal to 0.\n    phi_step_fine : float\n        Angular step size for phi in degrees for current, fine search.\n        Must be greater than or equal to 0.\n    theta_step_coarse : float\n        Angular step size for theta in degrees for previous, coarse\n        search. This corresponds to the\n        'OrientationSearchConfig.theta_step' value for the match template\n        program. Must be greater than or equal to 0.\n    theta_step_fine : float\n        Angular step size for theta in degrees for current, fine search.\n        Must be greater than or equal to 0.\n    psi_step_coarse : float\n        Angular step size for psi in degrees for previous, coarse search.\n        This corresponds to the 'OrientationSearchConfig.psi_step' value\n        for the match template program. Must be greater than or equal to 0.\n    psi_step_fine : float\n        Angular step size for psi in degrees for current, fine search.\n        Must be greater than or equal to 0.\n\n    \"\"\"\n\n    enabled: bool = True\n    phi_step_coarse: Annotated[float, Field(..., ge=0.0)] = 2.5\n    phi_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.25\n    theta_step_coarse: Annotated[float, Field(..., ge=0.0)] = 2.5\n    theta_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.25\n    psi_step_coarse: Annotated[float, Field(..., ge=0.0)] = 1.5\n    psi_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.1\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"basic\"] = \"uniform\"\n\n    @property\n    def euler_angles_offsets(self) -&gt; torch.Tensor:\n        \"\"\"Return the Euler angle offsets to search over.\n\n        Note that this method uses a uniform grid search which approximates SO(3) space\n        well when the angular ranges are small (e.g. \u00b12.5 degrees).\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of orientations to\n            search over. The columns represent the phi, theta, and psi angles,\n            respectively, in the 'ZYZ' convention.\n        \"\"\"\n        if not self.enabled:\n            return torch.zeros((1, 3))\n\n        return get_local_high_resolution_angles(\n            coarse_phi_step=self.phi_step_coarse,\n            coarse_theta_step=self.theta_step_coarse,\n            coarse_psi_step=self.psi_step_coarse,\n            fine_phi_step=self.phi_step_fine,\n            fine_theta_step=self.theta_step_fine,\n            fine_psi_step=self.psi_step_fine,\n            base_grid_method=self.base_grid_method,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.RefineOrientationConfig.euler_angles_offsets","title":"<code>euler_angles_offsets</code>  <code>property</code>","text":"<p>Return the Euler angle offsets to search over.</p> <p>Note that this method uses a uniform grid search which approximates SO(3) space well when the angular ranges are small (e.g. \u00b12.5 degrees).</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of orientations to search over. The columns represent the phi, theta, and psi angles, respectively, in the 'ZYZ' convention.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.WhiteningFilterConfig","title":"<code>WhiteningFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for the whitening filter.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a whitening filter to the input image and template projections. Default is True.</p> <code>num_freq_bins</code> <code>Optional[int]</code> <p>Number of frequency bins (in 1D) to use when calculating the power spectrum. Default is None which automatically determines the number of bins based on the input image size.</p> <code>max_freq</code> <code>Optional[float]</code> <p>Maximum frequency, in terms of Nyquist frequency, to use when calculating the whitening filter. Default is 0.5 with values pixels above 0.5 being set to 1.0 in the filter (i.e. no frequency scaling).</p> <code>do_power_spectrum</code> <code>Optional[bool]</code> <p>If True, calculate the power spectral density from the power of the input image. Default is True. If False, then the power spectral density is calculated from the amplitude of the input image.</p> <p>Methods:</p> Name Description <code>calculate_whitening_filter</code> <p>Helper function for the whitening filter based on the input reference image and held configuration parameters.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class WhiteningFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for the whitening filter.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a whitening filter to the input image and template projections.\n        Default is True.\n    num_freq_bins : Optional[int]\n        Number of frequency bins (in 1D) to use when calculating the power spectrum.\n        Default is None which automatically determines the number of bins based on the\n        input image size.\n    max_freq : Optional[float]\n        Maximum frequency, in terms of Nyquist frequency, to use when calculating the\n        whitening filter. Default is 0.5 with values pixels above 0.5 being set to 1.0\n        in the filter (i.e. no frequency scaling).\n    do_power_spectrum : Optional[bool]\n        If True, calculate the power spectral density from the power of the\n        input image. Default is True. If False, then the power spectral density is\n        calculated from the amplitude of the input image.\n\n    Methods\n    -------\n    calculate_whitening_filter(ref_img_rfft, output_shape, output_rfft, output_fftshift)\n        Helper function for the whitening filter based on the input reference image and\n        held configuration parameters.\n    \"\"\"\n\n    enabled: bool = True\n    num_freq_bins: Optional[int] = None\n    max_freq: Optional[float] = 0.5  # in terms of Nyquist frequency\n    do_power_spectrum: Optional[bool] = True\n\n    def calculate_whitening_filter(\n        self,\n        ref_img_rfft: torch.Tensor,\n        output_shape: Optional[tuple[int, ...]] = None,\n        output_rfft: bool = True,\n        output_fftshift: bool = False,\n    ) -&gt; torch.Tensor:\n        \"\"\"Helper function for the whitening filter based on the input reference image.\n\n        NOTE: This function is a wrapper around the `whitening_filter` function from\n        the `torch_fourier_filter` package. It expects the input image to be RFFT'd\n        and unshifted (zero-frequency component at the top-left corner). The output\n        can be of any shape, but the default is to return a filer of the same input\n        shape.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            The reference image (RFFT'd and unshifted) to calculate the whitening\n            filter from.\n        output_shape : Optional[tuple[int, ...]]\n            Desired output shape of the whitening filter. This is the filter shape in\n            Fourier space *not* real space (like in the torch_fourier_filter package).\n            Default is None, which is the same as the input shape.\n        output_rfft : Optional[bool]\n            If True, filter corresponds to a Fourier transform using the RFFT.\n            Default is None, which is the same as the 'rfft' parameter.\n        output_fftshift : Optional[bool]\n            If True, filter corresponds to a Fourier transform followed\n            by an fftshift. Default is None, which is the same as the 'fftshift'\n            parameter.\n\n        Returns\n        -------\n        torch.Tensor\n            The whitening filter with frequencies calculated from the input reference\n            image.\n        \"\"\"\n        if output_shape is None:\n            output_shape = ref_img_rfft.shape\n\n        # Handle case where whitening filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return whitening_filter(\n            image_dft=ref_img_rfft,\n            rfft=True,\n            fftshift=False,\n            dim=(-2, -1),\n            num_freq_bins=self.num_freq_bins,\n            max_freq=self.max_freq,\n            do_power_spectrum=self.do_power_spectrum,\n            output_shape=output_shape,\n            output_rfft=output_rfft,\n            output_fftshift=output_fftshift,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/#leopard_em.pydantic_models.config.WhiteningFilterConfig.calculate_whitening_filter","title":"<code>calculate_whitening_filter(ref_img_rfft, output_shape=None, output_rfft=True, output_fftshift=False)</code>","text":"<p>Helper function for the whitening filter based on the input reference image.</p> <p>NOTE: This function is a wrapper around the <code>whitening_filter</code> function from the <code>torch_fourier_filter</code> package. It expects the input image to be RFFT'd and unshifted (zero-frequency component at the top-left corner). The output can be of any shape, but the default is to return a filer of the same input shape.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>The reference image (RFFT'd and unshifted) to calculate the whitening filter from.</p> required <code>output_shape</code> <code>Optional[tuple[int, ...]]</code> <p>Desired output shape of the whitening filter. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package). Default is None, which is the same as the input shape.</p> <code>None</code> <code>output_rfft</code> <code>Optional[bool]</code> <p>If True, filter corresponds to a Fourier transform using the RFFT. Default is None, which is the same as the 'rfft' parameter.</p> <code>True</code> <code>output_fftshift</code> <code>Optional[bool]</code> <p>If True, filter corresponds to a Fourier transform followed by an fftshift. Default is None, which is the same as the 'fftshift' parameter.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The whitening filter with frequencies calculated from the input reference image.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_whitening_filter(\n    self,\n    ref_img_rfft: torch.Tensor,\n    output_shape: Optional[tuple[int, ...]] = None,\n    output_rfft: bool = True,\n    output_fftshift: bool = False,\n) -&gt; torch.Tensor:\n    \"\"\"Helper function for the whitening filter based on the input reference image.\n\n    NOTE: This function is a wrapper around the `whitening_filter` function from\n    the `torch_fourier_filter` package. It expects the input image to be RFFT'd\n    and unshifted (zero-frequency component at the top-left corner). The output\n    can be of any shape, but the default is to return a filer of the same input\n    shape.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        The reference image (RFFT'd and unshifted) to calculate the whitening\n        filter from.\n    output_shape : Optional[tuple[int, ...]]\n        Desired output shape of the whitening filter. This is the filter shape in\n        Fourier space *not* real space (like in the torch_fourier_filter package).\n        Default is None, which is the same as the input shape.\n    output_rfft : Optional[bool]\n        If True, filter corresponds to a Fourier transform using the RFFT.\n        Default is None, which is the same as the 'rfft' parameter.\n    output_fftshift : Optional[bool]\n        If True, filter corresponds to a Fourier transform followed\n        by an fftshift. Default is None, which is the same as the 'fftshift'\n        parameter.\n\n    Returns\n    -------\n    torch.Tensor\n        The whitening filter with frequencies calculated from the input reference\n        image.\n    \"\"\"\n    if output_shape is None:\n        output_shape = ref_img_rfft.shape\n\n    # Handle case where whitening filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return whitening_filter(\n        image_dft=ref_img_rfft,\n        rfft=True,\n        fftshift=False,\n        dim=(-2, -1),\n        num_freq_bins=self.num_freq_bins,\n        max_freq=self.max_freq,\n        do_power_spectrum=self.do_power_spectrum,\n        output_shape=output_shape,\n        output_rfft=output_rfft,\n        output_fftshift=output_fftshift,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/computational_config/","title":"computational_config","text":"<p>Computational configuration for 2DTM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/computational_config/#leopard_em.pydantic_models.config.computational_config.ComputationalConfig","title":"<code>ComputationalConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Serialization of computational resources allocated for 2DTM.</p> <p>NOTE: The field <code>gpu_ids</code> is not validated at instantiation past being one of the valid types. For example, if \"cuda:0\" is specified but no CUDA device is available, the instantiation will succeed, and only upon translating <code>gpu_ids</code> to a list of <code>torch.device</code> objects will an error be raised. This is done to allow for configuration files to be loaded without requiring the actual hardware to be present at the time of loading.</p> <p>Attributes:</p> Name Type Description <code>gpu_ids</code> <code>Optional[Union[int, list[int], str, list[str]]]</code> <p>Field which specifies which GPUs to use for computation. The following types of values are allowed: - A single integer, e.g. 0, which means to use GPU with ID 0. - A list of integers, e.g. [0, 2], which means to use GPUs with IDs 0 and 2. - A device specifier string, e.g. \"cuda:0\", which means to use GPU with ID 0. - A list of device specifier strings, e.g. [\"cuda:0\", \"cuda:1\"], which means to   use GPUs with IDs 0 and 1. - The specific string \"all\" which means to use all available GPUs identified   by torch.cuda.device_count(). - The specific string \"cpu\" which means to use CPU.</p> <code>num_cpus</code> <code>int</code> <p>Total number of CPUs to use, defaults to 1.</p> Source code in <code>src/leopard_em/pydantic_models/config/computational_config.py</code> <pre><code>class ComputationalConfig(BaseModel):\n    \"\"\"Serialization of computational resources allocated for 2DTM.\n\n    NOTE: The field `gpu_ids` is not validated at instantiation past being one of the\n    valid types. For example, if \"cuda:0\" is specified but no CUDA device is available,\n    the instantiation will succeed, and only upon translating `gpu_ids` to a list of\n    `torch.device` objects will an error be raised. This is done to allow for\n    configuration files to be loaded without requiring the actual hardware to be\n    present at the time of loading.\n\n    Attributes\n    ----------\n    gpu_ids : Optional[Union[int, list[int], str, list[str]]]\n        Field which specifies which GPUs to use for computation. The following types\n        of values are allowed:\n        - A single integer, e.g. 0, which means to use GPU with ID 0.\n        - A list of integers, e.g. [0, 2], which means to use GPUs with IDs 0 and 2.\n        - A device specifier string, e.g. \"cuda:0\", which means to use GPU with ID 0.\n        - A list of device specifier strings, e.g. [\"cuda:0\", \"cuda:1\"], which means to\n          use GPUs with IDs 0 and 1.\n        - The specific string \"all\" which means to use all available GPUs identified\n          by torch.cuda.device_count().\n        - The specific string \"cpu\" which means to use CPU.\n    num_cpus : int\n        Total number of CPUs to use, defaults to 1.\n    \"\"\"\n\n    # Type-hinting here is ensuring non-negative integers, and list of at least one\n    gpu_ids: Optional[\n        Union[\n            str,\n            NonNegativeInt,\n            Annotated[list[NonNegativeInt], Field(min_length=1)],\n            Annotated[list[str], Field(min_length=1)],\n        ]\n    ] = [0]\n    num_cpus: Annotated[int, Field(ge=1)] = 1\n\n    @property\n    def gpu_devices(self) -&gt; list[torch.device]:\n        \"\"\"Convert requested GPU IDs to torch device objects.\n\n        Returns\n        -------\n        list[torch.device]\n        \"\"\"\n        # Handle special string cases first\n        if self.gpu_ids == \"all\":\n            if not torch.cuda.is_available():\n                raise ValueError(\"No CUDA devices available.\")\n            return [torch.device(f\"cuda:{i}\") for i in range(torch.cuda.device_count())]\n\n        if self.gpu_ids == \"cpu\":\n            return [torch.device(\"cpu\")]\n\n        # Normalize to list for uniform processing\n        gpu_list = self.gpu_ids if isinstance(self.gpu_ids, list) else [self.gpu_ids]\n\n        # Process each item in the normalized list\n        devices = []\n        for gpu_id in gpu_list:\n            if isinstance(gpu_id, int):\n                devices.append(torch.device(f\"cuda:{gpu_id}\"))\n            elif isinstance(gpu_id, str):\n                devices.append(torch.device(gpu_id))\n            else:\n                raise TypeError(\n                    f\"Invalid type for gpu_ids element: {type(gpu_id)}. \"\n                    \"Expected int or str.\"\n                )\n\n        return devices\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/computational_config/#leopard_em.pydantic_models.config.computational_config.ComputationalConfig.gpu_devices","title":"<code>gpu_devices</code>  <code>property</code>","text":"<p>Convert requested GPU IDs to torch device objects.</p> <p>Returns:</p> Type Description <code>list[device]</code>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/","title":"correlation_filters","text":"<p>Set of classes for configuring correlation filters in 2DTM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.ArbitraryCurveFilterConfig","title":"<code>ArbitraryCurveFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Class holding frequency and amplitude values for arbitrary curve filter.</p> <p>Attributes:</p> Name Type Description <code>frequencies</code> <code>list[float]</code> <p>List of spatial frequencies (in terms of Nyquist) for the corresponding amplitudes.</p> <code>amplitudes</code> <code>list[float]</code> <p>List of amplitudes for the corresponding spatial frequencies.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class ArbitraryCurveFilterConfig(BaseModel2DTM):\n    \"\"\"Class holding frequency and amplitude values for arbitrary curve filter.\n\n    Attributes\n    ----------\n    frequencies : list[float]\n        List of spatial frequencies (in terms of Nyquist) for the corresponding\n        amplitudes.\n    amplitudes : list[float]\n        List of amplitudes for the corresponding spatial frequencies.\n    \"\"\"\n\n    enabled: bool = False\n    frequencies: Optional[list[float]] = None  # in terms of Nyquist frequency\n    amplitudes: Optional[list[float]] = None\n\n    def calculate_arbitrary_curve_filter(\n        self, output_shape: tuple[int, ...]\n    ) -&gt; torch.Tensor:\n        \"\"\"Calculates the curve filter for the desired output shape.\n\n        Parameters\n        ----------\n        output_shape : tuple[int, ...]\n            Desired output shape of the curve filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The curve filter for the desired output shape.\n        \"\"\"\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=torch.float32)\n\n        # Ensure that neither frequencies nor amplitudes are None\n        if self.frequencies is None or self.amplitudes is None:\n            raise ValueError(\n                \"When enabled, both 'frequencies' and 'amplitudes' must be provided.\"\n            )\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        freq_grid = fftfreq_grid(\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n            norm=True,\n        )\n\n        frequencies = torch.tensor(self.frequencies)\n        amplitudes = torch.tensor(self.amplitudes)\n        filter_ndim = curve_1dim_to_ndim(\n            frequency_1d=frequencies,\n            values_1d=amplitudes,\n            frequency_grid=freq_grid,\n            fill_lower=1.0,  # Fill oob areas with ones (no scaling)\n            fill_upper=1.0,\n        )\n\n        return filter_ndim\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.ArbitraryCurveFilterConfig.calculate_arbitrary_curve_filter","title":"<code>calculate_arbitrary_curve_filter(output_shape)</code>","text":"<p>Calculates the curve filter for the desired output shape.</p> <p>Parameters:</p> Name Type Description Default <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the curve filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The curve filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_arbitrary_curve_filter(\n    self, output_shape: tuple[int, ...]\n) -&gt; torch.Tensor:\n    \"\"\"Calculates the curve filter for the desired output shape.\n\n    Parameters\n    ----------\n    output_shape : tuple[int, ...]\n        Desired output shape of the curve filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The curve filter for the desired output shape.\n    \"\"\"\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=torch.float32)\n\n    # Ensure that neither frequencies nor amplitudes are None\n    if self.frequencies is None or self.amplitudes is None:\n        raise ValueError(\n            \"When enabled, both 'frequencies' and 'amplitudes' must be provided.\"\n        )\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    freq_grid = fftfreq_grid(\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n        norm=True,\n    )\n\n    frequencies = torch.tensor(self.frequencies)\n    amplitudes = torch.tensor(self.amplitudes)\n    filter_ndim = curve_1dim_to_ndim(\n        frequency_1d=frequencies,\n        values_1d=amplitudes,\n        frequency_grid=freq_grid,\n        fill_lower=1.0,  # Fill oob areas with ones (no scaling)\n        fill_upper=1.0,\n    )\n\n    return filter_ndim\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.BandpassFilterConfig","title":"<code>BandpassFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for the bandpass filter.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a bandpass filter to correlation during template matching. Default is False.</p> <code>low_freq_cutoff</code> <code>Optional[float]</code> <p>Low pass filter cutoff frequency. Default is None, which is no low pass filter.</p> <code>high_freq_cutoff</code> <code>Optional[float]</code> <p>High pass filter cutoff frequency. Default is None, which is no high pass filter.</p> <code>falloff</code> <code>Optional[float]</code> <p>Falloff factor for bandpass filter. Default is 0.0, which is no falloff.</p> <p>Methods:</p> Name Description <code>from_spatial_resolution</code> <p>Helper method to instantiate a bandpass filter from spatial resolutions and a pixel size.</p> <code>calculate_bandpass_filter</code> <p>Helper function for bandpass filter based on the desired output shape. This method returns a filter for a RFFT'd and unshifted (zero-frequency component at the top-left corner) image.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class BandpassFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for the bandpass filter.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a bandpass filter to correlation during template\n        matching. Default is False.\n    low_freq_cutoff : Optional[float]\n        Low pass filter cutoff frequency. Default is None, which is no low\n        pass filter.\n    high_freq_cutoff : Optional[float]\n        High pass filter cutoff frequency. Default is None, which is no high\n        pass filter.\n    falloff : Optional[float]\n        Falloff factor for bandpass filter. Default is 0.0, which is no\n        falloff.\n\n    Methods\n    -------\n    from_spatial_resolution(low_resolution, high_resolution, pixel_size, **kwargs)\n        Helper method to instantiate a bandpass filter from spatial resolutions and\n        a pixel size.\n    calculate_bandpass_filter(output_shape)\n        Helper function for bandpass filter based on the desired output shape. This\n        method returns a filter for a RFFT'd and unshifted (zero-frequency component\n        at the top-left corner) image.\n    \"\"\"\n\n    enabled: bool = False\n    low_freq_cutoff: Optional[Annotated[float, Field(ge=0.0)]] = None\n    high_freq_cutoff: Optional[Annotated[float, Field(ge=0.0)]] = None\n    falloff: Optional[Annotated[float, Field(ge=0.0)]] = None\n\n    @classmethod\n    def from_spatial_resolution(\n        cls,\n        low_resolution: float,\n        high_resolution: float,\n        pixel_size: float,\n        **kwargs: dict[str, Any],\n    ) -&gt; \"BandpassFilterConfig\":\n        \"\"\"Helper method to instantiate a bandpass filter from spatial resolutions.\n\n        Parameters\n        ----------\n        low_resolution : float\n            Low resolution cutoff frequency in Angstroms.\n        high_resolution : float\n            High resolution cutoff frequency in Angstroms.\n        pixel_size : float\n            Pixel size in Angstroms.\n        **kwargs\n            Additional keyword arguments to pass to the constructor method.\n\n        Returns\n        -------\n        BandpassFilterConfig\n            Bandpass filter configuration object.\n        \"\"\"\n        low_freq_cutoff = pixel_size / low_resolution\n        high_freq_cutoff = pixel_size / high_resolution\n\n        return cls(\n            low_freq_cutoff=low_freq_cutoff,\n            high_freq_cutoff=high_freq_cutoff,\n            **kwargs,\n        )\n\n    def calculate_bandpass_filter(self, output_shape: tuple[int, ...]) -&gt; torch.Tensor:\n        \"\"\"Helper function for bandpass filter based on the desired output shape.\n\n        Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency\n        component at the top-left corner) image.\n\n        Parameters\n        ----------\n        output_shape : tuple[int, ...]\n            Desired output shape of the bandpass filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The bandpass filter for the desired output shape.\n        \"\"\"\n        # Handle case where bandpass filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=torch.float32)\n\n        # Account for None values\n        low = self.low_freq_cutoff if self.low_freq_cutoff is not None else 0.0\n        high = self.high_freq_cutoff if self.high_freq_cutoff is not None else 1.0\n        falloff = self.falloff if self.falloff is not None else 0.0\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return bandpass_filter(\n            low=low,\n            high=high,\n            falloff=falloff,\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.BandpassFilterConfig.calculate_bandpass_filter","title":"<code>calculate_bandpass_filter(output_shape)</code>","text":"<p>Helper function for bandpass filter based on the desired output shape.</p> <p>Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency component at the top-left corner) image.</p> <p>Parameters:</p> Name Type Description Default <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the bandpass filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The bandpass filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_bandpass_filter(self, output_shape: tuple[int, ...]) -&gt; torch.Tensor:\n    \"\"\"Helper function for bandpass filter based on the desired output shape.\n\n    Note that the output will be in terms of an RFFT'd and unshifted (zero-frequency\n    component at the top-left corner) image.\n\n    Parameters\n    ----------\n    output_shape : tuple[int, ...]\n        Desired output shape of the bandpass filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The bandpass filter for the desired output shape.\n    \"\"\"\n    # Handle case where bandpass filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=torch.float32)\n\n    # Account for None values\n    low = self.low_freq_cutoff if self.low_freq_cutoff is not None else 0.0\n    high = self.high_freq_cutoff if self.high_freq_cutoff is not None else 1.0\n    falloff = self.falloff if self.falloff is not None else 0.0\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return bandpass_filter(\n        low=low,\n        high=high,\n        falloff=falloff,\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.BandpassFilterConfig.from_spatial_resolution","title":"<code>from_spatial_resolution(low_resolution, high_resolution, pixel_size, **kwargs)</code>  <code>classmethod</code>","text":"<p>Helper method to instantiate a bandpass filter from spatial resolutions.</p> <p>Parameters:</p> Name Type Description Default <code>low_resolution</code> <code>float</code> <p>Low resolution cutoff frequency in Angstroms.</p> required <code>high_resolution</code> <code>float</code> <p>High resolution cutoff frequency in Angstroms.</p> required <code>pixel_size</code> <code>float</code> <p>Pixel size in Angstroms.</p> required <code>**kwargs</code> <code>dict[str, Any]</code> <p>Additional keyword arguments to pass to the constructor method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>BandpassFilterConfig</code> <p>Bandpass filter configuration object.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>@classmethod\ndef from_spatial_resolution(\n    cls,\n    low_resolution: float,\n    high_resolution: float,\n    pixel_size: float,\n    **kwargs: dict[str, Any],\n) -&gt; \"BandpassFilterConfig\":\n    \"\"\"Helper method to instantiate a bandpass filter from spatial resolutions.\n\n    Parameters\n    ----------\n    low_resolution : float\n        Low resolution cutoff frequency in Angstroms.\n    high_resolution : float\n        High resolution cutoff frequency in Angstroms.\n    pixel_size : float\n        Pixel size in Angstroms.\n    **kwargs\n        Additional keyword arguments to pass to the constructor method.\n\n    Returns\n    -------\n    BandpassFilterConfig\n        Bandpass filter configuration object.\n    \"\"\"\n    low_freq_cutoff = pixel_size / low_resolution\n    high_freq_cutoff = pixel_size / high_resolution\n\n    return cls(\n        low_freq_cutoff=low_freq_cutoff,\n        high_freq_cutoff=high_freq_cutoff,\n        **kwargs,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.PhaseRandomizationFilterConfig","title":"<code>PhaseRandomizationFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for phase randomization filter.</p> <p>NOTE: Something is not working with the underlying torch_fourier_filter code for phase randomization.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a phase randomization filter to the input image. Default is False.</p> <code>cuton</code> <code>float</code> <p>Spatial resolution, in terms of Nyquist, above which to randomize the phase.</p> <p>Methods:</p> Name Description <code>calculate_phase_randomization_filter</code> <p>Helper function for the phase randomization filter based on the input reference image and held configuration parameters.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class PhaseRandomizationFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for phase randomization filter.\n\n    NOTE: Something is not working with the underlying torch_fourier_filter code\n    for phase randomization.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a phase randomization filter to the input image. Default\n        is False.\n    cuton : float\n        Spatial resolution, in terms of Nyquist, above which to randomize the phase.\n\n    Methods\n    -------\n    calculate_phase_randomization_filter(ref_img_rfft)\n        Helper function for the phase randomization filter based on the input reference\n        image and held configuration parameters.\n    \"\"\"\n\n    enabled: bool = False\n    cuton: Optional[Annotated[float, Field(ge=0.0)]] = None\n\n    def calculate_phase_randomization_filter(\n        self, ref_img_rfft: torch.Tensor\n    ) -&gt; torch.Tensor:\n        \"\"\"Helper function for phase randomization filter based on the reference image.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            The reference image to use as a template for phase randomization. This\n            should be RFFT'd and unshifted (zero-frequency component at the top-left\n            corner).\n        \"\"\"\n        output_shape = ref_img_rfft.shape\n\n        # Handle case where phase randomization filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n        # Fix for underlying shape bug in torch_fourier_filter\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return phase_randomize(\n            dft=ref_img_rfft,\n            image_shape=output_shape,\n            rfft=True,\n            fftshift=False,\n            cuton=self.cuton,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.PhaseRandomizationFilterConfig.calculate_phase_randomization_filter","title":"<code>calculate_phase_randomization_filter(ref_img_rfft)</code>","text":"<p>Helper function for phase randomization filter based on the reference image.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>The reference image to use as a template for phase randomization. This should be RFFT'd and unshifted (zero-frequency component at the top-left corner).</p> required Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_phase_randomization_filter(\n    self, ref_img_rfft: torch.Tensor\n) -&gt; torch.Tensor:\n    \"\"\"Helper function for phase randomization filter based on the reference image.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        The reference image to use as a template for phase randomization. This\n        should be RFFT'd and unshifted (zero-frequency component at the top-left\n        corner).\n    \"\"\"\n    output_shape = ref_img_rfft.shape\n\n    # Handle case where phase randomization filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n    # Fix for underlying shape bug in torch_fourier_filter\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return phase_randomize(\n        dft=ref_img_rfft,\n        image_shape=output_shape,\n        rfft=True,\n        fftshift=False,\n        cuton=self.cuton,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.PreprocessingFilters","title":"<code>PreprocessingFilters</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration class for all preprocessing filters.</p> <p>Attributes:</p> Name Type Description <code>whitening_filter_config</code> <code>WhiteningFilterConfig</code> <p>Configuration for the whitening filter.</p> <code>bandpass_filter_config</code> <code>BandpassFilterConfig</code> <p>Configuration for the bandpass filter.</p> <code>phase_randomization_filter_config</code> <code>PhaseRandomizationFilterConfig</code> <p>Configuration for the phase randomization filter.</p> <code>arbitrary_curve_filter_config</code> <code>ArbitraryCurveFilterConfig</code> <p>Configuration for the arbitrary curve filter.</p> <p>Methods:</p> Name Description <code>combined_filter</code> <p>Calculate and combine all Fourier filters into a single filter.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class PreprocessingFilters(BaseModel2DTM):\n    \"\"\"Configuration class for all preprocessing filters.\n\n    Attributes\n    ----------\n    whitening_filter_config : WhiteningFilterConfig\n        Configuration for the whitening filter.\n    bandpass_filter_config : BandpassFilterConfig\n        Configuration for the bandpass filter.\n    phase_randomization_filter_config : PhaseRandomizationFilterConfig\n        Configuration for the phase randomization filter.\n    arbitrary_curve_filter_config : ArbitraryCurveFilterConfig\n        Configuration for the arbitrary curve filter.\n\n    Methods\n    -------\n    combined_filter(ref_img_rfft, output_shape)\n        Calculate and combine all Fourier filters into a single filter.\n    \"\"\"\n\n    whitening_filter: WhiteningFilterConfig = WhiteningFilterConfig()\n    bandpass_filter: BandpassFilterConfig = BandpassFilterConfig()\n    phase_randomization_filter: PhaseRandomizationFilterConfig = (\n        PhaseRandomizationFilterConfig()\n    )\n    arbitrary_curve_filter: ArbitraryCurveFilterConfig = ArbitraryCurveFilterConfig()\n\n    def get_combined_filter(\n        self, ref_img_rfft: torch.Tensor, output_shape: tuple[int, ...]\n    ) -&gt; torch.Tensor:\n        \"\"\"Combine all filters into a single filter.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            Reference image to use for calculating the filters.\n        output_shape : tuple[int, ...]\n            Desired output shape of the combined filter in Fourier space. This is the\n            filter shape in Fourier space *not* real space (like in the\n            torch_fourier_filter package).\n\n        Returns\n        -------\n        torch.Tensor\n            The combined filter for the desired output shape.\n        \"\"\"\n        # NOTE: Phase randomization filter is not currently enabled\n        # pr_config = self.phase_randomization_filter\n        wf_config = self.whitening_filter\n        bf_config = self.bandpass_filter\n        ac_config = self.arbitrary_curve_filter\n\n        # Calculate each of the filters in turn\n        # phase_randomization_filter = pr_config.calculate_phase_randomization_filter(\n        #     ref_img_rfft=ref_img_rfft\n        # )\n        whitening_filter_tensor = wf_config.calculate_whitening_filter(\n            ref_img_rfft=ref_img_rfft, output_shape=output_shape\n        )\n        bandpass_filter_tensor = bf_config.calculate_bandpass_filter(\n            output_shape=output_shape\n        )\n        arbitrary_curve_filter_tensor = ac_config.calculate_arbitrary_curve_filter(\n            output_shape=output_shape\n        )\n\n        combined_filter = (\n            whitening_filter_tensor\n            * bandpass_filter_tensor\n            * arbitrary_curve_filter_tensor\n        )\n\n        return combined_filter\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.PreprocessingFilters.get_combined_filter","title":"<code>get_combined_filter(ref_img_rfft, output_shape)</code>","text":"<p>Combine all filters into a single filter.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>Reference image to use for calculating the filters.</p> required <code>output_shape</code> <code>tuple[int, ...]</code> <p>Desired output shape of the combined filter in Fourier space. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The combined filter for the desired output shape.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def get_combined_filter(\n    self, ref_img_rfft: torch.Tensor, output_shape: tuple[int, ...]\n) -&gt; torch.Tensor:\n    \"\"\"Combine all filters into a single filter.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        Reference image to use for calculating the filters.\n    output_shape : tuple[int, ...]\n        Desired output shape of the combined filter in Fourier space. This is the\n        filter shape in Fourier space *not* real space (like in the\n        torch_fourier_filter package).\n\n    Returns\n    -------\n    torch.Tensor\n        The combined filter for the desired output shape.\n    \"\"\"\n    # NOTE: Phase randomization filter is not currently enabled\n    # pr_config = self.phase_randomization_filter\n    wf_config = self.whitening_filter\n    bf_config = self.bandpass_filter\n    ac_config = self.arbitrary_curve_filter\n\n    # Calculate each of the filters in turn\n    # phase_randomization_filter = pr_config.calculate_phase_randomization_filter(\n    #     ref_img_rfft=ref_img_rfft\n    # )\n    whitening_filter_tensor = wf_config.calculate_whitening_filter(\n        ref_img_rfft=ref_img_rfft, output_shape=output_shape\n    )\n    bandpass_filter_tensor = bf_config.calculate_bandpass_filter(\n        output_shape=output_shape\n    )\n    arbitrary_curve_filter_tensor = ac_config.calculate_arbitrary_curve_filter(\n        output_shape=output_shape\n    )\n\n    combined_filter = (\n        whitening_filter_tensor\n        * bandpass_filter_tensor\n        * arbitrary_curve_filter_tensor\n    )\n\n    return combined_filter\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.WhiteningFilterConfig","title":"<code>WhiteningFilterConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for the whitening filter.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>If True, apply a whitening filter to the input image and template projections. Default is True.</p> <code>num_freq_bins</code> <code>Optional[int]</code> <p>Number of frequency bins (in 1D) to use when calculating the power spectrum. Default is None which automatically determines the number of bins based on the input image size.</p> <code>max_freq</code> <code>Optional[float]</code> <p>Maximum frequency, in terms of Nyquist frequency, to use when calculating the whitening filter. Default is 0.5 with values pixels above 0.5 being set to 1.0 in the filter (i.e. no frequency scaling).</p> <code>do_power_spectrum</code> <code>Optional[bool]</code> <p>If True, calculate the power spectral density from the power of the input image. Default is True. If False, then the power spectral density is calculated from the amplitude of the input image.</p> <p>Methods:</p> Name Description <code>calculate_whitening_filter</code> <p>Helper function for the whitening filter based on the input reference image and held configuration parameters.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>class WhiteningFilterConfig(BaseModel2DTM):\n    \"\"\"Configuration for the whitening filter.\n\n    Attributes\n    ----------\n    enabled : bool\n        If True, apply a whitening filter to the input image and template projections.\n        Default is True.\n    num_freq_bins : Optional[int]\n        Number of frequency bins (in 1D) to use when calculating the power spectrum.\n        Default is None which automatically determines the number of bins based on the\n        input image size.\n    max_freq : Optional[float]\n        Maximum frequency, in terms of Nyquist frequency, to use when calculating the\n        whitening filter. Default is 0.5 with values pixels above 0.5 being set to 1.0\n        in the filter (i.e. no frequency scaling).\n    do_power_spectrum : Optional[bool]\n        If True, calculate the power spectral density from the power of the\n        input image. Default is True. If False, then the power spectral density is\n        calculated from the amplitude of the input image.\n\n    Methods\n    -------\n    calculate_whitening_filter(ref_img_rfft, output_shape, output_rfft, output_fftshift)\n        Helper function for the whitening filter based on the input reference image and\n        held configuration parameters.\n    \"\"\"\n\n    enabled: bool = True\n    num_freq_bins: Optional[int] = None\n    max_freq: Optional[float] = 0.5  # in terms of Nyquist frequency\n    do_power_spectrum: Optional[bool] = True\n\n    def calculate_whitening_filter(\n        self,\n        ref_img_rfft: torch.Tensor,\n        output_shape: Optional[tuple[int, ...]] = None,\n        output_rfft: bool = True,\n        output_fftshift: bool = False,\n    ) -&gt; torch.Tensor:\n        \"\"\"Helper function for the whitening filter based on the input reference image.\n\n        NOTE: This function is a wrapper around the `whitening_filter` function from\n        the `torch_fourier_filter` package. It expects the input image to be RFFT'd\n        and unshifted (zero-frequency component at the top-left corner). The output\n        can be of any shape, but the default is to return a filer of the same input\n        shape.\n\n        Parameters\n        ----------\n        ref_img_rfft : torch.Tensor\n            The reference image (RFFT'd and unshifted) to calculate the whitening\n            filter from.\n        output_shape : Optional[tuple[int, ...]]\n            Desired output shape of the whitening filter. This is the filter shape in\n            Fourier space *not* real space (like in the torch_fourier_filter package).\n            Default is None, which is the same as the input shape.\n        output_rfft : Optional[bool]\n            If True, filter corresponds to a Fourier transform using the RFFT.\n            Default is None, which is the same as the 'rfft' parameter.\n        output_fftshift : Optional[bool]\n            If True, filter corresponds to a Fourier transform followed\n            by an fftshift. Default is None, which is the same as the 'fftshift'\n            parameter.\n\n        Returns\n        -------\n        torch.Tensor\n            The whitening filter with frequencies calculated from the input reference\n            image.\n        \"\"\"\n        if output_shape is None:\n            output_shape = ref_img_rfft.shape\n\n        # Handle case where whitening filter is disabled\n        if not self.enabled:\n            return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n        # Convert to real-space shape for function call\n        output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n        return whitening_filter(\n            image_dft=ref_img_rfft,\n            rfft=True,\n            fftshift=False,\n            dim=(-2, -1),\n            num_freq_bins=self.num_freq_bins,\n            max_freq=self.max_freq,\n            do_power_spectrum=self.do_power_spectrum,\n            output_shape=output_shape,\n            output_rfft=output_rfft,\n            output_fftshift=output_fftshift,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/correlation_filters/#leopard_em.pydantic_models.config.correlation_filters.WhiteningFilterConfig.calculate_whitening_filter","title":"<code>calculate_whitening_filter(ref_img_rfft, output_shape=None, output_rfft=True, output_fftshift=False)</code>","text":"<p>Helper function for the whitening filter based on the input reference image.</p> <p>NOTE: This function is a wrapper around the <code>whitening_filter</code> function from the <code>torch_fourier_filter</code> package. It expects the input image to be RFFT'd and unshifted (zero-frequency component at the top-left corner). The output can be of any shape, but the default is to return a filer of the same input shape.</p> <p>Parameters:</p> Name Type Description Default <code>ref_img_rfft</code> <code>Tensor</code> <p>The reference image (RFFT'd and unshifted) to calculate the whitening filter from.</p> required <code>output_shape</code> <code>Optional[tuple[int, ...]]</code> <p>Desired output shape of the whitening filter. This is the filter shape in Fourier space not real space (like in the torch_fourier_filter package). Default is None, which is the same as the input shape.</p> <code>None</code> <code>output_rfft</code> <code>Optional[bool]</code> <p>If True, filter corresponds to a Fourier transform using the RFFT. Default is None, which is the same as the 'rfft' parameter.</p> <code>True</code> <code>output_fftshift</code> <code>Optional[bool]</code> <p>If True, filter corresponds to a Fourier transform followed by an fftshift. Default is None, which is the same as the 'fftshift' parameter.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The whitening filter with frequencies calculated from the input reference image.</p> Source code in <code>src/leopard_em/pydantic_models/config/correlation_filters.py</code> <pre><code>def calculate_whitening_filter(\n    self,\n    ref_img_rfft: torch.Tensor,\n    output_shape: Optional[tuple[int, ...]] = None,\n    output_rfft: bool = True,\n    output_fftshift: bool = False,\n) -&gt; torch.Tensor:\n    \"\"\"Helper function for the whitening filter based on the input reference image.\n\n    NOTE: This function is a wrapper around the `whitening_filter` function from\n    the `torch_fourier_filter` package. It expects the input image to be RFFT'd\n    and unshifted (zero-frequency component at the top-left corner). The output\n    can be of any shape, but the default is to return a filer of the same input\n    shape.\n\n    Parameters\n    ----------\n    ref_img_rfft : torch.Tensor\n        The reference image (RFFT'd and unshifted) to calculate the whitening\n        filter from.\n    output_shape : Optional[tuple[int, ...]]\n        Desired output shape of the whitening filter. This is the filter shape in\n        Fourier space *not* real space (like in the torch_fourier_filter package).\n        Default is None, which is the same as the input shape.\n    output_rfft : Optional[bool]\n        If True, filter corresponds to a Fourier transform using the RFFT.\n        Default is None, which is the same as the 'rfft' parameter.\n    output_fftshift : Optional[bool]\n        If True, filter corresponds to a Fourier transform followed\n        by an fftshift. Default is None, which is the same as the 'fftshift'\n        parameter.\n\n    Returns\n    -------\n    torch.Tensor\n        The whitening filter with frequencies calculated from the input reference\n        image.\n    \"\"\"\n    if output_shape is None:\n        output_shape = ref_img_rfft.shape\n\n    # Handle case where whitening filter is disabled\n    if not self.enabled:\n        return torch.ones(output_shape, dtype=ref_img_rfft.dtype)\n\n    # Convert to real-space shape for function call\n    output_shape = output_shape[:-1] + (2 * (output_shape[-1] - 1),)\n\n    return whitening_filter(\n        image_dft=ref_img_rfft,\n        rfft=True,\n        fftshift=False,\n        dim=(-2, -1),\n        num_freq_bins=self.num_freq_bins,\n        max_freq=self.max_freq,\n        do_power_spectrum=self.do_power_spectrum,\n        output_shape=output_shape,\n        output_rfft=output_rfft,\n        output_fftshift=output_fftshift,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/defocus_search/","title":"defocus_search","text":"<p>Serialization and validation of defocus search parameters for 2DTM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/defocus_search/#leopard_em.pydantic_models.config.defocus_search.DefocusSearchConfig","title":"<code>DefocusSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of defocus search parameters for 2DTM.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable defocus search. Default is True.</p> <code>defocus_min</code> <code>float</code> <p>Minimum searched defocus relative to average defocus ('defocus_u' and 'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.</p> <code>defocus_max</code> <code>float</code> <p>Maximum searched defocus relative to average defocus ('defocus_u' and 'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.</p> <code>defocus_step</code> <code>float</code> <p>Step size for defocus search in units of Angstroms.</p> <code>skip_enforce_zero</code> <code>bool</code> <p>Whether to skip enforcing a zero value, by default False.</p> Properties <p>defocus_values : torch.Tensor     Tensor of relative defocus values to search over based on held params.</p> Source code in <code>src/leopard_em/pydantic_models/config/defocus_search.py</code> <pre><code>class DefocusSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of defocus search parameters for 2DTM.\n\n    Attributes\n    ----------\n    enabled : bool\n        Whether to enable defocus search. Default is True.\n    defocus_min : float\n        Minimum searched defocus relative to average defocus ('defocus_u' and\n        'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.\n    defocus_max : float\n        Maximum searched defocus relative to average defocus ('defocus_u' and\n        'defocus_v' in OpticsGroup) of micrograph in units of Angstroms.\n    defocus_step : float\n        Step size for defocus search in units of Angstroms.\n    skip_enforce_zero : bool\n        Whether to skip enforcing a zero value, by default False.\n\n    Properties\n    ----------\n    defocus_values : torch.Tensor\n        Tensor of relative defocus values to search over based on held params.\n    \"\"\"\n\n    enabled: bool = True\n    defocus_min: float = -1000.0\n    defocus_max: float = 1000.0\n    defocus_step: Annotated[float, Field(..., gt=0.0)] = 200.0\n    skip_enforce_zero: bool = False\n\n    @property\n    def defocus_values(self) -&gt; torch.Tensor:\n        \"\"\"Relative defocus values to search over based on held params.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of relative defocus values to search over, in units of Angstroms.\n\n        Raises\n        ------\n        ValueError\n            If defocus search parameters result in no defocus values to search over.\n        \"\"\"\n        # Return a relative defocus of 0.0 if search is disabled.\n        if not self.enabled:\n            return torch.tensor([0.0])\n\n            # Check if parameters would result in valid range before calling arange\n        if self.defocus_max &lt; self.defocus_min:\n            raise ValueError(\n                \"Defocus search parameters result in no values to search over!\\n\"\n                f\"  self.defocus_min: {self.defocus_min}\\n\"\n                f\"  self.defocus_max: {self.defocus_max}\\n\"\n                f\"  self.defocus_step: {self.defocus_step}\\n\"\n            )\n\n        return get_search_tensors(\n            self.defocus_min,\n            self.defocus_max,\n            self.defocus_step,\n            self.skip_enforce_zero,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/defocus_search/#leopard_em.pydantic_models.config.defocus_search.DefocusSearchConfig.defocus_values","title":"<code>defocus_values</code>  <code>property</code>","text":"<p>Relative defocus values to search over based on held params.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of relative defocus values to search over, in units of Angstroms.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If defocus search parameters result in no defocus values to search over.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/","title":"orientation_search","text":"<p>Serialization and validation of orientation search parameters for 2DTM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.ConstrainedOrientationConfig","title":"<code>ConstrainedOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of constrained orientation parameters.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable constrained orientation search.</p> <code>phi_step</code> <code>float</code> <p>Angular step size for phi in degrees. Must be greater than or equal to 0.</p> <code>theta_step</code> <code>float</code> <p>Angular step size for theta in degrees. Must be greater than or equal to 0.</p> <code>psi_step</code> <code>float</code> <p>Angular step size for psi in degrees. Must be greater than or equal to 0.</p> <code>rotation_axis_euler_angles</code> <code>list[float]</code> <p>List of Euler angles (phi, theta, psi) for the rotation axis.</p> <code>phi_min</code> <code>float</code> <p>Minimum value for the phi angle in degrees.</p> <code>phi_max</code> <code>float</code> <p>Maximum value for the phi angle in degrees.</p> <code>theta_min</code> <code>float</code> <p>Minimum value for the theta angle in degrees.</p> <code>theta_max</code> <code>float</code> <p>Maximum value for the theta angle in degrees.</p> <code>psi_min</code> <code>float</code> <p>Minimum value for the psi angle in degrees.</p> <code>psi_max</code> <code>float</code> <p>Maximum value for the psi angle in degrees.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class ConstrainedOrientationConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of constrained orientation parameters.\n\n    Attributes\n    ----------\n    enabled: bool\n        Whether to enable constrained orientation search.\n    phi_step: float\n        Angular step size for phi in degrees.\n        Must be greater than or equal to 0.\n    theta_step: float\n        Angular step size for theta in degrees.\n        Must be greater than or equal to 0.\n    psi_step: float\n        Angular step size for psi in degrees.\n        Must be greater than or equal to 0.\n    rotation_axis_euler_angles: list[float]\n        List of Euler angles (phi, theta, psi) for the rotation axis.\n    phi_min: float\n        Minimum value for the phi angle in degrees.\n    phi_max: float\n        Maximum value for the phi angle in degrees.\n    theta_min: float\n        Minimum value for the theta angle in degrees.\n    theta_max: float\n        Maximum value for the theta angle in degrees.\n    psi_min: float\n        Minimum value for the psi angle in degrees.\n    psi_max: float\n        Maximum value for the psi angle in degrees.\n    \"\"\"\n\n    enabled: bool = True\n    phi_step: Optional[float] = None\n    theta_step: float = 2.5\n    psi_step: float = 1.5\n    rotation_axis_euler_angles: tuple[float, float, float] = Field(\n        default=[0.0, 0.0, 0.0]\n    )\n    phi_min: float = 0.0\n    phi_max: float = 360.0\n    theta_min: float = 0.0\n    theta_max: float = 180.0\n    psi_min: float = 0.0\n    psi_max: float = 360.0\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"basic\", \"roll\"] = \"uniform\"\n\n    search_roll_axis: bool = True\n    roll_axis: Optional[tuple[float, float]] = Field(default=[0, 1])\n    roll_step: float = 2.0\n\n    @property\n    def euler_angles_offsets(self) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Return the Euler angle offsets to search over.\n\n        Note that this method uses a uniform grid search which approximates SO(3) space\n        well when the angular ranges are small.\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n            A tuple of two tensors of shape (N, 3) where N is the number of\n            orientations to search over. The first tensor represents the Euler\n            angles of the rotated template, and the second tensor represents\n            the Euler angles of the rotation axis. The columns represent the\n            phi, theta, and psi angles, respectively, in the 'ZYZ' convention.\n        \"\"\"\n        if not self.enabled:\n            return torch.zeros((1, 3)), torch.zeros((1, 3))\n\n        if self.search_roll_axis:\n            self.roll_axis = None\n        roll_axis = None\n        if self.roll_axis is not None:\n            roll_axis = torch.tensor(self.roll_axis)\n\n        if self.base_grid_method == \"roll\":\n            euler_angles_offsets = get_roll_angles(\n                psi_step=self.psi_step,\n                psi_min=self.psi_min,\n                psi_max=self.psi_max,\n                theta_step=self.theta_step,\n                theta_min=self.theta_min,\n                theta_max=self.theta_max,\n                roll_axis=roll_axis,\n                roll_axis_step=self.roll_step,\n            )\n        else:\n            euler_angles_offsets = get_uniform_euler_angles(\n                phi_step=self.phi_step,\n                theta_step=self.theta_step,\n                psi_step=self.psi_step,\n                phi_min=self.phi_min,\n                phi_max=self.phi_max,\n                theta_min=self.theta_min,\n                theta_max=self.theta_max,\n                psi_min=self.psi_min,\n                psi_max=self.psi_max,\n                base_grid_method=self.base_grid_method,\n            )\n        # Convert to rotation matrix\n        rot_z_matrix = roma.euler_to_rotmat(\n            \"ZYZ\",\n            euler_angles_offsets,\n            degrees=True,\n            device=euler_angles_offsets.device,\n        ).to(torch.float32)\n        # Apply rotation to the template\n        rot_axis_matrix = roma.euler_to_rotmat(\n            \"ZYZ\",\n            torch.tensor(self.rotation_axis_euler_angles),\n            degrees=True,\n            device=euler_angles_offsets.device,\n        ).to(torch.float32)\n\n        rot_matrix_batch = roma.rotmat_composition(\n            sequence=(rot_axis_matrix, rot_z_matrix, rot_axis_matrix.transpose(-1, -2))\n        )\n\n        # Convert back to Euler angles\n        euler_angles_offsets_rotated = roma.rotmat_to_euler(\n            \"ZYZ\", rot_matrix_batch, degrees=True\n        ).to(torch.float32)\n        return euler_angles_offsets_rotated, euler_angles_offsets\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.ConstrainedOrientationConfig.euler_angles_offsets","title":"<code>euler_angles_offsets</code>  <code>property</code>","text":"<p>Return the Euler angle offsets to search over.</p> <p>Note that this method uses a uniform grid search which approximates SO(3) space well when the angular ranges are small.</p> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A tuple of two tensors of shape (N, 3) where N is the number of orientations to search over. The first tensor represents the Euler angles of the rotated template, and the second tensor represents the Euler angles of the rotation axis. The columns represent the phi, theta, and psi angles, respectively, in the 'ZYZ' convention.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.MultipleOrientationConfig","title":"<code>MultipleOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Configuration for multiple orientation search ranges.</p> <p>This class allows specifying multiple complete orientation search configurations and concatenates their Euler angles.</p> <p>Attributes:</p> Name Type Description <code>orientation_configs</code> <code>list[OrientationSearchConfig]</code> <p>List of orientation search configurations to combine.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class MultipleOrientationConfig(BaseModel2DTM):\n    \"\"\"Configuration for multiple orientation search ranges.\n\n    This class allows specifying multiple complete orientation search\n    configurations and concatenates their Euler angles.\n\n    Attributes\n    ----------\n    orientation_configs : list[OrientationSearchConfig]\n        List of orientation search configurations to combine.\n    \"\"\"\n\n    orientation_configs: list[OrientationSearchConfig]\n\n    @property\n    def euler_angles(self) -&gt; torch.Tensor:\n        \"\"\"Returns the concatenated Euler angles from all orientation configs.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the total number of orientations\n            from all configurations. The columns represent the psi, theta, and phi\n            angles respectively.\n        \"\"\"\n        all_euler_angles = []\n        for config in self.orientation_configs:\n            all_euler_angles.append(config.euler_angles)\n\n        return torch.cat(all_euler_angles, dim=0)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.MultipleOrientationConfig.euler_angles","title":"<code>euler_angles</code>  <code>property</code>","text":"<p>Returns the concatenated Euler angles from all orientation configs.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the total number of orientations from all configurations. The columns represent the psi, theta, and phi angles respectively.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.OrientationSearchConfig","title":"<code>OrientationSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of orientation search parameters for 2DTM.</p> <p>The angles -- phi, theta, and psi -- represent Euler angles in the 'ZYZ' convention in units of degrees between 0 and 360 (for phi and psi) or between 0 and 180 (for theta).</p> <p>This model effectively acts as a connector into the <code>torch_so3.uniform_so3_sampling.get_uniform_euler_angles</code> function from the torch-so3 package.</p> <p>TODO: Implement indexing to get the i-th or range of orientations in the search space (need to be ordered).</p> <p>Attributes:</p> Name Type Description <code>psi_step</code> <code>float</code> <p>Angular step size for psi in degrees. Must be greater than 0.</p> <code>theta_step</code> <code>float</code> <p>Angular step size for theta in degrees. Must be greater than 0.</p> <code>phi_min</code> <code>float</code> <p>Minimum value for the phi angle in degrees.</p> <code>phi_max</code> <code>float</code> <p>Maximum value for the phi angle in degrees.</p> <code>theta_min</code> <code>float</code> <p>Minimum value for the theta angle in degrees.</p> <code>theta_max</code> <code>float</code> <p>Maximum value for the theta angle in degrees.</p> <code>psi_min</code> <code>float</code> <p>Minimum value for the psi angle in degrees.</p> <code>psi_max</code> <code>float</code> <p>Maximum value for the psi angle in degrees.</p> <code>base_grid_method</code> <code>str</code> <p>Method for sampling orientations. Default is 'uniform'. Currently only 'uniform' is supported.</p> <code>symmetry</code> <code>str</code> <p>Symmetry group of the template. Default is 'C1'. Note that if symmetry is provided, then the angle min/max values must be all set to None (validation will set these automatically based on the symmetry group).</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class OrientationSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of orientation search parameters for 2DTM.\n\n    The angles -- phi, theta, and psi -- represent Euler angles in the 'ZYZ'\n    convention in units of degrees between 0 and 360 (for phi and psi) or\n    between 0 and 180 (for theta).\n\n    This model effectively acts as a connector into the\n    `torch_so3.uniform_so3_sampling.get_uniform_euler_angles` function from the\n    [torch-so3](https://github.com/teamtomo/torch-so3) package.\n\n    TODO: Implement indexing to get the i-th or range of orientations in the\n    search space (need to be ordered).\n\n    Attributes\n    ----------\n    psi_step : float\n        Angular step size for psi in degrees. Must be greater\n        than 0.\n    theta_step : float\n        Angular step size for theta in degrees. Must be\n        greater than 0.\n    phi_min : float\n        Minimum value for the phi angle in degrees.\n    phi_max : float\n        Maximum value for the phi angle in degrees.\n    theta_min : float\n        Minimum value for the theta angle in degrees.\n    theta_max : float\n        Maximum value for the theta angle in degrees.\n    psi_min : float\n        Minimum value for the psi angle in degrees.\n    psi_max : float\n        Maximum value for the psi angle in degrees.\n    base_grid_method : str\n        Method for sampling orientations. Default is 'uniform'.\n        Currently only 'uniform' is supported.\n    symmetry : str\n        Symmetry group of the template. Default is 'C1'. Note that if symmetry is\n        provided, then the angle min/max values must be all set to None (validation\n        will set these automatically based on the symmetry group).\n    \"\"\"\n\n    psi_step: Annotated[float, Field(ge=0.0)] = 1.5\n    theta_step: Annotated[float, Field(ge=0.0)] = 2.5\n    phi_min: Optional[float] = None\n    phi_max: Optional[float] = None\n    theta_min: Optional[float] = None\n    theta_max: Optional[float] = None\n    psi_min: Optional[float] = None\n    psi_max: Optional[float] = None\n\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"cartesian\"] = \"uniform\"\n    symmetry: Optional[str] = \"C1\"\n\n    @model_validator(mode=\"after\")  # type: ignore\n    def validate_angle_ranges_and_symmetry(self) -&gt; Self:\n        \"\"\"Validate that angle ranges are consistent with symmetry.\n\n        There should be only two valid cases for combinations of manually defined\n        angle ranges and the symmetry group:\n        1. Symmetry argument is *not* None, and all angle min/max values\n           are set to None. In this case, the angle ranges will be set based on\n           the symmetry group.\n        2. Symmetry argument is None, and all angle min/max values are not None.\n\n        If any other combination is provided, a ValueError will be raised.\n        \"\"\"\n        _all_none = all(\n            x is None\n            for x in [\n                self.phi_min,\n                self.phi_max,\n                self.theta_min,\n                self.theta_max,\n                self.psi_min,\n                self.psi_max,\n            ]\n        )\n\n        # Check that both symmetry and angle ranges are not None\n        if not self.symmetry and _all_none:\n            raise ValueError(\n                \"Either a symmetry group must be provided, or all angle ranges must \"\n                \"not be None. Both symmetry and angle ranges were set to None.\"\n            )\n\n        # Case where both symmetry and angle ranges are provided\n        if self.symmetry and not _all_none:\n            raise ValueError(\n                \"Symmetry group is provided, but angle ranges are also set. \"\n                \"Please set all angle ranges to None when using symmetry.\"\n            )\n\n        # Case where symmetry group is provided, validate the symmetry\n        if self.symmetry:\n            match = re.match(r\"([A-Za-z]+)(\\d*)$\", self.symmetry)\n            if not match:\n                raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n        # If we reach here, it means that either symmetry is set or angle ranges are set\n        # but not both, so we can proceed.\n        return self\n\n    @property\n    def euler_angles(self) -&gt; torch.Tensor:\n        \"\"\"Returns the Euler angles ('ZYZ' convention) to search over.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of orientations to\n            search over. The columns represent the psi, theta, and phi angles\n            respectively.\n        \"\"\"\n        # If the symmetry used for the angular ranges, calculate the angular ranges\n        # based on the symmetry group.\n        if self.symmetry is not None:\n            match = re.match(r\"([A-Za-z]+)(\\d*)\", self.symmetry)\n            if match is None:\n                raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n            sym_group = match.group(1)\n            sym_order = int(match.group(2)) if match.group(2) else 1\n            (phi_min, phi_max, theta_min, theta_max, psi_min, psi_max) = (\n                get_symmetry_ranges(sym_group, sym_order)\n            )\n        # Otherwise, use the provided angular ranges replacing with default values if\n        # any are set to None.\n        else:\n            phi_min = self.phi_min if self.phi_min is not None else 0.0\n            phi_max = self.phi_max if self.phi_max is not None else 360.0\n            theta_min = self.theta_min if self.theta_min is not None else 0.0\n            theta_max = self.theta_max if self.theta_max is not None else 180.0\n            psi_min = self.psi_min if self.psi_min is not None else 0.0\n            psi_max = self.psi_max if self.psi_max is not None else 360.0\n\n        # Generate angles\n        return get_uniform_euler_angles(\n            psi_step=self.psi_step,\n            theta_step=self.theta_step,\n            phi_min=phi_min,\n            phi_max=phi_max,\n            theta_min=theta_min,\n            theta_max=theta_max,\n            psi_min=psi_min,\n            psi_max=psi_max,\n            base_grid_method=self.base_grid_method,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.OrientationSearchConfig.euler_angles","title":"<code>euler_angles</code>  <code>property</code>","text":"<p>Returns the Euler angles ('ZYZ' convention) to search over.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of orientations to search over. The columns represent the psi, theta, and phi angles respectively.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.OrientationSearchConfig.validate_angle_ranges_and_symmetry","title":"<code>validate_angle_ranges_and_symmetry()</code>","text":"<p>Validate that angle ranges are consistent with symmetry.</p> <p>There should be only two valid cases for combinations of manually defined angle ranges and the symmetry group: 1. Symmetry argument is not None, and all angle min/max values    are set to None. In this case, the angle ranges will be set based on    the symmetry group. 2. Symmetry argument is None, and all angle min/max values are not None.</p> <p>If any other combination is provided, a ValueError will be raised.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>@model_validator(mode=\"after\")  # type: ignore\ndef validate_angle_ranges_and_symmetry(self) -&gt; Self:\n    \"\"\"Validate that angle ranges are consistent with symmetry.\n\n    There should be only two valid cases for combinations of manually defined\n    angle ranges and the symmetry group:\n    1. Symmetry argument is *not* None, and all angle min/max values\n       are set to None. In this case, the angle ranges will be set based on\n       the symmetry group.\n    2. Symmetry argument is None, and all angle min/max values are not None.\n\n    If any other combination is provided, a ValueError will be raised.\n    \"\"\"\n    _all_none = all(\n        x is None\n        for x in [\n            self.phi_min,\n            self.phi_max,\n            self.theta_min,\n            self.theta_max,\n            self.psi_min,\n            self.psi_max,\n        ]\n    )\n\n    # Check that both symmetry and angle ranges are not None\n    if not self.symmetry and _all_none:\n        raise ValueError(\n            \"Either a symmetry group must be provided, or all angle ranges must \"\n            \"not be None. Both symmetry and angle ranges were set to None.\"\n        )\n\n    # Case where both symmetry and angle ranges are provided\n    if self.symmetry and not _all_none:\n        raise ValueError(\n            \"Symmetry group is provided, but angle ranges are also set. \"\n            \"Please set all angle ranges to None when using symmetry.\"\n        )\n\n    # Case where symmetry group is provided, validate the symmetry\n    if self.symmetry:\n        match = re.match(r\"([A-Za-z]+)(\\d*)$\", self.symmetry)\n        if not match:\n            raise ValueError(f\"Invalid symmetry format: {self.symmetry}\")\n\n    # If we reach here, it means that either symmetry is set or angle ranges are set\n    # but not both, so we can proceed.\n    return self\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.RefineOrientationConfig","title":"<code>RefineOrientationConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of orientation refinement parameters.</p> <p>Angles will be sampled from [-coarse_step, coarse_step] in increments of 'fine_step' for the orientation refinement search.</p> <p>Attributes:</p> Name Type Description <code>orientation_sampling_method</code> <code>str</code> <p>Method for sampling orientations. Default is 'Hopf Fibration'. Currently only 'Hopf Fibration' is supported.</p> <code>template_symmetry</code> <code>str</code> <p>Symmetry group of the template. Default is 'C1'. Currently only 'C1' is supported.</p> <code>phi_step_coarse</code> <code>float</code> <p>Angular step size for phi in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.phi_step' value for the match template program. Must be greater than or equal to 0.</p> <code>phi_step_fine</code> <code>float</code> <p>Angular step size for phi in degrees for current, fine search. Must be greater than or equal to 0.</p> <code>theta_step_coarse</code> <code>float</code> <p>Angular step size for theta in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.theta_step' value for the match template program. Must be greater than or equal to 0.</p> <code>theta_step_fine</code> <code>float</code> <p>Angular step size for theta in degrees for current, fine search. Must be greater than or equal to 0.</p> <code>psi_step_coarse</code> <code>float</code> <p>Angular step size for psi in degrees for previous, coarse search. This corresponds to the 'OrientationSearchConfig.psi_step' value for the match template program. Must be greater than or equal to 0.</p> <code>psi_step_fine</code> <code>float</code> <p>Angular step size for psi in degrees for current, fine search. Must be greater than or equal to 0.</p> Source code in <code>src/leopard_em/pydantic_models/config/orientation_search.py</code> <pre><code>class RefineOrientationConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of orientation refinement parameters.\n\n    Angles will be sampled from [-coarse_step, coarse_step] in increments of\n    'fine_step' for the orientation refinement search.\n\n    Attributes\n    ----------\n    orientation_sampling_method : str\n        Method for sampling orientations. Default is 'Hopf Fibration'.\n        Currently only 'Hopf Fibration' is supported.\n    template_symmetry : str\n        Symmetry group of the template. Default is 'C1'.\n        Currently only 'C1' is supported.\n    phi_step_coarse : float\n        Angular step size for phi in degrees for previous, coarse search.\n        This corresponds to the 'OrientationSearchConfig.phi_step' value\n        for the match template program. Must be greater than or equal to 0.\n    phi_step_fine : float\n        Angular step size for phi in degrees for current, fine search.\n        Must be greater than or equal to 0.\n    theta_step_coarse : float\n        Angular step size for theta in degrees for previous, coarse\n        search. This corresponds to the\n        'OrientationSearchConfig.theta_step' value for the match template\n        program. Must be greater than or equal to 0.\n    theta_step_fine : float\n        Angular step size for theta in degrees for current, fine search.\n        Must be greater than or equal to 0.\n    psi_step_coarse : float\n        Angular step size for psi in degrees for previous, coarse search.\n        This corresponds to the 'OrientationSearchConfig.psi_step' value\n        for the match template program. Must be greater than or equal to 0.\n    psi_step_fine : float\n        Angular step size for psi in degrees for current, fine search.\n        Must be greater than or equal to 0.\n\n    \"\"\"\n\n    enabled: bool = True\n    phi_step_coarse: Annotated[float, Field(..., ge=0.0)] = 2.5\n    phi_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.25\n    theta_step_coarse: Annotated[float, Field(..., ge=0.0)] = 2.5\n    theta_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.25\n    psi_step_coarse: Annotated[float, Field(..., ge=0.0)] = 1.5\n    psi_step_fine: Annotated[float, Field(..., ge=0.0)] = 0.1\n    base_grid_method: Literal[\"uniform\", \"healpix\", \"basic\"] = \"uniform\"\n\n    @property\n    def euler_angles_offsets(self) -&gt; torch.Tensor:\n        \"\"\"Return the Euler angle offsets to search over.\n\n        Note that this method uses a uniform grid search which approximates SO(3) space\n        well when the angular ranges are small (e.g. \u00b12.5 degrees).\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of orientations to\n            search over. The columns represent the phi, theta, and psi angles,\n            respectively, in the 'ZYZ' convention.\n        \"\"\"\n        if not self.enabled:\n            return torch.zeros((1, 3))\n\n        return get_local_high_resolution_angles(\n            coarse_phi_step=self.phi_step_coarse,\n            coarse_theta_step=self.theta_step_coarse,\n            coarse_psi_step=self.psi_step_coarse,\n            fine_phi_step=self.phi_step_fine,\n            fine_theta_step=self.theta_step_fine,\n            fine_psi_step=self.psi_step_fine,\n            base_grid_method=self.base_grid_method,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/orientation_search/#leopard_em.pydantic_models.config.orientation_search.RefineOrientationConfig.euler_angles_offsets","title":"<code>euler_angles_offsets</code>  <code>property</code>","text":"<p>Return the Euler angle offsets to search over.</p> <p>Note that this method uses a uniform grid search which approximates SO(3) space well when the angular ranges are small (e.g. \u00b12.5 degrees).</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of orientations to search over. The columns represent the phi, theta, and psi angles, respectively, in the 'ZYZ' convention.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/pixel_size_search/","title":"pixel_size_search","text":"<p>Serialization and validation of pixel size search parameters for 2DTM.</p>"},{"location":"autoapi/leopard_em/pydantic_models/config/pixel_size_search/#leopard_em.pydantic_models.config.pixel_size_search.PixelSizeSearchConfig","title":"<code>PixelSizeSearchConfig</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Serialization and validation of pixel size search parameters for 2DTM.</p> <p>Attributes:</p> Name Type Description <code>enabled</code> <code>bool</code> <p>Whether to enable pixel size search. Default is False.</p> <code>pixel_size_min</code> <code>float</code> <p>Minimum searched pixel size in units of Angstroms.</p> <code>pixel_size_max</code> <code>float</code> <p>Maximum searched pixel size in units of Angstroms.</p> <code>pixel_size_step</code> <code>float</code> <p>Step size for pixel size search in units of Angstroms.</p> <code>skip_enforce_zero</code> <code>bool</code> <p>Whether to skip enforcing a zero value, by default False.</p> Properties <p>pixel_size_values : torch.Tensor     Tensor of pixel sizes to search over based on held params.</p> Source code in <code>src/leopard_em/pydantic_models/config/pixel_size_search.py</code> <pre><code>class PixelSizeSearchConfig(BaseModel2DTM):\n    \"\"\"Serialization and validation of pixel size search parameters for 2DTM.\n\n    Attributes\n    ----------\n    enabled : bool\n        Whether to enable pixel size search. Default is False.\n    pixel_size_min : float\n        Minimum searched pixel size in units of Angstroms.\n    pixel_size_max : float\n        Maximum searched pixel size in units of Angstroms.\n    pixel_size_step : float\n        Step size for pixel size search in units of Angstroms.\n    skip_enforce_zero : bool\n        Whether to skip enforcing a zero value, by default False.\n\n    Properties\n    ----------\n    pixel_size_values : torch.Tensor\n        Tensor of pixel sizes to search over based on held params.\n    \"\"\"\n\n    enabled: bool = False\n    pixel_size_min: float = 0.0\n    pixel_size_max: float = 0.0\n    pixel_size_step: Annotated[float, Field(..., gt=0.0)] = 0.0\n    skip_enforce_zero: bool = False\n\n    @property\n    def pixel_size_values(self) -&gt; torch.Tensor:\n        \"\"\"Pixel sizes to search over based on held params.\n\n        Returns\n        -------\n        torch.Tensor\n            Tensor of pixel sizes to search over, in units of Angstroms.\n\n        Raises\n        ------\n        ValueError\n            If pixel size search parameters result in no pixel sizes to search over.\n        \"\"\"\n        # Return a relative pixel size of 0.0 if search is disabled.\n        if not self.enabled:\n            return torch.tensor([0.0])\n\n        # Check if parameters would result in valid range before calling arange\n        if self.pixel_size_max &lt; self.pixel_size_min:\n            raise ValueError(\n                \"Pixel size search parameters result in no values to search over!\\n\"\n                f\"  self.pixel_size_min: {self.pixel_size_min}\\n\"\n                f\"  self.pixel_size_max: {self.pixel_size_max}\\n\"\n                f\"  self.pixel_size_step: {self.pixel_size_step}\\n\"\n            )\n\n        return get_search_tensors(\n            self.pixel_size_min,\n            self.pixel_size_max,\n            self.pixel_size_step,\n            self.skip_enforce_zero,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/config/pixel_size_search/#leopard_em.pydantic_models.config.pixel_size_search.PixelSizeSearchConfig.pixel_size_values","title":"<code>pixel_size_values</code>  <code>property</code>","text":"<p>Pixel sizes to search over based on held params.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>Tensor of pixel sizes to search over, in units of Angstroms.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If pixel size search parameters result in no pixel sizes to search over.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/","title":"data_structures","text":"<p>Pydantic models for reused data structures across Leopard-EM programs.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.OpticsGroup","title":"<code>OpticsGroup</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Stores optics group parameters for the imaging system on a microscope.</p> <p>Currently utilizes the minimal set of parameters for calculating a contrast transfer function (CTF) for a given optics group. Other parameters for future use are included but currently unused.</p> <p>Attributes:</p> Name Type Description <code>label</code> <code>str</code> <p>Unique string (among other optics groups) for the optics group.</p> <code>pixel_size</code> <code>float</code> <p>Pixel size in Angstrom.</p> <code>voltage</code> <code>float</code> <p>Voltage in kV.</p> <code>spherical_aberration</code> <code>float</code> <p>Spherical aberration in mm. Default is 2.7.</p> <code>amplitude_contrast_ratio</code> <code>float</code> <p>Amplitude contrast ratio as a unitless percentage in [0, 1]. Default is 0.07.</p> <code>phase_shift</code> <code>float</code> <p>Additional phase shift of the contrast transfer function in degrees. Default is 0.0 degrees.</p> <code>defocus_u</code> <code>float</code> <p>Defocus (underfocus) along the major axis in Angstrom.</p> <code>defocus_v</code> <code>float</code> <p>Defocus (underfocus) along the minor axis in Angstrom.</p> <code>astigmatism_angle</code> <code>float</code> <p>Angle of defocus astigmatism relative to the X-axis in degrees.</p> <code>ctf_B_factor</code> <code>float</code> <p>B-factor to apply in the contrast transfer function in A^2. Default is 0.0.</p> Unused Attributes: <p>chromatic_aberration : float     Chromatic aberration in mm. Default is ???. mtf_reference : str | PathLike     Path to MTF reference file. mtf_values : list[float]     list of modulation transfer functions values on evenly spaced     resolution grid [0.0, ..., 0.5]. beam_tilt_x : float     Beam tilt X in mrad. beam_tilt_y : float     Beam tilt Y in mrad. odd_zernike : list[float]     list of odd Zernike moments. even_zernike : list[float]     list of even Zernike moments. zernike_moments : list[float]     list of Zernike moments.</p> <p>Methods:</p> Name Description <code>model_dump</code> <p>Returns a dictionary of the model parameters.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/optics_group.py</code> <pre><code>class OpticsGroup(BaseModel2DTM):\n    \"\"\"Stores optics group parameters for the imaging system on a microscope.\n\n    Currently utilizes the minimal set of parameters for calculating a\n    contrast transfer function (CTF) for a given optics group. Other parameters\n    for future use are included but currently unused.\n\n    Attributes\n    ----------\n    label : str\n        Unique string (among other optics groups) for the optics group.\n    pixel_size : float\n        Pixel size in Angstrom.\n    voltage : float\n        Voltage in kV.\n    spherical_aberration : float\n        Spherical aberration in mm. Default is 2.7.\n    amplitude_contrast_ratio : float\n        Amplitude contrast ratio as a unitless percentage in [0, 1]. Default\n        is 0.07.\n    phase_shift : float\n        Additional phase shift of the contrast transfer function in degrees.\n        Default is 0.0 degrees.\n    defocus_u : float\n        Defocus (underfocus) along the major axis in Angstrom.\n    defocus_v : float\n        Defocus (underfocus) along the minor axis in Angstrom.\n    astigmatism_angle : float\n        Angle of defocus astigmatism relative to the X-axis in degrees.\n    ctf_B_factor : float\n        B-factor to apply in the contrast transfer function in A^2. Default\n        is 0.0.\n\n    Unused Attributes:\n    ------------------\n    chromatic_aberration : float\n        Chromatic aberration in mm. Default is ???.\n    mtf_reference : str | PathLike\n        Path to MTF reference file.\n    mtf_values : list[float]\n        list of modulation transfer functions values on evenly spaced\n        resolution grid [0.0, ..., 0.5].\n    beam_tilt_x : float\n        Beam tilt X in mrad.\n    beam_tilt_y : float\n        Beam tilt Y in mrad.\n    odd_zernike : list[float]\n        list of odd Zernike moments.\n    even_zernike : list[float]\n        list of even Zernike moments.\n    zernike_moments : list[float]\n        list of Zernike moments.\n\n    Methods\n    -------\n    model_dump()\n        Returns a dictionary of the model parameters.\n    \"\"\"\n\n    # Currently implemented parameters\n    label: str\n    pixel_size: Annotated[float, Field(ge=0.0)]\n    voltage: Annotated[float, Field(ge=0.0)]\n    spherical_aberration: Annotated[float, Field(ge=0.0, default=2.7)] = 2.7\n    amplitude_contrast_ratio: Annotated[float, Field(ge=0.0, le=1.0, default=0.07)] = (\n        0.07\n    )\n    phase_shift: Annotated[float, Field(default=0.0)] = 0.0\n    defocus_u: float\n    defocus_v: float\n    astigmatism_angle: float\n    ctf_B_factor: Annotated[float, Field(ge=0.0, default=0.0)] = 0.0\n\n    chromatic_aberration: Optional[Annotated[float, Field(ge=0.0)]] = 0.0\n    mtf_reference: Optional[Union[str, PathLike]] = None\n    mtf_values: Optional[list[float]] = None\n    beam_tilt_x: Optional[float] = None\n    beam_tilt_y: Optional[float] = None\n    odd_zernike: Optional[list[float]] = None\n    even_zernike: Optional[list[float]] = None\n    zernike_moments: Optional[list[float]] = None\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack","title":"<code>ParticleStack</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Pydantic model for dealing with particle stack data.</p> <p>Attributes:</p> Name Type Description <code>df_path</code> <code>str</code> <p>Path to the DataFrame containing the particle data. The DataFrame must have the following columns (see the documentation for further information):</p> <ul> <li>mip</li> <li>scaled_mip</li> <li>correlation_mean</li> <li>correlation_variance</li> <li>total_correlations</li> <li>pos_x</li> <li>pos_y</li> <li>pos_x_img</li> <li>pos_y_img</li> <li>pos_x_img_angstrom</li> <li>pos_y_img_angstrom</li> <li>psi</li> <li>theta</li> <li>phi</li> <li>relative_defocus</li> <li>refined_relative_defocus</li> <li>defocus_u</li> <li>defocus_v</li> <li>astigmatism_angle</li> <li>pixel_size</li> <li>refined_pixel_size</li> <li>voltage</li> <li>spherical_aberration</li> <li>amplitude_contrast_ratio</li> <li>phase_shift</li> <li>ctf_B_factor</li> <li>micrograph_path</li> <li>template_path</li> <li>mip_path</li> <li>scaled_mip_path</li> <li>psi_path</li> <li>theta_path</li> <li>phi_path</li> <li>defocus_path</li> <li>correlation_average_path</li> <li>correlation_variance_path</li> </ul> <code>extracted_box_size</code> <code>tuple[int, int]</code> <p>The size of the extracted particle boxes in pixels in units of pixels.</p> <code>original_template_size</code> <code>tuple[int, int]</code> <p>The original size of the template used during the matching process. Should be smaller than the extracted box size.</p> <code>image_stack</code> <code>ExcludedTensor</code> <p>The stack of images extracted from the micrographs. Is effectively a pytorch Tensor with shape (N, H, W) where N is the number of particles and (H, W) is the extracted box size.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>class ParticleStack(BaseModel2DTM):\n    \"\"\"Pydantic model for dealing with particle stack data.\n\n    Attributes\n    ----------\n    df_path : str\n        Path to the DataFrame containing the particle data. The DataFrame must have\n        the following columns (see the documentation for further information):\n\n          - mip\n          - scaled_mip\n          - correlation_mean\n          - correlation_variance\n          - total_correlations\n          - pos_x\n          - pos_y\n          - pos_x_img\n          - pos_y_img\n          - pos_x_img_angstrom\n          - pos_y_img_angstrom\n          - psi\n          - theta\n          - phi\n          - relative_defocus\n          - refined_relative_defocus\n          - defocus_u\n          - defocus_v\n          - astigmatism_angle\n          - pixel_size\n          - refined_pixel_size\n          - voltage\n          - spherical_aberration\n          - amplitude_contrast_ratio\n          - phase_shift\n          - ctf_B_factor\n          - micrograph_path\n          - template_path\n          - mip_path\n          - scaled_mip_path\n          - psi_path\n          - theta_path\n          - phi_path\n          - defocus_path\n          - correlation_average_path\n          - correlation_variance_path\n\n    extracted_box_size : tuple[int, int]\n        The size of the extracted particle boxes in pixels in units of pixels.\n    original_template_size : tuple[int, int]\n        The original size of the template used during the matching process. Should be\n        smaller than the extracted box size.\n    image_stack : ExcludedTensor\n        The stack of images extracted from the micrographs. Is effectively a pytorch\n        Tensor with shape (N, H, W) where N is the number of particles and (H, W) is\n        the extracted box size.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized fields\n    df_path: str\n    extracted_box_size: tuple[int, int]\n    original_template_size: tuple[int, int]\n\n    # Imported tabular data (not serialized)\n    _df: pd.DataFrame\n\n    # Cropped out view of the particles from images\n    image_stack: ExcludedTensor\n\n    def __init__(self, skip_df_load: bool = False, **data: dict[str, Any]):\n        \"\"\"Initialize the ParticleStack object.\n\n        Parameters\n        ----------\n        skip_df_load : bool, optional\n            Whether to skip loading the DataFrame, by default False and the dataframe\n            is loaded automatically.\n        data : dict[str, Any]\n            The data to initialize the object with.\n        \"\"\"\n        super().__init__(**data)\n\n        if not skip_df_load:\n            self.load_df()\n\n    def load_df(self) -&gt; None:\n        \"\"\"Load the DataFrame from the specified path.\n\n        Raises\n        ------\n        ValueError\n            If the DataFrame is missing required columns.\n        \"\"\"\n        tmp_df = pd.read_csv(self.df_path)\n\n        # Validate the DataFrame columns\n        missing_columns = [\n            col for col in MATCH_TEMPLATE_DF_COLUMN_ORDER if col not in tmp_df.columns\n        ]\n        if missing_columns:\n            raise ValueError(\n                f\"Missing the following columns in DataFrame: {missing_columns}\"\n            )\n\n        self._df = tmp_df\n\n    def _get_position_reference_columns(self) -&gt; tuple[str, str]:\n        \"\"\"Get the position reference columns based on the DataFrame.\"\"\"\n        y_col = \"refined_pos_y\" if \"refined_pos_y\" in self._df.columns else \"pos_y\"\n        x_col = \"refined_pos_x\" if \"refined_pos_x\" in self._df.columns else \"pos_x\"\n        return y_col, x_col\n\n    def construct_image_stack(\n        self,\n        pos_reference: Literal[\"center\", \"top-left\"] = \"top-left\",\n        handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n        padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n        padding_value: float = 0.0,\n    ) -&gt; torch.Tensor:\n        \"\"\"Construct stack of images from the DataFrame (updates image_stack in-place).\n\n        This method preferentially selects refined position columns by default\n        (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling\n        back to unrefined positions (pos_x, pos_y) otherwise.\n\n        This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if\n        available) to extract the boxes from the images. When using top-left reference\n        position, the boxes are extracted as follows, where the dots represent the\n        actual particle in the image\n\n        Example:\n            :                +----------------------------------+\n            :                |                                  |\n            :                |                                  |\n            :                |     (x, y) *=== box_w ===+       |\n            :                |            |             |       |\n            :                |            |     ....  box_h     |\n            :           img_height        |    ......   |       |\n            :                |            |     ....    |       |\n            :                |            |             |       |\n            :                |            +=============+       |\n            :                |                                  |\n            :                +------------ img_width -----------+\n\n        When center reference is used, then the position columns in the DataFrame are\n        interpreted as the center of the particle, and the boxes are extracted around\n        this x and y position as follows:\n\n        Example:\n            :                +----------------------------------+\n            :                |                                  |\n            :                |                                  |\n            :                |            +=== box_w ===+       |\n            :                |            |             |       |\n            :                |            |     ....    |       |\n            :           img_height        |(x, y).*.. box_h     |\n            :                |            |     ....    |       |\n            :                |            |             |       |\n            :                |            +=============+       |\n            :                |                                  |\n            :                +------------ img_width -----------+\n\n        Parameters\n        ----------\n        pos_reference : Literal[\"center\", \"top-left\"], optional\n            The reference point for the positions, by default \"top-left\". If \"center\",\n            the boxes extracted will be\n            image[y - box_size // 2 : y + box_size // 2, ...].\n            Columns in the dataframe which are used as position references are always\n            pos_x and pos_y, or refined_pos_x and refined_pos_y if available.\n            If \"top-left\", the boxes will be image[y : y + box_size, ...].\n            Leopard-EM uses the \"top-left\" reference position, and unless you know data\n            was processed in a different way you should not change this value.\n        handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n            How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n            will be padded with the padding value based on the padding mode. If \"error\",\n            an error will be raised if any region exceeds the image bounds. NOTE:\n            clipping is not supported since returned stack may have inhomogeneous sizes.\n        padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n            The padding mode to use when padding the image, by default \"constant\".\n            \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n            reflection of the image at the edge, and \"replicate\" pads with the last\n            pixel of the image. These match the modes available in\n            `torch.nn.functional.pad`.\n        padding_value : float, optional\n            The value to use for padding when `padding_mode` is \"constant\", by default\n            0.0.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of images, this is the internal 'image_stack' attribute.\n        \"\"\"\n        # Determine which position columns to use (refined if available)\n        y_col, x_col = self._get_position_reference_columns()\n\n        # Create an empty tensor to store the image stack\n        h, w = self.original_template_size\n        box_h, box_w = self.extracted_box_size\n        image_stack = torch.zeros((self.num_particles, *self.extracted_box_size))\n\n        # Find the indexes in the DataFrame that correspond to each unique image\n        image_index_groups = self._df.groupby(\"micrograph_path\").groups\n        for img_path, indexes in image_index_groups.items():\n            img = load_mrc_image(img_path)\n\n            pos_y = self._df.loc[indexes, y_col].to_numpy()\n            pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n            # If the position reference is \"center\", shift (x, y) by half the original\n            # template width/height so reference is now the top-left corner\n            if pos_reference == \"center\":\n                pos_y = pos_y - h // 2\n                pos_x = pos_x - w // 2\n\n            # Our reference is now a top-left corner of a box of the original template\n            # shape, BUT we want a slightly larger box of extracted_box_size AND this\n            # box to be centered around the particle. Therefore, need to shift the\n            # position half the difference between the original template size and\n            # the extracted box size.\n            pos_y -= (box_h - h) // 2\n            pos_x -= (box_w - w) // 2\n\n            pos_y = torch.tensor(pos_y)\n            pos_x = torch.tensor(pos_x)\n\n            # Code logic is simplified by only using the top-left reference position\n            # in the `get_cropped_image_regions` function. Relative referencing handled\n            # by the ParticleStack class.\n            cropped_images = get_cropped_image_regions(\n                img,\n                pos_y,\n                pos_x,\n                self.extracted_box_size,\n                pos_reference=\"top-left\",\n                handle_bounds=handle_bounds,\n                padding_mode=padding_mode,\n                padding_value=padding_value,\n            )\n            image_stack[indexes] = cropped_images\n\n        self.image_stack = image_stack\n\n        return image_stack\n\n    def construct_cropped_statistic_stack(\n        self,\n        stat: Literal[\n            \"mip\",\n            \"scaled_mip\",\n            \"correlation_average\",\n            \"correlation_variance\",\n            \"defocus\",\n            \"psi\",\n            \"theta\",\n            \"phi\",\n        ],\n        handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n        padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n        padding_value: float = 0.0,\n    ) -&gt; torch.Tensor:\n        \"\"\"Return a tensor of the specified statistic for each cropped image.\n\n        NOTE: This function is very similar to `construct_image_stack` but returns the\n        statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).\n\n        Parameters\n        ----------\n        stat : Literal[\"mip\", \"scaled_mip\", \"correlation_average\",\n            \"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"]\n            The statistic to extract from the DataFrame.\n        handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n            How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n            will be padded with the padding value based on the padding mode. If \"error\",\n            an error will be raised if any region exceeds the image bounds. NOTE:\n            clipping is not supported since returned stack may have inhomogeneous sizes.\n        padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n            The padding mode to use when padding the image, by default \"constant\".\n            \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n            reflection of the image at the edge, and \"replicate\" pads with the last\n            pixel of the image. These match the modes available in\n            `torch.nn.functional.pad`.\n        padding_value : float, optional\n            The value to use for padding when `padding_mode` is \"constant\", by default\n            0.0.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the\n            number of particles and (H, W) is the extracted box size with (h, w) being\n            the original template size.\n        \"\"\"\n        stat_col = f\"{stat}_path\"\n        y_col, x_col = self._get_position_reference_columns()\n\n        if stat_col not in self._df.columns:\n            raise ValueError(f\"Statistic '{stat}' not found in the DataFrame.\")\n\n        # Create an empty tensor to store the stat stack\n        h, w = self.original_template_size\n        box_h, box_w = self.extracted_box_size\n        stat_stack = torch.zeros((self.num_particles, box_h - h + 1, box_w - w + 1))\n\n        # Find the indexes in the DataFrame that correspond to each unique stat map\n        stat_index_groups = self._df.groupby(stat_col).groups\n\n        # Loop over each unique stat map and extract the particles\n        for stat_path, indexes in stat_index_groups.items():\n            stat_map = load_mrc_image(stat_path)\n\n            # with reference to the exact pixel of the statistic (top-left)\n            # need to account for relative extracted box size\n            pos_y = self._df.loc[indexes, y_col].to_numpy()\n            pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n            # NOTE: For both references, we need to shift both x and y\n            # by half the different of the original template shape and extracted box\n            # so that the padding around the statistic peak is symmetric.\n            pos_y -= (box_h - h) // 2\n            pos_x -= (box_w - w) // 2\n\n            pos_y = torch.tensor(pos_y)\n            pos_x = torch.tensor(pos_x)\n\n            cropped_stat_maps = get_cropped_image_regions(\n                stat_map,\n                pos_y,\n                pos_x,\n                (box_h - h + 1, box_w - w + 1),\n                pos_reference=\"top-left\",\n                handle_bounds=handle_bounds,\n                padding_mode=padding_mode,\n                padding_value=padding_value,\n            )\n            stat_stack[indexes] = cropped_stat_maps\n\n        return stat_stack\n\n    def construct_filter_stack(\n        self, preprocess_filters: PreprocessingFilters, output_shape: tuple[int, int]\n    ) -&gt; torch.Tensor:\n        \"\"\"Get stack of Fourier filters from filter config and reference micrographs.\n\n        Note that here the filters are assumed to be applied globally (i.e. no local\n        whitening, etc. is being done). Whitening filters are calculated with reference\n        to each original micrograph in the DataFrame.\n\n        Parameters\n        ----------\n        preprocess_filters : PreprocessingFilters\n            Configuration object of filters to apply.\n        output_shape : tuple[int, int]\n            What shape along the last two dimensions the filters should be.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of filters with shape (N, h, w) where N is the number of particles\n            and (h, w) is the output shape.\n        \"\"\"\n        # Create an empty tensor to store the filter stack\n        filter_stack = torch.zeros((self.num_particles, *output_shape))\n\n        # Find the indexes in the DataFrame that correspond to each unique image\n        image_index_groups = self._df.groupby(\"micrograph_path\").groups\n\n        # Loop over each unique image and extract the particles\n        for img_path, indexes in image_index_groups.items():\n            img = load_mrc_image(img_path)\n\n            image_dft = torch.fft.rfftn(img)  # pylint: disable=not-callable\n            image_dft[0, 0] = 0 + 0j\n            cumulative_filter = preprocess_filters.get_combined_filter(\n                ref_img_rfft=image_dft,\n                output_shape=output_shape,\n            )\n\n            filter_stack[indexes] = cumulative_filter\n\n        return filter_stack\n\n    @property\n    def df_columns(self) -&gt; list[str]:\n        \"\"\"Get the columns of the DataFrame.\"\"\"\n        return list(self._df.columns.tolist())\n\n    @property\n    def num_particles(self) -&gt; int:\n        \"\"\"Get the number of particles in the stack.\"\"\"\n        return len(self._df)\n\n    def get_relative_defocus(\n        self,\n        prefer_refined_defocus: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Get the relative defocus values for each particle.\n\n        Parameters\n        ----------\n        prefer_refined_defocus : bool, optional\n            Whether to use the refined defocus values (columns prefixed with 'refined_')\n            or not, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            The relative defocus values for each particle.\n\n        Warnings\n        --------\n            Warns if NaN values or no column present for either\n            'refined_relative_defocus' or 'relative_defocus'.\n            Falls back to the unrefined values.\n        \"\"\"\n        rel_defocus_col = \"relative_defocus\"\n        # Both refined columns must be present AND no values can be NaN or inf\n        if prefer_refined_defocus:\n            if \"refined_relative_defocus\" not in self._df.columns:\n                warnings.warn(\n                    \"Refined defocus values not found in DataFrame, using original \"\n                    \"defocus values...\",\n                    stacklevel=2,\n                )\n            elif _any_nan_or_inf(self._df[\"refined_relative_defocus\"]):\n                warnings.warn(\n                    \"Refined defocus values contain NaN or inf values, using original \"\n                    \"defocus values...\",\n                    stacklevel=2,\n                )\n            else:\n                rel_defocus_col = \"refined_relative_defocus\"\n\n        return torch.tensor(self._df[rel_defocus_col].to_numpy())\n\n    def get_absolute_defocus(\n        self, prefer_refined_defocus: bool = True\n    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Get the absolute defocus values for each particle.\n\n        NOTE: If the refined defocus values are requested but not present in the\n        DataFrame (either no column or any NaN values), a user warning is raised\n        and the original defocus values are returned instead.\n\n        Parameters\n        ----------\n        prefer_refined_defocus : bool, optional\n            Whether to use the refined defocus values\n            (columns prefixed with 'refined_') or not, by default True.\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n            A tuple of two tensors containing the absolute defocus values along the\n            major (defocus_u) and minor axes (defocus_v), respectively in units of\n            Angstroms.\n        \"\"\"\n        particle_defocus = self.get_relative_defocus(prefer_refined_defocus)\n        defocus_u = torch.tensor(self._df[\"defocus_u\"].to_numpy()) + particle_defocus\n        defocus_v = torch.tensor(self._df[\"defocus_v\"].to_numpy()) + particle_defocus\n\n        return defocus_u, defocus_v\n\n    def get_pixel_size(\n        self,\n        prefer_refined_pixel_size: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Get the relative pixel size values for each particle.\n\n        Parameters\n        ----------\n        prefer_refined_pixel_size : bool, optional\n            Whether to use the refined pixel size values\n            (columns prefixed with 'refined_') or not, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            The relative pixel size values for each particle.\n\n        Warnings\n        --------\n            Warns if NaN values or no column present for either 'refined_pixel_size'\n            or 'pixel_size'. Falls back to the unrefined values.\n        \"\"\"\n        pixel_size_col = \"pixel_size\"\n        if prefer_refined_pixel_size:\n            if \"refined_pixel_size\" not in self._df.columns:\n                warnings.warn(\n                    \"Refined pixel size not found in DataFrame, using original\"\n                    \" pixel size values...\",\n                    stacklevel=2,\n                )\n            elif _any_nan_or_inf(self._df[\"refined_pixel_size\"]):\n                warnings.warn(\n                    \"Refined pixel size contain NaN or inf values, using original\"\n                    \" pixel size values...\",\n                    stacklevel=2,\n                )\n            else:\n                pixel_size_col = \"refined_pixel_size\"\n\n        return torch.tensor(self._df[pixel_size_col].to_numpy())\n\n    def get_euler_angles(self, prefer_refined_angles: bool = True) -&gt; torch.Tensor:\n        \"\"\"Return the Euler angles (phi, theta, psi) of all particles as a tensor.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool, optional\n            When true, the refined Euler angles are used (columns prefixed with\n            'refined_'), otherwise the original angles are used, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of particles and the columns\n            correspond to (phi, theta, psi) in ZYZ format.\n        \"\"\"\n        # Ensure all three refined columns are present, warning if not\n        phi_col = \"phi\"\n        theta_col = \"theta\"\n        psi_col = \"psi\"\n        if prefer_refined_angles:\n            if not all(\n                x in self._df.columns\n                for x in [\"refined_phi\", \"refined_theta\", \"refined_psi\"]\n            ):\n                warnings.warn(\n                    \"Refined angles not found in DataFrame, using original angles...\",\n                    stacklevel=2,\n                )\n            else:\n                phi_col = \"refined_phi\"\n                theta_col = \"refined_theta\"\n                psi_col = \"refined_psi\"\n\n        # Get the angles from the DataFrame\n        phi = torch.tensor(self._df[phi_col].to_numpy())\n        theta = torch.tensor(self._df[theta_col].to_numpy())\n        psi = torch.tensor(self._df[psi_col].to_numpy())\n\n        return torch.stack((phi, theta, psi), dim=-1)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Get an item from the DataFrame.\"\"\"\n        try:\n            return self._df[key]\n        except KeyError as err:\n            raise KeyError(f\"Key '{key}' not found in underlying DataFrame.\") from err\n\n    def set_column(self, column_name: str, value: Any) -&gt; None:\n        \"\"\"Set a column in the underlying DataFrame.\n\n        Parameters\n        ----------\n        column_name : str\n            The name of the column to set\n        value : Any\n            The value to set the column to\n        \"\"\"\n        self._df.loc[:, column_name] = value\n\n    def get_dataframe_copy(self) -&gt; pd.DataFrame:\n        \"\"\"Return a copy of the underlying DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n        A copy of the underlying DataFrame\n        \"\"\"\n        return self._df.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.df_columns","title":"<code>df_columns</code>  <code>property</code>","text":"<p>Get the columns of the DataFrame.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.num_particles","title":"<code>num_particles</code>  <code>property</code>","text":"<p>Get the number of particles in the stack.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get an item from the DataFrame.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Get an item from the DataFrame.\"\"\"\n    try:\n        return self._df[key]\n    except KeyError as err:\n        raise KeyError(f\"Key '{key}' not found in underlying DataFrame.\") from err\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.__init__","title":"<code>__init__(skip_df_load=False, **data)</code>","text":"<p>Initialize the ParticleStack object.</p> <p>Parameters:</p> Name Type Description Default <code>skip_df_load</code> <code>bool</code> <p>Whether to skip loading the DataFrame, by default False and the dataframe is loaded automatically.</p> <code>False</code> <code>data</code> <code>dict[str, Any]</code> <p>The data to initialize the object with.</p> <code>{}</code> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def __init__(self, skip_df_load: bool = False, **data: dict[str, Any]):\n    \"\"\"Initialize the ParticleStack object.\n\n    Parameters\n    ----------\n    skip_df_load : bool, optional\n        Whether to skip loading the DataFrame, by default False and the dataframe\n        is loaded automatically.\n    data : dict[str, Any]\n        The data to initialize the object with.\n    \"\"\"\n    super().__init__(**data)\n\n    if not skip_df_load:\n        self.load_df()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.construct_cropped_statistic_stack","title":"<code>construct_cropped_statistic_stack(stat, handle_bounds='pad', padding_mode='constant', padding_value=0.0)</code>","text":"<p>Return a tensor of the specified statistic for each cropped image.</p> <p>NOTE: This function is very similar to <code>construct_image_stack</code> but returns the statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).</p> <p>Parameters:</p> Name Type Description Default <code>stat</code> <code>Literal[\"mip\", \"scaled_mip\", \"correlation_average\",</code> <p>\"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"] The statistic to extract from the DataFrame.</p> required <code>handle_bounds</code> <code>Literal['pad', 'clip', 'error']</code> <p>How to handle the bounds of the image, by default \"pad\". If \"pad\", the image will be padded with the padding value based on the padding mode. If \"error\", an error will be raised if any region exceeds the image bounds. NOTE: clipping is not supported since returned stack may have inhomogeneous sizes.</p> <code>'pad'</code> <code>padding_mode</code> <code>Literal['constant', 'reflect', 'replicate']</code> <p>The padding mode to use when padding the image, by default \"constant\". \"constant\" pads with the value <code>padding_value</code>, \"reflect\" pads with the reflection of the image at the edge, and \"replicate\" pads with the last pixel of the image. These match the modes available in <code>torch.nn.functional.pad</code>.</p> <code>'constant'</code> <code>padding_value</code> <code>float</code> <p>The value to use for padding when <code>padding_mode</code> is \"constant\", by default 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the number of particles and (H, W) is the extracted box size with (h, w) being the original template size.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_cropped_statistic_stack(\n    self,\n    stat: Literal[\n        \"mip\",\n        \"scaled_mip\",\n        \"correlation_average\",\n        \"correlation_variance\",\n        \"defocus\",\n        \"psi\",\n        \"theta\",\n        \"phi\",\n    ],\n    handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n    padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n    padding_value: float = 0.0,\n) -&gt; torch.Tensor:\n    \"\"\"Return a tensor of the specified statistic for each cropped image.\n\n    NOTE: This function is very similar to `construct_image_stack` but returns the\n    statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).\n\n    Parameters\n    ----------\n    stat : Literal[\"mip\", \"scaled_mip\", \"correlation_average\",\n        \"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"]\n        The statistic to extract from the DataFrame.\n    handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n        How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n        will be padded with the padding value based on the padding mode. If \"error\",\n        an error will be raised if any region exceeds the image bounds. NOTE:\n        clipping is not supported since returned stack may have inhomogeneous sizes.\n    padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n        The padding mode to use when padding the image, by default \"constant\".\n        \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n        reflection of the image at the edge, and \"replicate\" pads with the last\n        pixel of the image. These match the modes available in\n        `torch.nn.functional.pad`.\n    padding_value : float, optional\n        The value to use for padding when `padding_mode` is \"constant\", by default\n        0.0.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the\n        number of particles and (H, W) is the extracted box size with (h, w) being\n        the original template size.\n    \"\"\"\n    stat_col = f\"{stat}_path\"\n    y_col, x_col = self._get_position_reference_columns()\n\n    if stat_col not in self._df.columns:\n        raise ValueError(f\"Statistic '{stat}' not found in the DataFrame.\")\n\n    # Create an empty tensor to store the stat stack\n    h, w = self.original_template_size\n    box_h, box_w = self.extracted_box_size\n    stat_stack = torch.zeros((self.num_particles, box_h - h + 1, box_w - w + 1))\n\n    # Find the indexes in the DataFrame that correspond to each unique stat map\n    stat_index_groups = self._df.groupby(stat_col).groups\n\n    # Loop over each unique stat map and extract the particles\n    for stat_path, indexes in stat_index_groups.items():\n        stat_map = load_mrc_image(stat_path)\n\n        # with reference to the exact pixel of the statistic (top-left)\n        # need to account for relative extracted box size\n        pos_y = self._df.loc[indexes, y_col].to_numpy()\n        pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n        # NOTE: For both references, we need to shift both x and y\n        # by half the different of the original template shape and extracted box\n        # so that the padding around the statistic peak is symmetric.\n        pos_y -= (box_h - h) // 2\n        pos_x -= (box_w - w) // 2\n\n        pos_y = torch.tensor(pos_y)\n        pos_x = torch.tensor(pos_x)\n\n        cropped_stat_maps = get_cropped_image_regions(\n            stat_map,\n            pos_y,\n            pos_x,\n            (box_h - h + 1, box_w - w + 1),\n            pos_reference=\"top-left\",\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode,\n            padding_value=padding_value,\n        )\n        stat_stack[indexes] = cropped_stat_maps\n\n    return stat_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.construct_filter_stack","title":"<code>construct_filter_stack(preprocess_filters, output_shape)</code>","text":"<p>Get stack of Fourier filters from filter config and reference micrographs.</p> <p>Note that here the filters are assumed to be applied globally (i.e. no local whitening, etc. is being done). Whitening filters are calculated with reference to each original micrograph in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>preprocess_filters</code> <code>PreprocessingFilters</code> <p>Configuration object of filters to apply.</p> required <code>output_shape</code> <code>tuple[int, int]</code> <p>What shape along the last two dimensions the filters should be.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of filters with shape (N, h, w) where N is the number of particles and (h, w) is the output shape.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_filter_stack(\n    self, preprocess_filters: PreprocessingFilters, output_shape: tuple[int, int]\n) -&gt; torch.Tensor:\n    \"\"\"Get stack of Fourier filters from filter config and reference micrographs.\n\n    Note that here the filters are assumed to be applied globally (i.e. no local\n    whitening, etc. is being done). Whitening filters are calculated with reference\n    to each original micrograph in the DataFrame.\n\n    Parameters\n    ----------\n    preprocess_filters : PreprocessingFilters\n        Configuration object of filters to apply.\n    output_shape : tuple[int, int]\n        What shape along the last two dimensions the filters should be.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of filters with shape (N, h, w) where N is the number of particles\n        and (h, w) is the output shape.\n    \"\"\"\n    # Create an empty tensor to store the filter stack\n    filter_stack = torch.zeros((self.num_particles, *output_shape))\n\n    # Find the indexes in the DataFrame that correspond to each unique image\n    image_index_groups = self._df.groupby(\"micrograph_path\").groups\n\n    # Loop over each unique image and extract the particles\n    for img_path, indexes in image_index_groups.items():\n        img = load_mrc_image(img_path)\n\n        image_dft = torch.fft.rfftn(img)  # pylint: disable=not-callable\n        image_dft[0, 0] = 0 + 0j\n        cumulative_filter = preprocess_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=output_shape,\n        )\n\n        filter_stack[indexes] = cumulative_filter\n\n    return filter_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.construct_image_stack","title":"<code>construct_image_stack(pos_reference='top-left', handle_bounds='pad', padding_mode='constant', padding_value=0.0)</code>","text":"<p>Construct stack of images from the DataFrame (updates image_stack in-place).</p> <p>This method preferentially selects refined position columns by default (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling back to unrefined positions (pos_x, pos_y) otherwise.</p> <p>This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if available) to extract the boxes from the images. When using top-left reference position, the boxes are extracted as follows, where the dots represent the actual particle in the image</p> <p>Example:     :                +----------------------------------+     :                |                                  |     :                |                                  |     :                |     (x, y) *=== box_w ===+       |     :                |            |             |       |     :                |            |     ....  box_h     |     :           img_height        |    ......   |       |     :                |            |     ....    |       |     :                |            |             |       |     :                |            +=============+       |     :                |                                  |     :                +------------ img_width -----------+</p> <p>When center reference is used, then the position columns in the DataFrame are interpreted as the center of the particle, and the boxes are extracted around this x and y position as follows:</p> <p>Example:     :                +----------------------------------+     :                |                                  |     :                |                                  |     :                |            +=== box_w ===+       |     :                |            |             |       |     :                |            |     ....    |       |     :           img_height        |(x, y).*.. box_h     |     :                |            |     ....    |       |     :                |            |             |       |     :                |            +=============+       |     :                |                                  |     :                +------------ img_width -----------+</p> <p>Parameters:</p> Name Type Description Default <code>pos_reference</code> <code>Literal['center', 'top-left']</code> <p>The reference point for the positions, by default \"top-left\". If \"center\", the boxes extracted will be image[y - box_size // 2 : y + box_size // 2, ...]. Columns in the dataframe which are used as position references are always pos_x and pos_y, or refined_pos_x and refined_pos_y if available. If \"top-left\", the boxes will be image[y : y + box_size, ...]. Leopard-EM uses the \"top-left\" reference position, and unless you know data was processed in a different way you should not change this value.</p> <code>'top-left'</code> <code>handle_bounds</code> <code>Literal['pad', 'clip', 'error']</code> <p>How to handle the bounds of the image, by default \"pad\". If \"pad\", the image will be padded with the padding value based on the padding mode. If \"error\", an error will be raised if any region exceeds the image bounds. NOTE: clipping is not supported since returned stack may have inhomogeneous sizes.</p> <code>'pad'</code> <code>padding_mode</code> <code>Literal['constant', 'reflect', 'replicate']</code> <p>The padding mode to use when padding the image, by default \"constant\". \"constant\" pads with the value <code>padding_value</code>, \"reflect\" pads with the reflection of the image at the edge, and \"replicate\" pads with the last pixel of the image. These match the modes available in <code>torch.nn.functional.pad</code>.</p> <code>'constant'</code> <code>padding_value</code> <code>float</code> <p>The value to use for padding when <code>padding_mode</code> is \"constant\", by default 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of images, this is the internal 'image_stack' attribute.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_image_stack(\n    self,\n    pos_reference: Literal[\"center\", \"top-left\"] = \"top-left\",\n    handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n    padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n    padding_value: float = 0.0,\n) -&gt; torch.Tensor:\n    \"\"\"Construct stack of images from the DataFrame (updates image_stack in-place).\n\n    This method preferentially selects refined position columns by default\n    (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling\n    back to unrefined positions (pos_x, pos_y) otherwise.\n\n    This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if\n    available) to extract the boxes from the images. When using top-left reference\n    position, the boxes are extracted as follows, where the dots represent the\n    actual particle in the image\n\n    Example:\n        :                +----------------------------------+\n        :                |                                  |\n        :                |                                  |\n        :                |     (x, y) *=== box_w ===+       |\n        :                |            |             |       |\n        :                |            |     ....  box_h     |\n        :           img_height        |    ......   |       |\n        :                |            |     ....    |       |\n        :                |            |             |       |\n        :                |            +=============+       |\n        :                |                                  |\n        :                +------------ img_width -----------+\n\n    When center reference is used, then the position columns in the DataFrame are\n    interpreted as the center of the particle, and the boxes are extracted around\n    this x and y position as follows:\n\n    Example:\n        :                +----------------------------------+\n        :                |                                  |\n        :                |                                  |\n        :                |            +=== box_w ===+       |\n        :                |            |             |       |\n        :                |            |     ....    |       |\n        :           img_height        |(x, y).*.. box_h     |\n        :                |            |     ....    |       |\n        :                |            |             |       |\n        :                |            +=============+       |\n        :                |                                  |\n        :                +------------ img_width -----------+\n\n    Parameters\n    ----------\n    pos_reference : Literal[\"center\", \"top-left\"], optional\n        The reference point for the positions, by default \"top-left\". If \"center\",\n        the boxes extracted will be\n        image[y - box_size // 2 : y + box_size // 2, ...].\n        Columns in the dataframe which are used as position references are always\n        pos_x and pos_y, or refined_pos_x and refined_pos_y if available.\n        If \"top-left\", the boxes will be image[y : y + box_size, ...].\n        Leopard-EM uses the \"top-left\" reference position, and unless you know data\n        was processed in a different way you should not change this value.\n    handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n        How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n        will be padded with the padding value based on the padding mode. If \"error\",\n        an error will be raised if any region exceeds the image bounds. NOTE:\n        clipping is not supported since returned stack may have inhomogeneous sizes.\n    padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n        The padding mode to use when padding the image, by default \"constant\".\n        \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n        reflection of the image at the edge, and \"replicate\" pads with the last\n        pixel of the image. These match the modes available in\n        `torch.nn.functional.pad`.\n    padding_value : float, optional\n        The value to use for padding when `padding_mode` is \"constant\", by default\n        0.0.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of images, this is the internal 'image_stack' attribute.\n    \"\"\"\n    # Determine which position columns to use (refined if available)\n    y_col, x_col = self._get_position_reference_columns()\n\n    # Create an empty tensor to store the image stack\n    h, w = self.original_template_size\n    box_h, box_w = self.extracted_box_size\n    image_stack = torch.zeros((self.num_particles, *self.extracted_box_size))\n\n    # Find the indexes in the DataFrame that correspond to each unique image\n    image_index_groups = self._df.groupby(\"micrograph_path\").groups\n    for img_path, indexes in image_index_groups.items():\n        img = load_mrc_image(img_path)\n\n        pos_y = self._df.loc[indexes, y_col].to_numpy()\n        pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n        # If the position reference is \"center\", shift (x, y) by half the original\n        # template width/height so reference is now the top-left corner\n        if pos_reference == \"center\":\n            pos_y = pos_y - h // 2\n            pos_x = pos_x - w // 2\n\n        # Our reference is now a top-left corner of a box of the original template\n        # shape, BUT we want a slightly larger box of extracted_box_size AND this\n        # box to be centered around the particle. Therefore, need to shift the\n        # position half the difference between the original template size and\n        # the extracted box size.\n        pos_y -= (box_h - h) // 2\n        pos_x -= (box_w - w) // 2\n\n        pos_y = torch.tensor(pos_y)\n        pos_x = torch.tensor(pos_x)\n\n        # Code logic is simplified by only using the top-left reference position\n        # in the `get_cropped_image_regions` function. Relative referencing handled\n        # by the ParticleStack class.\n        cropped_images = get_cropped_image_regions(\n            img,\n            pos_y,\n            pos_x,\n            self.extracted_box_size,\n            pos_reference=\"top-left\",\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode,\n            padding_value=padding_value,\n        )\n        image_stack[indexes] = cropped_images\n\n    self.image_stack = image_stack\n\n    return image_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.get_absolute_defocus","title":"<code>get_absolute_defocus(prefer_refined_defocus=True)</code>","text":"<p>Get the absolute defocus values for each particle.</p> <p>NOTE: If the refined defocus values are requested but not present in the DataFrame (either no column or any NaN values), a user warning is raised and the original defocus values are returned instead.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_defocus</code> <code>bool</code> <p>Whether to use the refined defocus values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A tuple of two tensors containing the absolute defocus values along the major (defocus_u) and minor axes (defocus_v), respectively in units of Angstroms.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_absolute_defocus(\n    self, prefer_refined_defocus: bool = True\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Get the absolute defocus values for each particle.\n\n    NOTE: If the refined defocus values are requested but not present in the\n    DataFrame (either no column or any NaN values), a user warning is raised\n    and the original defocus values are returned instead.\n\n    Parameters\n    ----------\n    prefer_refined_defocus : bool, optional\n        Whether to use the refined defocus values\n        (columns prefixed with 'refined_') or not, by default True.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        A tuple of two tensors containing the absolute defocus values along the\n        major (defocus_u) and minor axes (defocus_v), respectively in units of\n        Angstroms.\n    \"\"\"\n    particle_defocus = self.get_relative_defocus(prefer_refined_defocus)\n    defocus_u = torch.tensor(self._df[\"defocus_u\"].to_numpy()) + particle_defocus\n    defocus_v = torch.tensor(self._df[\"defocus_v\"].to_numpy()) + particle_defocus\n\n    return defocus_u, defocus_v\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.get_dataframe_copy","title":"<code>get_dataframe_copy()</code>","text":"<p>Return a copy of the underlying DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <code>A copy of the underlying DataFrame</code> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_dataframe_copy(self) -&gt; pd.DataFrame:\n    \"\"\"Return a copy of the underlying DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n    A copy of the underlying DataFrame\n    \"\"\"\n    return self._df.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.get_euler_angles","title":"<code>get_euler_angles(prefer_refined_angles=True)</code>","text":"<p>Return the Euler angles (phi, theta, psi) of all particles as a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>When true, the refined Euler angles are used (columns prefixed with 'refined_'), otherwise the original angles are used, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of particles and the columns correspond to (phi, theta, psi) in ZYZ format.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_euler_angles(self, prefer_refined_angles: bool = True) -&gt; torch.Tensor:\n    \"\"\"Return the Euler angles (phi, theta, psi) of all particles as a tensor.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool, optional\n        When true, the refined Euler angles are used (columns prefixed with\n        'refined_'), otherwise the original angles are used, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (N, 3) where N is the number of particles and the columns\n        correspond to (phi, theta, psi) in ZYZ format.\n    \"\"\"\n    # Ensure all three refined columns are present, warning if not\n    phi_col = \"phi\"\n    theta_col = \"theta\"\n    psi_col = \"psi\"\n    if prefer_refined_angles:\n        if not all(\n            x in self._df.columns\n            for x in [\"refined_phi\", \"refined_theta\", \"refined_psi\"]\n        ):\n            warnings.warn(\n                \"Refined angles not found in DataFrame, using original angles...\",\n                stacklevel=2,\n            )\n        else:\n            phi_col = \"refined_phi\"\n            theta_col = \"refined_theta\"\n            psi_col = \"refined_psi\"\n\n    # Get the angles from the DataFrame\n    phi = torch.tensor(self._df[phi_col].to_numpy())\n    theta = torch.tensor(self._df[theta_col].to_numpy())\n    psi = torch.tensor(self._df[psi_col].to_numpy())\n\n    return torch.stack((phi, theta, psi), dim=-1)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.get_pixel_size","title":"<code>get_pixel_size(prefer_refined_pixel_size=True)</code>","text":"<p>Get the relative pixel size values for each particle.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_pixel_size</code> <code>bool</code> <p>Whether to use the refined pixel size values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The relative pixel size values for each particle.</p> Warnings <pre><code>Warns if NaN values or no column present for either 'refined_pixel_size'\nor 'pixel_size'. Falls back to the unrefined values.\n</code></pre> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_pixel_size(\n    self,\n    prefer_refined_pixel_size: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Get the relative pixel size values for each particle.\n\n    Parameters\n    ----------\n    prefer_refined_pixel_size : bool, optional\n        Whether to use the refined pixel size values\n        (columns prefixed with 'refined_') or not, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        The relative pixel size values for each particle.\n\n    Warnings\n    --------\n        Warns if NaN values or no column present for either 'refined_pixel_size'\n        or 'pixel_size'. Falls back to the unrefined values.\n    \"\"\"\n    pixel_size_col = \"pixel_size\"\n    if prefer_refined_pixel_size:\n        if \"refined_pixel_size\" not in self._df.columns:\n            warnings.warn(\n                \"Refined pixel size not found in DataFrame, using original\"\n                \" pixel size values...\",\n                stacklevel=2,\n            )\n        elif _any_nan_or_inf(self._df[\"refined_pixel_size\"]):\n            warnings.warn(\n                \"Refined pixel size contain NaN or inf values, using original\"\n                \" pixel size values...\",\n                stacklevel=2,\n            )\n        else:\n            pixel_size_col = \"refined_pixel_size\"\n\n    return torch.tensor(self._df[pixel_size_col].to_numpy())\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.get_relative_defocus","title":"<code>get_relative_defocus(prefer_refined_defocus=True)</code>","text":"<p>Get the relative defocus values for each particle.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_defocus</code> <code>bool</code> <p>Whether to use the refined defocus values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The relative defocus values for each particle.</p> Warnings <pre><code>Warns if NaN values or no column present for either\n'refined_relative_defocus' or 'relative_defocus'.\nFalls back to the unrefined values.\n</code></pre> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_relative_defocus(\n    self,\n    prefer_refined_defocus: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Get the relative defocus values for each particle.\n\n    Parameters\n    ----------\n    prefer_refined_defocus : bool, optional\n        Whether to use the refined defocus values (columns prefixed with 'refined_')\n        or not, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        The relative defocus values for each particle.\n\n    Warnings\n    --------\n        Warns if NaN values or no column present for either\n        'refined_relative_defocus' or 'relative_defocus'.\n        Falls back to the unrefined values.\n    \"\"\"\n    rel_defocus_col = \"relative_defocus\"\n    # Both refined columns must be present AND no values can be NaN or inf\n    if prefer_refined_defocus:\n        if \"refined_relative_defocus\" not in self._df.columns:\n            warnings.warn(\n                \"Refined defocus values not found in DataFrame, using original \"\n                \"defocus values...\",\n                stacklevel=2,\n            )\n        elif _any_nan_or_inf(self._df[\"refined_relative_defocus\"]):\n            warnings.warn(\n                \"Refined defocus values contain NaN or inf values, using original \"\n                \"defocus values...\",\n                stacklevel=2,\n            )\n        else:\n            rel_defocus_col = \"refined_relative_defocus\"\n\n    return torch.tensor(self._df[rel_defocus_col].to_numpy())\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.load_df","title":"<code>load_df()</code>","text":"<p>Load the DataFrame from the specified path.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the DataFrame is missing required columns.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def load_df(self) -&gt; None:\n    \"\"\"Load the DataFrame from the specified path.\n\n    Raises\n    ------\n    ValueError\n        If the DataFrame is missing required columns.\n    \"\"\"\n    tmp_df = pd.read_csv(self.df_path)\n\n    # Validate the DataFrame columns\n    missing_columns = [\n        col for col in MATCH_TEMPLATE_DF_COLUMN_ORDER if col not in tmp_df.columns\n    ]\n    if missing_columns:\n        raise ValueError(\n            f\"Missing the following columns in DataFrame: {missing_columns}\"\n        )\n\n    self._df = tmp_df\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/#leopard_em.pydantic_models.data_structures.ParticleStack.set_column","title":"<code>set_column(column_name, value)</code>","text":"<p>Set a column in the underlying DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>The name of the column to set</p> required <code>value</code> <code>Any</code> <p>The value to set the column to</p> required Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def set_column(self, column_name: str, value: Any) -&gt; None:\n    \"\"\"Set a column in the underlying DataFrame.\n\n    Parameters\n    ----------\n    column_name : str\n        The name of the column to set\n    value : Any\n        The value to set the column to\n    \"\"\"\n    self._df.loc[:, column_name] = value\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/optics_group/","title":"optics_group","text":"<p>Microscope optics group model for micrograph parameters.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/optics_group/#leopard_em.pydantic_models.data_structures.optics_group.OpticsGroup","title":"<code>OpticsGroup</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Stores optics group parameters for the imaging system on a microscope.</p> <p>Currently utilizes the minimal set of parameters for calculating a contrast transfer function (CTF) for a given optics group. Other parameters for future use are included but currently unused.</p> <p>Attributes:</p> Name Type Description <code>label</code> <code>str</code> <p>Unique string (among other optics groups) for the optics group.</p> <code>pixel_size</code> <code>float</code> <p>Pixel size in Angstrom.</p> <code>voltage</code> <code>float</code> <p>Voltage in kV.</p> <code>spherical_aberration</code> <code>float</code> <p>Spherical aberration in mm. Default is 2.7.</p> <code>amplitude_contrast_ratio</code> <code>float</code> <p>Amplitude contrast ratio as a unitless percentage in [0, 1]. Default is 0.07.</p> <code>phase_shift</code> <code>float</code> <p>Additional phase shift of the contrast transfer function in degrees. Default is 0.0 degrees.</p> <code>defocus_u</code> <code>float</code> <p>Defocus (underfocus) along the major axis in Angstrom.</p> <code>defocus_v</code> <code>float</code> <p>Defocus (underfocus) along the minor axis in Angstrom.</p> <code>astigmatism_angle</code> <code>float</code> <p>Angle of defocus astigmatism relative to the X-axis in degrees.</p> <code>ctf_B_factor</code> <code>float</code> <p>B-factor to apply in the contrast transfer function in A^2. Default is 0.0.</p> Unused Attributes: <p>chromatic_aberration : float     Chromatic aberration in mm. Default is ???. mtf_reference : str | PathLike     Path to MTF reference file. mtf_values : list[float]     list of modulation transfer functions values on evenly spaced     resolution grid [0.0, ..., 0.5]. beam_tilt_x : float     Beam tilt X in mrad. beam_tilt_y : float     Beam tilt Y in mrad. odd_zernike : list[float]     list of odd Zernike moments. even_zernike : list[float]     list of even Zernike moments. zernike_moments : list[float]     list of Zernike moments.</p> <p>Methods:</p> Name Description <code>model_dump</code> <p>Returns a dictionary of the model parameters.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/optics_group.py</code> <pre><code>class OpticsGroup(BaseModel2DTM):\n    \"\"\"Stores optics group parameters for the imaging system on a microscope.\n\n    Currently utilizes the minimal set of parameters for calculating a\n    contrast transfer function (CTF) for a given optics group. Other parameters\n    for future use are included but currently unused.\n\n    Attributes\n    ----------\n    label : str\n        Unique string (among other optics groups) for the optics group.\n    pixel_size : float\n        Pixel size in Angstrom.\n    voltage : float\n        Voltage in kV.\n    spherical_aberration : float\n        Spherical aberration in mm. Default is 2.7.\n    amplitude_contrast_ratio : float\n        Amplitude contrast ratio as a unitless percentage in [0, 1]. Default\n        is 0.07.\n    phase_shift : float\n        Additional phase shift of the contrast transfer function in degrees.\n        Default is 0.0 degrees.\n    defocus_u : float\n        Defocus (underfocus) along the major axis in Angstrom.\n    defocus_v : float\n        Defocus (underfocus) along the minor axis in Angstrom.\n    astigmatism_angle : float\n        Angle of defocus astigmatism relative to the X-axis in degrees.\n    ctf_B_factor : float\n        B-factor to apply in the contrast transfer function in A^2. Default\n        is 0.0.\n\n    Unused Attributes:\n    ------------------\n    chromatic_aberration : float\n        Chromatic aberration in mm. Default is ???.\n    mtf_reference : str | PathLike\n        Path to MTF reference file.\n    mtf_values : list[float]\n        list of modulation transfer functions values on evenly spaced\n        resolution grid [0.0, ..., 0.5].\n    beam_tilt_x : float\n        Beam tilt X in mrad.\n    beam_tilt_y : float\n        Beam tilt Y in mrad.\n    odd_zernike : list[float]\n        list of odd Zernike moments.\n    even_zernike : list[float]\n        list of even Zernike moments.\n    zernike_moments : list[float]\n        list of Zernike moments.\n\n    Methods\n    -------\n    model_dump()\n        Returns a dictionary of the model parameters.\n    \"\"\"\n\n    # Currently implemented parameters\n    label: str\n    pixel_size: Annotated[float, Field(ge=0.0)]\n    voltage: Annotated[float, Field(ge=0.0)]\n    spherical_aberration: Annotated[float, Field(ge=0.0, default=2.7)] = 2.7\n    amplitude_contrast_ratio: Annotated[float, Field(ge=0.0, le=1.0, default=0.07)] = (\n        0.07\n    )\n    phase_shift: Annotated[float, Field(default=0.0)] = 0.0\n    defocus_u: float\n    defocus_v: float\n    astigmatism_angle: float\n    ctf_B_factor: Annotated[float, Field(ge=0.0, default=0.0)] = 0.0\n\n    chromatic_aberration: Optional[Annotated[float, Field(ge=0.0)]] = 0.0\n    mtf_reference: Optional[Union[str, PathLike]] = None\n    mtf_values: Optional[list[float]] = None\n    beam_tilt_x: Optional[float] = None\n    beam_tilt_y: Optional[float] = None\n    odd_zernike: Optional[list[float]] = None\n    even_zernike: Optional[list[float]] = None\n    zernike_moments: Optional[list[float]] = None\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/","title":"particle_stack","text":"<p>Particle stack Pydantic model for dealing with extracted particle data.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack","title":"<code>ParticleStack</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Pydantic model for dealing with particle stack data.</p> <p>Attributes:</p> Name Type Description <code>df_path</code> <code>str</code> <p>Path to the DataFrame containing the particle data. The DataFrame must have the following columns (see the documentation for further information):</p> <ul> <li>mip</li> <li>scaled_mip</li> <li>correlation_mean</li> <li>correlation_variance</li> <li>total_correlations</li> <li>pos_x</li> <li>pos_y</li> <li>pos_x_img</li> <li>pos_y_img</li> <li>pos_x_img_angstrom</li> <li>pos_y_img_angstrom</li> <li>psi</li> <li>theta</li> <li>phi</li> <li>relative_defocus</li> <li>refined_relative_defocus</li> <li>defocus_u</li> <li>defocus_v</li> <li>astigmatism_angle</li> <li>pixel_size</li> <li>refined_pixel_size</li> <li>voltage</li> <li>spherical_aberration</li> <li>amplitude_contrast_ratio</li> <li>phase_shift</li> <li>ctf_B_factor</li> <li>micrograph_path</li> <li>template_path</li> <li>mip_path</li> <li>scaled_mip_path</li> <li>psi_path</li> <li>theta_path</li> <li>phi_path</li> <li>defocus_path</li> <li>correlation_average_path</li> <li>correlation_variance_path</li> </ul> <code>extracted_box_size</code> <code>tuple[int, int]</code> <p>The size of the extracted particle boxes in pixels in units of pixels.</p> <code>original_template_size</code> <code>tuple[int, int]</code> <p>The original size of the template used during the matching process. Should be smaller than the extracted box size.</p> <code>image_stack</code> <code>ExcludedTensor</code> <p>The stack of images extracted from the micrographs. Is effectively a pytorch Tensor with shape (N, H, W) where N is the number of particles and (H, W) is the extracted box size.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>class ParticleStack(BaseModel2DTM):\n    \"\"\"Pydantic model for dealing with particle stack data.\n\n    Attributes\n    ----------\n    df_path : str\n        Path to the DataFrame containing the particle data. The DataFrame must have\n        the following columns (see the documentation for further information):\n\n          - mip\n          - scaled_mip\n          - correlation_mean\n          - correlation_variance\n          - total_correlations\n          - pos_x\n          - pos_y\n          - pos_x_img\n          - pos_y_img\n          - pos_x_img_angstrom\n          - pos_y_img_angstrom\n          - psi\n          - theta\n          - phi\n          - relative_defocus\n          - refined_relative_defocus\n          - defocus_u\n          - defocus_v\n          - astigmatism_angle\n          - pixel_size\n          - refined_pixel_size\n          - voltage\n          - spherical_aberration\n          - amplitude_contrast_ratio\n          - phase_shift\n          - ctf_B_factor\n          - micrograph_path\n          - template_path\n          - mip_path\n          - scaled_mip_path\n          - psi_path\n          - theta_path\n          - phi_path\n          - defocus_path\n          - correlation_average_path\n          - correlation_variance_path\n\n    extracted_box_size : tuple[int, int]\n        The size of the extracted particle boxes in pixels in units of pixels.\n    original_template_size : tuple[int, int]\n        The original size of the template used during the matching process. Should be\n        smaller than the extracted box size.\n    image_stack : ExcludedTensor\n        The stack of images extracted from the micrographs. Is effectively a pytorch\n        Tensor with shape (N, H, W) where N is the number of particles and (H, W) is\n        the extracted box size.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized fields\n    df_path: str\n    extracted_box_size: tuple[int, int]\n    original_template_size: tuple[int, int]\n\n    # Imported tabular data (not serialized)\n    _df: pd.DataFrame\n\n    # Cropped out view of the particles from images\n    image_stack: ExcludedTensor\n\n    def __init__(self, skip_df_load: bool = False, **data: dict[str, Any]):\n        \"\"\"Initialize the ParticleStack object.\n\n        Parameters\n        ----------\n        skip_df_load : bool, optional\n            Whether to skip loading the DataFrame, by default False and the dataframe\n            is loaded automatically.\n        data : dict[str, Any]\n            The data to initialize the object with.\n        \"\"\"\n        super().__init__(**data)\n\n        if not skip_df_load:\n            self.load_df()\n\n    def load_df(self) -&gt; None:\n        \"\"\"Load the DataFrame from the specified path.\n\n        Raises\n        ------\n        ValueError\n            If the DataFrame is missing required columns.\n        \"\"\"\n        tmp_df = pd.read_csv(self.df_path)\n\n        # Validate the DataFrame columns\n        missing_columns = [\n            col for col in MATCH_TEMPLATE_DF_COLUMN_ORDER if col not in tmp_df.columns\n        ]\n        if missing_columns:\n            raise ValueError(\n                f\"Missing the following columns in DataFrame: {missing_columns}\"\n            )\n\n        self._df = tmp_df\n\n    def _get_position_reference_columns(self) -&gt; tuple[str, str]:\n        \"\"\"Get the position reference columns based on the DataFrame.\"\"\"\n        y_col = \"refined_pos_y\" if \"refined_pos_y\" in self._df.columns else \"pos_y\"\n        x_col = \"refined_pos_x\" if \"refined_pos_x\" in self._df.columns else \"pos_x\"\n        return y_col, x_col\n\n    def construct_image_stack(\n        self,\n        pos_reference: Literal[\"center\", \"top-left\"] = \"top-left\",\n        handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n        padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n        padding_value: float = 0.0,\n    ) -&gt; torch.Tensor:\n        \"\"\"Construct stack of images from the DataFrame (updates image_stack in-place).\n\n        This method preferentially selects refined position columns by default\n        (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling\n        back to unrefined positions (pos_x, pos_y) otherwise.\n\n        This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if\n        available) to extract the boxes from the images. When using top-left reference\n        position, the boxes are extracted as follows, where the dots represent the\n        actual particle in the image\n\n        Example:\n            :                +----------------------------------+\n            :                |                                  |\n            :                |                                  |\n            :                |     (x, y) *=== box_w ===+       |\n            :                |            |             |       |\n            :                |            |     ....  box_h     |\n            :           img_height        |    ......   |       |\n            :                |            |     ....    |       |\n            :                |            |             |       |\n            :                |            +=============+       |\n            :                |                                  |\n            :                +------------ img_width -----------+\n\n        When center reference is used, then the position columns in the DataFrame are\n        interpreted as the center of the particle, and the boxes are extracted around\n        this x and y position as follows:\n\n        Example:\n            :                +----------------------------------+\n            :                |                                  |\n            :                |                                  |\n            :                |            +=== box_w ===+       |\n            :                |            |             |       |\n            :                |            |     ....    |       |\n            :           img_height        |(x, y).*.. box_h     |\n            :                |            |     ....    |       |\n            :                |            |             |       |\n            :                |            +=============+       |\n            :                |                                  |\n            :                +------------ img_width -----------+\n\n        Parameters\n        ----------\n        pos_reference : Literal[\"center\", \"top-left\"], optional\n            The reference point for the positions, by default \"top-left\". If \"center\",\n            the boxes extracted will be\n            image[y - box_size // 2 : y + box_size // 2, ...].\n            Columns in the dataframe which are used as position references are always\n            pos_x and pos_y, or refined_pos_x and refined_pos_y if available.\n            If \"top-left\", the boxes will be image[y : y + box_size, ...].\n            Leopard-EM uses the \"top-left\" reference position, and unless you know data\n            was processed in a different way you should not change this value.\n        handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n            How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n            will be padded with the padding value based on the padding mode. If \"error\",\n            an error will be raised if any region exceeds the image bounds. NOTE:\n            clipping is not supported since returned stack may have inhomogeneous sizes.\n        padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n            The padding mode to use when padding the image, by default \"constant\".\n            \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n            reflection of the image at the edge, and \"replicate\" pads with the last\n            pixel of the image. These match the modes available in\n            `torch.nn.functional.pad`.\n        padding_value : float, optional\n            The value to use for padding when `padding_mode` is \"constant\", by default\n            0.0.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of images, this is the internal 'image_stack' attribute.\n        \"\"\"\n        # Determine which position columns to use (refined if available)\n        y_col, x_col = self._get_position_reference_columns()\n\n        # Create an empty tensor to store the image stack\n        h, w = self.original_template_size\n        box_h, box_w = self.extracted_box_size\n        image_stack = torch.zeros((self.num_particles, *self.extracted_box_size))\n\n        # Find the indexes in the DataFrame that correspond to each unique image\n        image_index_groups = self._df.groupby(\"micrograph_path\").groups\n        for img_path, indexes in image_index_groups.items():\n            img = load_mrc_image(img_path)\n\n            pos_y = self._df.loc[indexes, y_col].to_numpy()\n            pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n            # If the position reference is \"center\", shift (x, y) by half the original\n            # template width/height so reference is now the top-left corner\n            if pos_reference == \"center\":\n                pos_y = pos_y - h // 2\n                pos_x = pos_x - w // 2\n\n            # Our reference is now a top-left corner of a box of the original template\n            # shape, BUT we want a slightly larger box of extracted_box_size AND this\n            # box to be centered around the particle. Therefore, need to shift the\n            # position half the difference between the original template size and\n            # the extracted box size.\n            pos_y -= (box_h - h) // 2\n            pos_x -= (box_w - w) // 2\n\n            pos_y = torch.tensor(pos_y)\n            pos_x = torch.tensor(pos_x)\n\n            # Code logic is simplified by only using the top-left reference position\n            # in the `get_cropped_image_regions` function. Relative referencing handled\n            # by the ParticleStack class.\n            cropped_images = get_cropped_image_regions(\n                img,\n                pos_y,\n                pos_x,\n                self.extracted_box_size,\n                pos_reference=\"top-left\",\n                handle_bounds=handle_bounds,\n                padding_mode=padding_mode,\n                padding_value=padding_value,\n            )\n            image_stack[indexes] = cropped_images\n\n        self.image_stack = image_stack\n\n        return image_stack\n\n    def construct_cropped_statistic_stack(\n        self,\n        stat: Literal[\n            \"mip\",\n            \"scaled_mip\",\n            \"correlation_average\",\n            \"correlation_variance\",\n            \"defocus\",\n            \"psi\",\n            \"theta\",\n            \"phi\",\n        ],\n        handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n        padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n        padding_value: float = 0.0,\n    ) -&gt; torch.Tensor:\n        \"\"\"Return a tensor of the specified statistic for each cropped image.\n\n        NOTE: This function is very similar to `construct_image_stack` but returns the\n        statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).\n\n        Parameters\n        ----------\n        stat : Literal[\"mip\", \"scaled_mip\", \"correlation_average\",\n            \"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"]\n            The statistic to extract from the DataFrame.\n        handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n            How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n            will be padded with the padding value based on the padding mode. If \"error\",\n            an error will be raised if any region exceeds the image bounds. NOTE:\n            clipping is not supported since returned stack may have inhomogeneous sizes.\n        padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n            The padding mode to use when padding the image, by default \"constant\".\n            \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n            reflection of the image at the edge, and \"replicate\" pads with the last\n            pixel of the image. These match the modes available in\n            `torch.nn.functional.pad`.\n        padding_value : float, optional\n            The value to use for padding when `padding_mode` is \"constant\", by default\n            0.0.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the\n            number of particles and (H, W) is the extracted box size with (h, w) being\n            the original template size.\n        \"\"\"\n        stat_col = f\"{stat}_path\"\n        y_col, x_col = self._get_position_reference_columns()\n\n        if stat_col not in self._df.columns:\n            raise ValueError(f\"Statistic '{stat}' not found in the DataFrame.\")\n\n        # Create an empty tensor to store the stat stack\n        h, w = self.original_template_size\n        box_h, box_w = self.extracted_box_size\n        stat_stack = torch.zeros((self.num_particles, box_h - h + 1, box_w - w + 1))\n\n        # Find the indexes in the DataFrame that correspond to each unique stat map\n        stat_index_groups = self._df.groupby(stat_col).groups\n\n        # Loop over each unique stat map and extract the particles\n        for stat_path, indexes in stat_index_groups.items():\n            stat_map = load_mrc_image(stat_path)\n\n            # with reference to the exact pixel of the statistic (top-left)\n            # need to account for relative extracted box size\n            pos_y = self._df.loc[indexes, y_col].to_numpy()\n            pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n            # NOTE: For both references, we need to shift both x and y\n            # by half the different of the original template shape and extracted box\n            # so that the padding around the statistic peak is symmetric.\n            pos_y -= (box_h - h) // 2\n            pos_x -= (box_w - w) // 2\n\n            pos_y = torch.tensor(pos_y)\n            pos_x = torch.tensor(pos_x)\n\n            cropped_stat_maps = get_cropped_image_regions(\n                stat_map,\n                pos_y,\n                pos_x,\n                (box_h - h + 1, box_w - w + 1),\n                pos_reference=\"top-left\",\n                handle_bounds=handle_bounds,\n                padding_mode=padding_mode,\n                padding_value=padding_value,\n            )\n            stat_stack[indexes] = cropped_stat_maps\n\n        return stat_stack\n\n    def construct_filter_stack(\n        self, preprocess_filters: PreprocessingFilters, output_shape: tuple[int, int]\n    ) -&gt; torch.Tensor:\n        \"\"\"Get stack of Fourier filters from filter config and reference micrographs.\n\n        Note that here the filters are assumed to be applied globally (i.e. no local\n        whitening, etc. is being done). Whitening filters are calculated with reference\n        to each original micrograph in the DataFrame.\n\n        Parameters\n        ----------\n        preprocess_filters : PreprocessingFilters\n            Configuration object of filters to apply.\n        output_shape : tuple[int, int]\n            What shape along the last two dimensions the filters should be.\n\n        Returns\n        -------\n        torch.Tensor\n            The stack of filters with shape (N, h, w) where N is the number of particles\n            and (h, w) is the output shape.\n        \"\"\"\n        # Create an empty tensor to store the filter stack\n        filter_stack = torch.zeros((self.num_particles, *output_shape))\n\n        # Find the indexes in the DataFrame that correspond to each unique image\n        image_index_groups = self._df.groupby(\"micrograph_path\").groups\n\n        # Loop over each unique image and extract the particles\n        for img_path, indexes in image_index_groups.items():\n            img = load_mrc_image(img_path)\n\n            image_dft = torch.fft.rfftn(img)  # pylint: disable=not-callable\n            image_dft[0, 0] = 0 + 0j\n            cumulative_filter = preprocess_filters.get_combined_filter(\n                ref_img_rfft=image_dft,\n                output_shape=output_shape,\n            )\n\n            filter_stack[indexes] = cumulative_filter\n\n        return filter_stack\n\n    @property\n    def df_columns(self) -&gt; list[str]:\n        \"\"\"Get the columns of the DataFrame.\"\"\"\n        return list(self._df.columns.tolist())\n\n    @property\n    def num_particles(self) -&gt; int:\n        \"\"\"Get the number of particles in the stack.\"\"\"\n        return len(self._df)\n\n    def get_relative_defocus(\n        self,\n        prefer_refined_defocus: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Get the relative defocus values for each particle.\n\n        Parameters\n        ----------\n        prefer_refined_defocus : bool, optional\n            Whether to use the refined defocus values (columns prefixed with 'refined_')\n            or not, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            The relative defocus values for each particle.\n\n        Warnings\n        --------\n            Warns if NaN values or no column present for either\n            'refined_relative_defocus' or 'relative_defocus'.\n            Falls back to the unrefined values.\n        \"\"\"\n        rel_defocus_col = \"relative_defocus\"\n        # Both refined columns must be present AND no values can be NaN or inf\n        if prefer_refined_defocus:\n            if \"refined_relative_defocus\" not in self._df.columns:\n                warnings.warn(\n                    \"Refined defocus values not found in DataFrame, using original \"\n                    \"defocus values...\",\n                    stacklevel=2,\n                )\n            elif _any_nan_or_inf(self._df[\"refined_relative_defocus\"]):\n                warnings.warn(\n                    \"Refined defocus values contain NaN or inf values, using original \"\n                    \"defocus values...\",\n                    stacklevel=2,\n                )\n            else:\n                rel_defocus_col = \"refined_relative_defocus\"\n\n        return torch.tensor(self._df[rel_defocus_col].to_numpy())\n\n    def get_absolute_defocus(\n        self, prefer_refined_defocus: bool = True\n    ) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Get the absolute defocus values for each particle.\n\n        NOTE: If the refined defocus values are requested but not present in the\n        DataFrame (either no column or any NaN values), a user warning is raised\n        and the original defocus values are returned instead.\n\n        Parameters\n        ----------\n        prefer_refined_defocus : bool, optional\n            Whether to use the refined defocus values\n            (columns prefixed with 'refined_') or not, by default True.\n\n        Returns\n        -------\n        tuple[torch.Tensor, torch.Tensor]\n            A tuple of two tensors containing the absolute defocus values along the\n            major (defocus_u) and minor axes (defocus_v), respectively in units of\n            Angstroms.\n        \"\"\"\n        particle_defocus = self.get_relative_defocus(prefer_refined_defocus)\n        defocus_u = torch.tensor(self._df[\"defocus_u\"].to_numpy()) + particle_defocus\n        defocus_v = torch.tensor(self._df[\"defocus_v\"].to_numpy()) + particle_defocus\n\n        return defocus_u, defocus_v\n\n    def get_pixel_size(\n        self,\n        prefer_refined_pixel_size: bool = True,\n    ) -&gt; torch.Tensor:\n        \"\"\"Get the relative pixel size values for each particle.\n\n        Parameters\n        ----------\n        prefer_refined_pixel_size : bool, optional\n            Whether to use the refined pixel size values\n            (columns prefixed with 'refined_') or not, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            The relative pixel size values for each particle.\n\n        Warnings\n        --------\n            Warns if NaN values or no column present for either 'refined_pixel_size'\n            or 'pixel_size'. Falls back to the unrefined values.\n        \"\"\"\n        pixel_size_col = \"pixel_size\"\n        if prefer_refined_pixel_size:\n            if \"refined_pixel_size\" not in self._df.columns:\n                warnings.warn(\n                    \"Refined pixel size not found in DataFrame, using original\"\n                    \" pixel size values...\",\n                    stacklevel=2,\n                )\n            elif _any_nan_or_inf(self._df[\"refined_pixel_size\"]):\n                warnings.warn(\n                    \"Refined pixel size contain NaN or inf values, using original\"\n                    \" pixel size values...\",\n                    stacklevel=2,\n                )\n            else:\n                pixel_size_col = \"refined_pixel_size\"\n\n        return torch.tensor(self._df[pixel_size_col].to_numpy())\n\n    def get_euler_angles(self, prefer_refined_angles: bool = True) -&gt; torch.Tensor:\n        \"\"\"Return the Euler angles (phi, theta, psi) of all particles as a tensor.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool, optional\n            When true, the refined Euler angles are used (columns prefixed with\n            'refined_'), otherwise the original angles are used, by default True.\n\n        Returns\n        -------\n        torch.Tensor\n            A tensor of shape (N, 3) where N is the number of particles and the columns\n            correspond to (phi, theta, psi) in ZYZ format.\n        \"\"\"\n        # Ensure all three refined columns are present, warning if not\n        phi_col = \"phi\"\n        theta_col = \"theta\"\n        psi_col = \"psi\"\n        if prefer_refined_angles:\n            if not all(\n                x in self._df.columns\n                for x in [\"refined_phi\", \"refined_theta\", \"refined_psi\"]\n            ):\n                warnings.warn(\n                    \"Refined angles not found in DataFrame, using original angles...\",\n                    stacklevel=2,\n                )\n            else:\n                phi_col = \"refined_phi\"\n                theta_col = \"refined_theta\"\n                psi_col = \"refined_psi\"\n\n        # Get the angles from the DataFrame\n        phi = torch.tensor(self._df[phi_col].to_numpy())\n        theta = torch.tensor(self._df[theta_col].to_numpy())\n        psi = torch.tensor(self._df[psi_col].to_numpy())\n\n        return torch.stack((phi, theta, psi), dim=-1)\n\n    def __getitem__(self, key: str) -&gt; Any:\n        \"\"\"Get an item from the DataFrame.\"\"\"\n        try:\n            return self._df[key]\n        except KeyError as err:\n            raise KeyError(f\"Key '{key}' not found in underlying DataFrame.\") from err\n\n    def set_column(self, column_name: str, value: Any) -&gt; None:\n        \"\"\"Set a column in the underlying DataFrame.\n\n        Parameters\n        ----------\n        column_name : str\n            The name of the column to set\n        value : Any\n            The value to set the column to\n        \"\"\"\n        self._df.loc[:, column_name] = value\n\n    def get_dataframe_copy(self) -&gt; pd.DataFrame:\n        \"\"\"Return a copy of the underlying DataFrame.\n\n        Returns\n        -------\n        pd.DataFrame\n        A copy of the underlying DataFrame\n        \"\"\"\n        return self._df.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.df_columns","title":"<code>df_columns</code>  <code>property</code>","text":"<p>Get the columns of the DataFrame.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.num_particles","title":"<code>num_particles</code>  <code>property</code>","text":"<p>Get the number of particles in the stack.</p>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Get an item from the DataFrame.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def __getitem__(self, key: str) -&gt; Any:\n    \"\"\"Get an item from the DataFrame.\"\"\"\n    try:\n        return self._df[key]\n    except KeyError as err:\n        raise KeyError(f\"Key '{key}' not found in underlying DataFrame.\") from err\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.__init__","title":"<code>__init__(skip_df_load=False, **data)</code>","text":"<p>Initialize the ParticleStack object.</p> <p>Parameters:</p> Name Type Description Default <code>skip_df_load</code> <code>bool</code> <p>Whether to skip loading the DataFrame, by default False and the dataframe is loaded automatically.</p> <code>False</code> <code>data</code> <code>dict[str, Any]</code> <p>The data to initialize the object with.</p> <code>{}</code> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def __init__(self, skip_df_load: bool = False, **data: dict[str, Any]):\n    \"\"\"Initialize the ParticleStack object.\n\n    Parameters\n    ----------\n    skip_df_load : bool, optional\n        Whether to skip loading the DataFrame, by default False and the dataframe\n        is loaded automatically.\n    data : dict[str, Any]\n        The data to initialize the object with.\n    \"\"\"\n    super().__init__(**data)\n\n    if not skip_df_load:\n        self.load_df()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.construct_cropped_statistic_stack","title":"<code>construct_cropped_statistic_stack(stat, handle_bounds='pad', padding_mode='constant', padding_value=0.0)</code>","text":"<p>Return a tensor of the specified statistic for each cropped image.</p> <p>NOTE: This function is very similar to <code>construct_image_stack</code> but returns the statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).</p> <p>Parameters:</p> Name Type Description Default <code>stat</code> <code>Literal[\"mip\", \"scaled_mip\", \"correlation_average\",</code> <p>\"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"] The statistic to extract from the DataFrame.</p> required <code>handle_bounds</code> <code>Literal['pad', 'clip', 'error']</code> <p>How to handle the bounds of the image, by default \"pad\". If \"pad\", the image will be padded with the padding value based on the padding mode. If \"error\", an error will be raised if any region exceeds the image bounds. NOTE: clipping is not supported since returned stack may have inhomogeneous sizes.</p> <code>'pad'</code> <code>padding_mode</code> <code>Literal['constant', 'reflect', 'replicate']</code> <p>The padding mode to use when padding the image, by default \"constant\". \"constant\" pads with the value <code>padding_value</code>, \"reflect\" pads with the reflection of the image at the edge, and \"replicate\" pads with the last pixel of the image. These match the modes available in <code>torch.nn.functional.pad</code>.</p> <code>'constant'</code> <code>padding_value</code> <code>float</code> <p>The value to use for padding when <code>padding_mode</code> is \"constant\", by default 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the number of particles and (H, W) is the extracted box size with (h, w) being the original template size.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_cropped_statistic_stack(\n    self,\n    stat: Literal[\n        \"mip\",\n        \"scaled_mip\",\n        \"correlation_average\",\n        \"correlation_variance\",\n        \"defocus\",\n        \"psi\",\n        \"theta\",\n        \"phi\",\n    ],\n    handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n    padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n    padding_value: float = 0.0,\n) -&gt; torch.Tensor:\n    \"\"\"Return a tensor of the specified statistic for each cropped image.\n\n    NOTE: This function is very similar to `construct_image_stack` but returns the\n    statistic in one of the result maps. Shape here is (N, H - h + 1, W - w + 1).\n\n    Parameters\n    ----------\n    stat : Literal[\"mip\", \"scaled_mip\", \"correlation_average\",\n        \"correlation_variance\", \"defocus\", \"psi\", \"theta\", \"phi\"]\n        The statistic to extract from the DataFrame.\n    handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n        How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n        will be padded with the padding value based on the padding mode. If \"error\",\n        an error will be raised if any region exceeds the image bounds. NOTE:\n        clipping is not supported since returned stack may have inhomogeneous sizes.\n    padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n        The padding mode to use when padding the image, by default \"constant\".\n        \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n        reflection of the image at the edge, and \"replicate\" pads with the last\n        pixel of the image. These match the modes available in\n        `torch.nn.functional.pad`.\n    padding_value : float, optional\n        The value to use for padding when `padding_mode` is \"constant\", by default\n        0.0.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of statistics with shape (N, H - h + 1, W - w + 1) where N is the\n        number of particles and (H, W) is the extracted box size with (h, w) being\n        the original template size.\n    \"\"\"\n    stat_col = f\"{stat}_path\"\n    y_col, x_col = self._get_position_reference_columns()\n\n    if stat_col not in self._df.columns:\n        raise ValueError(f\"Statistic '{stat}' not found in the DataFrame.\")\n\n    # Create an empty tensor to store the stat stack\n    h, w = self.original_template_size\n    box_h, box_w = self.extracted_box_size\n    stat_stack = torch.zeros((self.num_particles, box_h - h + 1, box_w - w + 1))\n\n    # Find the indexes in the DataFrame that correspond to each unique stat map\n    stat_index_groups = self._df.groupby(stat_col).groups\n\n    # Loop over each unique stat map and extract the particles\n    for stat_path, indexes in stat_index_groups.items():\n        stat_map = load_mrc_image(stat_path)\n\n        # with reference to the exact pixel of the statistic (top-left)\n        # need to account for relative extracted box size\n        pos_y = self._df.loc[indexes, y_col].to_numpy()\n        pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n        # NOTE: For both references, we need to shift both x and y\n        # by half the different of the original template shape and extracted box\n        # so that the padding around the statistic peak is symmetric.\n        pos_y -= (box_h - h) // 2\n        pos_x -= (box_w - w) // 2\n\n        pos_y = torch.tensor(pos_y)\n        pos_x = torch.tensor(pos_x)\n\n        cropped_stat_maps = get_cropped_image_regions(\n            stat_map,\n            pos_y,\n            pos_x,\n            (box_h - h + 1, box_w - w + 1),\n            pos_reference=\"top-left\",\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode,\n            padding_value=padding_value,\n        )\n        stat_stack[indexes] = cropped_stat_maps\n\n    return stat_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.construct_filter_stack","title":"<code>construct_filter_stack(preprocess_filters, output_shape)</code>","text":"<p>Get stack of Fourier filters from filter config and reference micrographs.</p> <p>Note that here the filters are assumed to be applied globally (i.e. no local whitening, etc. is being done). Whitening filters are calculated with reference to each original micrograph in the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>preprocess_filters</code> <code>PreprocessingFilters</code> <p>Configuration object of filters to apply.</p> required <code>output_shape</code> <code>tuple[int, int]</code> <p>What shape along the last two dimensions the filters should be.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of filters with shape (N, h, w) where N is the number of particles and (h, w) is the output shape.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_filter_stack(\n    self, preprocess_filters: PreprocessingFilters, output_shape: tuple[int, int]\n) -&gt; torch.Tensor:\n    \"\"\"Get stack of Fourier filters from filter config and reference micrographs.\n\n    Note that here the filters are assumed to be applied globally (i.e. no local\n    whitening, etc. is being done). Whitening filters are calculated with reference\n    to each original micrograph in the DataFrame.\n\n    Parameters\n    ----------\n    preprocess_filters : PreprocessingFilters\n        Configuration object of filters to apply.\n    output_shape : tuple[int, int]\n        What shape along the last two dimensions the filters should be.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of filters with shape (N, h, w) where N is the number of particles\n        and (h, w) is the output shape.\n    \"\"\"\n    # Create an empty tensor to store the filter stack\n    filter_stack = torch.zeros((self.num_particles, *output_shape))\n\n    # Find the indexes in the DataFrame that correspond to each unique image\n    image_index_groups = self._df.groupby(\"micrograph_path\").groups\n\n    # Loop over each unique image and extract the particles\n    for img_path, indexes in image_index_groups.items():\n        img = load_mrc_image(img_path)\n\n        image_dft = torch.fft.rfftn(img)  # pylint: disable=not-callable\n        image_dft[0, 0] = 0 + 0j\n        cumulative_filter = preprocess_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=output_shape,\n        )\n\n        filter_stack[indexes] = cumulative_filter\n\n    return filter_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.construct_image_stack","title":"<code>construct_image_stack(pos_reference='top-left', handle_bounds='pad', padding_mode='constant', padding_value=0.0)</code>","text":"<p>Construct stack of images from the DataFrame (updates image_stack in-place).</p> <p>This method preferentially selects refined position columns by default (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling back to unrefined positions (pos_x, pos_y) otherwise.</p> <p>This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if available) to extract the boxes from the images. When using top-left reference position, the boxes are extracted as follows, where the dots represent the actual particle in the image</p> <p>Example:     :                +----------------------------------+     :                |                                  |     :                |                                  |     :                |     (x, y) *=== box_w ===+       |     :                |            |             |       |     :                |            |     ....  box_h     |     :           img_height        |    ......   |       |     :                |            |     ....    |       |     :                |            |             |       |     :                |            +=============+       |     :                |                                  |     :                +------------ img_width -----------+</p> <p>When center reference is used, then the position columns in the DataFrame are interpreted as the center of the particle, and the boxes are extracted around this x and y position as follows:</p> <p>Example:     :                +----------------------------------+     :                |                                  |     :                |                                  |     :                |            +=== box_w ===+       |     :                |            |             |       |     :                |            |     ....    |       |     :           img_height        |(x, y).*.. box_h     |     :                |            |     ....    |       |     :                |            |             |       |     :                |            +=============+       |     :                |                                  |     :                +------------ img_width -----------+</p> <p>Parameters:</p> Name Type Description Default <code>pos_reference</code> <code>Literal['center', 'top-left']</code> <p>The reference point for the positions, by default \"top-left\". If \"center\", the boxes extracted will be image[y - box_size // 2 : y + box_size // 2, ...]. Columns in the dataframe which are used as position references are always pos_x and pos_y, or refined_pos_x and refined_pos_y if available. If \"top-left\", the boxes will be image[y : y + box_size, ...]. Leopard-EM uses the \"top-left\" reference position, and unless you know data was processed in a different way you should not change this value.</p> <code>'top-left'</code> <code>handle_bounds</code> <code>Literal['pad', 'clip', 'error']</code> <p>How to handle the bounds of the image, by default \"pad\". If \"pad\", the image will be padded with the padding value based on the padding mode. If \"error\", an error will be raised if any region exceeds the image bounds. NOTE: clipping is not supported since returned stack may have inhomogeneous sizes.</p> <code>'pad'</code> <code>padding_mode</code> <code>Literal['constant', 'reflect', 'replicate']</code> <p>The padding mode to use when padding the image, by default \"constant\". \"constant\" pads with the value <code>padding_value</code>, \"reflect\" pads with the reflection of the image at the edge, and \"replicate\" pads with the last pixel of the image. These match the modes available in <code>torch.nn.functional.pad</code>.</p> <code>'constant'</code> <code>padding_value</code> <code>float</code> <p>The value to use for padding when <code>padding_mode</code> is \"constant\", by default 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The stack of images, this is the internal 'image_stack' attribute.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def construct_image_stack(\n    self,\n    pos_reference: Literal[\"center\", \"top-left\"] = \"top-left\",\n    handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n    padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n    padding_value: float = 0.0,\n) -&gt; torch.Tensor:\n    \"\"\"Construct stack of images from the DataFrame (updates image_stack in-place).\n\n    This method preferentially selects refined position columns by default\n    (refined_pos_x, refined_pos_y) if they are present in the DataFrame, falling\n    back to unrefined positions (pos_x, pos_y) otherwise.\n\n    This method uses columns pos_x and pos_y (or refined_pos_x and refined_pos_y if\n    available) to extract the boxes from the images. When using top-left reference\n    position, the boxes are extracted as follows, where the dots represent the\n    actual particle in the image\n\n    Example:\n        :                +----------------------------------+\n        :                |                                  |\n        :                |                                  |\n        :                |     (x, y) *=== box_w ===+       |\n        :                |            |             |       |\n        :                |            |     ....  box_h     |\n        :           img_height        |    ......   |       |\n        :                |            |     ....    |       |\n        :                |            |             |       |\n        :                |            +=============+       |\n        :                |                                  |\n        :                +------------ img_width -----------+\n\n    When center reference is used, then the position columns in the DataFrame are\n    interpreted as the center of the particle, and the boxes are extracted around\n    this x and y position as follows:\n\n    Example:\n        :                +----------------------------------+\n        :                |                                  |\n        :                |                                  |\n        :                |            +=== box_w ===+       |\n        :                |            |             |       |\n        :                |            |     ....    |       |\n        :           img_height        |(x, y).*.. box_h     |\n        :                |            |     ....    |       |\n        :                |            |             |       |\n        :                |            +=============+       |\n        :                |                                  |\n        :                +------------ img_width -----------+\n\n    Parameters\n    ----------\n    pos_reference : Literal[\"center\", \"top-left\"], optional\n        The reference point for the positions, by default \"top-left\". If \"center\",\n        the boxes extracted will be\n        image[y - box_size // 2 : y + box_size // 2, ...].\n        Columns in the dataframe which are used as position references are always\n        pos_x and pos_y, or refined_pos_x and refined_pos_y if available.\n        If \"top-left\", the boxes will be image[y : y + box_size, ...].\n        Leopard-EM uses the \"top-left\" reference position, and unless you know data\n        was processed in a different way you should not change this value.\n    handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n        How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n        will be padded with the padding value based on the padding mode. If \"error\",\n        an error will be raised if any region exceeds the image bounds. NOTE:\n        clipping is not supported since returned stack may have inhomogeneous sizes.\n    padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n        The padding mode to use when padding the image, by default \"constant\".\n        \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n        reflection of the image at the edge, and \"replicate\" pads with the last\n        pixel of the image. These match the modes available in\n        `torch.nn.functional.pad`.\n    padding_value : float, optional\n        The value to use for padding when `padding_mode` is \"constant\", by default\n        0.0.\n\n    Returns\n    -------\n    torch.Tensor\n        The stack of images, this is the internal 'image_stack' attribute.\n    \"\"\"\n    # Determine which position columns to use (refined if available)\n    y_col, x_col = self._get_position_reference_columns()\n\n    # Create an empty tensor to store the image stack\n    h, w = self.original_template_size\n    box_h, box_w = self.extracted_box_size\n    image_stack = torch.zeros((self.num_particles, *self.extracted_box_size))\n\n    # Find the indexes in the DataFrame that correspond to each unique image\n    image_index_groups = self._df.groupby(\"micrograph_path\").groups\n    for img_path, indexes in image_index_groups.items():\n        img = load_mrc_image(img_path)\n\n        pos_y = self._df.loc[indexes, y_col].to_numpy()\n        pos_x = self._df.loc[indexes, x_col].to_numpy()\n\n        # If the position reference is \"center\", shift (x, y) by half the original\n        # template width/height so reference is now the top-left corner\n        if pos_reference == \"center\":\n            pos_y = pos_y - h // 2\n            pos_x = pos_x - w // 2\n\n        # Our reference is now a top-left corner of a box of the original template\n        # shape, BUT we want a slightly larger box of extracted_box_size AND this\n        # box to be centered around the particle. Therefore, need to shift the\n        # position half the difference between the original template size and\n        # the extracted box size.\n        pos_y -= (box_h - h) // 2\n        pos_x -= (box_w - w) // 2\n\n        pos_y = torch.tensor(pos_y)\n        pos_x = torch.tensor(pos_x)\n\n        # Code logic is simplified by only using the top-left reference position\n        # in the `get_cropped_image_regions` function. Relative referencing handled\n        # by the ParticleStack class.\n        cropped_images = get_cropped_image_regions(\n            img,\n            pos_y,\n            pos_x,\n            self.extracted_box_size,\n            pos_reference=\"top-left\",\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode,\n            padding_value=padding_value,\n        )\n        image_stack[indexes] = cropped_images\n\n    self.image_stack = image_stack\n\n    return image_stack\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.get_absolute_defocus","title":"<code>get_absolute_defocus(prefer_refined_defocus=True)</code>","text":"<p>Get the absolute defocus values for each particle.</p> <p>NOTE: If the refined defocus values are requested but not present in the DataFrame (either no column or any NaN values), a user warning is raised and the original defocus values are returned instead.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_defocus</code> <code>bool</code> <p>Whether to use the refined defocus values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>A tuple of two tensors containing the absolute defocus values along the major (defocus_u) and minor axes (defocus_v), respectively in units of Angstroms.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_absolute_defocus(\n    self, prefer_refined_defocus: bool = True\n) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Get the absolute defocus values for each particle.\n\n    NOTE: If the refined defocus values are requested but not present in the\n    DataFrame (either no column or any NaN values), a user warning is raised\n    and the original defocus values are returned instead.\n\n    Parameters\n    ----------\n    prefer_refined_defocus : bool, optional\n        Whether to use the refined defocus values\n        (columns prefixed with 'refined_') or not, by default True.\n\n    Returns\n    -------\n    tuple[torch.Tensor, torch.Tensor]\n        A tuple of two tensors containing the absolute defocus values along the\n        major (defocus_u) and minor axes (defocus_v), respectively in units of\n        Angstroms.\n    \"\"\"\n    particle_defocus = self.get_relative_defocus(prefer_refined_defocus)\n    defocus_u = torch.tensor(self._df[\"defocus_u\"].to_numpy()) + particle_defocus\n    defocus_v = torch.tensor(self._df[\"defocus_v\"].to_numpy()) + particle_defocus\n\n    return defocus_u, defocus_v\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.get_dataframe_copy","title":"<code>get_dataframe_copy()</code>","text":"<p>Return a copy of the underlying DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <code>A copy of the underlying DataFrame</code> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_dataframe_copy(self) -&gt; pd.DataFrame:\n    \"\"\"Return a copy of the underlying DataFrame.\n\n    Returns\n    -------\n    pd.DataFrame\n    A copy of the underlying DataFrame\n    \"\"\"\n    return self._df.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.get_euler_angles","title":"<code>get_euler_angles(prefer_refined_angles=True)</code>","text":"<p>Return the Euler angles (phi, theta, psi) of all particles as a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>When true, the refined Euler angles are used (columns prefixed with 'refined_'), otherwise the original angles are used, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3) where N is the number of particles and the columns correspond to (phi, theta, psi) in ZYZ format.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_euler_angles(self, prefer_refined_angles: bool = True) -&gt; torch.Tensor:\n    \"\"\"Return the Euler angles (phi, theta, psi) of all particles as a tensor.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool, optional\n        When true, the refined Euler angles are used (columns prefixed with\n        'refined_'), otherwise the original angles are used, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (N, 3) where N is the number of particles and the columns\n        correspond to (phi, theta, psi) in ZYZ format.\n    \"\"\"\n    # Ensure all three refined columns are present, warning if not\n    phi_col = \"phi\"\n    theta_col = \"theta\"\n    psi_col = \"psi\"\n    if prefer_refined_angles:\n        if not all(\n            x in self._df.columns\n            for x in [\"refined_phi\", \"refined_theta\", \"refined_psi\"]\n        ):\n            warnings.warn(\n                \"Refined angles not found in DataFrame, using original angles...\",\n                stacklevel=2,\n            )\n        else:\n            phi_col = \"refined_phi\"\n            theta_col = \"refined_theta\"\n            psi_col = \"refined_psi\"\n\n    # Get the angles from the DataFrame\n    phi = torch.tensor(self._df[phi_col].to_numpy())\n    theta = torch.tensor(self._df[theta_col].to_numpy())\n    psi = torch.tensor(self._df[psi_col].to_numpy())\n\n    return torch.stack((phi, theta, psi), dim=-1)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.get_pixel_size","title":"<code>get_pixel_size(prefer_refined_pixel_size=True)</code>","text":"<p>Get the relative pixel size values for each particle.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_pixel_size</code> <code>bool</code> <p>Whether to use the refined pixel size values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The relative pixel size values for each particle.</p> Warnings <pre><code>Warns if NaN values or no column present for either 'refined_pixel_size'\nor 'pixel_size'. Falls back to the unrefined values.\n</code></pre> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_pixel_size(\n    self,\n    prefer_refined_pixel_size: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Get the relative pixel size values for each particle.\n\n    Parameters\n    ----------\n    prefer_refined_pixel_size : bool, optional\n        Whether to use the refined pixel size values\n        (columns prefixed with 'refined_') or not, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        The relative pixel size values for each particle.\n\n    Warnings\n    --------\n        Warns if NaN values or no column present for either 'refined_pixel_size'\n        or 'pixel_size'. Falls back to the unrefined values.\n    \"\"\"\n    pixel_size_col = \"pixel_size\"\n    if prefer_refined_pixel_size:\n        if \"refined_pixel_size\" not in self._df.columns:\n            warnings.warn(\n                \"Refined pixel size not found in DataFrame, using original\"\n                \" pixel size values...\",\n                stacklevel=2,\n            )\n        elif _any_nan_or_inf(self._df[\"refined_pixel_size\"]):\n            warnings.warn(\n                \"Refined pixel size contain NaN or inf values, using original\"\n                \" pixel size values...\",\n                stacklevel=2,\n            )\n        else:\n            pixel_size_col = \"refined_pixel_size\"\n\n    return torch.tensor(self._df[pixel_size_col].to_numpy())\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.get_relative_defocus","title":"<code>get_relative_defocus(prefer_refined_defocus=True)</code>","text":"<p>Get the relative defocus values for each particle.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_defocus</code> <code>bool</code> <p>Whether to use the refined defocus values (columns prefixed with 'refined_') or not, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The relative defocus values for each particle.</p> Warnings <pre><code>Warns if NaN values or no column present for either\n'refined_relative_defocus' or 'relative_defocus'.\nFalls back to the unrefined values.\n</code></pre> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_relative_defocus(\n    self,\n    prefer_refined_defocus: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Get the relative defocus values for each particle.\n\n    Parameters\n    ----------\n    prefer_refined_defocus : bool, optional\n        Whether to use the refined defocus values (columns prefixed with 'refined_')\n        or not, by default True.\n\n    Returns\n    -------\n    torch.Tensor\n        The relative defocus values for each particle.\n\n    Warnings\n    --------\n        Warns if NaN values or no column present for either\n        'refined_relative_defocus' or 'relative_defocus'.\n        Falls back to the unrefined values.\n    \"\"\"\n    rel_defocus_col = \"relative_defocus\"\n    # Both refined columns must be present AND no values can be NaN or inf\n    if prefer_refined_defocus:\n        if \"refined_relative_defocus\" not in self._df.columns:\n            warnings.warn(\n                \"Refined defocus values not found in DataFrame, using original \"\n                \"defocus values...\",\n                stacklevel=2,\n            )\n        elif _any_nan_or_inf(self._df[\"refined_relative_defocus\"]):\n            warnings.warn(\n                \"Refined defocus values contain NaN or inf values, using original \"\n                \"defocus values...\",\n                stacklevel=2,\n            )\n        else:\n            rel_defocus_col = \"refined_relative_defocus\"\n\n    return torch.tensor(self._df[rel_defocus_col].to_numpy())\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.load_df","title":"<code>load_df()</code>","text":"<p>Load the DataFrame from the specified path.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the DataFrame is missing required columns.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def load_df(self) -&gt; None:\n    \"\"\"Load the DataFrame from the specified path.\n\n    Raises\n    ------\n    ValueError\n        If the DataFrame is missing required columns.\n    \"\"\"\n    tmp_df = pd.read_csv(self.df_path)\n\n    # Validate the DataFrame columns\n    missing_columns = [\n        col for col in MATCH_TEMPLATE_DF_COLUMN_ORDER if col not in tmp_df.columns\n    ]\n    if missing_columns:\n        raise ValueError(\n            f\"Missing the following columns in DataFrame: {missing_columns}\"\n        )\n\n    self._df = tmp_df\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.ParticleStack.set_column","title":"<code>set_column(column_name, value)</code>","text":"<p>Set a column in the underlying DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>The name of the column to set</p> required <code>value</code> <code>Any</code> <p>The value to set the column to</p> required Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def set_column(self, column_name: str, value: Any) -&gt; None:\n    \"\"\"Set a column in the underlying DataFrame.\n\n    Parameters\n    ----------\n    column_name : str\n        The name of the column to set\n    value : Any\n        The value to set the column to\n    \"\"\"\n    self._df.loc[:, column_name] = value\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/data_structures/particle_stack/#leopard_em.pydantic_models.data_structures.particle_stack.get_cropped_image_regions","title":"<code>get_cropped_image_regions(image, pos_y, pos_x, box_size, pos_reference='top-left', handle_bounds='pad', padding_mode='constant', padding_value=0.0)</code>","text":"<p>Extracts regions from an image into a stack of cropped images.</p> <p>The <code>pos_reference</code> argument determines how the (y, x) coordinates are interpreted when extracting boxes:</p> <ul> <li> <p>If <code>pos_reference=\"center\"</code>:     The (y, x) coordinate refers to the center of the box.     The box extends from (y - height // 2, x - width // 2) to     (y + height // 2, x + width // 2).</p> <p>Example:     :                +------------------+     :                |                  |     :              height      * (y, x) |     :                |                  |     :                +------ width -----+</p> </li> <li> <p>If <code>pos_reference=\"top-left\"</code>:     The (y, x) coordinate refers to the top-left corner of the box.     The box extends from (y, x) to (y + height, x + width).</p> <p>Example:     :         (y, x) *------ width -----+     :                |                  |     :                |                height     :                |                  |     :                +------------------+</p> </li> </ul> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Tensor | ndarray</code> <p>The input image from which to extract the regions.</p> required <code>pos_y</code> <code>Tensor | ndarray</code> <p>The y positions of the regions to extract. Type must mach <code>image</code></p> required <code>pos_x</code> <code>Tensor | ndarray</code> <p>The x positions of the regions to extract. Type must mach <code>image</code></p> required <code>box_size</code> <code>int | tuple[int, int]</code> <p>The size of the box to extract. If an integer is passed, the box will be square.</p> required <code>pos_reference</code> <code>Literal['center', 'top-left']</code> <p>The reference point for the positions, by default \"center\". If \"center\", the boxes extracted will be image[y - box_size // 2 : y + box_size // 2, ...]. If \"top-left\", the boxes will be image[y : y + box_size, ...].</p> <code>'top-left'</code> <code>handle_bounds</code> <code>Literal['pad', 'clip', 'error']</code> <p>How to handle the bounds of the image, by default \"pad\". If \"pad\", the image will be padded with the padding value based on the padding mode. If \"error\", an error will be raised if any region exceeds the image bounds. Note clipping is not supported since returned stack may have inhomogeneous sizes.</p> <code>'pad'</code> <code>padding_mode</code> <code>Literal['constant', 'reflect', 'replicate']</code> <p>The padding mode to use when padding the image, by default \"constant\". \"constant\" pads with the value <code>padding_value</code>, \"reflect\" pads with the reflection of the image at the edge, and \"replicate\" pads with the last pixel of the image. These match the modes available in <code>torch.nn.functional.pad</code>.</p> <code>'constant'</code> <code>padding_value</code> <code>float</code> <p>The value to use for padding when <code>padding_mode</code> is \"constant\", by default 0.0.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>Tensor | ndarray</code> <p>The stack of cropped images extracted from the input image. Type will match the input image type.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>pos_reference</code> is not one of \"center\" or \"top-left\", or if <code>image</code> is not a torch.Tensor or np.ndarray.</p> Source code in <code>src/leopard_em/pydantic_models/data_structures/particle_stack.py</code> <pre><code>def get_cropped_image_regions(\n    image: torch.Tensor | np.ndarray,\n    pos_y: torch.Tensor | np.ndarray,\n    pos_x: torch.Tensor | np.ndarray,\n    box_size: int | tuple[int, int],\n    pos_reference: Literal[\"center\", \"top-left\"] = \"top-left\",\n    handle_bounds: Literal[\"pad\", \"error\"] = \"pad\",\n    padding_mode: Literal[\"constant\", \"reflect\", \"replicate\"] = \"constant\",\n    padding_value: float = 0.0,\n) -&gt; torch.Tensor | np.ndarray:\n    \"\"\"Extracts regions from an image into a stack of cropped images.\n\n    The `pos_reference` argument determines how the (y, x) coordinates are interpreted\n    when extracting boxes:\n\n    - If ``pos_reference=\"center\"``:\n        The (y, x) coordinate refers to the **center** of the box.\n        The box extends from (y - height // 2, x - width // 2) to\n        (y + height // 2, x + width // 2).\n\n        Example:\n            :                +------------------+\n            :                |                  |\n            :              height      * (y, x) |\n            :                |                  |\n            :                +------ width -----+\n\n    - If ``pos_reference=\"top-left\"``:\n        The (y, x) coordinate refers to the **top-left corner** of the box.\n        The box extends from (y, x) to (y + height, x + width).\n\n        Example:\n            :         (y, x) *------ width -----+\n            :                |                  |\n            :                |                height\n            :                |                  |\n            :                +------------------+\n\n    Parameters\n    ----------\n    image : torch.Tensor | np.ndarray\n        The input image from which to extract the regions.\n    pos_y : torch.Tensor | np.ndarray\n        The y positions of the regions to extract. Type must mach `image`\n    pos_x : torch.Tensor | np.ndarray\n        The x positions of the regions to extract. Type must mach `image`\n    box_size : int | tuple[int, int]\n        The size of the box to extract. If an integer is passed, the box will be square.\n    pos_reference : Literal[\"center\", \"top-left\"], optional\n        The reference point for the positions, by default \"center\". If \"center\", the\n        boxes extracted will be image[y - box_size // 2 : y + box_size // 2, ...]. If\n        \"top-left\", the boxes will be image[y : y + box_size, ...].\n    handle_bounds : Literal[\"pad\", \"clip\", \"error\"], optional\n        How to handle the bounds of the image, by default \"pad\". If \"pad\", the image\n        will be padded with the padding value based on the padding mode. If \"error\", an\n        error will be raised if any region exceeds the image bounds. Note clipping is\n        not supported since returned stack may have inhomogeneous sizes.\n    padding_mode : Literal[\"constant\", \"reflect\", \"replicate\"], optional\n        The padding mode to use when padding the image, by default \"constant\".\n        \"constant\" pads with the value `padding_value`, \"reflect\" pads with the\n        reflection of the image at the edge, and \"replicate\" pads with the last pixel\n        of the image. These match the modes available in `torch.nn.functional.pad`.\n    padding_value : float, optional\n        The value to use for padding when `padding_mode` is \"constant\", by default 0.0.\n\n    Returns\n    -------\n    torch.Tensor | np.ndarray\n        The stack of cropped images extracted from the input image. Type will match the\n        input image type.\n\n    Raises\n    ------\n    ValueError\n        If `pos_reference` is not one of \"center\" or \"top-left\", or if `image` is not a\n        torch.Tensor or np.ndarray.\n    \"\"\"\n    if isinstance(box_size, int):\n        box_size = (box_size, box_size)\n\n    # The underlying numpy/torch functions only operate on the top-left corner\n    # reference, so shift the position half a box height/width if using center.\n    if pos_reference == \"center\":\n        pos_y = pos_y - box_size[0] // 2\n        pos_x = pos_x - box_size[1] // 2\n    elif pos_reference == \"top-left\":\n        pass\n    else:\n        raise ValueError(f\"Unknown pos_reference: {pos_reference}\")\n\n    if isinstance(image, torch.Tensor):\n        return _get_cropped_image_regions_torch(\n            image=image,\n            pos_y=pos_y,\n            pos_x=pos_x,\n            box_size=box_size,\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode,\n            padding_value=padding_value,\n        )\n\n    if isinstance(image, np.ndarray):\n        padding_mode_np = TORCH_TO_NUMPY_PADDING_MODE[padding_mode]\n        return _get_cropped_image_regions_numpy(\n            image=image,\n            pos_y=pos_y,\n            pos_x=pos_x,\n            box_size=box_size,\n            handle_bounds=handle_bounds,\n            padding_mode=padding_mode_np,\n            padding_value=padding_value,\n        )\n\n    raise ValueError(f\"Unknown image type: {type(image)}\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/","title":"managers","text":"<p>Pydantic models for Leopard-EM program managers.</p>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.ConstrainedSearchManager","title":"<code>ConstrainedSearchManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the constrained search program.</p> <p>NOTE: The constrained search program should only be run on data from a single reference micrograph. That is, if you have data from two or more micrographs, that data from each micrograph needs processed separately. This restriction may be lifted in the future.</p> <p>Attributes:</p> Name Type Description <code>template_volume_path</code> <code>str</code> <p>Path to the template volume MRC file.</p> <code>center_vector</code> <code>list[float]</code> <p>The centre vector of the template volume.</p> <code>particle_stack_reference</code> <code>ParticleStack</code> <p>Particle stack object containing particle data reference particles.</p> <code>particle_stack_constrained</code> <code>ParticleStack</code> <p>Particle stack object containing particle data constrained particles.</p> <code>defocus_refinement_config</code> <code>DefocusSearchConfig</code> <p>Configuration for defocus refinement.</p> <code>orientation_refinement_config</code> <code>RefineOrientationConfig</code> <p>Configuration for orientation refinement.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>The template volume tensor (excluded from serialization).</p> <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the constrained search manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend refine_template core function.</p> <code>run_constrained_search</code> <p>Run the constrained search program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>class ConstrainedSearchManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the constrained search program.\n\n    NOTE: The constrained search program should only be run on data from a single\n    reference micrograph. That is, if you have data from two or more micrographs, that\n    data from each micrograph needs processed separately. This restriction may be lifted\n    in the future.\n\n    Attributes\n    ----------\n    template_volume_path : str\n        Path to the template volume MRC file.\n    center_vector : list[float]\n        The centre vector of the template volume.\n    particle_stack_reference : ParticleStack\n        Particle stack object containing particle data reference particles.\n    particle_stack_constrained : ParticleStack\n        Particle stack object containing particle data constrained particles.\n    defocus_refinement_config : DefocusSearchConfig\n        Configuration for defocus refinement.\n    orientation_refinement_config : RefineOrientationConfig\n        Configuration for orientation refinement.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    template_volume : ExcludedTensor\n        The template volume tensor (excluded from serialization).\n    false_positives : float\n        The number of false positives to allow per particle.\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the constrained search manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend refine_template core function.\n    run_constrained_search(self, orientation_batch_size: int = 64) -&gt; None\n        Run the constrained search program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    template_volume_path: str  # In df per-particle, but ensure only one reference\n    center_vector: list[float] = Field(default=[0.0, 0.0, 0.0])\n\n    particle_stack_reference: ParticleStack\n    particle_stack_constrained: ParticleStack\n    defocus_refinement_config: DefocusSearchConfig\n    orientation_refinement_config: ConstrainedOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n    zdiffs: ExcludedTensor = torch.tensor([0.0])\n\n    def __init__(self, skip_mrc_preloads: bool = False, **data: Any):\n        super().__init__(**data)\n\n        # Load the data from the MRC files\n        if not skip_mrc_preloads:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    # pylint: disable=too-many-locals\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend constrained_template core function.\"\"\"\n        part_stk = self.particle_stack_reference\n\n        # Checks to make sure manager is properly configured\n        # pylint: disable=protected-access\n        assert part_stk._df[\"micrograph_path\"].nunique() == 1, (\n            \"Constrained search can only be run on data from a single micrograph. \"\n            \"Please ensure that the particle stack contains particles from only one \"\n            \"micrograph.\"\n        )\n\n        device_list = self.computational_config.gpu_devices\n\n        template = load_template_tensor(\n            template_volume=self.template_volume,\n            template_volume_path=self.template_volume_path,\n        )\n\n        euler_angles = part_stk.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over\n        euler_angle_offsets, _ = self.orientation_refinement_config.euler_angles_offsets\n\n        # No pixel size refinement\n        pixel_size_offsets = torch.tensor([0.0])\n\n        # Extract and preprocess images and filters\n        (\n            particle_images_dft,\n            template_dft,\n            projective_filters,\n        ) = setup_images_filters_particle_stack(\n            part_stk, self.preprocessing_filters, template\n        )\n\n        # get z diff for each particle\n        if not isinstance(self.center_vector, torch.Tensor):\n            self.center_vector = torch.tensor(self.center_vector, dtype=torch.float32)\n        rotation_matrices = roma.rotvec_to_rotmat(\n            roma.euler_to_rotvec(convention=\"ZYZ\", angles=euler_angles)\n        ).to(torch.float32)\n        rotated_vectors = rotation_matrices @ self.center_vector\n\n        # Get z for each particle -&gt; tensor shape [batch_size]\n        new_z_diffs = rotated_vectors[:, 2]\n\n        # The best defocus values for each particle (+ astigmatism)\n        defocus_u, defocus_v = part_stk.get_absolute_defocus()\n        defocus_u = defocus_u - new_z_diffs\n        defocus_v = defocus_v - new_z_diffs\n        # Store defocus values as instance attributes for later access\n        self.zdiffs = new_z_diffs\n        defocus_angle = torch.tensor(part_stk[\"astigmatism_angle\"])\n\n        # The relative defocus values to search over\n        defocus_offsets = self.defocus_refinement_config.defocus_values\n\n        ctf_kwargs = _setup_ctf_kwargs_from_particle_stack(\n            part_stk, (template.shape[-2], template.shape[-1])\n        )\n\n        # Ger corr mean and variance\n        # The position of the extracted areas needs to be from the larger particle, but\n        # the mean and variance must come from the initial match template on the\n        # smaller constrained particle.\n        # Currently, we just set the searched file (as in paths below) to the first\n        # element in the constrained particle stack.\n        # NOTE: This will *not* work if the constrained particle stack contains\n        # particles from multiple reference images.\n        part_stk.set_column(\n            \"correlation_average_path\",\n            self.particle_stack_constrained[\"correlation_average_path\"][0],\n        )\n        part_stk.set_column(\n            \"correlation_variance_path\",\n            self.particle_stack_constrained[\"correlation_variance_path\"][0],\n        )\n        # Get correlation statistics\n        corr_mean_stack = part_stk.construct_cropped_statistic_stack(\n            stat=\"correlation_average\",\n            handle_bounds=\"pad\",\n            padding_mode=\"constant\",\n            padding_value=0.0,  # pad with zeros\n        )\n        corr_std_stack = part_stk.construct_cropped_statistic_stack(\n            stat=\"correlation_variance\",\n            handle_bounds=\"pad\",\n            padding_mode=\"constant\",\n            padding_value=1e10,  # large to avoid out of bound pixels having inf z-score\n        )\n        corr_std_stack = corr_std_stack**0.5  # Convert variance to standard deviation\n\n        return {\n            \"particle_stack_dft\": particle_images_dft,\n            \"template_dft\": template_dft,\n            \"euler_angles\": euler_angles,\n            \"euler_angle_offsets\": euler_angle_offsets,\n            \"defocus_u\": defocus_u,\n            \"defocus_v\": defocus_v,\n            \"defocus_angle\": defocus_angle,\n            \"defocus_offsets\": defocus_offsets,\n            \"pixel_size_offsets\": pixel_size_offsets,\n            \"corr_mean\": corr_mean_stack,\n            \"corr_std\": corr_std_stack,\n            \"ctf_kwargs\": ctf_kwargs,\n            \"projective_filters\": projective_filters,\n            \"device\": device_list,  # Pass all devices to core_refine_template\n        }\n\n    def run_constrained_search(\n        self,\n        output_dataframe_path: str,\n        false_positives: float = 0.005,\n        orientation_batch_size: int = 64,\n    ) -&gt; None:\n        \"\"\"Run the constrained search program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the constrained search results.\n        false_positives : float\n            The number of false positives to allow per particle.\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n        \"\"\"\n        backend_kwargs = self.make_backend_core_function_kwargs()\n\n        result = self.get_refine_result(backend_kwargs, orientation_batch_size)\n\n        self.refine_result_to_dataframe(\n            output_dataframe_path=output_dataframe_path,\n            result=result,\n            false_positives=false_positives,\n        )\n\n    def get_refine_result(\n        self, backend_kwargs: dict, orientation_batch_size: int = 64\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get refine template result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # Adjust batch size if orientation search is disabled\n        if not self.orientation_refinement_config.enabled:\n            orientation_batch_size = 1\n        elif (\n            self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n            &lt; orientation_batch_size\n        ):\n            orientation_batch_size = (\n                self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n            )\n\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=orientation_batch_size, **backend_kwargs\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n        return result\n\n    # pylint: disable=too-many-locals\n    def refine_result_to_dataframe(\n        self,\n        output_dataframe_path: str,\n        result: dict[str, np.ndarray],\n        false_positives: float = 0.005,\n    ) -&gt; None:\n        \"\"\"Convert refine template result to dataframe.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        result : dict[str, np.ndarray]\n            The result of the refine template program.\n        false_positives : float\n            The number of false positives to allow per particle.\n        \"\"\"\n        df_refined = self.particle_stack_reference.get_dataframe_copy()\n\n        # x and y positions\n        pos_offset_y = result[\"refined_pos_y\"]\n        pos_offset_x = result[\"refined_pos_x\"]\n        pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n        pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n        df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n        df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n        df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n        df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n        df_refined[\"refined_pos_y_img_angstrom\"] = (\n            pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n        )\n        df_refined[\"refined_pos_x_img_angstrom\"] = (\n            pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n        )\n\n        # Euler angles\n        angle_idx = result[\"angle_idx\"]\n        df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n        df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n        df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n        _, euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n        euler_angle_offsets_np = euler_angle_offsets.cpu().numpy()\n        # Store the matched original offsets in the dataframe\n        df_refined[\"original_offset_phi\"] = euler_angle_offsets_np[angle_idx, 0]\n        df_refined[\"original_offset_theta\"] = euler_angle_offsets_np[angle_idx, 1]\n        df_refined[\"original_offset_psi\"] = euler_angle_offsets_np[angle_idx, 2]\n\n        # Defocus\n        df_refined[\"refined_relative_defocus\"] = (\n            result[\"refined_defocus_offset\"]\n            + self.particle_stack_reference.get_relative_defocus().cpu().numpy()\n            - self.zdiffs.cpu().numpy()\n        )\n\n        # Pixel size\n        df_refined[\"refined_pixel_size\"] = (\n            result[\"refined_pixel_size_offset\"]\n            + self.particle_stack_reference.get_pixel_size().cpu().numpy()\n        )\n\n        # Cross-correlation statistics\n        refined_mip = result[\"refined_cross_correlation\"]\n        refined_scaled_mip = result[\"refined_z_score\"]\n        df_refined[\"refined_mip\"] = refined_mip\n        df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n        # Reorder the columns\n        df_refined = df_refined.reindex(columns=CONSTRAINED_DF_COLUMN_ORDER).fillna(0)\n\n        # Save the refined DataFrame to disk\n        df_refined.to_csv(output_dataframe_path)\n\n        # Save a second dataframe\n        # I also want the original user input offsets back somewhere\n        # This one will have only those above threshold\n        num_projections = (\n            self.defocus_refinement_config.defocus_values.shape[0]\n            * self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        )\n        num_px = (\n            self.particle_stack_reference.extracted_box_size[0]\n            - self.particle_stack_reference.original_template_size[0]\n            + 1\n        ) * (\n            self.particle_stack_reference.extracted_box_size[1]\n            - self.particle_stack_reference.original_template_size[1]\n            + 1\n        )\n        num_correlations = num_projections * num_px\n        threshold = gaussian_noise_zscore_cutoff(\n            num_correlations, float(false_positives)\n        )\n\n        # Save all parameters to CSV including false-positives\n        params_df = pd.DataFrame(\n            {\n                \"num_projections\": [num_projections],\n                \"num_px\": [num_px],\n                \"num_correlations\": [num_correlations],\n                \"false_positives\": [false_positives],\n                \"threshold\": [threshold],\n            }\n        )\n        params_df.to_csv(output_dataframe_path.replace(\".csv\", \"_parameters.csv\"))\n\n        print(\n            f\"Threshold: {threshold} which gives {false_positives} \"\n            \"false positives per particle\"\n        )\n        df_refined_above_threshold = df_refined[\n            df_refined[\"refined_scaled_mip\"] &gt; threshold\n        ]\n        # Also remove if refined_scaled_mip is inf or nan\n        df_refined_above_threshold = df_refined_above_threshold[\n            df_refined_above_threshold[\"refined_scaled_mip\"] != np.inf\n        ]\n        df_refined_above_threshold = df_refined_above_threshold[\n            df_refined_above_threshold[\"refined_scaled_mip\"] != np.nan\n        ]\n        # Save the above threshold dataframe\n        print(\n            f\"Saving above threshold dataframe to \"\n            f\"{output_dataframe_path.replace('.csv', '_above_threshold.csv')}\"\n        )\n        df_refined_above_threshold.to_csv(\n            output_dataframe_path.replace(\".csv\", \"_above_threshold.csv\")\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.ConstrainedSearchManager.get_refine_result","title":"<code>get_refine_result(backend_kwargs, orientation_batch_size=64)</code>","text":"<p>Get refine template result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def get_refine_result(\n    self, backend_kwargs: dict, orientation_batch_size: int = 64\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get refine template result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # Adjust batch size if orientation search is disabled\n    if not self.orientation_refinement_config.enabled:\n        orientation_batch_size = 1\n    elif (\n        self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        &lt; orientation_batch_size\n    ):\n        orientation_batch_size = (\n            self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        )\n\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=orientation_batch_size, **backend_kwargs\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.ConstrainedSearchManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend constrained_template core function.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend constrained_template core function.\"\"\"\n    part_stk = self.particle_stack_reference\n\n    # Checks to make sure manager is properly configured\n    # pylint: disable=protected-access\n    assert part_stk._df[\"micrograph_path\"].nunique() == 1, (\n        \"Constrained search can only be run on data from a single micrograph. \"\n        \"Please ensure that the particle stack contains particles from only one \"\n        \"micrograph.\"\n    )\n\n    device_list = self.computational_config.gpu_devices\n\n    template = load_template_tensor(\n        template_volume=self.template_volume,\n        template_volume_path=self.template_volume_path,\n    )\n\n    euler_angles = part_stk.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over\n    euler_angle_offsets, _ = self.orientation_refinement_config.euler_angles_offsets\n\n    # No pixel size refinement\n    pixel_size_offsets = torch.tensor([0.0])\n\n    # Extract and preprocess images and filters\n    (\n        particle_images_dft,\n        template_dft,\n        projective_filters,\n    ) = setup_images_filters_particle_stack(\n        part_stk, self.preprocessing_filters, template\n    )\n\n    # get z diff for each particle\n    if not isinstance(self.center_vector, torch.Tensor):\n        self.center_vector = torch.tensor(self.center_vector, dtype=torch.float32)\n    rotation_matrices = roma.rotvec_to_rotmat(\n        roma.euler_to_rotvec(convention=\"ZYZ\", angles=euler_angles)\n    ).to(torch.float32)\n    rotated_vectors = rotation_matrices @ self.center_vector\n\n    # Get z for each particle -&gt; tensor shape [batch_size]\n    new_z_diffs = rotated_vectors[:, 2]\n\n    # The best defocus values for each particle (+ astigmatism)\n    defocus_u, defocus_v = part_stk.get_absolute_defocus()\n    defocus_u = defocus_u - new_z_diffs\n    defocus_v = defocus_v - new_z_diffs\n    # Store defocus values as instance attributes for later access\n    self.zdiffs = new_z_diffs\n    defocus_angle = torch.tensor(part_stk[\"astigmatism_angle\"])\n\n    # The relative defocus values to search over\n    defocus_offsets = self.defocus_refinement_config.defocus_values\n\n    ctf_kwargs = _setup_ctf_kwargs_from_particle_stack(\n        part_stk, (template.shape[-2], template.shape[-1])\n    )\n\n    # Ger corr mean and variance\n    # The position of the extracted areas needs to be from the larger particle, but\n    # the mean and variance must come from the initial match template on the\n    # smaller constrained particle.\n    # Currently, we just set the searched file (as in paths below) to the first\n    # element in the constrained particle stack.\n    # NOTE: This will *not* work if the constrained particle stack contains\n    # particles from multiple reference images.\n    part_stk.set_column(\n        \"correlation_average_path\",\n        self.particle_stack_constrained[\"correlation_average_path\"][0],\n    )\n    part_stk.set_column(\n        \"correlation_variance_path\",\n        self.particle_stack_constrained[\"correlation_variance_path\"][0],\n    )\n    # Get correlation statistics\n    corr_mean_stack = part_stk.construct_cropped_statistic_stack(\n        stat=\"correlation_average\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=0.0,  # pad with zeros\n    )\n    corr_std_stack = part_stk.construct_cropped_statistic_stack(\n        stat=\"correlation_variance\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=1e10,  # large to avoid out of bound pixels having inf z-score\n    )\n    corr_std_stack = corr_std_stack**0.5  # Convert variance to standard deviation\n\n    return {\n        \"particle_stack_dft\": particle_images_dft,\n        \"template_dft\": template_dft,\n        \"euler_angles\": euler_angles,\n        \"euler_angle_offsets\": euler_angle_offsets,\n        \"defocus_u\": defocus_u,\n        \"defocus_v\": defocus_v,\n        \"defocus_angle\": defocus_angle,\n        \"defocus_offsets\": defocus_offsets,\n        \"pixel_size_offsets\": pixel_size_offsets,\n        \"corr_mean\": corr_mean_stack,\n        \"corr_std\": corr_std_stack,\n        \"ctf_kwargs\": ctf_kwargs,\n        \"projective_filters\": projective_filters,\n        \"device\": device_list,  # Pass all devices to core_refine_template\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.ConstrainedSearchManager.refine_result_to_dataframe","title":"<code>refine_result_to_dataframe(output_dataframe_path, result, false_positives=0.005)</code>","text":"<p>Convert refine template result to dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> required <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <code>0.005</code> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def refine_result_to_dataframe(\n    self,\n    output_dataframe_path: str,\n    result: dict[str, np.ndarray],\n    false_positives: float = 0.005,\n) -&gt; None:\n    \"\"\"Convert refine template result to dataframe.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    result : dict[str, np.ndarray]\n        The result of the refine template program.\n    false_positives : float\n        The number of false positives to allow per particle.\n    \"\"\"\n    df_refined = self.particle_stack_reference.get_dataframe_copy()\n\n    # x and y positions\n    pos_offset_y = result[\"refined_pos_y\"]\n    pos_offset_x = result[\"refined_pos_x\"]\n    pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n    pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n    df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n    df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n    df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n    df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n    df_refined[\"refined_pos_y_img_angstrom\"] = (\n        pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n    )\n    df_refined[\"refined_pos_x_img_angstrom\"] = (\n        pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n    )\n\n    # Euler angles\n    angle_idx = result[\"angle_idx\"]\n    df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n    df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n    df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n    _, euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n    euler_angle_offsets_np = euler_angle_offsets.cpu().numpy()\n    # Store the matched original offsets in the dataframe\n    df_refined[\"original_offset_phi\"] = euler_angle_offsets_np[angle_idx, 0]\n    df_refined[\"original_offset_theta\"] = euler_angle_offsets_np[angle_idx, 1]\n    df_refined[\"original_offset_psi\"] = euler_angle_offsets_np[angle_idx, 2]\n\n    # Defocus\n    df_refined[\"refined_relative_defocus\"] = (\n        result[\"refined_defocus_offset\"]\n        + self.particle_stack_reference.get_relative_defocus().cpu().numpy()\n        - self.zdiffs.cpu().numpy()\n    )\n\n    # Pixel size\n    df_refined[\"refined_pixel_size\"] = (\n        result[\"refined_pixel_size_offset\"]\n        + self.particle_stack_reference.get_pixel_size().cpu().numpy()\n    )\n\n    # Cross-correlation statistics\n    refined_mip = result[\"refined_cross_correlation\"]\n    refined_scaled_mip = result[\"refined_z_score\"]\n    df_refined[\"refined_mip\"] = refined_mip\n    df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n    # Reorder the columns\n    df_refined = df_refined.reindex(columns=CONSTRAINED_DF_COLUMN_ORDER).fillna(0)\n\n    # Save the refined DataFrame to disk\n    df_refined.to_csv(output_dataframe_path)\n\n    # Save a second dataframe\n    # I also want the original user input offsets back somewhere\n    # This one will have only those above threshold\n    num_projections = (\n        self.defocus_refinement_config.defocus_values.shape[0]\n        * self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n    )\n    num_px = (\n        self.particle_stack_reference.extracted_box_size[0]\n        - self.particle_stack_reference.original_template_size[0]\n        + 1\n    ) * (\n        self.particle_stack_reference.extracted_box_size[1]\n        - self.particle_stack_reference.original_template_size[1]\n        + 1\n    )\n    num_correlations = num_projections * num_px\n    threshold = gaussian_noise_zscore_cutoff(\n        num_correlations, float(false_positives)\n    )\n\n    # Save all parameters to CSV including false-positives\n    params_df = pd.DataFrame(\n        {\n            \"num_projections\": [num_projections],\n            \"num_px\": [num_px],\n            \"num_correlations\": [num_correlations],\n            \"false_positives\": [false_positives],\n            \"threshold\": [threshold],\n        }\n    )\n    params_df.to_csv(output_dataframe_path.replace(\".csv\", \"_parameters.csv\"))\n\n    print(\n        f\"Threshold: {threshold} which gives {false_positives} \"\n        \"false positives per particle\"\n    )\n    df_refined_above_threshold = df_refined[\n        df_refined[\"refined_scaled_mip\"] &gt; threshold\n    ]\n    # Also remove if refined_scaled_mip is inf or nan\n    df_refined_above_threshold = df_refined_above_threshold[\n        df_refined_above_threshold[\"refined_scaled_mip\"] != np.inf\n    ]\n    df_refined_above_threshold = df_refined_above_threshold[\n        df_refined_above_threshold[\"refined_scaled_mip\"] != np.nan\n    ]\n    # Save the above threshold dataframe\n    print(\n        f\"Saving above threshold dataframe to \"\n        f\"{output_dataframe_path.replace('.csv', '_above_threshold.csv')}\"\n    )\n    df_refined_above_threshold.to_csv(\n        output_dataframe_path.replace(\".csv\", \"_above_threshold.csv\")\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.ConstrainedSearchManager.run_constrained_search","title":"<code>run_constrained_search(output_dataframe_path, false_positives=0.005, orientation_batch_size=64)</code>","text":"<p>Run the constrained search program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the constrained search results.</p> required <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <code>0.005</code> <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def run_constrained_search(\n    self,\n    output_dataframe_path: str,\n    false_positives: float = 0.005,\n    orientation_batch_size: int = 64,\n) -&gt; None:\n    \"\"\"Run the constrained search program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the constrained search results.\n    false_positives : float\n        The number of false positives to allow per particle.\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n    \"\"\"\n    backend_kwargs = self.make_backend_core_function_kwargs()\n\n    result = self.get_refine_result(backend_kwargs, orientation_batch_size)\n\n    self.refine_result_to_dataframe(\n        output_dataframe_path=output_dataframe_path,\n        result=result,\n        false_positives=false_positives,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager","title":"<code>MatchTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running full orientation 2DTM.</p> <p>Attributes:</p> Name Type Description <code>micrograph_path</code> <code>str</code> <p>Path to the micrograph .mrc file.</p> <code>template_volume_path</code> <code>str</code> <p>Path to the template volume .mrc file.</p> <code>micrograph</code> <code>ExcludedTensor</code> <p>Image to run template matching on. Not serialized.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>Template volume to match against. Not serialized.</p> <code>optics_group</code> <code>OpticsGroup</code> <p>Optics group parameters for the imaging system on the microscope.</p> <code>defocus_search_config</code> <code>DefocusSearchConfig</code> <p>Parameters for searching over defocus values.</p> <code>orientation_search_config</code> <code>OrientationSearchConfig</code> <p>Parameters for searching over orientation angles.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Configurations for the preprocessing filters to apply during correlation.</p> <code>match_template_result</code> <code>MatchTemplateResult</code> <p>Result of the match template program stored as an instance of the <code>MatchTemplateResult</code> class.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>Parameters for controlling computational resources.</p> <p>Methods:</p> Name Description <code>validate_micrograph_path</code> <p>Ensure the micrograph file exists.</p> <code>validate_template_volume_path</code> <p>Ensure the template volume file exists.</p> <code>__init__</code> <p>Constructor which also loads the micrograph and template volume from disk. The 'preload_mrc_files' parameter controls whether to read the MRC files immediately upon initialization.</p> <code>make_backend_core_function_kwargs</code> <p>Generates the keyword arguments for backend 'core_match_template' call from held parameters. Does the necessary pre-processing steps to filter the image and template.</p> <code>run_match_template</code> <p>Runs the base match template program in PyTorch.</p> <code>results_to_dataframe</code> <p>half_template_width_pos_shift: bool = True, exclude_columns: Optional[list] = None, locate_peaks_kwargs: Optional[dict] = None,</p> <code>) -&gt; pd.DataFrame</code> <p>Converts the basic extracted peak info DataFrame (from the result object) to a DataFrame with additional information about reference files, microscope parameters, etc.</p> <code>save_config</code> <p>Save this Pydantic model config to disk.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>class MatchTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running full orientation 2DTM.\n\n    Attributes\n    ----------\n    micrograph_path : str\n        Path to the micrograph .mrc file.\n    template_volume_path : str\n        Path to the template volume .mrc file.\n    micrograph : ExcludedTensor\n        Image to run template matching on. Not serialized.\n    template_volume : ExcludedTensor\n        Template volume to match against. Not serialized.\n    optics_group : OpticsGroup\n        Optics group parameters for the imaging system on the microscope.\n    defocus_search_config : DefocusSearchConfig\n        Parameters for searching over defocus values.\n    orientation_search_config : OrientationSearchConfig\n        Parameters for searching over orientation angles.\n    preprocessing_filters : PreprocessingFilters\n        Configurations for the preprocessing filters to apply during\n        correlation.\n    match_template_result : MatchTemplateResult\n        Result of the match template program stored as an instance of the\n        `MatchTemplateResult` class.\n    computational_config : ComputationalConfig\n        Parameters for controlling computational resources.\n\n    Methods\n    -------\n    validate_micrograph_path(v: str) -&gt; str\n        Ensure the micrograph file exists.\n    validate_template_volume_path(v: str) -&gt; str\n        Ensure the template volume file exists.\n    __init__(preload_mrc_files: bool = False , **data: Any)\n        Constructor which also loads the micrograph and template volume from disk.\n        The 'preload_mrc_files' parameter controls whether to read the MRC files\n        immediately upon initialization.\n    make_backend_core_function_kwargs() -&gt; dict[str, Any]\n        Generates the keyword arguments for backend 'core_match_template' call from\n        held parameters. Does the necessary pre-processing steps to filter the image\n        and template.\n    run_match_template(orientation_batch_size: int = 1, do_result_export: bool = True)\n        Runs the base match template program in PyTorch.\n    results_to_dataframe(\n        half_template_width_pos_shift: bool = True,\n        exclude_columns: Optional[list] = None,\n        locate_peaks_kwargs: Optional[dict] = None,\n    ) -&gt; pd.DataFrame\n        Converts the basic extracted peak info DataFrame (from the result object) to a\n        DataFrame with additional information about reference files, microscope\n        parameters, etc.\n    save_config(path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None\n        Save this Pydantic model config to disk.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized attributes\n    micrograph_path: str\n    template_volume_path: str\n    optics_group: OpticsGroup\n    defocus_search_config: DefocusSearchConfig\n    orientation_search_config: OrientationSearchConfig | MultipleOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    match_template_result: MatchTemplateResult\n    computational_config: ComputationalConfig\n\n    # Non-serialized large array-like attributes\n    micrograph: ExcludedTensor\n    template_volume: ExcludedTensor\n\n    ###########################\n    ### Pydantic Validators ###\n    ###########################\n\n    @field_validator(\"micrograph_path\")  # type: ignore\n    def validate_micrograph_path(cls, v) -&gt; str:\n        \"\"\"Ensure the micrograph file exists.\"\"\"\n        if not os.path.exists(v):\n            raise ValueError(f\"File '{v}' for micrograph does not exist.\")\n\n        return str(v)\n\n    @field_validator(\"template_volume_path\")  # type: ignore\n    def validate_template_volume_path(cls, v) -&gt; str:\n        \"\"\"Ensure the template volume file exists.\"\"\"\n        if not os.path.exists(v):\n            raise ValueError(f\"File '{v}' for template volume does not exist.\")\n\n        return str(v)\n\n    def __init__(self, preload_mrc_files: bool = False, **data: Any):\n        super().__init__(**data)\n\n        if preload_mrc_files:\n            # Load the data from the MRC files\n            self.micrograph = load_mrc_image(self.micrograph_path)\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    ############################################\n    ### Functional (data processing) methods ###\n    ############################################\n\n    def make_backend_core_function_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Generates the keyword arguments for backend call from held parameters.\"\"\"\n        # Ensure the micrograph and template are loaded and in the correct format\n        if self.micrograph is None:\n            self.micrograph = load_mrc_image(self.micrograph_path)\n        if self.template_volume is None:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n        # Ensure the micrograph and template are both Tensors before proceeding\n        if not isinstance(self.micrograph, torch.Tensor):\n            image = torch.from_numpy(self.micrograph)\n        else:\n            image = self.micrograph\n\n        if not isinstance(self.template_volume, torch.Tensor):\n            template = torch.from_numpy(self.template_volume)\n        else:\n            template = self.template_volume\n\n        # Fourier transform the image (RFFT, unshifted)\n        image_dft = torch.fft.rfftn(image)  # pylint: disable=E1102\n        image_dft[0, 0] = 0 + 0j  # zero out the constant term\n\n        # Get the bandpass filter individually\n        bp_config = self.preprocessing_filters.bandpass_filter\n        bandpass_filter = bp_config.calculate_bandpass_filter(image_dft.shape)\n\n        # Calculate the cumulative filters for both the image and the template.\n        cumulative_filter_image = self.preprocessing_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=image_dft.shape,\n        )\n        # NOTE: Here, manually accounting for the RFFT in output shape since we have not\n        # RFFT'd the template volume yet. Also, this is 2-dimensional, not 3-dimensional\n        cumulative_filter_template = self.preprocessing_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=(template.shape[-2], template.shape[-1] // 2 + 1),\n        )\n\n        # Apply the pre-processing and normalization\n        image_preprocessed_dft = preprocess_image(\n            image_rfft=image_dft,\n            cumulative_fourier_filters=cumulative_filter_image,\n            bandpass_filter=bandpass_filter,\n        )\n\n        # Calculate the CTF filters at each defocus value\n        defocus_values = self.defocus_search_config.defocus_values\n\n        # set pixel search to 0.0 for match template\n        pixel_size_offsets = torch.tensor([0.0], dtype=torch.float32)\n\n        ctf_filters = calculate_ctf_filter_stack(\n            template_shape=(template.shape[0], template.shape[0]),\n            optics_group=self.optics_group,\n            defocus_offsets=defocus_values,\n            pixel_size_offsets=pixel_size_offsets,\n        )\n\n        # Grab the Euler angles from the orientation search configuration\n        # (phi, theta, psi) for ZYZ convention\n        euler_angles = self.orientation_search_config.euler_angles\n        euler_angles = euler_angles.to(torch.float32)\n\n        template_dft = volume_to_rfft_fourier_slice(template)\n\n        return {\n            \"image_dft\": image_preprocessed_dft,\n            \"template_dft\": template_dft,\n            \"ctf_filters\": ctf_filters,\n            \"whitening_filter_template\": cumulative_filter_template,\n            \"euler_angles\": euler_angles,\n            \"defocus_values\": defocus_values,\n            \"pixel_values\": pixel_size_offsets,\n            \"device\": self.computational_config.gpu_devices,\n        }\n\n    def run_match_template(\n        self,\n        orientation_batch_size: int = 16,\n        do_result_export: bool = True,\n        do_valid_cropping: bool = True,\n    ) -&gt; None:\n        \"\"\"Runs the base match template in pytorch.\n\n        Parameters\n        ----------\n        orientation_batch_size : int\n            The number of projections to process in a single batch. Default is 1.\n        do_result_export : bool\n            If True, call the `MatchTemplateResult.export_results` method to save the\n            results to disk directly after running the match template. Default is True.\n        do_valid_cropping : bool\n            If True, apply the valid cropping mode to the results. Default is True.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        core_kwargs = self.make_backend_core_function_kwargs()\n        results = core_match_template(\n            **core_kwargs,\n            orientation_batch_size=orientation_batch_size,\n            num_cuda_streams=self.computational_config.num_cpus,\n        )\n\n        # Place results into the `MatchTemplateResult` object and save it.\n        self.match_template_result.mip = results[\"mip\"]\n        self.match_template_result.scaled_mip = results[\"scaled_mip\"]\n\n        self.match_template_result.correlation_average = results[\"correlation_mean\"]\n        self.match_template_result.correlation_variance = results[\n            \"correlation_variance\"\n        ]\n        self.match_template_result.orientation_psi = results[\"best_psi\"]\n        self.match_template_result.orientation_theta = results[\"best_theta\"]\n        self.match_template_result.orientation_phi = results[\"best_phi\"]\n        self.match_template_result.relative_defocus = results[\"best_defocus\"]\n\n        self.match_template_result.total_projections = results[\"total_projections\"]\n        self.match_template_result.total_orientations = results[\"total_orientations\"]\n        self.match_template_result.total_defocus = results[\"total_defocus\"]\n\n        # Apply the valid cropping mode to the results\n        if do_valid_cropping:\n            nx = self.template_volume.shape[-1]\n            self.match_template_result.apply_valid_cropping((nx, nx))\n\n        if do_result_export:\n            self.match_template_result.export_results()\n\n    def results_to_dataframe(\n        self,\n        half_template_width_pos_shift: bool = True,\n        exclude_columns: Optional[list] = None,\n        locate_peaks_kwargs: Optional[dict] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Converts the match template results to a DataFrame with additional info.\n\n        Data included in this dataframe should be sufficient to do cross-correlation on\n        the extracted peaks, that is, all the microscope parameters, defocus parameters,\n        etc. are included in the dataframe. Run-specific filter information is *not*\n        included in this dataframe; use the YAML configuration file to replicate a\n        match_template run.\n\n        Parameters\n        ----------\n        half_template_width_pos_shift : bool, optional\n            If True, columns for the image peak position are shifted by half a template\n            width to correspond to the center of the particle. This should be done when\n            the position of a peak corresponds to the top-left corner of the template\n            rather than the center. Default is True. This should generally be left as\n            True unless you know what you are doing.\n        exclude_columns : list, optional\n            List of columns to exclude from the DataFrame. Default is None and no\n            columns are excluded.\n        locate_peaks_kwargs : dict, optional\n            Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method.\n            Default is None and no additional keyword arguments are passed.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame containing the match template results.\n        \"\"\"\n        # Short circuit if no kwargs and peaks have already been located\n        if locate_peaks_kwargs is None:\n            if self.match_template_result.match_template_peaks is None:\n                self.match_template_result.locate_peaks()\n        else:\n            self.match_template_result.locate_peaks(**locate_peaks_kwargs)\n\n        # DataFrame comes with the following columns :\n        # ['mip', 'scaled_mip', 'correlation_mean', 'correlation_variance',\n        # 'total_correlations'. 'pos_y', 'pos_x', 'psi', 'theta', 'phi',\n        # 'relative_defocus', ]\n        df = self.match_template_result.peaks_to_dataframe()\n\n        # DataFrame currently contains pixel coordinates for results. Coordinates in\n        # image correspond with upper left corner of the template. Need to translate\n        # coordinates by half template width to get to particle center in image.\n        # NOTE: We are assuming the template is cubic\n        nx = mrcfile.open(self.template_volume_path).header.nx\n        if half_template_width_pos_shift:\n            df[\"pos_y_img\"] = df[\"pos_y\"] + nx // 2\n            df[\"pos_x_img\"] = df[\"pos_x\"] + nx // 2\n        else:\n            df[\"pos_y_img\"] = df[\"pos_y\"]\n            df[\"pos_x_img\"] = df[\"pos_x\"]\n\n        # Also, the positions are in terms of pixels. Also add columns for particle\n        # positions in terms of Angstroms.\n        pixel_size = self.optics_group.pixel_size\n        df[\"pos_y_img_angstrom\"] = df[\"pos_y_img\"] * pixel_size\n        df[\"pos_x_img_angstrom\"] = df[\"pos_x_img\"] * pixel_size\n\n        # Add microscope (CTF) parameters\n        df[\"defocus_u\"] = self.optics_group.defocus_u\n        df[\"defocus_v\"] = self.optics_group.defocus_v\n        df[\"astigmatism_angle\"] = self.optics_group.astigmatism_angle\n        df[\"pixel_size\"] = pixel_size\n        df[\"refined_pixel_size\"] = pixel_size\n        df[\"voltage\"] = self.optics_group.voltage\n        df[\"spherical_aberration\"] = self.optics_group.spherical_aberration\n        df[\"amplitude_contrast_ratio\"] = self.optics_group.amplitude_contrast_ratio\n        df[\"phase_shift\"] = self.optics_group.phase_shift\n        df[\"ctf_B_factor\"] = self.optics_group.ctf_B_factor\n\n        # Add paths to the micrograph and reference template\n        df[\"micrograph_path\"] = self.micrograph_path\n        df[\"template_path\"] = self.template_volume_path\n\n        # Add paths to the output statistic files\n        df[\"mip_path\"] = self.match_template_result.mip_path\n        df[\"scaled_mip_path\"] = self.match_template_result.scaled_mip_path\n        df[\"psi_path\"] = self.match_template_result.orientation_psi_path\n        df[\"theta_path\"] = self.match_template_result.orientation_theta_path\n        df[\"phi_path\"] = self.match_template_result.orientation_phi_path\n        df[\"defocus_path\"] = self.match_template_result.relative_defocus_path\n        df[\"correlation_average_path\"] = (\n            self.match_template_result.correlation_average_path\n        )\n        df[\"correlation_variance_path\"] = (\n            self.match_template_result.correlation_variance_path\n        )\n\n        # Add particle index\n        df[\"particle_index\"] = df.index\n\n        # Reorder columns\n        df = df.reindex(columns=MATCH_TEMPLATE_DF_COLUMN_ORDER)\n\n        # Drop columns if requested\n        if exclude_columns is not None:\n            df = df.drop(columns=exclude_columns)\n\n        return df\n\n    def save_config(self, path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None:\n        \"\"\"Save this Pydandic model to disk. Wrapper around the serialization methods.\n\n        Parameters\n        ----------\n        path : str\n            Path to save the configuration file.\n        mode : Literal[\"yaml\", \"json\"], optional\n            Serialization format to use. Default is 'yaml'.\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        ValueError\n            If an invalid serialization mode is provided.\n        \"\"\"\n        if mode == \"yaml\":\n            self.to_yaml(path)\n        elif mode == \"json\":\n            self.to_json(path)\n        else:\n            raise ValueError(f\"Invalid serialization mode '{mode}'.\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs()</code>","text":"<p>Generates the keyword arguments for backend call from held parameters.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(self) -&gt; dict[str, Any]:\n    \"\"\"Generates the keyword arguments for backend call from held parameters.\"\"\"\n    # Ensure the micrograph and template are loaded and in the correct format\n    if self.micrograph is None:\n        self.micrograph = load_mrc_image(self.micrograph_path)\n    if self.template_volume is None:\n        self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    # Ensure the micrograph and template are both Tensors before proceeding\n    if not isinstance(self.micrograph, torch.Tensor):\n        image = torch.from_numpy(self.micrograph)\n    else:\n        image = self.micrograph\n\n    if not isinstance(self.template_volume, torch.Tensor):\n        template = torch.from_numpy(self.template_volume)\n    else:\n        template = self.template_volume\n\n    # Fourier transform the image (RFFT, unshifted)\n    image_dft = torch.fft.rfftn(image)  # pylint: disable=E1102\n    image_dft[0, 0] = 0 + 0j  # zero out the constant term\n\n    # Get the bandpass filter individually\n    bp_config = self.preprocessing_filters.bandpass_filter\n    bandpass_filter = bp_config.calculate_bandpass_filter(image_dft.shape)\n\n    # Calculate the cumulative filters for both the image and the template.\n    cumulative_filter_image = self.preprocessing_filters.get_combined_filter(\n        ref_img_rfft=image_dft,\n        output_shape=image_dft.shape,\n    )\n    # NOTE: Here, manually accounting for the RFFT in output shape since we have not\n    # RFFT'd the template volume yet. Also, this is 2-dimensional, not 3-dimensional\n    cumulative_filter_template = self.preprocessing_filters.get_combined_filter(\n        ref_img_rfft=image_dft,\n        output_shape=(template.shape[-2], template.shape[-1] // 2 + 1),\n    )\n\n    # Apply the pre-processing and normalization\n    image_preprocessed_dft = preprocess_image(\n        image_rfft=image_dft,\n        cumulative_fourier_filters=cumulative_filter_image,\n        bandpass_filter=bandpass_filter,\n    )\n\n    # Calculate the CTF filters at each defocus value\n    defocus_values = self.defocus_search_config.defocus_values\n\n    # set pixel search to 0.0 for match template\n    pixel_size_offsets = torch.tensor([0.0], dtype=torch.float32)\n\n    ctf_filters = calculate_ctf_filter_stack(\n        template_shape=(template.shape[0], template.shape[0]),\n        optics_group=self.optics_group,\n        defocus_offsets=defocus_values,\n        pixel_size_offsets=pixel_size_offsets,\n    )\n\n    # Grab the Euler angles from the orientation search configuration\n    # (phi, theta, psi) for ZYZ convention\n    euler_angles = self.orientation_search_config.euler_angles\n    euler_angles = euler_angles.to(torch.float32)\n\n    template_dft = volume_to_rfft_fourier_slice(template)\n\n    return {\n        \"image_dft\": image_preprocessed_dft,\n        \"template_dft\": template_dft,\n        \"ctf_filters\": ctf_filters,\n        \"whitening_filter_template\": cumulative_filter_template,\n        \"euler_angles\": euler_angles,\n        \"defocus_values\": defocus_values,\n        \"pixel_values\": pixel_size_offsets,\n        \"device\": self.computational_config.gpu_devices,\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.results_to_dataframe","title":"<code>results_to_dataframe(half_template_width_pos_shift=True, exclude_columns=None, locate_peaks_kwargs=None)</code>","text":"<p>Converts the match template results to a DataFrame with additional info.</p> <p>Data included in this dataframe should be sufficient to do cross-correlation on the extracted peaks, that is, all the microscope parameters, defocus parameters, etc. are included in the dataframe. Run-specific filter information is not included in this dataframe; use the YAML configuration file to replicate a match_template run.</p> <p>Parameters:</p> Name Type Description Default <code>half_template_width_pos_shift</code> <code>bool</code> <p>If True, columns for the image peak position are shifted by half a template width to correspond to the center of the particle. This should be done when the position of a peak corresponds to the top-left corner of the template rather than the center. Default is True. This should generally be left as True unless you know what you are doing.</p> <code>True</code> <code>exclude_columns</code> <code>list</code> <p>List of columns to exclude from the DataFrame. Default is None and no columns are excluded.</p> <code>None</code> <code>locate_peaks_kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method. Default is None and no additional keyword arguments are passed.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the match template results.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def results_to_dataframe(\n    self,\n    half_template_width_pos_shift: bool = True,\n    exclude_columns: Optional[list] = None,\n    locate_peaks_kwargs: Optional[dict] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Converts the match template results to a DataFrame with additional info.\n\n    Data included in this dataframe should be sufficient to do cross-correlation on\n    the extracted peaks, that is, all the microscope parameters, defocus parameters,\n    etc. are included in the dataframe. Run-specific filter information is *not*\n    included in this dataframe; use the YAML configuration file to replicate a\n    match_template run.\n\n    Parameters\n    ----------\n    half_template_width_pos_shift : bool, optional\n        If True, columns for the image peak position are shifted by half a template\n        width to correspond to the center of the particle. This should be done when\n        the position of a peak corresponds to the top-left corner of the template\n        rather than the center. Default is True. This should generally be left as\n        True unless you know what you are doing.\n    exclude_columns : list, optional\n        List of columns to exclude from the DataFrame. Default is None and no\n        columns are excluded.\n    locate_peaks_kwargs : dict, optional\n        Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method.\n        Default is None and no additional keyword arguments are passed.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the match template results.\n    \"\"\"\n    # Short circuit if no kwargs and peaks have already been located\n    if locate_peaks_kwargs is None:\n        if self.match_template_result.match_template_peaks is None:\n            self.match_template_result.locate_peaks()\n    else:\n        self.match_template_result.locate_peaks(**locate_peaks_kwargs)\n\n    # DataFrame comes with the following columns :\n    # ['mip', 'scaled_mip', 'correlation_mean', 'correlation_variance',\n    # 'total_correlations'. 'pos_y', 'pos_x', 'psi', 'theta', 'phi',\n    # 'relative_defocus', ]\n    df = self.match_template_result.peaks_to_dataframe()\n\n    # DataFrame currently contains pixel coordinates for results. Coordinates in\n    # image correspond with upper left corner of the template. Need to translate\n    # coordinates by half template width to get to particle center in image.\n    # NOTE: We are assuming the template is cubic\n    nx = mrcfile.open(self.template_volume_path).header.nx\n    if half_template_width_pos_shift:\n        df[\"pos_y_img\"] = df[\"pos_y\"] + nx // 2\n        df[\"pos_x_img\"] = df[\"pos_x\"] + nx // 2\n    else:\n        df[\"pos_y_img\"] = df[\"pos_y\"]\n        df[\"pos_x_img\"] = df[\"pos_x\"]\n\n    # Also, the positions are in terms of pixels. Also add columns for particle\n    # positions in terms of Angstroms.\n    pixel_size = self.optics_group.pixel_size\n    df[\"pos_y_img_angstrom\"] = df[\"pos_y_img\"] * pixel_size\n    df[\"pos_x_img_angstrom\"] = df[\"pos_x_img\"] * pixel_size\n\n    # Add microscope (CTF) parameters\n    df[\"defocus_u\"] = self.optics_group.defocus_u\n    df[\"defocus_v\"] = self.optics_group.defocus_v\n    df[\"astigmatism_angle\"] = self.optics_group.astigmatism_angle\n    df[\"pixel_size\"] = pixel_size\n    df[\"refined_pixel_size\"] = pixel_size\n    df[\"voltage\"] = self.optics_group.voltage\n    df[\"spherical_aberration\"] = self.optics_group.spherical_aberration\n    df[\"amplitude_contrast_ratio\"] = self.optics_group.amplitude_contrast_ratio\n    df[\"phase_shift\"] = self.optics_group.phase_shift\n    df[\"ctf_B_factor\"] = self.optics_group.ctf_B_factor\n\n    # Add paths to the micrograph and reference template\n    df[\"micrograph_path\"] = self.micrograph_path\n    df[\"template_path\"] = self.template_volume_path\n\n    # Add paths to the output statistic files\n    df[\"mip_path\"] = self.match_template_result.mip_path\n    df[\"scaled_mip_path\"] = self.match_template_result.scaled_mip_path\n    df[\"psi_path\"] = self.match_template_result.orientation_psi_path\n    df[\"theta_path\"] = self.match_template_result.orientation_theta_path\n    df[\"phi_path\"] = self.match_template_result.orientation_phi_path\n    df[\"defocus_path\"] = self.match_template_result.relative_defocus_path\n    df[\"correlation_average_path\"] = (\n        self.match_template_result.correlation_average_path\n    )\n    df[\"correlation_variance_path\"] = (\n        self.match_template_result.correlation_variance_path\n    )\n\n    # Add particle index\n    df[\"particle_index\"] = df.index\n\n    # Reorder columns\n    df = df.reindex(columns=MATCH_TEMPLATE_DF_COLUMN_ORDER)\n\n    # Drop columns if requested\n    if exclude_columns is not None:\n        df = df.drop(columns=exclude_columns)\n\n    return df\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.run_match_template","title":"<code>run_match_template(orientation_batch_size=16, do_result_export=True, do_valid_cropping=True)</code>","text":"<p>Runs the base match template in pytorch.</p> <p>Parameters:</p> Name Type Description Default <code>orientation_batch_size</code> <code>int</code> <p>The number of projections to process in a single batch. Default is 1.</p> <code>16</code> <code>do_result_export</code> <code>bool</code> <p>If True, call the <code>MatchTemplateResult.export_results</code> method to save the results to disk directly after running the match template. Default is True.</p> <code>True</code> <code>do_valid_cropping</code> <code>bool</code> <p>If True, apply the valid cropping mode to the results. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def run_match_template(\n    self,\n    orientation_batch_size: int = 16,\n    do_result_export: bool = True,\n    do_valid_cropping: bool = True,\n) -&gt; None:\n    \"\"\"Runs the base match template in pytorch.\n\n    Parameters\n    ----------\n    orientation_batch_size : int\n        The number of projections to process in a single batch. Default is 1.\n    do_result_export : bool\n        If True, call the `MatchTemplateResult.export_results` method to save the\n        results to disk directly after running the match template. Default is True.\n    do_valid_cropping : bool\n        If True, apply the valid cropping mode to the results. Default is True.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    core_kwargs = self.make_backend_core_function_kwargs()\n    results = core_match_template(\n        **core_kwargs,\n        orientation_batch_size=orientation_batch_size,\n        num_cuda_streams=self.computational_config.num_cpus,\n    )\n\n    # Place results into the `MatchTemplateResult` object and save it.\n    self.match_template_result.mip = results[\"mip\"]\n    self.match_template_result.scaled_mip = results[\"scaled_mip\"]\n\n    self.match_template_result.correlation_average = results[\"correlation_mean\"]\n    self.match_template_result.correlation_variance = results[\n        \"correlation_variance\"\n    ]\n    self.match_template_result.orientation_psi = results[\"best_psi\"]\n    self.match_template_result.orientation_theta = results[\"best_theta\"]\n    self.match_template_result.orientation_phi = results[\"best_phi\"]\n    self.match_template_result.relative_defocus = results[\"best_defocus\"]\n\n    self.match_template_result.total_projections = results[\"total_projections\"]\n    self.match_template_result.total_orientations = results[\"total_orientations\"]\n    self.match_template_result.total_defocus = results[\"total_defocus\"]\n\n    # Apply the valid cropping mode to the results\n    if do_valid_cropping:\n        nx = self.template_volume.shape[-1]\n        self.match_template_result.apply_valid_cropping((nx, nx))\n\n    if do_result_export:\n        self.match_template_result.export_results()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.save_config","title":"<code>save_config(path, mode='yaml')</code>","text":"<p>Save this Pydandic model to disk. Wrapper around the serialization methods.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to save the configuration file.</p> required <code>mode</code> <code>Literal['yaml', 'json']</code> <p>Serialization format to use. Default is 'yaml'.</p> <code>'yaml'</code> <p>Returns:</p> Type Description <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid serialization mode is provided.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def save_config(self, path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None:\n    \"\"\"Save this Pydandic model to disk. Wrapper around the serialization methods.\n\n    Parameters\n    ----------\n    path : str\n        Path to save the configuration file.\n    mode : Literal[\"yaml\", \"json\"], optional\n        Serialization format to use. Default is 'yaml'.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If an invalid serialization mode is provided.\n    \"\"\"\n    if mode == \"yaml\":\n        self.to_yaml(path)\n    elif mode == \"json\":\n        self.to_json(path)\n    else:\n        raise ValueError(f\"Invalid serialization mode '{mode}'.\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.validate_micrograph_path","title":"<code>validate_micrograph_path(v)</code>","text":"<p>Ensure the micrograph file exists.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>@field_validator(\"micrograph_path\")  # type: ignore\ndef validate_micrograph_path(cls, v) -&gt; str:\n    \"\"\"Ensure the micrograph file exists.\"\"\"\n    if not os.path.exists(v):\n        raise ValueError(f\"File '{v}' for micrograph does not exist.\")\n\n    return str(v)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.MatchTemplateManager.validate_template_volume_path","title":"<code>validate_template_volume_path(v)</code>","text":"<p>Ensure the template volume file exists.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>@field_validator(\"template_volume_path\")  # type: ignore\ndef validate_template_volume_path(cls, v) -&gt; str:\n    \"\"\"Ensure the template volume file exists.\"\"\"\n    if not os.path.exists(v):\n        raise ValueError(f\"File '{v}' for template volume does not exist.\")\n\n    return str(v)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager","title":"<code>OptimizeTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the optimize template program.</p> <p>Attributes:</p> Name Type Description <code>particle_stack</code> <code>ParticleStack</code> <p>Particle stack object containing particle data.</p> <code>pixel_size_coarse_search</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size coarse search.</p> <code>pixel_size_fine_search</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size fine search.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>simulator</code> <code>Simulator</code> <p>The simulator object.</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the optimize template manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend optimize_template core function.</p> <code>run_optimize_template</code> <p>Run the optimize template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>class OptimizeTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the optimize template program.\n\n    Attributes\n    ----------\n    particle_stack : ParticleStack\n        Particle stack object containing particle data.\n    pixel_size_coarse_search : PixelSizeSearchConfig\n        Configuration for pixel size coarse search.\n    pixel_size_fine_search : PixelSizeSearchConfig\n        Configuration for pixel size fine search.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    simulator : Simulator\n        The simulator object.\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the optimize template manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend optimize_template core function.\n    run_optimize_template(self, output_text_path: str) -&gt; None\n        Run the optimize template program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    particle_stack: ParticleStack\n    pixel_size_coarse_search: PixelSizeSearchConfig\n    pixel_size_fine_search: PixelSizeSearchConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n    simulator: Simulator\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend refine_template core function.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool\n            Whether to use refined angles or not. Defaults to True.\n        \"\"\"\n        # simulate template volume\n        template = self.simulator.run(device=self.computational_config.gpu_ids)\n\n        # The set of \"best\" euler angles from match template search\n        # Check if refined angles exist, otherwise use the original angles\n        euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over (none for optimization)\n        euler_angle_offsets = torch.zeros((1, 3))\n\n        # The relative defocus values to search over (none for optimization)\n        defocus_offsets = torch.tensor([0.0])\n\n        # The relative pixel size values to search over (none for optimization)\n        pixel_size_offsets = torch.tensor([0.0])\n\n        # Use the common utility function to set up the backend kwargs\n        # pylint: disable=duplicate-code\n        return setup_particle_backend_kwargs(\n            particle_stack=self.particle_stack,\n            template=template,\n            preprocessing_filters=self.preprocessing_filters,\n            euler_angles=euler_angles,\n            euler_angle_offsets=euler_angle_offsets,\n            defocus_offsets=defocus_offsets,\n            pixel_size_offsets=pixel_size_offsets,\n            device_list=self.computational_config.gpu_devices,\n        )\n\n    def run_optimize_template(self, output_text_path: str) -&gt; None:\n        \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_text_path : str\n            Path to save the optimized template pixel size.\n        \"\"\"\n        if self.pixel_size_coarse_search.enabled:\n            # Create a file for logging all iterations\n            all_results_path = self._get_all_results_path(output_text_path)\n            # Create the file and write header\n            with open(all_results_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"Pixel Size (\u00c5),SNR\\n\")\n\n            optimal_template_px = self.optimize_pixel_size(all_results_path)\n            print(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n            # print this to the text file\n            with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n\n    def optimize_pixel_size(self, all_results_path: str) -&gt; float:\n        \"\"\"Optimize the pixel size of the template volume.\n\n        Parameters\n        ----------\n        all_results_path : str\n            Path to the file for logging all iterations\n\n        Returns\n        -------\n        float\n            The optimal pixel size.\n        \"\"\"\n        initial_template_px = self.simulator.pixel_spacing\n        print(f\"Initial template px: {initial_template_px:.3f} \u00c5\")\n\n        best_snr = float(\"-inf\")\n        best_px = float(initial_template_px)\n\n        print(\"Starting coarse search...\")\n\n        pixel_size_offsets_coarse = self.pixel_size_coarse_search.pixel_size_values\n        coarse_px_values = pixel_size_offsets_coarse + initial_template_px\n\n        consecutive_decreases = 0\n        consecutive_threshold = 2\n        previous_snr = float(\"-inf\")\n        for px in coarse_px_values:\n            snr = self.evaluate_template_px(px=px.item())\n            print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n            # Log to file\n            with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n            if snr &gt; best_snr:\n                best_snr = snr\n                best_px = px.item()\n            if snr &gt; previous_snr:\n                consecutive_decreases = 0\n            else:\n                consecutive_decreases += 1\n                if consecutive_decreases &gt;= consecutive_threshold:\n                    print(\n                        f\"SNR decreased for {consecutive_threshold} iterations. \"\n                        f\"Stopping coarse px search.\"\n                    )\n                    break\n            previous_snr = snr\n\n        if self.pixel_size_fine_search.enabled:\n            pixel_size_offsets_fine = self.pixel_size_fine_search.pixel_size_values\n            fine_px_values = pixel_size_offsets_fine + best_px\n\n            consecutive_decreases = 0\n            previous_snr = float(\"-inf\")\n            for px in fine_px_values:\n                snr = self.evaluate_template_px(px=px.item())\n                print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n                # Log to file\n                with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n                if snr &gt; best_snr:\n                    best_snr = snr\n                    best_px = px.item()\n                if snr &gt; previous_snr:\n                    consecutive_decreases = 0\n                else:\n                    consecutive_decreases += 1\n                    if consecutive_decreases &gt;= consecutive_threshold:\n                        print(\n                            f\"SNR decreased for {consecutive_threshold} iterations. \"\n                            \"Stopping fine px search.\"\n                        )\n                        break\n                previous_snr = snr\n\n        return best_px\n\n    def evaluate_template_px(self, px: float) -&gt; float:\n        \"\"\"Evaluate the template pixel size.\n\n        Parameters\n        ----------\n        px : float\n            The pixel size to evaluate.\n\n        Returns\n        -------\n        float\n            The mean SNR of the template.\n        \"\"\"\n        self.simulator.pixel_spacing = px\n        backend_kwargs = self.make_backend_core_function_kwargs()\n        result = self.get_correlation_result(backend_kwargs, 1)\n        mean_snr = self.results_to_snr(result)\n        return mean_snr\n\n    def get_correlation_result(\n        self, backend_kwargs: dict, orientation_batch_size: int = 64\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get correlation result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=orientation_batch_size, **backend_kwargs\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n\n        return result\n\n    def results_to_snr(self, result: dict[str, np.ndarray]) -&gt; float:\n        \"\"\"Convert optimize template result to mean SNR.\n\n        Parameters\n        ----------\n        result : dict[str, np.ndarray]\n            The result of the optimize template program.\n\n        Returns\n        -------\n        float\n            The mean SNR of the template.\n        \"\"\"\n        # Filter out any infinite or NaN values\n        # NOTE: There should not be NaNs or infs, will follow up later\n        refined_scaled_mip = result[\"refined_z_score\"]\n        refined_scaled_mip = refined_scaled_mip[np.isfinite(refined_scaled_mip)]\n\n        # If more than n values, keep only the top n highest SNRs\n        best_n = 6\n        if len(refined_scaled_mip) &gt; best_n:\n            refined_scaled_mip = np.sort(refined_scaled_mip)[-best_n:]\n\n        # Printing out the results to console\n        print(\n            f\"max snr: {refined_scaled_mip.max()}, min snr: {refined_scaled_mip.min()}\"\n        )\n\n        mean_snr = float(refined_scaled_mip.mean())\n\n        return mean_snr\n\n    def _get_all_results_path(self, output_text_path: str) -&gt; str:\n        \"\"\"Generate the results file path from the output text path.\n\n        Parameters\n        ----------\n        output_text_path : str\n            Path to the output text file\n\n        Returns\n        -------\n        str\n            Path to the file with _all.txt extension\n        \"\"\"\n        base, _ = os.path.splitext(output_text_path)\n        return f\"{base}_all.csv\"\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.evaluate_template_px","title":"<code>evaluate_template_px(px)</code>","text":"<p>Evaluate the template pixel size.</p> <p>Parameters:</p> Name Type Description Default <code>px</code> <code>float</code> <p>The pixel size to evaluate.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean SNR of the template.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def evaluate_template_px(self, px: float) -&gt; float:\n    \"\"\"Evaluate the template pixel size.\n\n    Parameters\n    ----------\n    px : float\n        The pixel size to evaluate.\n\n    Returns\n    -------\n    float\n        The mean SNR of the template.\n    \"\"\"\n    self.simulator.pixel_spacing = px\n    backend_kwargs = self.make_backend_core_function_kwargs()\n    result = self.get_correlation_result(backend_kwargs, 1)\n    mean_snr = self.results_to_snr(result)\n    return mean_snr\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.get_correlation_result","title":"<code>get_correlation_result(backend_kwargs, orientation_batch_size=64)</code>","text":"<p>Get correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def get_correlation_result(\n    self, backend_kwargs: dict, orientation_batch_size: int = 64\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get correlation result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=orientation_batch_size, **backend_kwargs\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend refine_template core function.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>Whether to use refined angles or not. Defaults to True.</p> <code>True</code> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend refine_template core function.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool\n        Whether to use refined angles or not. Defaults to True.\n    \"\"\"\n    # simulate template volume\n    template = self.simulator.run(device=self.computational_config.gpu_ids)\n\n    # The set of \"best\" euler angles from match template search\n    # Check if refined angles exist, otherwise use the original angles\n    euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over (none for optimization)\n    euler_angle_offsets = torch.zeros((1, 3))\n\n    # The relative defocus values to search over (none for optimization)\n    defocus_offsets = torch.tensor([0.0])\n\n    # The relative pixel size values to search over (none for optimization)\n    pixel_size_offsets = torch.tensor([0.0])\n\n    # Use the common utility function to set up the backend kwargs\n    # pylint: disable=duplicate-code\n    return setup_particle_backend_kwargs(\n        particle_stack=self.particle_stack,\n        template=template,\n        preprocessing_filters=self.preprocessing_filters,\n        euler_angles=euler_angles,\n        euler_angle_offsets=euler_angle_offsets,\n        defocus_offsets=defocus_offsets,\n        pixel_size_offsets=pixel_size_offsets,\n        device_list=self.computational_config.gpu_devices,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.optimize_pixel_size","title":"<code>optimize_pixel_size(all_results_path)</code>","text":"<p>Optimize the pixel size of the template volume.</p> <p>Parameters:</p> Name Type Description Default <code>all_results_path</code> <code>str</code> <p>Path to the file for logging all iterations</p> required <p>Returns:</p> Type Description <code>float</code> <p>The optimal pixel size.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def optimize_pixel_size(self, all_results_path: str) -&gt; float:\n    \"\"\"Optimize the pixel size of the template volume.\n\n    Parameters\n    ----------\n    all_results_path : str\n        Path to the file for logging all iterations\n\n    Returns\n    -------\n    float\n        The optimal pixel size.\n    \"\"\"\n    initial_template_px = self.simulator.pixel_spacing\n    print(f\"Initial template px: {initial_template_px:.3f} \u00c5\")\n\n    best_snr = float(\"-inf\")\n    best_px = float(initial_template_px)\n\n    print(\"Starting coarse search...\")\n\n    pixel_size_offsets_coarse = self.pixel_size_coarse_search.pixel_size_values\n    coarse_px_values = pixel_size_offsets_coarse + initial_template_px\n\n    consecutive_decreases = 0\n    consecutive_threshold = 2\n    previous_snr = float(\"-inf\")\n    for px in coarse_px_values:\n        snr = self.evaluate_template_px(px=px.item())\n        print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n        # Log to file\n        with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n        if snr &gt; best_snr:\n            best_snr = snr\n            best_px = px.item()\n        if snr &gt; previous_snr:\n            consecutive_decreases = 0\n        else:\n            consecutive_decreases += 1\n            if consecutive_decreases &gt;= consecutive_threshold:\n                print(\n                    f\"SNR decreased for {consecutive_threshold} iterations. \"\n                    f\"Stopping coarse px search.\"\n                )\n                break\n        previous_snr = snr\n\n    if self.pixel_size_fine_search.enabled:\n        pixel_size_offsets_fine = self.pixel_size_fine_search.pixel_size_values\n        fine_px_values = pixel_size_offsets_fine + best_px\n\n        consecutive_decreases = 0\n        previous_snr = float(\"-inf\")\n        for px in fine_px_values:\n            snr = self.evaluate_template_px(px=px.item())\n            print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n            # Log to file\n            with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n            if snr &gt; best_snr:\n                best_snr = snr\n                best_px = px.item()\n            if snr &gt; previous_snr:\n                consecutive_decreases = 0\n            else:\n                consecutive_decreases += 1\n                if consecutive_decreases &gt;= consecutive_threshold:\n                    print(\n                        f\"SNR decreased for {consecutive_threshold} iterations. \"\n                        \"Stopping fine px search.\"\n                    )\n                    break\n            previous_snr = snr\n\n    return best_px\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.results_to_snr","title":"<code>results_to_snr(result)</code>","text":"<p>Convert optimize template result to mean SNR.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the optimize template program.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean SNR of the template.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def results_to_snr(self, result: dict[str, np.ndarray]) -&gt; float:\n    \"\"\"Convert optimize template result to mean SNR.\n\n    Parameters\n    ----------\n    result : dict[str, np.ndarray]\n        The result of the optimize template program.\n\n    Returns\n    -------\n    float\n        The mean SNR of the template.\n    \"\"\"\n    # Filter out any infinite or NaN values\n    # NOTE: There should not be NaNs or infs, will follow up later\n    refined_scaled_mip = result[\"refined_z_score\"]\n    refined_scaled_mip = refined_scaled_mip[np.isfinite(refined_scaled_mip)]\n\n    # If more than n values, keep only the top n highest SNRs\n    best_n = 6\n    if len(refined_scaled_mip) &gt; best_n:\n        refined_scaled_mip = np.sort(refined_scaled_mip)[-best_n:]\n\n    # Printing out the results to console\n    print(\n        f\"max snr: {refined_scaled_mip.max()}, min snr: {refined_scaled_mip.min()}\"\n    )\n\n    mean_snr = float(refined_scaled_mip.mean())\n\n    return mean_snr\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.OptimizeTemplateManager.run_optimize_template","title":"<code>run_optimize_template(output_text_path)</code>","text":"<p>Run the refine template program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_text_path</code> <code>str</code> <p>Path to save the optimized template pixel size.</p> required Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def run_optimize_template(self, output_text_path: str) -&gt; None:\n    \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_text_path : str\n        Path to save the optimized template pixel size.\n    \"\"\"\n    if self.pixel_size_coarse_search.enabled:\n        # Create a file for logging all iterations\n        all_results_path = self._get_all_results_path(output_text_path)\n        # Create the file and write header\n        with open(all_results_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"Pixel Size (\u00c5),SNR\\n\")\n\n        optimal_template_px = self.optimize_pixel_size(all_results_path)\n        print(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n        # print this to the text file\n        with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.RefineTemplateManager","title":"<code>RefineTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the refine template program.</p> <p>Attributes:</p> Name Type Description <code>template_volume_path</code> <code>str</code> <p>Path to the template volume MRC file.</p> <code>particle_stack</code> <code>ParticleStack</code> <p>Particle stack object containing particle data.</p> <code>defocus_refinement_config</code> <code>DefocusSearchConfig</code> <p>Configuration for defocus refinement.</p> <code>pixel_size_refinement_config</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size refinement.</p> <code>orientation_refinement_config</code> <code>RefineOrientationConfig</code> <p>Configuration for orientation refinement.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>The template volume tensor (excluded from serialization).</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the refine template manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend refine_template core function.</p> <code>run_refine_template</code> <p>Run the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>class RefineTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the refine template program.\n\n    Attributes\n    ----------\n    template_volume_path : str\n        Path to the template volume MRC file.\n    particle_stack : ParticleStack\n        Particle stack object containing particle data.\n    defocus_refinement_config : DefocusSearchConfig\n        Configuration for defocus refinement.\n    pixel_size_refinement_config : PixelSizeSearchConfig\n        Configuration for pixel size refinement.\n    orientation_refinement_config : RefineOrientationConfig\n        Configuration for orientation refinement.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    template_volume : ExcludedTensor\n        The template volume tensor (excluded from serialization).\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the refine template manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend refine_template core function.\n    run_refine_template(self, correlation_batch_size: int = 32) -&gt; None\n        Run the refine template program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    template_volume_path: str  # In df per-particle, but ensure only one reference\n    particle_stack: ParticleStack\n    defocus_refinement_config: DefocusSearchConfig\n    pixel_size_refinement_config: PixelSizeSearchConfig\n    orientation_refinement_config: RefineOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n\n    def __init__(self, skip_mrc_preloads: bool = False, **data: Any):\n        super().__init__(**data)\n\n        # Load the data from the MRC files\n        if not skip_mrc_preloads:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend refine_template core function.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool\n            Whether to use the refined angles from the particle stack. Defaults to\n            False.\n        \"\"\"\n        # Ensure the template is loaded in as a Tensor object\n        template = load_template_tensor(\n            template_volume=self.template_volume,\n            template_volume_path=self.template_volume_path,\n        )\n\n        # The set of \"best\" euler angles from match template search\n        # Check if refined angles exist, otherwise use the original angles\n        euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over\n        euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n\n        # The relative defocus values to search over\n        defocus_offsets = self.defocus_refinement_config.defocus_values\n\n        # The relative pixel size values to search over\n        pixel_size_offsets = self.pixel_size_refinement_config.pixel_size_values\n\n        # Use the common utility function to set up the backend kwargs\n        # pylint: disable=duplicate-code\n        return setup_particle_backend_kwargs(\n            particle_stack=self.particle_stack,\n            template=template,\n            preprocessing_filters=self.preprocessing_filters,\n            euler_angles=euler_angles,\n            euler_angle_offsets=euler_angle_offsets,\n            defocus_offsets=defocus_offsets,\n            pixel_size_offsets=pixel_size_offsets,\n            device_list=self.computational_config.gpu_devices,\n        )\n\n    def run_refine_template(\n        self, output_dataframe_path: str, correlation_batch_size: int = 32\n    ) -&gt; None:\n        \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        correlation_batch_size : int\n            Number of cross-correlations to process in one batch, defaults to 32.\n        \"\"\"\n        backend_kwargs = self.make_backend_core_function_kwargs()\n\n        result = self.get_refine_result(backend_kwargs, correlation_batch_size)\n\n        self.refine_result_to_dataframe(\n            output_dataframe_path=output_dataframe_path, result=result\n        )\n\n    def get_refine_result(\n        self, backend_kwargs: dict, correlation_batch_size: int = 32\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get refine template result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        correlation_batch_size : int\n            Number of orientations to process at once. Defaults to 32.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=correlation_batch_size,\n            num_cuda_streams=self.computational_config.num_cpus,\n            **backend_kwargs,\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n\n        return result\n\n    def refine_result_to_dataframe(\n        self, output_dataframe_path: str, result: dict[str, np.ndarray]\n    ) -&gt; None:\n        \"\"\"Convert refine template result to dataframe.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        result : dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        df_refined = self.particle_stack._df.copy()  # pylint: disable=protected-access\n\n        # x and y positions\n        pos_offset_y = result[\"refined_pos_y\"]\n        pos_offset_x = result[\"refined_pos_x\"]\n        pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n        pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n        df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n        df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n        df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n        df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n        df_refined[\"refined_pos_y_img_angstrom\"] = (\n            pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n        )\n        df_refined[\"refined_pos_x_img_angstrom\"] = (\n            pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n        )\n\n        # Euler angles\n        df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n        df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n        df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n        # Defocus\n        df_refined[\"refined_relative_defocus\"] = (\n            result[\"refined_defocus_offset\"]\n            + self.particle_stack.get_relative_defocus().cpu().numpy()\n        )\n\n        # Pixel size\n        df_refined[\"refined_pixel_size\"] = (\n            result[\"refined_pixel_size_offset\"]\n            + self.particle_stack.get_pixel_size().cpu().numpy()\n        )\n\n        # Cross-correlation statistics\n        # Check if correlation statistic files exist and use them if available\n        # This allows for shifts during refinement\n\n        # if (\n        #    \"correlation_average_path\" in df_refined.columns\n        #    and \"correlation_variance_path\" in df_refined.columns\n        # ):\n        # Check if files exist for at least the first entry\n        #    if (\n        #        df_refined[\"correlation_average_path\"].iloc[0]\n        #        and df_refined[\"correlation_variance_path\"].iloc[0]\n        #    ):\n        # Load the correlation statistics from the files\n        #        correlation_average = read_mrc_to_numpy(\n        #            df_refined[\"correlation_average_path\"].iloc[0]\n        #        )\n        #        correlation_variance = read_mrc_to_numpy(\n        #            df_refined[\"correlation_variance_path\"].iloc[0]\n        #        )\n        #        df_refined[\"correlation_mean\"] = correlation_average[\n        #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n        #           ]\n        #        df_refined[\"correlation_variance\"] = correlation_variance[\n        #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n        #        ]\n        refined_mip = result[\"refined_cross_correlation\"]\n        refined_scaled_mip = result[\"refined_z_score\"]\n        df_refined[\"refined_mip\"] = refined_mip\n        df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n        # Reorder the columns\n        df_refined = df_refined.reindex(columns=REFINED_DF_COLUMN_ORDER)\n\n        # Save the refined DataFrame to disk\n        df_refined.to_csv(output_dataframe_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.RefineTemplateManager.get_refine_result","title":"<code>get_refine_result(backend_kwargs, correlation_batch_size=32)</code>","text":"<p>Get refine template result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>correlation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 32.</p> <code>32</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def get_refine_result(\n    self, backend_kwargs: dict, correlation_batch_size: int = 32\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get refine template result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    correlation_batch_size : int\n        Number of orientations to process at once. Defaults to 32.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=correlation_batch_size,\n        num_cuda_streams=self.computational_config.num_cpus,\n        **backend_kwargs,\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.RefineTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend refine_template core function.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>Whether to use the refined angles from the particle stack. Defaults to False.</p> <code>True</code> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend refine_template core function.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool\n        Whether to use the refined angles from the particle stack. Defaults to\n        False.\n    \"\"\"\n    # Ensure the template is loaded in as a Tensor object\n    template = load_template_tensor(\n        template_volume=self.template_volume,\n        template_volume_path=self.template_volume_path,\n    )\n\n    # The set of \"best\" euler angles from match template search\n    # Check if refined angles exist, otherwise use the original angles\n    euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over\n    euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n\n    # The relative defocus values to search over\n    defocus_offsets = self.defocus_refinement_config.defocus_values\n\n    # The relative pixel size values to search over\n    pixel_size_offsets = self.pixel_size_refinement_config.pixel_size_values\n\n    # Use the common utility function to set up the backend kwargs\n    # pylint: disable=duplicate-code\n    return setup_particle_backend_kwargs(\n        particle_stack=self.particle_stack,\n        template=template,\n        preprocessing_filters=self.preprocessing_filters,\n        euler_angles=euler_angles,\n        euler_angle_offsets=euler_angle_offsets,\n        defocus_offsets=defocus_offsets,\n        pixel_size_offsets=pixel_size_offsets,\n        device_list=self.computational_config.gpu_devices,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.RefineTemplateManager.refine_result_to_dataframe","title":"<code>refine_result_to_dataframe(output_dataframe_path, result)</code>","text":"<p>Convert refine template result to dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> required Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def refine_result_to_dataframe(\n    self, output_dataframe_path: str, result: dict[str, np.ndarray]\n) -&gt; None:\n    \"\"\"Convert refine template result to dataframe.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    result : dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    df_refined = self.particle_stack._df.copy()  # pylint: disable=protected-access\n\n    # x and y positions\n    pos_offset_y = result[\"refined_pos_y\"]\n    pos_offset_x = result[\"refined_pos_x\"]\n    pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n    pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n    df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n    df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n    df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n    df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n    df_refined[\"refined_pos_y_img_angstrom\"] = (\n        pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n    )\n    df_refined[\"refined_pos_x_img_angstrom\"] = (\n        pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n    )\n\n    # Euler angles\n    df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n    df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n    df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n    # Defocus\n    df_refined[\"refined_relative_defocus\"] = (\n        result[\"refined_defocus_offset\"]\n        + self.particle_stack.get_relative_defocus().cpu().numpy()\n    )\n\n    # Pixel size\n    df_refined[\"refined_pixel_size\"] = (\n        result[\"refined_pixel_size_offset\"]\n        + self.particle_stack.get_pixel_size().cpu().numpy()\n    )\n\n    # Cross-correlation statistics\n    # Check if correlation statistic files exist and use them if available\n    # This allows for shifts during refinement\n\n    # if (\n    #    \"correlation_average_path\" in df_refined.columns\n    #    and \"correlation_variance_path\" in df_refined.columns\n    # ):\n    # Check if files exist for at least the first entry\n    #    if (\n    #        df_refined[\"correlation_average_path\"].iloc[0]\n    #        and df_refined[\"correlation_variance_path\"].iloc[0]\n    #    ):\n    # Load the correlation statistics from the files\n    #        correlation_average = read_mrc_to_numpy(\n    #            df_refined[\"correlation_average_path\"].iloc[0]\n    #        )\n    #        correlation_variance = read_mrc_to_numpy(\n    #            df_refined[\"correlation_variance_path\"].iloc[0]\n    #        )\n    #        df_refined[\"correlation_mean\"] = correlation_average[\n    #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n    #           ]\n    #        df_refined[\"correlation_variance\"] = correlation_variance[\n    #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n    #        ]\n    refined_mip = result[\"refined_cross_correlation\"]\n    refined_scaled_mip = result[\"refined_z_score\"]\n    df_refined[\"refined_mip\"] = refined_mip\n    df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n    # Reorder the columns\n    df_refined = df_refined.reindex(columns=REFINED_DF_COLUMN_ORDER)\n\n    # Save the refined DataFrame to disk\n    df_refined.to_csv(output_dataframe_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/#leopard_em.pydantic_models.managers.RefineTemplateManager.run_refine_template","title":"<code>run_refine_template(output_dataframe_path, correlation_batch_size=32)</code>","text":"<p>Run the refine template program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>correlation_batch_size</code> <code>int</code> <p>Number of cross-correlations to process in one batch, defaults to 32.</p> <code>32</code> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def run_refine_template(\n    self, output_dataframe_path: str, correlation_batch_size: int = 32\n) -&gt; None:\n    \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    correlation_batch_size : int\n        Number of cross-correlations to process in one batch, defaults to 32.\n    \"\"\"\n    backend_kwargs = self.make_backend_core_function_kwargs()\n\n    result = self.get_refine_result(backend_kwargs, correlation_batch_size)\n\n    self.refine_result_to_dataframe(\n        output_dataframe_path=output_dataframe_path, result=result\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/","title":"constrained_search_manager","text":"<p>Pydantic model for running the constrained search program.</p>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/#leopard_em.pydantic_models.managers.constrained_search_manager.ConstrainedSearchManager","title":"<code>ConstrainedSearchManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the constrained search program.</p> <p>NOTE: The constrained search program should only be run on data from a single reference micrograph. That is, if you have data from two or more micrographs, that data from each micrograph needs processed separately. This restriction may be lifted in the future.</p> <p>Attributes:</p> Name Type Description <code>template_volume_path</code> <code>str</code> <p>Path to the template volume MRC file.</p> <code>center_vector</code> <code>list[float]</code> <p>The centre vector of the template volume.</p> <code>particle_stack_reference</code> <code>ParticleStack</code> <p>Particle stack object containing particle data reference particles.</p> <code>particle_stack_constrained</code> <code>ParticleStack</code> <p>Particle stack object containing particle data constrained particles.</p> <code>defocus_refinement_config</code> <code>DefocusSearchConfig</code> <p>Configuration for defocus refinement.</p> <code>orientation_refinement_config</code> <code>RefineOrientationConfig</code> <p>Configuration for orientation refinement.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>The template volume tensor (excluded from serialization).</p> <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the constrained search manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend refine_template core function.</p> <code>run_constrained_search</code> <p>Run the constrained search program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>class ConstrainedSearchManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the constrained search program.\n\n    NOTE: The constrained search program should only be run on data from a single\n    reference micrograph. That is, if you have data from two or more micrographs, that\n    data from each micrograph needs processed separately. This restriction may be lifted\n    in the future.\n\n    Attributes\n    ----------\n    template_volume_path : str\n        Path to the template volume MRC file.\n    center_vector : list[float]\n        The centre vector of the template volume.\n    particle_stack_reference : ParticleStack\n        Particle stack object containing particle data reference particles.\n    particle_stack_constrained : ParticleStack\n        Particle stack object containing particle data constrained particles.\n    defocus_refinement_config : DefocusSearchConfig\n        Configuration for defocus refinement.\n    orientation_refinement_config : RefineOrientationConfig\n        Configuration for orientation refinement.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    template_volume : ExcludedTensor\n        The template volume tensor (excluded from serialization).\n    false_positives : float\n        The number of false positives to allow per particle.\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the constrained search manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend refine_template core function.\n    run_constrained_search(self, orientation_batch_size: int = 64) -&gt; None\n        Run the constrained search program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    template_volume_path: str  # In df per-particle, but ensure only one reference\n    center_vector: list[float] = Field(default=[0.0, 0.0, 0.0])\n\n    particle_stack_reference: ParticleStack\n    particle_stack_constrained: ParticleStack\n    defocus_refinement_config: DefocusSearchConfig\n    orientation_refinement_config: ConstrainedOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n    zdiffs: ExcludedTensor = torch.tensor([0.0])\n\n    def __init__(self, skip_mrc_preloads: bool = False, **data: Any):\n        super().__init__(**data)\n\n        # Load the data from the MRC files\n        if not skip_mrc_preloads:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    # pylint: disable=too-many-locals\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend constrained_template core function.\"\"\"\n        part_stk = self.particle_stack_reference\n\n        # Checks to make sure manager is properly configured\n        # pylint: disable=protected-access\n        assert part_stk._df[\"micrograph_path\"].nunique() == 1, (\n            \"Constrained search can only be run on data from a single micrograph. \"\n            \"Please ensure that the particle stack contains particles from only one \"\n            \"micrograph.\"\n        )\n\n        device_list = self.computational_config.gpu_devices\n\n        template = load_template_tensor(\n            template_volume=self.template_volume,\n            template_volume_path=self.template_volume_path,\n        )\n\n        euler_angles = part_stk.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over\n        euler_angle_offsets, _ = self.orientation_refinement_config.euler_angles_offsets\n\n        # No pixel size refinement\n        pixel_size_offsets = torch.tensor([0.0])\n\n        # Extract and preprocess images and filters\n        (\n            particle_images_dft,\n            template_dft,\n            projective_filters,\n        ) = setup_images_filters_particle_stack(\n            part_stk, self.preprocessing_filters, template\n        )\n\n        # get z diff for each particle\n        if not isinstance(self.center_vector, torch.Tensor):\n            self.center_vector = torch.tensor(self.center_vector, dtype=torch.float32)\n        rotation_matrices = roma.rotvec_to_rotmat(\n            roma.euler_to_rotvec(convention=\"ZYZ\", angles=euler_angles)\n        ).to(torch.float32)\n        rotated_vectors = rotation_matrices @ self.center_vector\n\n        # Get z for each particle -&gt; tensor shape [batch_size]\n        new_z_diffs = rotated_vectors[:, 2]\n\n        # The best defocus values for each particle (+ astigmatism)\n        defocus_u, defocus_v = part_stk.get_absolute_defocus()\n        defocus_u = defocus_u - new_z_diffs\n        defocus_v = defocus_v - new_z_diffs\n        # Store defocus values as instance attributes for later access\n        self.zdiffs = new_z_diffs\n        defocus_angle = torch.tensor(part_stk[\"astigmatism_angle\"])\n\n        # The relative defocus values to search over\n        defocus_offsets = self.defocus_refinement_config.defocus_values\n\n        ctf_kwargs = _setup_ctf_kwargs_from_particle_stack(\n            part_stk, (template.shape[-2], template.shape[-1])\n        )\n\n        # Ger corr mean and variance\n        # The position of the extracted areas needs to be from the larger particle, but\n        # the mean and variance must come from the initial match template on the\n        # smaller constrained particle.\n        # Currently, we just set the searched file (as in paths below) to the first\n        # element in the constrained particle stack.\n        # NOTE: This will *not* work if the constrained particle stack contains\n        # particles from multiple reference images.\n        part_stk.set_column(\n            \"correlation_average_path\",\n            self.particle_stack_constrained[\"correlation_average_path\"][0],\n        )\n        part_stk.set_column(\n            \"correlation_variance_path\",\n            self.particle_stack_constrained[\"correlation_variance_path\"][0],\n        )\n        # Get correlation statistics\n        corr_mean_stack = part_stk.construct_cropped_statistic_stack(\n            stat=\"correlation_average\",\n            handle_bounds=\"pad\",\n            padding_mode=\"constant\",\n            padding_value=0.0,  # pad with zeros\n        )\n        corr_std_stack = part_stk.construct_cropped_statistic_stack(\n            stat=\"correlation_variance\",\n            handle_bounds=\"pad\",\n            padding_mode=\"constant\",\n            padding_value=1e10,  # large to avoid out of bound pixels having inf z-score\n        )\n        corr_std_stack = corr_std_stack**0.5  # Convert variance to standard deviation\n\n        return {\n            \"particle_stack_dft\": particle_images_dft,\n            \"template_dft\": template_dft,\n            \"euler_angles\": euler_angles,\n            \"euler_angle_offsets\": euler_angle_offsets,\n            \"defocus_u\": defocus_u,\n            \"defocus_v\": defocus_v,\n            \"defocus_angle\": defocus_angle,\n            \"defocus_offsets\": defocus_offsets,\n            \"pixel_size_offsets\": pixel_size_offsets,\n            \"corr_mean\": corr_mean_stack,\n            \"corr_std\": corr_std_stack,\n            \"ctf_kwargs\": ctf_kwargs,\n            \"projective_filters\": projective_filters,\n            \"device\": device_list,  # Pass all devices to core_refine_template\n        }\n\n    def run_constrained_search(\n        self,\n        output_dataframe_path: str,\n        false_positives: float = 0.005,\n        orientation_batch_size: int = 64,\n    ) -&gt; None:\n        \"\"\"Run the constrained search program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the constrained search results.\n        false_positives : float\n            The number of false positives to allow per particle.\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n        \"\"\"\n        backend_kwargs = self.make_backend_core_function_kwargs()\n\n        result = self.get_refine_result(backend_kwargs, orientation_batch_size)\n\n        self.refine_result_to_dataframe(\n            output_dataframe_path=output_dataframe_path,\n            result=result,\n            false_positives=false_positives,\n        )\n\n    def get_refine_result(\n        self, backend_kwargs: dict, orientation_batch_size: int = 64\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get refine template result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # Adjust batch size if orientation search is disabled\n        if not self.orientation_refinement_config.enabled:\n            orientation_batch_size = 1\n        elif (\n            self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n            &lt; orientation_batch_size\n        ):\n            orientation_batch_size = (\n                self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n            )\n\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=orientation_batch_size, **backend_kwargs\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n        return result\n\n    # pylint: disable=too-many-locals\n    def refine_result_to_dataframe(\n        self,\n        output_dataframe_path: str,\n        result: dict[str, np.ndarray],\n        false_positives: float = 0.005,\n    ) -&gt; None:\n        \"\"\"Convert refine template result to dataframe.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        result : dict[str, np.ndarray]\n            The result of the refine template program.\n        false_positives : float\n            The number of false positives to allow per particle.\n        \"\"\"\n        df_refined = self.particle_stack_reference.get_dataframe_copy()\n\n        # x and y positions\n        pos_offset_y = result[\"refined_pos_y\"]\n        pos_offset_x = result[\"refined_pos_x\"]\n        pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n        pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n        df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n        df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n        df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n        df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n        df_refined[\"refined_pos_y_img_angstrom\"] = (\n            pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n        )\n        df_refined[\"refined_pos_x_img_angstrom\"] = (\n            pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n        )\n\n        # Euler angles\n        angle_idx = result[\"angle_idx\"]\n        df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n        df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n        df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n        _, euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n        euler_angle_offsets_np = euler_angle_offsets.cpu().numpy()\n        # Store the matched original offsets in the dataframe\n        df_refined[\"original_offset_phi\"] = euler_angle_offsets_np[angle_idx, 0]\n        df_refined[\"original_offset_theta\"] = euler_angle_offsets_np[angle_idx, 1]\n        df_refined[\"original_offset_psi\"] = euler_angle_offsets_np[angle_idx, 2]\n\n        # Defocus\n        df_refined[\"refined_relative_defocus\"] = (\n            result[\"refined_defocus_offset\"]\n            + self.particle_stack_reference.get_relative_defocus().cpu().numpy()\n            - self.zdiffs.cpu().numpy()\n        )\n\n        # Pixel size\n        df_refined[\"refined_pixel_size\"] = (\n            result[\"refined_pixel_size_offset\"]\n            + self.particle_stack_reference.get_pixel_size().cpu().numpy()\n        )\n\n        # Cross-correlation statistics\n        refined_mip = result[\"refined_cross_correlation\"]\n        refined_scaled_mip = result[\"refined_z_score\"]\n        df_refined[\"refined_mip\"] = refined_mip\n        df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n        # Reorder the columns\n        df_refined = df_refined.reindex(columns=CONSTRAINED_DF_COLUMN_ORDER).fillna(0)\n\n        # Save the refined DataFrame to disk\n        df_refined.to_csv(output_dataframe_path)\n\n        # Save a second dataframe\n        # I also want the original user input offsets back somewhere\n        # This one will have only those above threshold\n        num_projections = (\n            self.defocus_refinement_config.defocus_values.shape[0]\n            * self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        )\n        num_px = (\n            self.particle_stack_reference.extracted_box_size[0]\n            - self.particle_stack_reference.original_template_size[0]\n            + 1\n        ) * (\n            self.particle_stack_reference.extracted_box_size[1]\n            - self.particle_stack_reference.original_template_size[1]\n            + 1\n        )\n        num_correlations = num_projections * num_px\n        threshold = gaussian_noise_zscore_cutoff(\n            num_correlations, float(false_positives)\n        )\n\n        # Save all parameters to CSV including false-positives\n        params_df = pd.DataFrame(\n            {\n                \"num_projections\": [num_projections],\n                \"num_px\": [num_px],\n                \"num_correlations\": [num_correlations],\n                \"false_positives\": [false_positives],\n                \"threshold\": [threshold],\n            }\n        )\n        params_df.to_csv(output_dataframe_path.replace(\".csv\", \"_parameters.csv\"))\n\n        print(\n            f\"Threshold: {threshold} which gives {false_positives} \"\n            \"false positives per particle\"\n        )\n        df_refined_above_threshold = df_refined[\n            df_refined[\"refined_scaled_mip\"] &gt; threshold\n        ]\n        # Also remove if refined_scaled_mip is inf or nan\n        df_refined_above_threshold = df_refined_above_threshold[\n            df_refined_above_threshold[\"refined_scaled_mip\"] != np.inf\n        ]\n        df_refined_above_threshold = df_refined_above_threshold[\n            df_refined_above_threshold[\"refined_scaled_mip\"] != np.nan\n        ]\n        # Save the above threshold dataframe\n        print(\n            f\"Saving above threshold dataframe to \"\n            f\"{output_dataframe_path.replace('.csv', '_above_threshold.csv')}\"\n        )\n        df_refined_above_threshold.to_csv(\n            output_dataframe_path.replace(\".csv\", \"_above_threshold.csv\")\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/#leopard_em.pydantic_models.managers.constrained_search_manager.ConstrainedSearchManager.get_refine_result","title":"<code>get_refine_result(backend_kwargs, orientation_batch_size=64)</code>","text":"<p>Get refine template result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def get_refine_result(\n    self, backend_kwargs: dict, orientation_batch_size: int = 64\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get refine template result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # Adjust batch size if orientation search is disabled\n    if not self.orientation_refinement_config.enabled:\n        orientation_batch_size = 1\n    elif (\n        self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        &lt; orientation_batch_size\n    ):\n        orientation_batch_size = (\n            self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n        )\n\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=orientation_batch_size, **backend_kwargs\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/#leopard_em.pydantic_models.managers.constrained_search_manager.ConstrainedSearchManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend constrained_template core function.</p> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend constrained_template core function.\"\"\"\n    part_stk = self.particle_stack_reference\n\n    # Checks to make sure manager is properly configured\n    # pylint: disable=protected-access\n    assert part_stk._df[\"micrograph_path\"].nunique() == 1, (\n        \"Constrained search can only be run on data from a single micrograph. \"\n        \"Please ensure that the particle stack contains particles from only one \"\n        \"micrograph.\"\n    )\n\n    device_list = self.computational_config.gpu_devices\n\n    template = load_template_tensor(\n        template_volume=self.template_volume,\n        template_volume_path=self.template_volume_path,\n    )\n\n    euler_angles = part_stk.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over\n    euler_angle_offsets, _ = self.orientation_refinement_config.euler_angles_offsets\n\n    # No pixel size refinement\n    pixel_size_offsets = torch.tensor([0.0])\n\n    # Extract and preprocess images and filters\n    (\n        particle_images_dft,\n        template_dft,\n        projective_filters,\n    ) = setup_images_filters_particle_stack(\n        part_stk, self.preprocessing_filters, template\n    )\n\n    # get z diff for each particle\n    if not isinstance(self.center_vector, torch.Tensor):\n        self.center_vector = torch.tensor(self.center_vector, dtype=torch.float32)\n    rotation_matrices = roma.rotvec_to_rotmat(\n        roma.euler_to_rotvec(convention=\"ZYZ\", angles=euler_angles)\n    ).to(torch.float32)\n    rotated_vectors = rotation_matrices @ self.center_vector\n\n    # Get z for each particle -&gt; tensor shape [batch_size]\n    new_z_diffs = rotated_vectors[:, 2]\n\n    # The best defocus values for each particle (+ astigmatism)\n    defocus_u, defocus_v = part_stk.get_absolute_defocus()\n    defocus_u = defocus_u - new_z_diffs\n    defocus_v = defocus_v - new_z_diffs\n    # Store defocus values as instance attributes for later access\n    self.zdiffs = new_z_diffs\n    defocus_angle = torch.tensor(part_stk[\"astigmatism_angle\"])\n\n    # The relative defocus values to search over\n    defocus_offsets = self.defocus_refinement_config.defocus_values\n\n    ctf_kwargs = _setup_ctf_kwargs_from_particle_stack(\n        part_stk, (template.shape[-2], template.shape[-1])\n    )\n\n    # Ger corr mean and variance\n    # The position of the extracted areas needs to be from the larger particle, but\n    # the mean and variance must come from the initial match template on the\n    # smaller constrained particle.\n    # Currently, we just set the searched file (as in paths below) to the first\n    # element in the constrained particle stack.\n    # NOTE: This will *not* work if the constrained particle stack contains\n    # particles from multiple reference images.\n    part_stk.set_column(\n        \"correlation_average_path\",\n        self.particle_stack_constrained[\"correlation_average_path\"][0],\n    )\n    part_stk.set_column(\n        \"correlation_variance_path\",\n        self.particle_stack_constrained[\"correlation_variance_path\"][0],\n    )\n    # Get correlation statistics\n    corr_mean_stack = part_stk.construct_cropped_statistic_stack(\n        stat=\"correlation_average\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=0.0,  # pad with zeros\n    )\n    corr_std_stack = part_stk.construct_cropped_statistic_stack(\n        stat=\"correlation_variance\",\n        handle_bounds=\"pad\",\n        padding_mode=\"constant\",\n        padding_value=1e10,  # large to avoid out of bound pixels having inf z-score\n    )\n    corr_std_stack = corr_std_stack**0.5  # Convert variance to standard deviation\n\n    return {\n        \"particle_stack_dft\": particle_images_dft,\n        \"template_dft\": template_dft,\n        \"euler_angles\": euler_angles,\n        \"euler_angle_offsets\": euler_angle_offsets,\n        \"defocus_u\": defocus_u,\n        \"defocus_v\": defocus_v,\n        \"defocus_angle\": defocus_angle,\n        \"defocus_offsets\": defocus_offsets,\n        \"pixel_size_offsets\": pixel_size_offsets,\n        \"corr_mean\": corr_mean_stack,\n        \"corr_std\": corr_std_stack,\n        \"ctf_kwargs\": ctf_kwargs,\n        \"projective_filters\": projective_filters,\n        \"device\": device_list,  # Pass all devices to core_refine_template\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/#leopard_em.pydantic_models.managers.constrained_search_manager.ConstrainedSearchManager.refine_result_to_dataframe","title":"<code>refine_result_to_dataframe(output_dataframe_path, result, false_positives=0.005)</code>","text":"<p>Convert refine template result to dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> required <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <code>0.005</code> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def refine_result_to_dataframe(\n    self,\n    output_dataframe_path: str,\n    result: dict[str, np.ndarray],\n    false_positives: float = 0.005,\n) -&gt; None:\n    \"\"\"Convert refine template result to dataframe.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    result : dict[str, np.ndarray]\n        The result of the refine template program.\n    false_positives : float\n        The number of false positives to allow per particle.\n    \"\"\"\n    df_refined = self.particle_stack_reference.get_dataframe_copy()\n\n    # x and y positions\n    pos_offset_y = result[\"refined_pos_y\"]\n    pos_offset_x = result[\"refined_pos_x\"]\n    pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n    pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n    df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n    df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n    df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n    df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n    df_refined[\"refined_pos_y_img_angstrom\"] = (\n        pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n    )\n    df_refined[\"refined_pos_x_img_angstrom\"] = (\n        pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n    )\n\n    # Euler angles\n    angle_idx = result[\"angle_idx\"]\n    df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n    df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n    df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n    _, euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n    euler_angle_offsets_np = euler_angle_offsets.cpu().numpy()\n    # Store the matched original offsets in the dataframe\n    df_refined[\"original_offset_phi\"] = euler_angle_offsets_np[angle_idx, 0]\n    df_refined[\"original_offset_theta\"] = euler_angle_offsets_np[angle_idx, 1]\n    df_refined[\"original_offset_psi\"] = euler_angle_offsets_np[angle_idx, 2]\n\n    # Defocus\n    df_refined[\"refined_relative_defocus\"] = (\n        result[\"refined_defocus_offset\"]\n        + self.particle_stack_reference.get_relative_defocus().cpu().numpy()\n        - self.zdiffs.cpu().numpy()\n    )\n\n    # Pixel size\n    df_refined[\"refined_pixel_size\"] = (\n        result[\"refined_pixel_size_offset\"]\n        + self.particle_stack_reference.get_pixel_size().cpu().numpy()\n    )\n\n    # Cross-correlation statistics\n    refined_mip = result[\"refined_cross_correlation\"]\n    refined_scaled_mip = result[\"refined_z_score\"]\n    df_refined[\"refined_mip\"] = refined_mip\n    df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n    # Reorder the columns\n    df_refined = df_refined.reindex(columns=CONSTRAINED_DF_COLUMN_ORDER).fillna(0)\n\n    # Save the refined DataFrame to disk\n    df_refined.to_csv(output_dataframe_path)\n\n    # Save a second dataframe\n    # I also want the original user input offsets back somewhere\n    # This one will have only those above threshold\n    num_projections = (\n        self.defocus_refinement_config.defocus_values.shape[0]\n        * self.orientation_refinement_config.euler_angles_offsets[0].shape[0]\n    )\n    num_px = (\n        self.particle_stack_reference.extracted_box_size[0]\n        - self.particle_stack_reference.original_template_size[0]\n        + 1\n    ) * (\n        self.particle_stack_reference.extracted_box_size[1]\n        - self.particle_stack_reference.original_template_size[1]\n        + 1\n    )\n    num_correlations = num_projections * num_px\n    threshold = gaussian_noise_zscore_cutoff(\n        num_correlations, float(false_positives)\n    )\n\n    # Save all parameters to CSV including false-positives\n    params_df = pd.DataFrame(\n        {\n            \"num_projections\": [num_projections],\n            \"num_px\": [num_px],\n            \"num_correlations\": [num_correlations],\n            \"false_positives\": [false_positives],\n            \"threshold\": [threshold],\n        }\n    )\n    params_df.to_csv(output_dataframe_path.replace(\".csv\", \"_parameters.csv\"))\n\n    print(\n        f\"Threshold: {threshold} which gives {false_positives} \"\n        \"false positives per particle\"\n    )\n    df_refined_above_threshold = df_refined[\n        df_refined[\"refined_scaled_mip\"] &gt; threshold\n    ]\n    # Also remove if refined_scaled_mip is inf or nan\n    df_refined_above_threshold = df_refined_above_threshold[\n        df_refined_above_threshold[\"refined_scaled_mip\"] != np.inf\n    ]\n    df_refined_above_threshold = df_refined_above_threshold[\n        df_refined_above_threshold[\"refined_scaled_mip\"] != np.nan\n    ]\n    # Save the above threshold dataframe\n    print(\n        f\"Saving above threshold dataframe to \"\n        f\"{output_dataframe_path.replace('.csv', '_above_threshold.csv')}\"\n    )\n    df_refined_above_threshold.to_csv(\n        output_dataframe_path.replace(\".csv\", \"_above_threshold.csv\")\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/constrained_search_manager/#leopard_em.pydantic_models.managers.constrained_search_manager.ConstrainedSearchManager.run_constrained_search","title":"<code>run_constrained_search(output_dataframe_path, false_positives=0.005, orientation_batch_size=64)</code>","text":"<p>Run the constrained search program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the constrained search results.</p> required <code>false_positives</code> <code>float</code> <p>The number of false positives to allow per particle.</p> <code>0.005</code> <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> Source code in <code>src/leopard_em/pydantic_models/managers/constrained_search_manager.py</code> <pre><code>def run_constrained_search(\n    self,\n    output_dataframe_path: str,\n    false_positives: float = 0.005,\n    orientation_batch_size: int = 64,\n) -&gt; None:\n    \"\"\"Run the constrained search program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the constrained search results.\n    false_positives : float\n        The number of false positives to allow per particle.\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n    \"\"\"\n    backend_kwargs = self.make_backend_core_function_kwargs()\n\n    result = self.get_refine_result(backend_kwargs, orientation_batch_size)\n\n    self.refine_result_to_dataframe(\n        output_dataframe_path=output_dataframe_path,\n        result=result,\n        false_positives=false_positives,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/","title":"match_template_manager","text":"<p>Root-level model for serialization and validation of 2DTM parameters.</p>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager","title":"<code>MatchTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running full orientation 2DTM.</p> <p>Attributes:</p> Name Type Description <code>micrograph_path</code> <code>str</code> <p>Path to the micrograph .mrc file.</p> <code>template_volume_path</code> <code>str</code> <p>Path to the template volume .mrc file.</p> <code>micrograph</code> <code>ExcludedTensor</code> <p>Image to run template matching on. Not serialized.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>Template volume to match against. Not serialized.</p> <code>optics_group</code> <code>OpticsGroup</code> <p>Optics group parameters for the imaging system on the microscope.</p> <code>defocus_search_config</code> <code>DefocusSearchConfig</code> <p>Parameters for searching over defocus values.</p> <code>orientation_search_config</code> <code>OrientationSearchConfig</code> <p>Parameters for searching over orientation angles.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Configurations for the preprocessing filters to apply during correlation.</p> <code>match_template_result</code> <code>MatchTemplateResult</code> <p>Result of the match template program stored as an instance of the <code>MatchTemplateResult</code> class.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>Parameters for controlling computational resources.</p> <p>Methods:</p> Name Description <code>validate_micrograph_path</code> <p>Ensure the micrograph file exists.</p> <code>validate_template_volume_path</code> <p>Ensure the template volume file exists.</p> <code>__init__</code> <p>Constructor which also loads the micrograph and template volume from disk. The 'preload_mrc_files' parameter controls whether to read the MRC files immediately upon initialization.</p> <code>make_backend_core_function_kwargs</code> <p>Generates the keyword arguments for backend 'core_match_template' call from held parameters. Does the necessary pre-processing steps to filter the image and template.</p> <code>run_match_template</code> <p>Runs the base match template program in PyTorch.</p> <code>results_to_dataframe</code> <p>half_template_width_pos_shift: bool = True, exclude_columns: Optional[list] = None, locate_peaks_kwargs: Optional[dict] = None,</p> <code>) -&gt; pd.DataFrame</code> <p>Converts the basic extracted peak info DataFrame (from the result object) to a DataFrame with additional information about reference files, microscope parameters, etc.</p> <code>save_config</code> <p>Save this Pydantic model config to disk.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>class MatchTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running full orientation 2DTM.\n\n    Attributes\n    ----------\n    micrograph_path : str\n        Path to the micrograph .mrc file.\n    template_volume_path : str\n        Path to the template volume .mrc file.\n    micrograph : ExcludedTensor\n        Image to run template matching on. Not serialized.\n    template_volume : ExcludedTensor\n        Template volume to match against. Not serialized.\n    optics_group : OpticsGroup\n        Optics group parameters for the imaging system on the microscope.\n    defocus_search_config : DefocusSearchConfig\n        Parameters for searching over defocus values.\n    orientation_search_config : OrientationSearchConfig\n        Parameters for searching over orientation angles.\n    preprocessing_filters : PreprocessingFilters\n        Configurations for the preprocessing filters to apply during\n        correlation.\n    match_template_result : MatchTemplateResult\n        Result of the match template program stored as an instance of the\n        `MatchTemplateResult` class.\n    computational_config : ComputationalConfig\n        Parameters for controlling computational resources.\n\n    Methods\n    -------\n    validate_micrograph_path(v: str) -&gt; str\n        Ensure the micrograph file exists.\n    validate_template_volume_path(v: str) -&gt; str\n        Ensure the template volume file exists.\n    __init__(preload_mrc_files: bool = False , **data: Any)\n        Constructor which also loads the micrograph and template volume from disk.\n        The 'preload_mrc_files' parameter controls whether to read the MRC files\n        immediately upon initialization.\n    make_backend_core_function_kwargs() -&gt; dict[str, Any]\n        Generates the keyword arguments for backend 'core_match_template' call from\n        held parameters. Does the necessary pre-processing steps to filter the image\n        and template.\n    run_match_template(orientation_batch_size: int = 1, do_result_export: bool = True)\n        Runs the base match template program in PyTorch.\n    results_to_dataframe(\n        half_template_width_pos_shift: bool = True,\n        exclude_columns: Optional[list] = None,\n        locate_peaks_kwargs: Optional[dict] = None,\n    ) -&gt; pd.DataFrame\n        Converts the basic extracted peak info DataFrame (from the result object) to a\n        DataFrame with additional information about reference files, microscope\n        parameters, etc.\n    save_config(path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None\n        Save this Pydantic model config to disk.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized attributes\n    micrograph_path: str\n    template_volume_path: str\n    optics_group: OpticsGroup\n    defocus_search_config: DefocusSearchConfig\n    orientation_search_config: OrientationSearchConfig | MultipleOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    match_template_result: MatchTemplateResult\n    computational_config: ComputationalConfig\n\n    # Non-serialized large array-like attributes\n    micrograph: ExcludedTensor\n    template_volume: ExcludedTensor\n\n    ###########################\n    ### Pydantic Validators ###\n    ###########################\n\n    @field_validator(\"micrograph_path\")  # type: ignore\n    def validate_micrograph_path(cls, v) -&gt; str:\n        \"\"\"Ensure the micrograph file exists.\"\"\"\n        if not os.path.exists(v):\n            raise ValueError(f\"File '{v}' for micrograph does not exist.\")\n\n        return str(v)\n\n    @field_validator(\"template_volume_path\")  # type: ignore\n    def validate_template_volume_path(cls, v) -&gt; str:\n        \"\"\"Ensure the template volume file exists.\"\"\"\n        if not os.path.exists(v):\n            raise ValueError(f\"File '{v}' for template volume does not exist.\")\n\n        return str(v)\n\n    def __init__(self, preload_mrc_files: bool = False, **data: Any):\n        super().__init__(**data)\n\n        if preload_mrc_files:\n            # Load the data from the MRC files\n            self.micrograph = load_mrc_image(self.micrograph_path)\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    ############################################\n    ### Functional (data processing) methods ###\n    ############################################\n\n    def make_backend_core_function_kwargs(self) -&gt; dict[str, Any]:\n        \"\"\"Generates the keyword arguments for backend call from held parameters.\"\"\"\n        # Ensure the micrograph and template are loaded and in the correct format\n        if self.micrograph is None:\n            self.micrograph = load_mrc_image(self.micrograph_path)\n        if self.template_volume is None:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n        # Ensure the micrograph and template are both Tensors before proceeding\n        if not isinstance(self.micrograph, torch.Tensor):\n            image = torch.from_numpy(self.micrograph)\n        else:\n            image = self.micrograph\n\n        if not isinstance(self.template_volume, torch.Tensor):\n            template = torch.from_numpy(self.template_volume)\n        else:\n            template = self.template_volume\n\n        # Fourier transform the image (RFFT, unshifted)\n        image_dft = torch.fft.rfftn(image)  # pylint: disable=E1102\n        image_dft[0, 0] = 0 + 0j  # zero out the constant term\n\n        # Get the bandpass filter individually\n        bp_config = self.preprocessing_filters.bandpass_filter\n        bandpass_filter = bp_config.calculate_bandpass_filter(image_dft.shape)\n\n        # Calculate the cumulative filters for both the image and the template.\n        cumulative_filter_image = self.preprocessing_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=image_dft.shape,\n        )\n        # NOTE: Here, manually accounting for the RFFT in output shape since we have not\n        # RFFT'd the template volume yet. Also, this is 2-dimensional, not 3-dimensional\n        cumulative_filter_template = self.preprocessing_filters.get_combined_filter(\n            ref_img_rfft=image_dft,\n            output_shape=(template.shape[-2], template.shape[-1] // 2 + 1),\n        )\n\n        # Apply the pre-processing and normalization\n        image_preprocessed_dft = preprocess_image(\n            image_rfft=image_dft,\n            cumulative_fourier_filters=cumulative_filter_image,\n            bandpass_filter=bandpass_filter,\n        )\n\n        # Calculate the CTF filters at each defocus value\n        defocus_values = self.defocus_search_config.defocus_values\n\n        # set pixel search to 0.0 for match template\n        pixel_size_offsets = torch.tensor([0.0], dtype=torch.float32)\n\n        ctf_filters = calculate_ctf_filter_stack(\n            template_shape=(template.shape[0], template.shape[0]),\n            optics_group=self.optics_group,\n            defocus_offsets=defocus_values,\n            pixel_size_offsets=pixel_size_offsets,\n        )\n\n        # Grab the Euler angles from the orientation search configuration\n        # (phi, theta, psi) for ZYZ convention\n        euler_angles = self.orientation_search_config.euler_angles\n        euler_angles = euler_angles.to(torch.float32)\n\n        template_dft = volume_to_rfft_fourier_slice(template)\n\n        return {\n            \"image_dft\": image_preprocessed_dft,\n            \"template_dft\": template_dft,\n            \"ctf_filters\": ctf_filters,\n            \"whitening_filter_template\": cumulative_filter_template,\n            \"euler_angles\": euler_angles,\n            \"defocus_values\": defocus_values,\n            \"pixel_values\": pixel_size_offsets,\n            \"device\": self.computational_config.gpu_devices,\n        }\n\n    def run_match_template(\n        self,\n        orientation_batch_size: int = 16,\n        do_result_export: bool = True,\n        do_valid_cropping: bool = True,\n    ) -&gt; None:\n        \"\"\"Runs the base match template in pytorch.\n\n        Parameters\n        ----------\n        orientation_batch_size : int\n            The number of projections to process in a single batch. Default is 1.\n        do_result_export : bool\n            If True, call the `MatchTemplateResult.export_results` method to save the\n            results to disk directly after running the match template. Default is True.\n        do_valid_cropping : bool\n            If True, apply the valid cropping mode to the results. Default is True.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        core_kwargs = self.make_backend_core_function_kwargs()\n        results = core_match_template(\n            **core_kwargs,\n            orientation_batch_size=orientation_batch_size,\n            num_cuda_streams=self.computational_config.num_cpus,\n        )\n\n        # Place results into the `MatchTemplateResult` object and save it.\n        self.match_template_result.mip = results[\"mip\"]\n        self.match_template_result.scaled_mip = results[\"scaled_mip\"]\n\n        self.match_template_result.correlation_average = results[\"correlation_mean\"]\n        self.match_template_result.correlation_variance = results[\n            \"correlation_variance\"\n        ]\n        self.match_template_result.orientation_psi = results[\"best_psi\"]\n        self.match_template_result.orientation_theta = results[\"best_theta\"]\n        self.match_template_result.orientation_phi = results[\"best_phi\"]\n        self.match_template_result.relative_defocus = results[\"best_defocus\"]\n\n        self.match_template_result.total_projections = results[\"total_projections\"]\n        self.match_template_result.total_orientations = results[\"total_orientations\"]\n        self.match_template_result.total_defocus = results[\"total_defocus\"]\n\n        # Apply the valid cropping mode to the results\n        if do_valid_cropping:\n            nx = self.template_volume.shape[-1]\n            self.match_template_result.apply_valid_cropping((nx, nx))\n\n        if do_result_export:\n            self.match_template_result.export_results()\n\n    def results_to_dataframe(\n        self,\n        half_template_width_pos_shift: bool = True,\n        exclude_columns: Optional[list] = None,\n        locate_peaks_kwargs: Optional[dict] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"Converts the match template results to a DataFrame with additional info.\n\n        Data included in this dataframe should be sufficient to do cross-correlation on\n        the extracted peaks, that is, all the microscope parameters, defocus parameters,\n        etc. are included in the dataframe. Run-specific filter information is *not*\n        included in this dataframe; use the YAML configuration file to replicate a\n        match_template run.\n\n        Parameters\n        ----------\n        half_template_width_pos_shift : bool, optional\n            If True, columns for the image peak position are shifted by half a template\n            width to correspond to the center of the particle. This should be done when\n            the position of a peak corresponds to the top-left corner of the template\n            rather than the center. Default is True. This should generally be left as\n            True unless you know what you are doing.\n        exclude_columns : list, optional\n            List of columns to exclude from the DataFrame. Default is None and no\n            columns are excluded.\n        locate_peaks_kwargs : dict, optional\n            Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method.\n            Default is None and no additional keyword arguments are passed.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame containing the match template results.\n        \"\"\"\n        # Short circuit if no kwargs and peaks have already been located\n        if locate_peaks_kwargs is None:\n            if self.match_template_result.match_template_peaks is None:\n                self.match_template_result.locate_peaks()\n        else:\n            self.match_template_result.locate_peaks(**locate_peaks_kwargs)\n\n        # DataFrame comes with the following columns :\n        # ['mip', 'scaled_mip', 'correlation_mean', 'correlation_variance',\n        # 'total_correlations'. 'pos_y', 'pos_x', 'psi', 'theta', 'phi',\n        # 'relative_defocus', ]\n        df = self.match_template_result.peaks_to_dataframe()\n\n        # DataFrame currently contains pixel coordinates for results. Coordinates in\n        # image correspond with upper left corner of the template. Need to translate\n        # coordinates by half template width to get to particle center in image.\n        # NOTE: We are assuming the template is cubic\n        nx = mrcfile.open(self.template_volume_path).header.nx\n        if half_template_width_pos_shift:\n            df[\"pos_y_img\"] = df[\"pos_y\"] + nx // 2\n            df[\"pos_x_img\"] = df[\"pos_x\"] + nx // 2\n        else:\n            df[\"pos_y_img\"] = df[\"pos_y\"]\n            df[\"pos_x_img\"] = df[\"pos_x\"]\n\n        # Also, the positions are in terms of pixels. Also add columns for particle\n        # positions in terms of Angstroms.\n        pixel_size = self.optics_group.pixel_size\n        df[\"pos_y_img_angstrom\"] = df[\"pos_y_img\"] * pixel_size\n        df[\"pos_x_img_angstrom\"] = df[\"pos_x_img\"] * pixel_size\n\n        # Add microscope (CTF) parameters\n        df[\"defocus_u\"] = self.optics_group.defocus_u\n        df[\"defocus_v\"] = self.optics_group.defocus_v\n        df[\"astigmatism_angle\"] = self.optics_group.astigmatism_angle\n        df[\"pixel_size\"] = pixel_size\n        df[\"refined_pixel_size\"] = pixel_size\n        df[\"voltage\"] = self.optics_group.voltage\n        df[\"spherical_aberration\"] = self.optics_group.spherical_aberration\n        df[\"amplitude_contrast_ratio\"] = self.optics_group.amplitude_contrast_ratio\n        df[\"phase_shift\"] = self.optics_group.phase_shift\n        df[\"ctf_B_factor\"] = self.optics_group.ctf_B_factor\n\n        # Add paths to the micrograph and reference template\n        df[\"micrograph_path\"] = self.micrograph_path\n        df[\"template_path\"] = self.template_volume_path\n\n        # Add paths to the output statistic files\n        df[\"mip_path\"] = self.match_template_result.mip_path\n        df[\"scaled_mip_path\"] = self.match_template_result.scaled_mip_path\n        df[\"psi_path\"] = self.match_template_result.orientation_psi_path\n        df[\"theta_path\"] = self.match_template_result.orientation_theta_path\n        df[\"phi_path\"] = self.match_template_result.orientation_phi_path\n        df[\"defocus_path\"] = self.match_template_result.relative_defocus_path\n        df[\"correlation_average_path\"] = (\n            self.match_template_result.correlation_average_path\n        )\n        df[\"correlation_variance_path\"] = (\n            self.match_template_result.correlation_variance_path\n        )\n\n        # Add particle index\n        df[\"particle_index\"] = df.index\n\n        # Reorder columns\n        df = df.reindex(columns=MATCH_TEMPLATE_DF_COLUMN_ORDER)\n\n        # Drop columns if requested\n        if exclude_columns is not None:\n            df = df.drop(columns=exclude_columns)\n\n        return df\n\n    def save_config(self, path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None:\n        \"\"\"Save this Pydandic model to disk. Wrapper around the serialization methods.\n\n        Parameters\n        ----------\n        path : str\n            Path to save the configuration file.\n        mode : Literal[\"yaml\", \"json\"], optional\n            Serialization format to use. Default is 'yaml'.\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        ValueError\n            If an invalid serialization mode is provided.\n        \"\"\"\n        if mode == \"yaml\":\n            self.to_yaml(path)\n        elif mode == \"json\":\n            self.to_json(path)\n        else:\n            raise ValueError(f\"Invalid serialization mode '{mode}'.\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs()</code>","text":"<p>Generates the keyword arguments for backend call from held parameters.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(self) -&gt; dict[str, Any]:\n    \"\"\"Generates the keyword arguments for backend call from held parameters.\"\"\"\n    # Ensure the micrograph and template are loaded and in the correct format\n    if self.micrograph is None:\n        self.micrograph = load_mrc_image(self.micrograph_path)\n    if self.template_volume is None:\n        self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    # Ensure the micrograph and template are both Tensors before proceeding\n    if not isinstance(self.micrograph, torch.Tensor):\n        image = torch.from_numpy(self.micrograph)\n    else:\n        image = self.micrograph\n\n    if not isinstance(self.template_volume, torch.Tensor):\n        template = torch.from_numpy(self.template_volume)\n    else:\n        template = self.template_volume\n\n    # Fourier transform the image (RFFT, unshifted)\n    image_dft = torch.fft.rfftn(image)  # pylint: disable=E1102\n    image_dft[0, 0] = 0 + 0j  # zero out the constant term\n\n    # Get the bandpass filter individually\n    bp_config = self.preprocessing_filters.bandpass_filter\n    bandpass_filter = bp_config.calculate_bandpass_filter(image_dft.shape)\n\n    # Calculate the cumulative filters for both the image and the template.\n    cumulative_filter_image = self.preprocessing_filters.get_combined_filter(\n        ref_img_rfft=image_dft,\n        output_shape=image_dft.shape,\n    )\n    # NOTE: Here, manually accounting for the RFFT in output shape since we have not\n    # RFFT'd the template volume yet. Also, this is 2-dimensional, not 3-dimensional\n    cumulative_filter_template = self.preprocessing_filters.get_combined_filter(\n        ref_img_rfft=image_dft,\n        output_shape=(template.shape[-2], template.shape[-1] // 2 + 1),\n    )\n\n    # Apply the pre-processing and normalization\n    image_preprocessed_dft = preprocess_image(\n        image_rfft=image_dft,\n        cumulative_fourier_filters=cumulative_filter_image,\n        bandpass_filter=bandpass_filter,\n    )\n\n    # Calculate the CTF filters at each defocus value\n    defocus_values = self.defocus_search_config.defocus_values\n\n    # set pixel search to 0.0 for match template\n    pixel_size_offsets = torch.tensor([0.0], dtype=torch.float32)\n\n    ctf_filters = calculate_ctf_filter_stack(\n        template_shape=(template.shape[0], template.shape[0]),\n        optics_group=self.optics_group,\n        defocus_offsets=defocus_values,\n        pixel_size_offsets=pixel_size_offsets,\n    )\n\n    # Grab the Euler angles from the orientation search configuration\n    # (phi, theta, psi) for ZYZ convention\n    euler_angles = self.orientation_search_config.euler_angles\n    euler_angles = euler_angles.to(torch.float32)\n\n    template_dft = volume_to_rfft_fourier_slice(template)\n\n    return {\n        \"image_dft\": image_preprocessed_dft,\n        \"template_dft\": template_dft,\n        \"ctf_filters\": ctf_filters,\n        \"whitening_filter_template\": cumulative_filter_template,\n        \"euler_angles\": euler_angles,\n        \"defocus_values\": defocus_values,\n        \"pixel_values\": pixel_size_offsets,\n        \"device\": self.computational_config.gpu_devices,\n    }\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.results_to_dataframe","title":"<code>results_to_dataframe(half_template_width_pos_shift=True, exclude_columns=None, locate_peaks_kwargs=None)</code>","text":"<p>Converts the match template results to a DataFrame with additional info.</p> <p>Data included in this dataframe should be sufficient to do cross-correlation on the extracted peaks, that is, all the microscope parameters, defocus parameters, etc. are included in the dataframe. Run-specific filter information is not included in this dataframe; use the YAML configuration file to replicate a match_template run.</p> <p>Parameters:</p> Name Type Description Default <code>half_template_width_pos_shift</code> <code>bool</code> <p>If True, columns for the image peak position are shifted by half a template width to correspond to the center of the particle. This should be done when the position of a peak corresponds to the top-left corner of the template rather than the center. Default is True. This should generally be left as True unless you know what you are doing.</p> <code>True</code> <code>exclude_columns</code> <code>list</code> <p>List of columns to exclude from the DataFrame. Default is None and no columns are excluded.</p> <code>None</code> <code>locate_peaks_kwargs</code> <code>dict</code> <p>Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method. Default is None and no additional keyword arguments are passed.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the match template results.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def results_to_dataframe(\n    self,\n    half_template_width_pos_shift: bool = True,\n    exclude_columns: Optional[list] = None,\n    locate_peaks_kwargs: Optional[dict] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"Converts the match template results to a DataFrame with additional info.\n\n    Data included in this dataframe should be sufficient to do cross-correlation on\n    the extracted peaks, that is, all the microscope parameters, defocus parameters,\n    etc. are included in the dataframe. Run-specific filter information is *not*\n    included in this dataframe; use the YAML configuration file to replicate a\n    match_template run.\n\n    Parameters\n    ----------\n    half_template_width_pos_shift : bool, optional\n        If True, columns for the image peak position are shifted by half a template\n        width to correspond to the center of the particle. This should be done when\n        the position of a peak corresponds to the top-left corner of the template\n        rather than the center. Default is True. This should generally be left as\n        True unless you know what you are doing.\n    exclude_columns : list, optional\n        List of columns to exclude from the DataFrame. Default is None and no\n        columns are excluded.\n    locate_peaks_kwargs : dict, optional\n        Keyword arguments to pass to the 'MatchTemplateResult.locate_peaks' method.\n        Default is None and no additional keyword arguments are passed.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing the match template results.\n    \"\"\"\n    # Short circuit if no kwargs and peaks have already been located\n    if locate_peaks_kwargs is None:\n        if self.match_template_result.match_template_peaks is None:\n            self.match_template_result.locate_peaks()\n    else:\n        self.match_template_result.locate_peaks(**locate_peaks_kwargs)\n\n    # DataFrame comes with the following columns :\n    # ['mip', 'scaled_mip', 'correlation_mean', 'correlation_variance',\n    # 'total_correlations'. 'pos_y', 'pos_x', 'psi', 'theta', 'phi',\n    # 'relative_defocus', ]\n    df = self.match_template_result.peaks_to_dataframe()\n\n    # DataFrame currently contains pixel coordinates for results. Coordinates in\n    # image correspond with upper left corner of the template. Need to translate\n    # coordinates by half template width to get to particle center in image.\n    # NOTE: We are assuming the template is cubic\n    nx = mrcfile.open(self.template_volume_path).header.nx\n    if half_template_width_pos_shift:\n        df[\"pos_y_img\"] = df[\"pos_y\"] + nx // 2\n        df[\"pos_x_img\"] = df[\"pos_x\"] + nx // 2\n    else:\n        df[\"pos_y_img\"] = df[\"pos_y\"]\n        df[\"pos_x_img\"] = df[\"pos_x\"]\n\n    # Also, the positions are in terms of pixels. Also add columns for particle\n    # positions in terms of Angstroms.\n    pixel_size = self.optics_group.pixel_size\n    df[\"pos_y_img_angstrom\"] = df[\"pos_y_img\"] * pixel_size\n    df[\"pos_x_img_angstrom\"] = df[\"pos_x_img\"] * pixel_size\n\n    # Add microscope (CTF) parameters\n    df[\"defocus_u\"] = self.optics_group.defocus_u\n    df[\"defocus_v\"] = self.optics_group.defocus_v\n    df[\"astigmatism_angle\"] = self.optics_group.astigmatism_angle\n    df[\"pixel_size\"] = pixel_size\n    df[\"refined_pixel_size\"] = pixel_size\n    df[\"voltage\"] = self.optics_group.voltage\n    df[\"spherical_aberration\"] = self.optics_group.spherical_aberration\n    df[\"amplitude_contrast_ratio\"] = self.optics_group.amplitude_contrast_ratio\n    df[\"phase_shift\"] = self.optics_group.phase_shift\n    df[\"ctf_B_factor\"] = self.optics_group.ctf_B_factor\n\n    # Add paths to the micrograph and reference template\n    df[\"micrograph_path\"] = self.micrograph_path\n    df[\"template_path\"] = self.template_volume_path\n\n    # Add paths to the output statistic files\n    df[\"mip_path\"] = self.match_template_result.mip_path\n    df[\"scaled_mip_path\"] = self.match_template_result.scaled_mip_path\n    df[\"psi_path\"] = self.match_template_result.orientation_psi_path\n    df[\"theta_path\"] = self.match_template_result.orientation_theta_path\n    df[\"phi_path\"] = self.match_template_result.orientation_phi_path\n    df[\"defocus_path\"] = self.match_template_result.relative_defocus_path\n    df[\"correlation_average_path\"] = (\n        self.match_template_result.correlation_average_path\n    )\n    df[\"correlation_variance_path\"] = (\n        self.match_template_result.correlation_variance_path\n    )\n\n    # Add particle index\n    df[\"particle_index\"] = df.index\n\n    # Reorder columns\n    df = df.reindex(columns=MATCH_TEMPLATE_DF_COLUMN_ORDER)\n\n    # Drop columns if requested\n    if exclude_columns is not None:\n        df = df.drop(columns=exclude_columns)\n\n    return df\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.run_match_template","title":"<code>run_match_template(orientation_batch_size=16, do_result_export=True, do_valid_cropping=True)</code>","text":"<p>Runs the base match template in pytorch.</p> <p>Parameters:</p> Name Type Description Default <code>orientation_batch_size</code> <code>int</code> <p>The number of projections to process in a single batch. Default is 1.</p> <code>16</code> <code>do_result_export</code> <code>bool</code> <p>If True, call the <code>MatchTemplateResult.export_results</code> method to save the results to disk directly after running the match template. Default is True.</p> <code>True</code> <code>do_valid_cropping</code> <code>bool</code> <p>If True, apply the valid cropping mode to the results. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def run_match_template(\n    self,\n    orientation_batch_size: int = 16,\n    do_result_export: bool = True,\n    do_valid_cropping: bool = True,\n) -&gt; None:\n    \"\"\"Runs the base match template in pytorch.\n\n    Parameters\n    ----------\n    orientation_batch_size : int\n        The number of projections to process in a single batch. Default is 1.\n    do_result_export : bool\n        If True, call the `MatchTemplateResult.export_results` method to save the\n        results to disk directly after running the match template. Default is True.\n    do_valid_cropping : bool\n        If True, apply the valid cropping mode to the results. Default is True.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    core_kwargs = self.make_backend_core_function_kwargs()\n    results = core_match_template(\n        **core_kwargs,\n        orientation_batch_size=orientation_batch_size,\n        num_cuda_streams=self.computational_config.num_cpus,\n    )\n\n    # Place results into the `MatchTemplateResult` object and save it.\n    self.match_template_result.mip = results[\"mip\"]\n    self.match_template_result.scaled_mip = results[\"scaled_mip\"]\n\n    self.match_template_result.correlation_average = results[\"correlation_mean\"]\n    self.match_template_result.correlation_variance = results[\n        \"correlation_variance\"\n    ]\n    self.match_template_result.orientation_psi = results[\"best_psi\"]\n    self.match_template_result.orientation_theta = results[\"best_theta\"]\n    self.match_template_result.orientation_phi = results[\"best_phi\"]\n    self.match_template_result.relative_defocus = results[\"best_defocus\"]\n\n    self.match_template_result.total_projections = results[\"total_projections\"]\n    self.match_template_result.total_orientations = results[\"total_orientations\"]\n    self.match_template_result.total_defocus = results[\"total_defocus\"]\n\n    # Apply the valid cropping mode to the results\n    if do_valid_cropping:\n        nx = self.template_volume.shape[-1]\n        self.match_template_result.apply_valid_cropping((nx, nx))\n\n    if do_result_export:\n        self.match_template_result.export_results()\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.save_config","title":"<code>save_config(path, mode='yaml')</code>","text":"<p>Save this Pydandic model to disk. Wrapper around the serialization methods.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to save the configuration file.</p> required <code>mode</code> <code>Literal['yaml', 'json']</code> <p>Serialization format to use. Default is 'yaml'.</p> <code>'yaml'</code> <p>Returns:</p> Type Description <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an invalid serialization mode is provided.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>def save_config(self, path: str, mode: Literal[\"yaml\", \"json\"] = \"yaml\") -&gt; None:\n    \"\"\"Save this Pydandic model to disk. Wrapper around the serialization methods.\n\n    Parameters\n    ----------\n    path : str\n        Path to save the configuration file.\n    mode : Literal[\"yaml\", \"json\"], optional\n        Serialization format to use. Default is 'yaml'.\n\n    Returns\n    -------\n    None\n\n    Raises\n    ------\n    ValueError\n        If an invalid serialization mode is provided.\n    \"\"\"\n    if mode == \"yaml\":\n        self.to_yaml(path)\n    elif mode == \"json\":\n        self.to_json(path)\n    else:\n        raise ValueError(f\"Invalid serialization mode '{mode}'.\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.validate_micrograph_path","title":"<code>validate_micrograph_path(v)</code>","text":"<p>Ensure the micrograph file exists.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>@field_validator(\"micrograph_path\")  # type: ignore\ndef validate_micrograph_path(cls, v) -&gt; str:\n    \"\"\"Ensure the micrograph file exists.\"\"\"\n    if not os.path.exists(v):\n        raise ValueError(f\"File '{v}' for micrograph does not exist.\")\n\n    return str(v)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/match_template_manager/#leopard_em.pydantic_models.managers.match_template_manager.MatchTemplateManager.validate_template_volume_path","title":"<code>validate_template_volume_path(v)</code>","text":"<p>Ensure the template volume file exists.</p> Source code in <code>src/leopard_em/pydantic_models/managers/match_template_manager.py</code> <pre><code>@field_validator(\"template_volume_path\")  # type: ignore\ndef validate_template_volume_path(cls, v) -&gt; str:\n    \"\"\"Ensure the template volume file exists.\"\"\"\n    if not os.path.exists(v):\n        raise ValueError(f\"File '{v}' for template volume does not exist.\")\n\n    return str(v)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/","title":"optimize_template_manager","text":"<p>Pydantic model for running the optimize template program.</p>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager","title":"<code>OptimizeTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the optimize template program.</p> <p>Attributes:</p> Name Type Description <code>particle_stack</code> <code>ParticleStack</code> <p>Particle stack object containing particle data.</p> <code>pixel_size_coarse_search</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size coarse search.</p> <code>pixel_size_fine_search</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size fine search.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>simulator</code> <code>Simulator</code> <p>The simulator object.</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the optimize template manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend optimize_template core function.</p> <code>run_optimize_template</code> <p>Run the optimize template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>class OptimizeTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the optimize template program.\n\n    Attributes\n    ----------\n    particle_stack : ParticleStack\n        Particle stack object containing particle data.\n    pixel_size_coarse_search : PixelSizeSearchConfig\n        Configuration for pixel size coarse search.\n    pixel_size_fine_search : PixelSizeSearchConfig\n        Configuration for pixel size fine search.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    simulator : Simulator\n        The simulator object.\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the optimize template manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend optimize_template core function.\n    run_optimize_template(self, output_text_path: str) -&gt; None\n        Run the optimize template program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    particle_stack: ParticleStack\n    pixel_size_coarse_search: PixelSizeSearchConfig\n    pixel_size_fine_search: PixelSizeSearchConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n    simulator: Simulator\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend refine_template core function.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool\n            Whether to use refined angles or not. Defaults to True.\n        \"\"\"\n        # simulate template volume\n        template = self.simulator.run(device=self.computational_config.gpu_ids)\n\n        # The set of \"best\" euler angles from match template search\n        # Check if refined angles exist, otherwise use the original angles\n        euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over (none for optimization)\n        euler_angle_offsets = torch.zeros((1, 3))\n\n        # The relative defocus values to search over (none for optimization)\n        defocus_offsets = torch.tensor([0.0])\n\n        # The relative pixel size values to search over (none for optimization)\n        pixel_size_offsets = torch.tensor([0.0])\n\n        # Use the common utility function to set up the backend kwargs\n        # pylint: disable=duplicate-code\n        return setup_particle_backend_kwargs(\n            particle_stack=self.particle_stack,\n            template=template,\n            preprocessing_filters=self.preprocessing_filters,\n            euler_angles=euler_angles,\n            euler_angle_offsets=euler_angle_offsets,\n            defocus_offsets=defocus_offsets,\n            pixel_size_offsets=pixel_size_offsets,\n            device_list=self.computational_config.gpu_devices,\n        )\n\n    def run_optimize_template(self, output_text_path: str) -&gt; None:\n        \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_text_path : str\n            Path to save the optimized template pixel size.\n        \"\"\"\n        if self.pixel_size_coarse_search.enabled:\n            # Create a file for logging all iterations\n            all_results_path = self._get_all_results_path(output_text_path)\n            # Create the file and write header\n            with open(all_results_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(\"Pixel Size (\u00c5),SNR\\n\")\n\n            optimal_template_px = self.optimize_pixel_size(all_results_path)\n            print(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n            # print this to the text file\n            with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n\n    def optimize_pixel_size(self, all_results_path: str) -&gt; float:\n        \"\"\"Optimize the pixel size of the template volume.\n\n        Parameters\n        ----------\n        all_results_path : str\n            Path to the file for logging all iterations\n\n        Returns\n        -------\n        float\n            The optimal pixel size.\n        \"\"\"\n        initial_template_px = self.simulator.pixel_spacing\n        print(f\"Initial template px: {initial_template_px:.3f} \u00c5\")\n\n        best_snr = float(\"-inf\")\n        best_px = float(initial_template_px)\n\n        print(\"Starting coarse search...\")\n\n        pixel_size_offsets_coarse = self.pixel_size_coarse_search.pixel_size_values\n        coarse_px_values = pixel_size_offsets_coarse + initial_template_px\n\n        consecutive_decreases = 0\n        consecutive_threshold = 2\n        previous_snr = float(\"-inf\")\n        for px in coarse_px_values:\n            snr = self.evaluate_template_px(px=px.item())\n            print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n            # Log to file\n            with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n            if snr &gt; best_snr:\n                best_snr = snr\n                best_px = px.item()\n            if snr &gt; previous_snr:\n                consecutive_decreases = 0\n            else:\n                consecutive_decreases += 1\n                if consecutive_decreases &gt;= consecutive_threshold:\n                    print(\n                        f\"SNR decreased for {consecutive_threshold} iterations. \"\n                        f\"Stopping coarse px search.\"\n                    )\n                    break\n            previous_snr = snr\n\n        if self.pixel_size_fine_search.enabled:\n            pixel_size_offsets_fine = self.pixel_size_fine_search.pixel_size_values\n            fine_px_values = pixel_size_offsets_fine + best_px\n\n            consecutive_decreases = 0\n            previous_snr = float(\"-inf\")\n            for px in fine_px_values:\n                snr = self.evaluate_template_px(px=px.item())\n                print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n                # Log to file\n                with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                    f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n                if snr &gt; best_snr:\n                    best_snr = snr\n                    best_px = px.item()\n                if snr &gt; previous_snr:\n                    consecutive_decreases = 0\n                else:\n                    consecutive_decreases += 1\n                    if consecutive_decreases &gt;= consecutive_threshold:\n                        print(\n                            f\"SNR decreased for {consecutive_threshold} iterations. \"\n                            \"Stopping fine px search.\"\n                        )\n                        break\n                previous_snr = snr\n\n        return best_px\n\n    def evaluate_template_px(self, px: float) -&gt; float:\n        \"\"\"Evaluate the template pixel size.\n\n        Parameters\n        ----------\n        px : float\n            The pixel size to evaluate.\n\n        Returns\n        -------\n        float\n            The mean SNR of the template.\n        \"\"\"\n        self.simulator.pixel_spacing = px\n        backend_kwargs = self.make_backend_core_function_kwargs()\n        result = self.get_correlation_result(backend_kwargs, 1)\n        mean_snr = self.results_to_snr(result)\n        return mean_snr\n\n    def get_correlation_result(\n        self, backend_kwargs: dict, orientation_batch_size: int = 64\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get correlation result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        orientation_batch_size : int\n            Number of orientations to process at once. Defaults to 64.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=orientation_batch_size, **backend_kwargs\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n\n        return result\n\n    def results_to_snr(self, result: dict[str, np.ndarray]) -&gt; float:\n        \"\"\"Convert optimize template result to mean SNR.\n\n        Parameters\n        ----------\n        result : dict[str, np.ndarray]\n            The result of the optimize template program.\n\n        Returns\n        -------\n        float\n            The mean SNR of the template.\n        \"\"\"\n        # Filter out any infinite or NaN values\n        # NOTE: There should not be NaNs or infs, will follow up later\n        refined_scaled_mip = result[\"refined_z_score\"]\n        refined_scaled_mip = refined_scaled_mip[np.isfinite(refined_scaled_mip)]\n\n        # If more than n values, keep only the top n highest SNRs\n        best_n = 6\n        if len(refined_scaled_mip) &gt; best_n:\n            refined_scaled_mip = np.sort(refined_scaled_mip)[-best_n:]\n\n        # Printing out the results to console\n        print(\n            f\"max snr: {refined_scaled_mip.max()}, min snr: {refined_scaled_mip.min()}\"\n        )\n\n        mean_snr = float(refined_scaled_mip.mean())\n\n        return mean_snr\n\n    def _get_all_results_path(self, output_text_path: str) -&gt; str:\n        \"\"\"Generate the results file path from the output text path.\n\n        Parameters\n        ----------\n        output_text_path : str\n            Path to the output text file\n\n        Returns\n        -------\n        str\n            Path to the file with _all.txt extension\n        \"\"\"\n        base, _ = os.path.splitext(output_text_path)\n        return f\"{base}_all.csv\"\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.evaluate_template_px","title":"<code>evaluate_template_px(px)</code>","text":"<p>Evaluate the template pixel size.</p> <p>Parameters:</p> Name Type Description Default <code>px</code> <code>float</code> <p>The pixel size to evaluate.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean SNR of the template.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def evaluate_template_px(self, px: float) -&gt; float:\n    \"\"\"Evaluate the template pixel size.\n\n    Parameters\n    ----------\n    px : float\n        The pixel size to evaluate.\n\n    Returns\n    -------\n    float\n        The mean SNR of the template.\n    \"\"\"\n    self.simulator.pixel_spacing = px\n    backend_kwargs = self.make_backend_core_function_kwargs()\n    result = self.get_correlation_result(backend_kwargs, 1)\n    mean_snr = self.results_to_snr(result)\n    return mean_snr\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.get_correlation_result","title":"<code>get_correlation_result(backend_kwargs, orientation_batch_size=64)</code>","text":"<p>Get correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>orientation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 64.</p> <code>64</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def get_correlation_result(\n    self, backend_kwargs: dict, orientation_batch_size: int = 64\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get correlation result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    orientation_batch_size : int\n        Number of orientations to process at once. Defaults to 64.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=orientation_batch_size, **backend_kwargs\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend refine_template core function.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>Whether to use refined angles or not. Defaults to True.</p> <code>True</code> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend refine_template core function.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool\n        Whether to use refined angles or not. Defaults to True.\n    \"\"\"\n    # simulate template volume\n    template = self.simulator.run(device=self.computational_config.gpu_ids)\n\n    # The set of \"best\" euler angles from match template search\n    # Check if refined angles exist, otherwise use the original angles\n    euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over (none for optimization)\n    euler_angle_offsets = torch.zeros((1, 3))\n\n    # The relative defocus values to search over (none for optimization)\n    defocus_offsets = torch.tensor([0.0])\n\n    # The relative pixel size values to search over (none for optimization)\n    pixel_size_offsets = torch.tensor([0.0])\n\n    # Use the common utility function to set up the backend kwargs\n    # pylint: disable=duplicate-code\n    return setup_particle_backend_kwargs(\n        particle_stack=self.particle_stack,\n        template=template,\n        preprocessing_filters=self.preprocessing_filters,\n        euler_angles=euler_angles,\n        euler_angle_offsets=euler_angle_offsets,\n        defocus_offsets=defocus_offsets,\n        pixel_size_offsets=pixel_size_offsets,\n        device_list=self.computational_config.gpu_devices,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.optimize_pixel_size","title":"<code>optimize_pixel_size(all_results_path)</code>","text":"<p>Optimize the pixel size of the template volume.</p> <p>Parameters:</p> Name Type Description Default <code>all_results_path</code> <code>str</code> <p>Path to the file for logging all iterations</p> required <p>Returns:</p> Type Description <code>float</code> <p>The optimal pixel size.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def optimize_pixel_size(self, all_results_path: str) -&gt; float:\n    \"\"\"Optimize the pixel size of the template volume.\n\n    Parameters\n    ----------\n    all_results_path : str\n        Path to the file for logging all iterations\n\n    Returns\n    -------\n    float\n        The optimal pixel size.\n    \"\"\"\n    initial_template_px = self.simulator.pixel_spacing\n    print(f\"Initial template px: {initial_template_px:.3f} \u00c5\")\n\n    best_snr = float(\"-inf\")\n    best_px = float(initial_template_px)\n\n    print(\"Starting coarse search...\")\n\n    pixel_size_offsets_coarse = self.pixel_size_coarse_search.pixel_size_values\n    coarse_px_values = pixel_size_offsets_coarse + initial_template_px\n\n    consecutive_decreases = 0\n    consecutive_threshold = 2\n    previous_snr = float(\"-inf\")\n    for px in coarse_px_values:\n        snr = self.evaluate_template_px(px=px.item())\n        print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n        # Log to file\n        with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n            f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n        if snr &gt; best_snr:\n            best_snr = snr\n            best_px = px.item()\n        if snr &gt; previous_snr:\n            consecutive_decreases = 0\n        else:\n            consecutive_decreases += 1\n            if consecutive_decreases &gt;= consecutive_threshold:\n                print(\n                    f\"SNR decreased for {consecutive_threshold} iterations. \"\n                    f\"Stopping coarse px search.\"\n                )\n                break\n        previous_snr = snr\n\n    if self.pixel_size_fine_search.enabled:\n        pixel_size_offsets_fine = self.pixel_size_fine_search.pixel_size_values\n        fine_px_values = pixel_size_offsets_fine + best_px\n\n        consecutive_decreases = 0\n        previous_snr = float(\"-inf\")\n        for px in fine_px_values:\n            snr = self.evaluate_template_px(px=px.item())\n            print(f\"Pixel size: {px:.3f}, SNR: {snr:.3f}\")\n\n            # Log to file\n            with open(all_results_path, \"a\", encoding=\"utf-8\") as f:\n                f.write(f\"{px:.3f},{snr:.3f}\\n\")\n\n            if snr &gt; best_snr:\n                best_snr = snr\n                best_px = px.item()\n            if snr &gt; previous_snr:\n                consecutive_decreases = 0\n            else:\n                consecutive_decreases += 1\n                if consecutive_decreases &gt;= consecutive_threshold:\n                    print(\n                        f\"SNR decreased for {consecutive_threshold} iterations. \"\n                        \"Stopping fine px search.\"\n                    )\n                    break\n            previous_snr = snr\n\n    return best_px\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.results_to_snr","title":"<code>results_to_snr(result)</code>","text":"<p>Convert optimize template result to mean SNR.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the optimize template program.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The mean SNR of the template.</p> Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def results_to_snr(self, result: dict[str, np.ndarray]) -&gt; float:\n    \"\"\"Convert optimize template result to mean SNR.\n\n    Parameters\n    ----------\n    result : dict[str, np.ndarray]\n        The result of the optimize template program.\n\n    Returns\n    -------\n    float\n        The mean SNR of the template.\n    \"\"\"\n    # Filter out any infinite or NaN values\n    # NOTE: There should not be NaNs or infs, will follow up later\n    refined_scaled_mip = result[\"refined_z_score\"]\n    refined_scaled_mip = refined_scaled_mip[np.isfinite(refined_scaled_mip)]\n\n    # If more than n values, keep only the top n highest SNRs\n    best_n = 6\n    if len(refined_scaled_mip) &gt; best_n:\n        refined_scaled_mip = np.sort(refined_scaled_mip)[-best_n:]\n\n    # Printing out the results to console\n    print(\n        f\"max snr: {refined_scaled_mip.max()}, min snr: {refined_scaled_mip.min()}\"\n    )\n\n    mean_snr = float(refined_scaled_mip.mean())\n\n    return mean_snr\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/optimize_template_manager/#leopard_em.pydantic_models.managers.optimize_template_manager.OptimizeTemplateManager.run_optimize_template","title":"<code>run_optimize_template(output_text_path)</code>","text":"<p>Run the refine template program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_text_path</code> <code>str</code> <p>Path to save the optimized template pixel size.</p> required Source code in <code>src/leopard_em/pydantic_models/managers/optimize_template_manager.py</code> <pre><code>def run_optimize_template(self, output_text_path: str) -&gt; None:\n    \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_text_path : str\n        Path to save the optimized template pixel size.\n    \"\"\"\n    if self.pixel_size_coarse_search.enabled:\n        # Create a file for logging all iterations\n        all_results_path = self._get_all_results_path(output_text_path)\n        # Create the file and write header\n        with open(all_results_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(\"Pixel Size (\u00c5),SNR\\n\")\n\n        optimal_template_px = self.optimize_pixel_size(all_results_path)\n        print(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n        # print this to the text file\n        with open(output_text_path, \"w\", encoding=\"utf-8\") as f:\n            f.write(f\"Optimal template px: {optimal_template_px:.3f} \u00c5\")\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/","title":"refine_template_manager","text":"<p>Pydantic model for running the refine template program.</p>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/#leopard_em.pydantic_models.managers.refine_template_manager.RefineTemplateManager","title":"<code>RefineTemplateManager</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Model holding parameters necessary for running the refine template program.</p> <p>Attributes:</p> Name Type Description <code>template_volume_path</code> <code>str</code> <p>Path to the template volume MRC file.</p> <code>particle_stack</code> <code>ParticleStack</code> <p>Particle stack object containing particle data.</p> <code>defocus_refinement_config</code> <code>DefocusSearchConfig</code> <p>Configuration for defocus refinement.</p> <code>pixel_size_refinement_config</code> <code>PixelSizeSearchConfig</code> <p>Configuration for pixel size refinement.</p> <code>orientation_refinement_config</code> <code>RefineOrientationConfig</code> <p>Configuration for orientation refinement.</p> <code>preprocessing_filters</code> <code>PreprocessingFilters</code> <p>Filters to apply to the particle images.</p> <code>computational_config</code> <code>ComputationalConfig</code> <p>What computational resources to allocate for the program.</p> <code>template_volume</code> <code>ExcludedTensor</code> <p>The template volume tensor (excluded from serialization).</p> <p>Methods:</p> Name Description <code>TODO serialization/import methods</code> <code>__init__</code> <p>Initialize the refine template manager.</p> <code>make_backend_core_function_kwargs</code> <p>Create the kwargs for the backend refine_template core function.</p> <code>run_refine_template</code> <p>Run the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>class RefineTemplateManager(BaseModel2DTM):\n    \"\"\"Model holding parameters necessary for running the refine template program.\n\n    Attributes\n    ----------\n    template_volume_path : str\n        Path to the template volume MRC file.\n    particle_stack : ParticleStack\n        Particle stack object containing particle data.\n    defocus_refinement_config : DefocusSearchConfig\n        Configuration for defocus refinement.\n    pixel_size_refinement_config : PixelSizeSearchConfig\n        Configuration for pixel size refinement.\n    orientation_refinement_config : RefineOrientationConfig\n        Configuration for orientation refinement.\n    preprocessing_filters : PreprocessingFilters\n        Filters to apply to the particle images.\n    computational_config : ComputationalConfig\n        What computational resources to allocate for the program.\n    template_volume : ExcludedTensor\n        The template volume tensor (excluded from serialization).\n\n    Methods\n    -------\n    TODO serialization/import methods\n    __init__(self, skip_mrc_preloads: bool = False, **data: Any)\n        Initialize the refine template manager.\n    make_backend_core_function_kwargs(self) -&gt; dict[str, Any]\n        Create the kwargs for the backend refine_template core function.\n    run_refine_template(self, correlation_batch_size: int = 32) -&gt; None\n        Run the refine template program.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    template_volume_path: str  # In df per-particle, but ensure only one reference\n    particle_stack: ParticleStack\n    defocus_refinement_config: DefocusSearchConfig\n    pixel_size_refinement_config: PixelSizeSearchConfig\n    orientation_refinement_config: RefineOrientationConfig\n    preprocessing_filters: PreprocessingFilters\n    computational_config: ComputationalConfig\n\n    # Excluded tensors\n    template_volume: ExcludedTensor\n\n    def __init__(self, skip_mrc_preloads: bool = False, **data: Any):\n        super().__init__(**data)\n\n        # Load the data from the MRC files\n        if not skip_mrc_preloads:\n            self.template_volume = load_mrc_volume(self.template_volume_path)\n\n    def make_backend_core_function_kwargs(\n        self, prefer_refined_angles: bool = True\n    ) -&gt; dict[str, Any]:\n        \"\"\"Create the kwargs for the backend refine_template core function.\n\n        Parameters\n        ----------\n        prefer_refined_angles : bool\n            Whether to use the refined angles from the particle stack. Defaults to\n            False.\n        \"\"\"\n        # Ensure the template is loaded in as a Tensor object\n        template = load_template_tensor(\n            template_volume=self.template_volume,\n            template_volume_path=self.template_volume_path,\n        )\n\n        # The set of \"best\" euler angles from match template search\n        # Check if refined angles exist, otherwise use the original angles\n        euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n        # The relative Euler angle offsets to search over\n        euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n\n        # The relative defocus values to search over\n        defocus_offsets = self.defocus_refinement_config.defocus_values\n\n        # The relative pixel size values to search over\n        pixel_size_offsets = self.pixel_size_refinement_config.pixel_size_values\n\n        # Use the common utility function to set up the backend kwargs\n        # pylint: disable=duplicate-code\n        return setup_particle_backend_kwargs(\n            particle_stack=self.particle_stack,\n            template=template,\n            preprocessing_filters=self.preprocessing_filters,\n            euler_angles=euler_angles,\n            euler_angle_offsets=euler_angle_offsets,\n            defocus_offsets=defocus_offsets,\n            pixel_size_offsets=pixel_size_offsets,\n            device_list=self.computational_config.gpu_devices,\n        )\n\n    def run_refine_template(\n        self, output_dataframe_path: str, correlation_batch_size: int = 32\n    ) -&gt; None:\n        \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        correlation_batch_size : int\n            Number of cross-correlations to process in one batch, defaults to 32.\n        \"\"\"\n        backend_kwargs = self.make_backend_core_function_kwargs()\n\n        result = self.get_refine_result(backend_kwargs, correlation_batch_size)\n\n        self.refine_result_to_dataframe(\n            output_dataframe_path=output_dataframe_path, result=result\n        )\n\n    def get_refine_result(\n        self, backend_kwargs: dict, correlation_batch_size: int = 32\n    ) -&gt; dict[str, np.ndarray]:\n        \"\"\"Get refine template result.\n\n        Parameters\n        ----------\n        backend_kwargs : dict\n            Keyword arguments for the backend processing\n        correlation_batch_size : int\n            Number of orientations to process at once. Defaults to 32.\n\n        Returns\n        -------\n        dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        result: dict[str, np.ndarray] = {}\n        result = core_refine_template(\n            batch_size=correlation_batch_size,\n            num_cuda_streams=self.computational_config.num_cpus,\n            **backend_kwargs,\n        )\n        result = {k: v.cpu().numpy() for k, v in result.items()}\n\n        return result\n\n    def refine_result_to_dataframe(\n        self, output_dataframe_path: str, result: dict[str, np.ndarray]\n    ) -&gt; None:\n        \"\"\"Convert refine template result to dataframe.\n\n        Parameters\n        ----------\n        output_dataframe_path : str\n            Path to save the refined particle data.\n        result : dict[str, np.ndarray]\n            The result of the refine template program.\n        \"\"\"\n        # pylint: disable=duplicate-code\n        df_refined = self.particle_stack._df.copy()  # pylint: disable=protected-access\n\n        # x and y positions\n        pos_offset_y = result[\"refined_pos_y\"]\n        pos_offset_x = result[\"refined_pos_x\"]\n        pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n        pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n        df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n        df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n        df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n        df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n        df_refined[\"refined_pos_y_img_angstrom\"] = (\n            pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n        )\n        df_refined[\"refined_pos_x_img_angstrom\"] = (\n            pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n        )\n\n        # Euler angles\n        df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n        df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n        df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n        # Defocus\n        df_refined[\"refined_relative_defocus\"] = (\n            result[\"refined_defocus_offset\"]\n            + self.particle_stack.get_relative_defocus().cpu().numpy()\n        )\n\n        # Pixel size\n        df_refined[\"refined_pixel_size\"] = (\n            result[\"refined_pixel_size_offset\"]\n            + self.particle_stack.get_pixel_size().cpu().numpy()\n        )\n\n        # Cross-correlation statistics\n        # Check if correlation statistic files exist and use them if available\n        # This allows for shifts during refinement\n\n        # if (\n        #    \"correlation_average_path\" in df_refined.columns\n        #    and \"correlation_variance_path\" in df_refined.columns\n        # ):\n        # Check if files exist for at least the first entry\n        #    if (\n        #        df_refined[\"correlation_average_path\"].iloc[0]\n        #        and df_refined[\"correlation_variance_path\"].iloc[0]\n        #    ):\n        # Load the correlation statistics from the files\n        #        correlation_average = read_mrc_to_numpy(\n        #            df_refined[\"correlation_average_path\"].iloc[0]\n        #        )\n        #        correlation_variance = read_mrc_to_numpy(\n        #            df_refined[\"correlation_variance_path\"].iloc[0]\n        #        )\n        #        df_refined[\"correlation_mean\"] = correlation_average[\n        #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n        #           ]\n        #        df_refined[\"correlation_variance\"] = correlation_variance[\n        #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n        #        ]\n        refined_mip = result[\"refined_cross_correlation\"]\n        refined_scaled_mip = result[\"refined_z_score\"]\n        df_refined[\"refined_mip\"] = refined_mip\n        df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n        # Reorder the columns\n        df_refined = df_refined.reindex(columns=REFINED_DF_COLUMN_ORDER)\n\n        # Save the refined DataFrame to disk\n        df_refined.to_csv(output_dataframe_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/#leopard_em.pydantic_models.managers.refine_template_manager.RefineTemplateManager.get_refine_result","title":"<code>get_refine_result(backend_kwargs, correlation_batch_size=32)</code>","text":"<p>Get refine template result.</p> <p>Parameters:</p> Name Type Description Default <code>backend_kwargs</code> <code>dict</code> <p>Keyword arguments for the backend processing</p> required <code>correlation_batch_size</code> <code>int</code> <p>Number of orientations to process at once. Defaults to 32.</p> <code>32</code> <p>Returns:</p> Type Description <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def get_refine_result(\n    self, backend_kwargs: dict, correlation_batch_size: int = 32\n) -&gt; dict[str, np.ndarray]:\n    \"\"\"Get refine template result.\n\n    Parameters\n    ----------\n    backend_kwargs : dict\n        Keyword arguments for the backend processing\n    correlation_batch_size : int\n        Number of orientations to process at once. Defaults to 32.\n\n    Returns\n    -------\n    dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    result: dict[str, np.ndarray] = {}\n    result = core_refine_template(\n        batch_size=correlation_batch_size,\n        num_cuda_streams=self.computational_config.num_cpus,\n        **backend_kwargs,\n    )\n    result = {k: v.cpu().numpy() for k, v in result.items()}\n\n    return result\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/#leopard_em.pydantic_models.managers.refine_template_manager.RefineTemplateManager.make_backend_core_function_kwargs","title":"<code>make_backend_core_function_kwargs(prefer_refined_angles=True)</code>","text":"<p>Create the kwargs for the backend refine_template core function.</p> <p>Parameters:</p> Name Type Description Default <code>prefer_refined_angles</code> <code>bool</code> <p>Whether to use the refined angles from the particle stack. Defaults to False.</p> <code>True</code> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def make_backend_core_function_kwargs(\n    self, prefer_refined_angles: bool = True\n) -&gt; dict[str, Any]:\n    \"\"\"Create the kwargs for the backend refine_template core function.\n\n    Parameters\n    ----------\n    prefer_refined_angles : bool\n        Whether to use the refined angles from the particle stack. Defaults to\n        False.\n    \"\"\"\n    # Ensure the template is loaded in as a Tensor object\n    template = load_template_tensor(\n        template_volume=self.template_volume,\n        template_volume_path=self.template_volume_path,\n    )\n\n    # The set of \"best\" euler angles from match template search\n    # Check if refined angles exist, otherwise use the original angles\n    euler_angles = self.particle_stack.get_euler_angles(prefer_refined_angles)\n\n    # The relative Euler angle offsets to search over\n    euler_angle_offsets = self.orientation_refinement_config.euler_angles_offsets\n\n    # The relative defocus values to search over\n    defocus_offsets = self.defocus_refinement_config.defocus_values\n\n    # The relative pixel size values to search over\n    pixel_size_offsets = self.pixel_size_refinement_config.pixel_size_values\n\n    # Use the common utility function to set up the backend kwargs\n    # pylint: disable=duplicate-code\n    return setup_particle_backend_kwargs(\n        particle_stack=self.particle_stack,\n        template=template,\n        preprocessing_filters=self.preprocessing_filters,\n        euler_angles=euler_angles,\n        euler_angle_offsets=euler_angle_offsets,\n        defocus_offsets=defocus_offsets,\n        pixel_size_offsets=pixel_size_offsets,\n        device_list=self.computational_config.gpu_devices,\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/#leopard_em.pydantic_models.managers.refine_template_manager.RefineTemplateManager.refine_result_to_dataframe","title":"<code>refine_result_to_dataframe(output_dataframe_path, result)</code>","text":"<p>Convert refine template result to dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>result</code> <code>dict[str, ndarray]</code> <p>The result of the refine template program.</p> required Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def refine_result_to_dataframe(\n    self, output_dataframe_path: str, result: dict[str, np.ndarray]\n) -&gt; None:\n    \"\"\"Convert refine template result to dataframe.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    result : dict[str, np.ndarray]\n        The result of the refine template program.\n    \"\"\"\n    # pylint: disable=duplicate-code\n    df_refined = self.particle_stack._df.copy()  # pylint: disable=protected-access\n\n    # x and y positions\n    pos_offset_y = result[\"refined_pos_y\"]\n    pos_offset_x = result[\"refined_pos_x\"]\n    pos_offset_y_ang = pos_offset_y * df_refined[\"pixel_size\"]\n    pos_offset_x_ang = pos_offset_x * df_refined[\"pixel_size\"]\n\n    df_refined[\"refined_pos_y\"] = pos_offset_y + df_refined[\"pos_y\"]\n    df_refined[\"refined_pos_x\"] = pos_offset_x + df_refined[\"pos_x\"]\n    df_refined[\"refined_pos_y_img\"] = pos_offset_y + df_refined[\"pos_y_img\"]\n    df_refined[\"refined_pos_x_img\"] = pos_offset_x + df_refined[\"pos_x_img\"]\n    df_refined[\"refined_pos_y_img_angstrom\"] = (\n        pos_offset_y_ang + df_refined[\"pos_y_img_angstrom\"]\n    )\n    df_refined[\"refined_pos_x_img_angstrom\"] = (\n        pos_offset_x_ang + df_refined[\"pos_x_img_angstrom\"]\n    )\n\n    # Euler angles\n    df_refined[\"refined_psi\"] = result[\"refined_euler_angles\"][:, 2]\n    df_refined[\"refined_theta\"] = result[\"refined_euler_angles\"][:, 1]\n    df_refined[\"refined_phi\"] = result[\"refined_euler_angles\"][:, 0]\n\n    # Defocus\n    df_refined[\"refined_relative_defocus\"] = (\n        result[\"refined_defocus_offset\"]\n        + self.particle_stack.get_relative_defocus().cpu().numpy()\n    )\n\n    # Pixel size\n    df_refined[\"refined_pixel_size\"] = (\n        result[\"refined_pixel_size_offset\"]\n        + self.particle_stack.get_pixel_size().cpu().numpy()\n    )\n\n    # Cross-correlation statistics\n    # Check if correlation statistic files exist and use them if available\n    # This allows for shifts during refinement\n\n    # if (\n    #    \"correlation_average_path\" in df_refined.columns\n    #    and \"correlation_variance_path\" in df_refined.columns\n    # ):\n    # Check if files exist for at least the first entry\n    #    if (\n    #        df_refined[\"correlation_average_path\"].iloc[0]\n    #        and df_refined[\"correlation_variance_path\"].iloc[0]\n    #    ):\n    # Load the correlation statistics from the files\n    #        correlation_average = read_mrc_to_numpy(\n    #            df_refined[\"correlation_average_path\"].iloc[0]\n    #        )\n    #        correlation_variance = read_mrc_to_numpy(\n    #            df_refined[\"correlation_variance_path\"].iloc[0]\n    #        )\n    #        df_refined[\"correlation_mean\"] = correlation_average[\n    #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n    #           ]\n    #        df_refined[\"correlation_variance\"] = correlation_variance[\n    #            df_refined[\"refined_pos_y\"], df_refined[\"refined_pos_x\"]\n    #        ]\n    refined_mip = result[\"refined_cross_correlation\"]\n    refined_scaled_mip = result[\"refined_z_score\"]\n    df_refined[\"refined_mip\"] = refined_mip\n    df_refined[\"refined_scaled_mip\"] = refined_scaled_mip\n\n    # Reorder the columns\n    df_refined = df_refined.reindex(columns=REFINED_DF_COLUMN_ORDER)\n\n    # Save the refined DataFrame to disk\n    df_refined.to_csv(output_dataframe_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/managers/refine_template_manager/#leopard_em.pydantic_models.managers.refine_template_manager.RefineTemplateManager.run_refine_template","title":"<code>run_refine_template(output_dataframe_path, correlation_batch_size=32)</code>","text":"<p>Run the refine template program and saves the resultant DataFrame to csv.</p> <p>Parameters:</p> Name Type Description Default <code>output_dataframe_path</code> <code>str</code> <p>Path to save the refined particle data.</p> required <code>correlation_batch_size</code> <code>int</code> <p>Number of cross-correlations to process in one batch, defaults to 32.</p> <code>32</code> Source code in <code>src/leopard_em/pydantic_models/managers/refine_template_manager.py</code> <pre><code>def run_refine_template(\n    self, output_dataframe_path: str, correlation_batch_size: int = 32\n) -&gt; None:\n    \"\"\"Run the refine template program and saves the resultant DataFrame to csv.\n\n    Parameters\n    ----------\n    output_dataframe_path : str\n        Path to save the refined particle data.\n    correlation_batch_size : int\n        Number of cross-correlations to process in one batch, defaults to 32.\n    \"\"\"\n    backend_kwargs = self.make_backend_core_function_kwargs()\n\n    result = self.get_refine_result(backend_kwargs, correlation_batch_size)\n\n    self.refine_result_to_dataframe(\n        output_dataframe_path=output_dataframe_path, result=result\n    )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/","title":"results","text":"<p>Pydantic models for Leopard-EM program results.</p>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult","title":"<code>MatchTemplateResult</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Class to hold and export results from the match_template program.</p> <p>TODO: Implement tracking of how far along the template matching is (e.g. orientations up to what index have been searched). TODO: Implement method for exporting intermediary results in case of error or program interruption. TODO: Implement functionality for restarting template matching from a saved state (e.g. after a program interruption).</p> <p>Attributes:</p> Name Type Description <code>allow_file_overwrite</code> <code>bool = False</code> <p>Weather to allow overwriting of existing files. Default is False. WARNING: Setting to True can overwrite existing files!</p> <code>mip_path</code> <code>str</code> <p>Path to the output maximum intensity projection (MIP) file.</p> <code>scaled_mip_path</code> <code>str</code> <p>Path to the output scaled MIP file.</p> <code>correlation_average_path</code> <code>str</code> <p>Path to the output correlation average file.</p> <code>correlation_variance_path</code> <code>str</code> <p>Path to the output correlation variance file.</p> <code>orientation_psi_path</code> <code>str</code> <p>Path to the output orientation psi file.</p> <code>orientation_theta_path</code> <code>str</code> <p>Path to the output orientation theta file.</p> <code>orientation_phi_path</code> <code>str</code> <p>Path to the output orientation phi file.</p> <code>relative_defocus_path</code> <code>str</code> <p>Path to the output relative defocus file.</p> <code>mip</code> <code>ExcludedTensor</code> <p>Maximum intensity projection (MIP).</p> <code>scaled_mip</code> <code>ExcludedTensor</code> <p>Scaled MIP.</p> <code>correlation_average</code> <code>ExcludedTensor</code> <p>Correlation average.</p> <code>correlation_variance</code> <code>ExcludedTensor</code> <p>Correlation variance.</p> <code>orientation_psi</code> <code>ExcludedTensor</code> <p>Best orientation angle psi.</p> <code>orientation_theta</code> <code>ExcludedTensor</code> <p>Best orientation angle theta.</p> <code>orientation_phi</code> <code>ExcludedTensor</code> <p>Best orientation angle phi.</p> <code>relative_defocus</code> <code>ExcludedTensor</code> <p>Best relative defocus.</p> <code>total_projections</code> <code>(int, optional)</code> <p>Total number of cross-correlograms of projections computed. Should be 'total_orientations x total_defocus' Default is 0, and this field is updated automatically after a match_template run.</p> <code>total_orientations</code> <code>(int, optional)</code> <p>Total number of orientations searched. Default is 0, and this field is updated automatically after a match_template run.</p> <code>total_defocus</code> <code>(int, optional)</code> <p>Total number of defocus values searched. Default is 0, and this field is updated automatically after a match_template run.</p> <code>match_template_peaks</code> <code>MatchTemplatePeaks</code> <p>Named tuple object containing the peak locations, heights, and pose statistics. See the 'analysis.pick_match_template_peaks' module for more information.</p> <p>Methods:</p> Name Description <code>validate_paths</code> <p>Validates the output paths for write permissions and overwriting.</p> <code>load_tensors_from_paths</code> <p>Load tensors from the specified (held) paths into memory.</p> <code>locate_peaks</code> <p>Updates the 'match_template_peaks' attribute with info from held tensors. Additional keyword arguments can be passed to the 'extract_peaks_and_statistics' function.</p> <code>peaks_to_dict</code> <p>Convert the 'match_template_peaks' attribute to a dictionary.</p> <code>peaks_to_dataframe</code> <p>Convert the 'match_template_peaks' attribute to a pandas DataFrame.</p> <code>export_results</code> <p>Export the torch.Tensor results to the specified mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>class MatchTemplateResult(BaseModel2DTM):\n    \"\"\"Class to hold and export results from the match_template program.\n\n    TODO: Implement tracking of how far along the template matching is\n    (e.g. orientations up to what index have been searched).\n    TODO: Implement method for exporting intermediary results in case of error\n    or program interruption.\n    TODO: Implement functionality for restarting template matching from a\n    saved state (e.g. after a program interruption).\n\n    Attributes\n    ----------\n    allow_file_overwrite : bool = False\n        Weather to allow overwriting of existing files. Default is False.\n        WARNING: Setting to True can overwrite existing files!\n    mip_path : str\n        Path to the output maximum intensity projection (MIP) file.\n    scaled_mip_path : str\n        Path to the output scaled MIP file.\n    correlation_average_path : str\n        Path to the output correlation average file.\n    correlation_variance_path : str\n        Path to the output correlation variance file.\n    orientation_psi_path : str\n        Path to the output orientation psi file.\n    orientation_theta_path : str\n        Path to the output orientation theta file.\n    orientation_phi_path : str\n        Path to the output orientation phi file.\n    relative_defocus_path : str\n        Path to the output relative defocus file.\n    mip : ExcludedTensor\n        Maximum intensity projection (MIP).\n    scaled_mip : ExcludedTensor\n        Scaled MIP.\n    correlation_average : ExcludedTensor\n        Correlation average.\n    correlation_variance : ExcludedTensor\n        Correlation variance.\n    orientation_psi : ExcludedTensor\n        Best orientation angle psi.\n    orientation_theta : ExcludedTensor\n        Best orientation angle theta.\n    orientation_phi : ExcludedTensor\n        Best orientation angle phi.\n    relative_defocus : ExcludedTensor\n        Best relative defocus.\n    total_projections : int, optional\n        Total number of cross-correlograms of projections computed. Should be\n        'total_orientations x total_defocus' Default is 0, and this field is updated\n        automatically after a match_template run.\n    total_orientations : int, optional\n        Total number of orientations searched. Default is 0, and this field is updated\n        automatically after a match_template run.\n    total_defocus : int, optional\n        Total number of defocus values searched. Default is 0, and this field is updated\n        automatically after a match_template run.\n    match_template_peaks : MatchTemplatePeaks\n        Named tuple object containing the peak locations, heights, and pose statistics.\n        See the 'analysis.pick_match_template_peaks' module for more information.\n\n    Methods\n    -------\n    validate_paths()\n        Validates the output paths for write permissions and overwriting.\n\n    load_tensors_from_paths()\n        Load tensors from the specified (held) paths into memory.\n\n    locate_peaks(**kwargs)\n        Updates the 'match_template_peaks' attribute with info from held tensors.\n        Additional keyword arguments can be passed to the 'extract_peaks_and_statistics'\n        function.\n\n    peaks_to_dict()\n        Convert the 'match_template_peaks' attribute to a dictionary.\n\n    peaks_to_dataframe()\n        Convert the 'match_template_peaks' attribute to a pandas DataFrame.\n\n    export_results()\n        Export the torch.Tensor results to the specified mrc files.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized attributes\n    # NOTE: This overwrite attribute is a bit overbearing currently. I predict\n    # it will lead to headaches when attempting to load a result, this is set\n    # to True, and the result files already exist.\n    allow_file_overwrite: bool = False\n    mip_path: str\n    scaled_mip_path: str\n    correlation_average_path: str\n    correlation_variance_path: str\n    orientation_psi_path: str\n    orientation_theta_path: str\n    orientation_phi_path: str\n    relative_defocus_path: str\n\n    # Scalar (non-tensor) attributes\n    total_projections: int = 0\n    total_orientations: int = 0\n    total_defocus: int = 0\n\n    match_template_peaks: MatchTemplatePeaks = Field(default=None, exclude=True)\n\n    # Large array-like attributes saved to individual files (not in JSON)\n    mip: ExcludedTensor\n    scaled_mip: ExcludedTensor\n    correlation_average: ExcludedTensor\n    correlation_variance: ExcludedTensor\n    orientation_psi: ExcludedTensor\n    orientation_theta: ExcludedTensor\n    orientation_phi: ExcludedTensor\n    relative_defocus: ExcludedTensor\n\n    ###########################\n    ### Pydantic Validators ###\n    ###########################\n\n    @model_validator(mode=\"after\")  # type: ignore\n    def validate_paths(self) -&gt; Self:\n        \"\"\"Validate output paths for write permissions and overwriting.\n\n        Note: This method runs after instantiation, so attributes are already\n        set. We can safely access them with `self`.\n\n        Returns\n        -------\n        Self\n            The validated instance.\n\n        Raises\n        ------\n        ValueError\n            If the output paths are not writable or do not permit overwriting.\n        \"\"\"\n        # 1. Check write permissions and overwriting for each path\n        paths = [\n            self.mip_path,\n            self.scaled_mip_path,\n            self.correlation_average_path,\n            self.correlation_variance_path,\n            self.orientation_psi_path,\n            self.orientation_theta_path,\n            self.orientation_phi_path,\n            self.relative_defocus_path,\n        ]\n        for path in paths:\n            check_file_path_and_permissions(path, self.allow_file_overwrite)\n\n        return self\n\n    ############################################\n    ### Functional (data processing) methods ###\n    ############################################\n\n    def apply_valid_cropping(self, template_shape: tuple[int, int]) -&gt; None:\n        \"\"\"Applies valid mode cropping to the stored tensors in-place.\n\n        Valid mode cropping ensures that positions correspond to where no overlapping\n        occurs between the template and edges of the image (i.e. the template fully\n        tiles the image in the cross-correlograms). For an image of shape (H, W) and\n        template shape of (h, w), this corresponds to cropping out the region\n        (H - h + 1, W - w + 1).\n\n        Parameters\n        ----------\n        template_shape : tuple[int, int]\n            Shape of the template used in the match_template run.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        # Assuming all statistic files have the same shape (which should be true!)\n        img_h, img_w = self.mip.shape\n        h, w = template_shape\n        slice_obj = (slice(img_h - h + 1), slice(img_w - w + 1))\n\n        self.mip = self.mip[slice_obj]\n        self.scaled_mip = self.scaled_mip[slice_obj]\n        self.correlation_average = self.correlation_average[slice_obj]\n        self.correlation_variance = self.correlation_variance[slice_obj]\n        self.orientation_psi = self.orientation_psi[slice_obj]\n        self.orientation_theta = self.orientation_theta[slice_obj]\n        self.orientation_phi = self.orientation_phi[slice_obj]\n        self.relative_defocus = self.relative_defocus[slice_obj]\n\n    def load_tensors_from_paths(self) -&gt; None:\n        \"\"\"Use the held paths to load tensors into memory.\n\n        NOTE: Currently only supports .mrc files.\n        \"\"\"\n        self.mip = load_mrc_image(self.mip_path)\n        self.scaled_mip = load_mrc_image(self.scaled_mip_path)\n        self.correlation_average = load_mrc_image(self.correlation_average_path)\n        self.correlation_variance = load_mrc_image(self.correlation_variance_path)\n        self.orientation_psi = load_mrc_image(self.orientation_psi_path)\n        self.orientation_theta = load_mrc_image(self.orientation_theta_path)\n        self.orientation_phi = load_mrc_image(self.orientation_phi_path)\n        self.relative_defocus = load_mrc_image(self.relative_defocus_path)\n\n    def locate_peaks(self, **kwargs) -&gt; MatchTemplatePeaks:  # type: ignore\n        \"\"\"Updates the 'match_template_peaks' attribute with info from held tensors.\n\n        This method calls the `extract_peaks_and_statistics` function to first locate\n        particles based on the z-scores of the correlation results, then finds the\n        best orientations and defocus values at those locations. Returned named tuple\n        object is stored in the 'match_template_peaks' attribute.\n\n        NOTE: Method intended to be called after running match_template or loading\n        the tensors from disk.\n\n        Parameters\n        ----------\n        **kwargs\n            Additional keyword arguments to pass to the 'extract_peaks_and_statistics'\n            function.\n\n        Returns\n        -------\n        MatchTemplatePeaks\n            Named tuple object containing the peak locations, heights, and pose\n            statistics.\n        \"\"\"\n        self.match_template_peaks = extract_peaks_and_statistics_zscore(\n            mip=self.mip,\n            scaled_mip=self.scaled_mip,\n            best_psi=self.orientation_psi,\n            best_theta=self.orientation_theta,\n            best_phi=self.orientation_phi,\n            best_defocus=self.relative_defocus,\n            correlation_average=self.correlation_average,\n            correlation_variance=self.correlation_variance,\n            total_correlation_positions=self.total_projections,\n            **kwargs,\n        )\n\n        return self.match_template_peaks\n\n    def peaks_to_dict(self) -&gt; dict:\n        \"\"\"Convert the 'match_template_peaks' attribute to a dictionary.\"\"\"\n        if self.match_template_peaks is None:\n            self.locate_peaks()\n\n        return match_template_peaks_to_dict(self.match_template_peaks)\n\n    def peaks_to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert the 'match_template_peaks' attribute to a pandas DataFrame.\"\"\"\n        if self.match_template_peaks is None:\n            self.locate_peaks()\n\n        return match_template_peaks_to_dataframe(self.match_template_peaks)\n\n    ######################\n    ### Export methods ###\n    ######################\n\n    def export_results(self) -&gt; None:\n        \"\"\"Export the torch.Tensor results to the specified mrc files.\"\"\"\n        paths = [\n            self.mip_path,\n            self.scaled_mip_path,\n            self.correlation_average_path,\n            self.correlation_variance_path,\n            self.orientation_psi_path,\n            self.orientation_theta_path,\n            self.orientation_phi_path,\n            self.relative_defocus_path,\n        ]\n        tensors = [\n            self.mip,\n            self.scaled_mip,\n            self.correlation_average,\n            self.correlation_variance,\n            self.orientation_psi,\n            self.orientation_theta,\n            self.orientation_phi,\n            self.relative_defocus,\n        ]\n\n        for path, tensor in zip(paths, tensors):\n            write_mrc_from_tensor(\n                data=tensor,\n                mrc_path=path,\n                mrc_header=None,\n                overwrite=self.allow_file_overwrite,\n            )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.apply_valid_cropping","title":"<code>apply_valid_cropping(template_shape)</code>","text":"<p>Applies valid mode cropping to the stored tensors in-place.</p> <p>Valid mode cropping ensures that positions correspond to where no overlapping occurs between the template and edges of the image (i.e. the template fully tiles the image in the cross-correlograms). For an image of shape (H, W) and template shape of (h, w), this corresponds to cropping out the region (H - h + 1, W - w + 1).</p> <p>Parameters:</p> Name Type Description Default <code>template_shape</code> <code>tuple[int, int]</code> <p>Shape of the template used in the match_template run.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def apply_valid_cropping(self, template_shape: tuple[int, int]) -&gt; None:\n    \"\"\"Applies valid mode cropping to the stored tensors in-place.\n\n    Valid mode cropping ensures that positions correspond to where no overlapping\n    occurs between the template and edges of the image (i.e. the template fully\n    tiles the image in the cross-correlograms). For an image of shape (H, W) and\n    template shape of (h, w), this corresponds to cropping out the region\n    (H - h + 1, W - w + 1).\n\n    Parameters\n    ----------\n    template_shape : tuple[int, int]\n        Shape of the template used in the match_template run.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # Assuming all statistic files have the same shape (which should be true!)\n    img_h, img_w = self.mip.shape\n    h, w = template_shape\n    slice_obj = (slice(img_h - h + 1), slice(img_w - w + 1))\n\n    self.mip = self.mip[slice_obj]\n    self.scaled_mip = self.scaled_mip[slice_obj]\n    self.correlation_average = self.correlation_average[slice_obj]\n    self.correlation_variance = self.correlation_variance[slice_obj]\n    self.orientation_psi = self.orientation_psi[slice_obj]\n    self.orientation_theta = self.orientation_theta[slice_obj]\n    self.orientation_phi = self.orientation_phi[slice_obj]\n    self.relative_defocus = self.relative_defocus[slice_obj]\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.export_results","title":"<code>export_results()</code>","text":"<p>Export the torch.Tensor results to the specified mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def export_results(self) -&gt; None:\n    \"\"\"Export the torch.Tensor results to the specified mrc files.\"\"\"\n    paths = [\n        self.mip_path,\n        self.scaled_mip_path,\n        self.correlation_average_path,\n        self.correlation_variance_path,\n        self.orientation_psi_path,\n        self.orientation_theta_path,\n        self.orientation_phi_path,\n        self.relative_defocus_path,\n    ]\n    tensors = [\n        self.mip,\n        self.scaled_mip,\n        self.correlation_average,\n        self.correlation_variance,\n        self.orientation_psi,\n        self.orientation_theta,\n        self.orientation_phi,\n        self.relative_defocus,\n    ]\n\n    for path, tensor in zip(paths, tensors):\n        write_mrc_from_tensor(\n            data=tensor,\n            mrc_path=path,\n            mrc_header=None,\n            overwrite=self.allow_file_overwrite,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.load_tensors_from_paths","title":"<code>load_tensors_from_paths()</code>","text":"<p>Use the held paths to load tensors into memory.</p> <p>NOTE: Currently only supports .mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def load_tensors_from_paths(self) -&gt; None:\n    \"\"\"Use the held paths to load tensors into memory.\n\n    NOTE: Currently only supports .mrc files.\n    \"\"\"\n    self.mip = load_mrc_image(self.mip_path)\n    self.scaled_mip = load_mrc_image(self.scaled_mip_path)\n    self.correlation_average = load_mrc_image(self.correlation_average_path)\n    self.correlation_variance = load_mrc_image(self.correlation_variance_path)\n    self.orientation_psi = load_mrc_image(self.orientation_psi_path)\n    self.orientation_theta = load_mrc_image(self.orientation_theta_path)\n    self.orientation_phi = load_mrc_image(self.orientation_phi_path)\n    self.relative_defocus = load_mrc_image(self.relative_defocus_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.locate_peaks","title":"<code>locate_peaks(**kwargs)</code>","text":"<p>Updates the 'match_template_peaks' attribute with info from held tensors.</p> <p>This method calls the <code>extract_peaks_and_statistics</code> function to first locate particles based on the z-scores of the correlation results, then finds the best orientations and defocus values at those locations. Returned named tuple object is stored in the 'match_template_peaks' attribute.</p> <p>NOTE: Method intended to be called after running match_template or loading the tensors from disk.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to the 'extract_peaks_and_statistics' function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>Named tuple object containing the peak locations, heights, and pose statistics.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def locate_peaks(self, **kwargs) -&gt; MatchTemplatePeaks:  # type: ignore\n    \"\"\"Updates the 'match_template_peaks' attribute with info from held tensors.\n\n    This method calls the `extract_peaks_and_statistics` function to first locate\n    particles based on the z-scores of the correlation results, then finds the\n    best orientations and defocus values at those locations. Returned named tuple\n    object is stored in the 'match_template_peaks' attribute.\n\n    NOTE: Method intended to be called after running match_template or loading\n    the tensors from disk.\n\n    Parameters\n    ----------\n    **kwargs\n        Additional keyword arguments to pass to the 'extract_peaks_and_statistics'\n        function.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        Named tuple object containing the peak locations, heights, and pose\n        statistics.\n    \"\"\"\n    self.match_template_peaks = extract_peaks_and_statistics_zscore(\n        mip=self.mip,\n        scaled_mip=self.scaled_mip,\n        best_psi=self.orientation_psi,\n        best_theta=self.orientation_theta,\n        best_phi=self.orientation_phi,\n        best_defocus=self.relative_defocus,\n        correlation_average=self.correlation_average,\n        correlation_variance=self.correlation_variance,\n        total_correlation_positions=self.total_projections,\n        **kwargs,\n    )\n\n    return self.match_template_peaks\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.peaks_to_dataframe","title":"<code>peaks_to_dataframe()</code>","text":"<p>Convert the 'match_template_peaks' attribute to a pandas DataFrame.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def peaks_to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the 'match_template_peaks' attribute to a pandas DataFrame.\"\"\"\n    if self.match_template_peaks is None:\n        self.locate_peaks()\n\n    return match_template_peaks_to_dataframe(self.match_template_peaks)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.peaks_to_dict","title":"<code>peaks_to_dict()</code>","text":"<p>Convert the 'match_template_peaks' attribute to a dictionary.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def peaks_to_dict(self) -&gt; dict:\n    \"\"\"Convert the 'match_template_peaks' attribute to a dictionary.\"\"\"\n    if self.match_template_peaks is None:\n        self.locate_peaks()\n\n    return match_template_peaks_to_dict(self.match_template_peaks)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/#leopard_em.pydantic_models.results.MatchTemplateResult.validate_paths","title":"<code>validate_paths()</code>","text":"<p>Validate output paths for write permissions and overwriting.</p> <p>Note: This method runs after instantiation, so attributes are already set. We can safely access them with <code>self</code>.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the output paths are not writable or do not permit overwriting.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>@model_validator(mode=\"after\")  # type: ignore\ndef validate_paths(self) -&gt; Self:\n    \"\"\"Validate output paths for write permissions and overwriting.\n\n    Note: This method runs after instantiation, so attributes are already\n    set. We can safely access them with `self`.\n\n    Returns\n    -------\n    Self\n        The validated instance.\n\n    Raises\n    ------\n    ValueError\n        If the output paths are not writable or do not permit overwriting.\n    \"\"\"\n    # 1. Check write permissions and overwriting for each path\n    paths = [\n        self.mip_path,\n        self.scaled_mip_path,\n        self.correlation_average_path,\n        self.correlation_variance_path,\n        self.orientation_psi_path,\n        self.orientation_theta_path,\n        self.orientation_phi_path,\n        self.relative_defocus_path,\n    ]\n    for path in paths:\n        check_file_path_and_permissions(path, self.allow_file_overwrite)\n\n    return self\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/","title":"match_template_result","text":"<p>Reading, storing, and exporting results from the match_template program.</p>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult","title":"<code>MatchTemplateResult</code>","text":"<p>               Bases: <code>BaseModel2DTM</code></p> <p>Class to hold and export results from the match_template program.</p> <p>TODO: Implement tracking of how far along the template matching is (e.g. orientations up to what index have been searched). TODO: Implement method for exporting intermediary results in case of error or program interruption. TODO: Implement functionality for restarting template matching from a saved state (e.g. after a program interruption).</p> <p>Attributes:</p> Name Type Description <code>allow_file_overwrite</code> <code>bool = False</code> <p>Weather to allow overwriting of existing files. Default is False. WARNING: Setting to True can overwrite existing files!</p> <code>mip_path</code> <code>str</code> <p>Path to the output maximum intensity projection (MIP) file.</p> <code>scaled_mip_path</code> <code>str</code> <p>Path to the output scaled MIP file.</p> <code>correlation_average_path</code> <code>str</code> <p>Path to the output correlation average file.</p> <code>correlation_variance_path</code> <code>str</code> <p>Path to the output correlation variance file.</p> <code>orientation_psi_path</code> <code>str</code> <p>Path to the output orientation psi file.</p> <code>orientation_theta_path</code> <code>str</code> <p>Path to the output orientation theta file.</p> <code>orientation_phi_path</code> <code>str</code> <p>Path to the output orientation phi file.</p> <code>relative_defocus_path</code> <code>str</code> <p>Path to the output relative defocus file.</p> <code>mip</code> <code>ExcludedTensor</code> <p>Maximum intensity projection (MIP).</p> <code>scaled_mip</code> <code>ExcludedTensor</code> <p>Scaled MIP.</p> <code>correlation_average</code> <code>ExcludedTensor</code> <p>Correlation average.</p> <code>correlation_variance</code> <code>ExcludedTensor</code> <p>Correlation variance.</p> <code>orientation_psi</code> <code>ExcludedTensor</code> <p>Best orientation angle psi.</p> <code>orientation_theta</code> <code>ExcludedTensor</code> <p>Best orientation angle theta.</p> <code>orientation_phi</code> <code>ExcludedTensor</code> <p>Best orientation angle phi.</p> <code>relative_defocus</code> <code>ExcludedTensor</code> <p>Best relative defocus.</p> <code>total_projections</code> <code>(int, optional)</code> <p>Total number of cross-correlograms of projections computed. Should be 'total_orientations x total_defocus' Default is 0, and this field is updated automatically after a match_template run.</p> <code>total_orientations</code> <code>(int, optional)</code> <p>Total number of orientations searched. Default is 0, and this field is updated automatically after a match_template run.</p> <code>total_defocus</code> <code>(int, optional)</code> <p>Total number of defocus values searched. Default is 0, and this field is updated automatically after a match_template run.</p> <code>match_template_peaks</code> <code>MatchTemplatePeaks</code> <p>Named tuple object containing the peak locations, heights, and pose statistics. See the 'analysis.pick_match_template_peaks' module for more information.</p> <p>Methods:</p> Name Description <code>validate_paths</code> <p>Validates the output paths for write permissions and overwriting.</p> <code>load_tensors_from_paths</code> <p>Load tensors from the specified (held) paths into memory.</p> <code>locate_peaks</code> <p>Updates the 'match_template_peaks' attribute with info from held tensors. Additional keyword arguments can be passed to the 'extract_peaks_and_statistics' function.</p> <code>peaks_to_dict</code> <p>Convert the 'match_template_peaks' attribute to a dictionary.</p> <code>peaks_to_dataframe</code> <p>Convert the 'match_template_peaks' attribute to a pandas DataFrame.</p> <code>export_results</code> <p>Export the torch.Tensor results to the specified mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>class MatchTemplateResult(BaseModel2DTM):\n    \"\"\"Class to hold and export results from the match_template program.\n\n    TODO: Implement tracking of how far along the template matching is\n    (e.g. orientations up to what index have been searched).\n    TODO: Implement method for exporting intermediary results in case of error\n    or program interruption.\n    TODO: Implement functionality for restarting template matching from a\n    saved state (e.g. after a program interruption).\n\n    Attributes\n    ----------\n    allow_file_overwrite : bool = False\n        Weather to allow overwriting of existing files. Default is False.\n        WARNING: Setting to True can overwrite existing files!\n    mip_path : str\n        Path to the output maximum intensity projection (MIP) file.\n    scaled_mip_path : str\n        Path to the output scaled MIP file.\n    correlation_average_path : str\n        Path to the output correlation average file.\n    correlation_variance_path : str\n        Path to the output correlation variance file.\n    orientation_psi_path : str\n        Path to the output orientation psi file.\n    orientation_theta_path : str\n        Path to the output orientation theta file.\n    orientation_phi_path : str\n        Path to the output orientation phi file.\n    relative_defocus_path : str\n        Path to the output relative defocus file.\n    mip : ExcludedTensor\n        Maximum intensity projection (MIP).\n    scaled_mip : ExcludedTensor\n        Scaled MIP.\n    correlation_average : ExcludedTensor\n        Correlation average.\n    correlation_variance : ExcludedTensor\n        Correlation variance.\n    orientation_psi : ExcludedTensor\n        Best orientation angle psi.\n    orientation_theta : ExcludedTensor\n        Best orientation angle theta.\n    orientation_phi : ExcludedTensor\n        Best orientation angle phi.\n    relative_defocus : ExcludedTensor\n        Best relative defocus.\n    total_projections : int, optional\n        Total number of cross-correlograms of projections computed. Should be\n        'total_orientations x total_defocus' Default is 0, and this field is updated\n        automatically after a match_template run.\n    total_orientations : int, optional\n        Total number of orientations searched. Default is 0, and this field is updated\n        automatically after a match_template run.\n    total_defocus : int, optional\n        Total number of defocus values searched. Default is 0, and this field is updated\n        automatically after a match_template run.\n    match_template_peaks : MatchTemplatePeaks\n        Named tuple object containing the peak locations, heights, and pose statistics.\n        See the 'analysis.pick_match_template_peaks' module for more information.\n\n    Methods\n    -------\n    validate_paths()\n        Validates the output paths for write permissions and overwriting.\n\n    load_tensors_from_paths()\n        Load tensors from the specified (held) paths into memory.\n\n    locate_peaks(**kwargs)\n        Updates the 'match_template_peaks' attribute with info from held tensors.\n        Additional keyword arguments can be passed to the 'extract_peaks_and_statistics'\n        function.\n\n    peaks_to_dict()\n        Convert the 'match_template_peaks' attribute to a dictionary.\n\n    peaks_to_dataframe()\n        Convert the 'match_template_peaks' attribute to a pandas DataFrame.\n\n    export_results()\n        Export the torch.Tensor results to the specified mrc files.\n    \"\"\"\n\n    model_config: ClassVar = ConfigDict(arbitrary_types_allowed=True)\n\n    # Serialized attributes\n    # NOTE: This overwrite attribute is a bit overbearing currently. I predict\n    # it will lead to headaches when attempting to load a result, this is set\n    # to True, and the result files already exist.\n    allow_file_overwrite: bool = False\n    mip_path: str\n    scaled_mip_path: str\n    correlation_average_path: str\n    correlation_variance_path: str\n    orientation_psi_path: str\n    orientation_theta_path: str\n    orientation_phi_path: str\n    relative_defocus_path: str\n\n    # Scalar (non-tensor) attributes\n    total_projections: int = 0\n    total_orientations: int = 0\n    total_defocus: int = 0\n\n    match_template_peaks: MatchTemplatePeaks = Field(default=None, exclude=True)\n\n    # Large array-like attributes saved to individual files (not in JSON)\n    mip: ExcludedTensor\n    scaled_mip: ExcludedTensor\n    correlation_average: ExcludedTensor\n    correlation_variance: ExcludedTensor\n    orientation_psi: ExcludedTensor\n    orientation_theta: ExcludedTensor\n    orientation_phi: ExcludedTensor\n    relative_defocus: ExcludedTensor\n\n    ###########################\n    ### Pydantic Validators ###\n    ###########################\n\n    @model_validator(mode=\"after\")  # type: ignore\n    def validate_paths(self) -&gt; Self:\n        \"\"\"Validate output paths for write permissions and overwriting.\n\n        Note: This method runs after instantiation, so attributes are already\n        set. We can safely access them with `self`.\n\n        Returns\n        -------\n        Self\n            The validated instance.\n\n        Raises\n        ------\n        ValueError\n            If the output paths are not writable or do not permit overwriting.\n        \"\"\"\n        # 1. Check write permissions and overwriting for each path\n        paths = [\n            self.mip_path,\n            self.scaled_mip_path,\n            self.correlation_average_path,\n            self.correlation_variance_path,\n            self.orientation_psi_path,\n            self.orientation_theta_path,\n            self.orientation_phi_path,\n            self.relative_defocus_path,\n        ]\n        for path in paths:\n            check_file_path_and_permissions(path, self.allow_file_overwrite)\n\n        return self\n\n    ############################################\n    ### Functional (data processing) methods ###\n    ############################################\n\n    def apply_valid_cropping(self, template_shape: tuple[int, int]) -&gt; None:\n        \"\"\"Applies valid mode cropping to the stored tensors in-place.\n\n        Valid mode cropping ensures that positions correspond to where no overlapping\n        occurs between the template and edges of the image (i.e. the template fully\n        tiles the image in the cross-correlograms). For an image of shape (H, W) and\n        template shape of (h, w), this corresponds to cropping out the region\n        (H - h + 1, W - w + 1).\n\n        Parameters\n        ----------\n        template_shape : tuple[int, int]\n            Shape of the template used in the match_template run.\n\n        Returns\n        -------\n        None\n        \"\"\"\n        # Assuming all statistic files have the same shape (which should be true!)\n        img_h, img_w = self.mip.shape\n        h, w = template_shape\n        slice_obj = (slice(img_h - h + 1), slice(img_w - w + 1))\n\n        self.mip = self.mip[slice_obj]\n        self.scaled_mip = self.scaled_mip[slice_obj]\n        self.correlation_average = self.correlation_average[slice_obj]\n        self.correlation_variance = self.correlation_variance[slice_obj]\n        self.orientation_psi = self.orientation_psi[slice_obj]\n        self.orientation_theta = self.orientation_theta[slice_obj]\n        self.orientation_phi = self.orientation_phi[slice_obj]\n        self.relative_defocus = self.relative_defocus[slice_obj]\n\n    def load_tensors_from_paths(self) -&gt; None:\n        \"\"\"Use the held paths to load tensors into memory.\n\n        NOTE: Currently only supports .mrc files.\n        \"\"\"\n        self.mip = load_mrc_image(self.mip_path)\n        self.scaled_mip = load_mrc_image(self.scaled_mip_path)\n        self.correlation_average = load_mrc_image(self.correlation_average_path)\n        self.correlation_variance = load_mrc_image(self.correlation_variance_path)\n        self.orientation_psi = load_mrc_image(self.orientation_psi_path)\n        self.orientation_theta = load_mrc_image(self.orientation_theta_path)\n        self.orientation_phi = load_mrc_image(self.orientation_phi_path)\n        self.relative_defocus = load_mrc_image(self.relative_defocus_path)\n\n    def locate_peaks(self, **kwargs) -&gt; MatchTemplatePeaks:  # type: ignore\n        \"\"\"Updates the 'match_template_peaks' attribute with info from held tensors.\n\n        This method calls the `extract_peaks_and_statistics` function to first locate\n        particles based on the z-scores of the correlation results, then finds the\n        best orientations and defocus values at those locations. Returned named tuple\n        object is stored in the 'match_template_peaks' attribute.\n\n        NOTE: Method intended to be called after running match_template or loading\n        the tensors from disk.\n\n        Parameters\n        ----------\n        **kwargs\n            Additional keyword arguments to pass to the 'extract_peaks_and_statistics'\n            function.\n\n        Returns\n        -------\n        MatchTemplatePeaks\n            Named tuple object containing the peak locations, heights, and pose\n            statistics.\n        \"\"\"\n        self.match_template_peaks = extract_peaks_and_statistics_zscore(\n            mip=self.mip,\n            scaled_mip=self.scaled_mip,\n            best_psi=self.orientation_psi,\n            best_theta=self.orientation_theta,\n            best_phi=self.orientation_phi,\n            best_defocus=self.relative_defocus,\n            correlation_average=self.correlation_average,\n            correlation_variance=self.correlation_variance,\n            total_correlation_positions=self.total_projections,\n            **kwargs,\n        )\n\n        return self.match_template_peaks\n\n    def peaks_to_dict(self) -&gt; dict:\n        \"\"\"Convert the 'match_template_peaks' attribute to a dictionary.\"\"\"\n        if self.match_template_peaks is None:\n            self.locate_peaks()\n\n        return match_template_peaks_to_dict(self.match_template_peaks)\n\n    def peaks_to_dataframe(self) -&gt; pd.DataFrame:\n        \"\"\"Convert the 'match_template_peaks' attribute to a pandas DataFrame.\"\"\"\n        if self.match_template_peaks is None:\n            self.locate_peaks()\n\n        return match_template_peaks_to_dataframe(self.match_template_peaks)\n\n    ######################\n    ### Export methods ###\n    ######################\n\n    def export_results(self) -&gt; None:\n        \"\"\"Export the torch.Tensor results to the specified mrc files.\"\"\"\n        paths = [\n            self.mip_path,\n            self.scaled_mip_path,\n            self.correlation_average_path,\n            self.correlation_variance_path,\n            self.orientation_psi_path,\n            self.orientation_theta_path,\n            self.orientation_phi_path,\n            self.relative_defocus_path,\n        ]\n        tensors = [\n            self.mip,\n            self.scaled_mip,\n            self.correlation_average,\n            self.correlation_variance,\n            self.orientation_psi,\n            self.orientation_theta,\n            self.orientation_phi,\n            self.relative_defocus,\n        ]\n\n        for path, tensor in zip(paths, tensors):\n            write_mrc_from_tensor(\n                data=tensor,\n                mrc_path=path,\n                mrc_header=None,\n                overwrite=self.allow_file_overwrite,\n            )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.apply_valid_cropping","title":"<code>apply_valid_cropping(template_shape)</code>","text":"<p>Applies valid mode cropping to the stored tensors in-place.</p> <p>Valid mode cropping ensures that positions correspond to where no overlapping occurs between the template and edges of the image (i.e. the template fully tiles the image in the cross-correlograms). For an image of shape (H, W) and template shape of (h, w), this corresponds to cropping out the region (H - h + 1, W - w + 1).</p> <p>Parameters:</p> Name Type Description Default <code>template_shape</code> <code>tuple[int, int]</code> <p>Shape of the template used in the match_template run.</p> required <p>Returns:</p> Type Description <code>None</code> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def apply_valid_cropping(self, template_shape: tuple[int, int]) -&gt; None:\n    \"\"\"Applies valid mode cropping to the stored tensors in-place.\n\n    Valid mode cropping ensures that positions correspond to where no overlapping\n    occurs between the template and edges of the image (i.e. the template fully\n    tiles the image in the cross-correlograms). For an image of shape (H, W) and\n    template shape of (h, w), this corresponds to cropping out the region\n    (H - h + 1, W - w + 1).\n\n    Parameters\n    ----------\n    template_shape : tuple[int, int]\n        Shape of the template used in the match_template run.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    # Assuming all statistic files have the same shape (which should be true!)\n    img_h, img_w = self.mip.shape\n    h, w = template_shape\n    slice_obj = (slice(img_h - h + 1), slice(img_w - w + 1))\n\n    self.mip = self.mip[slice_obj]\n    self.scaled_mip = self.scaled_mip[slice_obj]\n    self.correlation_average = self.correlation_average[slice_obj]\n    self.correlation_variance = self.correlation_variance[slice_obj]\n    self.orientation_psi = self.orientation_psi[slice_obj]\n    self.orientation_theta = self.orientation_theta[slice_obj]\n    self.orientation_phi = self.orientation_phi[slice_obj]\n    self.relative_defocus = self.relative_defocus[slice_obj]\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.export_results","title":"<code>export_results()</code>","text":"<p>Export the torch.Tensor results to the specified mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def export_results(self) -&gt; None:\n    \"\"\"Export the torch.Tensor results to the specified mrc files.\"\"\"\n    paths = [\n        self.mip_path,\n        self.scaled_mip_path,\n        self.correlation_average_path,\n        self.correlation_variance_path,\n        self.orientation_psi_path,\n        self.orientation_theta_path,\n        self.orientation_phi_path,\n        self.relative_defocus_path,\n    ]\n    tensors = [\n        self.mip,\n        self.scaled_mip,\n        self.correlation_average,\n        self.correlation_variance,\n        self.orientation_psi,\n        self.orientation_theta,\n        self.orientation_phi,\n        self.relative_defocus,\n    ]\n\n    for path, tensor in zip(paths, tensors):\n        write_mrc_from_tensor(\n            data=tensor,\n            mrc_path=path,\n            mrc_header=None,\n            overwrite=self.allow_file_overwrite,\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.load_tensors_from_paths","title":"<code>load_tensors_from_paths()</code>","text":"<p>Use the held paths to load tensors into memory.</p> <p>NOTE: Currently only supports .mrc files.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def load_tensors_from_paths(self) -&gt; None:\n    \"\"\"Use the held paths to load tensors into memory.\n\n    NOTE: Currently only supports .mrc files.\n    \"\"\"\n    self.mip = load_mrc_image(self.mip_path)\n    self.scaled_mip = load_mrc_image(self.scaled_mip_path)\n    self.correlation_average = load_mrc_image(self.correlation_average_path)\n    self.correlation_variance = load_mrc_image(self.correlation_variance_path)\n    self.orientation_psi = load_mrc_image(self.orientation_psi_path)\n    self.orientation_theta = load_mrc_image(self.orientation_theta_path)\n    self.orientation_phi = load_mrc_image(self.orientation_phi_path)\n    self.relative_defocus = load_mrc_image(self.relative_defocus_path)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.locate_peaks","title":"<code>locate_peaks(**kwargs)</code>","text":"<p>Updates the 'match_template_peaks' attribute with info from held tensors.</p> <p>This method calls the <code>extract_peaks_and_statistics</code> function to first locate particles based on the z-scores of the correlation results, then finds the best orientations and defocus values at those locations. Returned named tuple object is stored in the 'match_template_peaks' attribute.</p> <p>NOTE: Method intended to be called after running match_template or loading the tensors from disk.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Additional keyword arguments to pass to the 'extract_peaks_and_statistics' function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MatchTemplatePeaks</code> <p>Named tuple object containing the peak locations, heights, and pose statistics.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def locate_peaks(self, **kwargs) -&gt; MatchTemplatePeaks:  # type: ignore\n    \"\"\"Updates the 'match_template_peaks' attribute with info from held tensors.\n\n    This method calls the `extract_peaks_and_statistics` function to first locate\n    particles based on the z-scores of the correlation results, then finds the\n    best orientations and defocus values at those locations. Returned named tuple\n    object is stored in the 'match_template_peaks' attribute.\n\n    NOTE: Method intended to be called after running match_template or loading\n    the tensors from disk.\n\n    Parameters\n    ----------\n    **kwargs\n        Additional keyword arguments to pass to the 'extract_peaks_and_statistics'\n        function.\n\n    Returns\n    -------\n    MatchTemplatePeaks\n        Named tuple object containing the peak locations, heights, and pose\n        statistics.\n    \"\"\"\n    self.match_template_peaks = extract_peaks_and_statistics_zscore(\n        mip=self.mip,\n        scaled_mip=self.scaled_mip,\n        best_psi=self.orientation_psi,\n        best_theta=self.orientation_theta,\n        best_phi=self.orientation_phi,\n        best_defocus=self.relative_defocus,\n        correlation_average=self.correlation_average,\n        correlation_variance=self.correlation_variance,\n        total_correlation_positions=self.total_projections,\n        **kwargs,\n    )\n\n    return self.match_template_peaks\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.peaks_to_dataframe","title":"<code>peaks_to_dataframe()</code>","text":"<p>Convert the 'match_template_peaks' attribute to a pandas DataFrame.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def peaks_to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the 'match_template_peaks' attribute to a pandas DataFrame.\"\"\"\n    if self.match_template_peaks is None:\n        self.locate_peaks()\n\n    return match_template_peaks_to_dataframe(self.match_template_peaks)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.peaks_to_dict","title":"<code>peaks_to_dict()</code>","text":"<p>Convert the 'match_template_peaks' attribute to a dictionary.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def peaks_to_dict(self) -&gt; dict:\n    \"\"\"Convert the 'match_template_peaks' attribute to a dictionary.\"\"\"\n    if self.match_template_peaks is None:\n        self.locate_peaks()\n\n    return match_template_peaks_to_dict(self.match_template_peaks)\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.MatchTemplateResult.validate_paths","title":"<code>validate_paths()</code>","text":"<p>Validate output paths for write permissions and overwriting.</p> <p>Note: This method runs after instantiation, so attributes are already set. We can safely access them with <code>self</code>.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The validated instance.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the output paths are not writable or do not permit overwriting.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>@model_validator(mode=\"after\")  # type: ignore\ndef validate_paths(self) -&gt; Self:\n    \"\"\"Validate output paths for write permissions and overwriting.\n\n    Note: This method runs after instantiation, so attributes are already\n    set. We can safely access them with `self`.\n\n    Returns\n    -------\n    Self\n        The validated instance.\n\n    Raises\n    ------\n    ValueError\n        If the output paths are not writable or do not permit overwriting.\n    \"\"\"\n    # 1. Check write permissions and overwriting for each path\n    paths = [\n        self.mip_path,\n        self.scaled_mip_path,\n        self.correlation_average_path,\n        self.correlation_variance_path,\n        self.orientation_psi_path,\n        self.orientation_theta_path,\n        self.orientation_phi_path,\n        self.relative_defocus_path,\n    ]\n    for path in paths:\n        check_file_path_and_permissions(path, self.allow_file_overwrite)\n\n    return self\n</code></pre>"},{"location":"autoapi/leopard_em/pydantic_models/results/match_template_result/#leopard_em.pydantic_models.results.match_template_result.check_file_path_and_permissions","title":"<code>check_file_path_and_permissions(path, allow_overwrite)</code>","text":"<p>Ensures path is writable and it does not exist, if <code>allow_overwrite</code> is False.</p> Source code in <code>src/leopard_em/pydantic_models/results/match_template_result.py</code> <pre><code>def check_file_path_and_permissions(path: str, allow_overwrite: bool) -&gt; None:\n    \"\"\"Ensures path is writable and it does not exist, if `allow_overwrite` is False.\"\"\"\n    # 1. Create path to file, if it does not exist\n    directory = os.path.dirname(path)\n    if directory and not os.path.exists(directory):\n        os.makedirs(directory, exist_ok=True)\n\n    # 2. Check write permissions\n    if directory and not os.access(directory, os.W_OK):\n        raise ValueError(\n            f\"Directory '{directory}' does not permit writing.\"\n            f\"Will be unable to write results to '{path}'.\"\n        )\n\n    # 3. Check if file exists\n    if not allow_overwrite and os.path.exists(path):\n        raise ValueError(\n            f\"File '{path}' already exists, but 'allow_file_overwrite' \"\n            \"is False. Set 'allow_file_overwrite' to True to permit. \"\n            \"overwriting.\\n\"\n            \"WARNING: Overwriting will delete the existing file(s)!\"\n        )\n</code></pre>"},{"location":"autoapi/leopard_em/utils/","title":"utils","text":"<p>Utilities submodule for various data and pre- and post-processing tasks.</p>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.handle_correlation_mode","title":"<code>handle_correlation_mode(cross_correlation, out_shape, mode)</code>","text":"<p>Handle cropping for cross correlation mode.</p> <p>NOTE: 'full' mode is not implemented.</p> <p>Parameters:</p> Name Type Description Default <code>cross_correlation</code> <code>Tensor</code> <p>The cross correlation result.</p> required <code>out_shape</code> <code>tuple[int, ...]</code> <p>The desired shape of the output.</p> required <code>mode</code> <code>Literal['valid', 'same']</code> <p>The mode of the cross correlation. Either 'valid' or 'same'. See numpy.correlate for more details.</p> required Source code in <code>src/leopard_em/utils/cross_correlation.py</code> <pre><code>def handle_correlation_mode(\n    cross_correlation: torch.Tensor,\n    out_shape: tuple[int, ...],\n    mode: Literal[\"valid\", \"same\"],\n) -&gt; torch.Tensor:\n    \"\"\"Handle cropping for cross correlation mode.\n\n     NOTE: 'full' mode is not implemented.\n\n    Parameters\n    ----------\n    cross_correlation : torch.Tensor\n        The cross correlation result.\n    out_shape : tuple[int, ...]\n        The desired shape of the output.\n    mode : Literal[\"valid\", \"same\"]\n        The mode of the cross correlation. Either 'valid' or 'same'. See\n        [numpy.correlate](https://numpy.org/doc/stable/reference/generated/\n        numpy.convolve.html#numpy.convolve)\n        for more details.\n    \"\"\"\n    # Crop the result to the valid bounds\n    if mode == \"valid\":\n        slices = [slice(0, _out_s) for _out_s in out_shape]\n        cross_correlation = cross_correlation[slices]\n    elif mode == \"same\":\n        pass\n    elif mode == \"full\":\n        raise NotImplementedError(\"Full mode not supported\")\n    else:\n        raise ValueError(f\"Invalid mode: {mode}\")\n\n    return cross_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.load_mrc_image","title":"<code>load_mrc_image(file_path)</code>","text":"<p>Helper function for loading an two-dimensional MRC image into a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC image as a tensor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the MRC file is not two-dimensional.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_mrc_image(file_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Helper function for loading an two-dimensional MRC image into a tensor.\n\n    Parameters\n    ----------\n    file_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC image as a tensor.\n\n    Raises\n    ------\n    ValueError\n        If the MRC file is not two-dimensional.\n    \"\"\"\n    tensor = read_mrc_to_tensor(file_path)\n\n    # Check that tensor is 2D, squeezing if necessary\n    tensor = tensor.squeeze()\n    if len(tensor.shape) != 2:\n        raise ValueError(f\"MRC file is not two-dimensional. Got shape: {tensor.shape}\")\n\n    return tensor\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.load_mrc_volume","title":"<code>load_mrc_volume(file_path)</code>","text":"<p>Helper function for loading an three-dimensional MRC volume into a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC volume as a tensor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the MRC file is not three-dimensional.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_mrc_volume(file_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Helper function for loading an three-dimensional MRC volume into a tensor.\n\n    Parameters\n    ----------\n    file_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC volume as a tensor.\n\n    Raises\n    ------\n    ValueError\n        If the MRC file is not three-dimensional.\n    \"\"\"\n    tensor = read_mrc_to_tensor(file_path)\n\n    # Check that tensor is 3D, squeezing if necessary\n    tensor = tensor.squeeze()\n    if len(tensor.shape) != 3:\n        raise ValueError(\n            f\"MRC file is not three-dimensional. Got shape: {tensor.shape}\"\n        )\n\n    return tensor\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.load_template_tensor","title":"<code>load_template_tensor(template_volume=None, template_volume_path=None)</code>","text":"<p>Load and convert template volume to a torch.Tensor.</p> <p>This function ensures that the template volume is a torch.Tensor. If template_volume is None, it loads the volume from template_volume_path. If template_volume is not a torch.Tensor, it converts it to one.</p> <p>Parameters:</p> Name Type Description Default <code>template_volume</code> <code>Optional[Union[Tensor, Any]]</code> <p>The template volume object, by default None</p> <code>None</code> <code>template_volume_path</code> <code>Optional[Union[str, PathLike, Path]]</code> <p>Path to the template volume file, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The template volume as a torch.Tensor</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both template_volume and template_volume_path are None</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_template_tensor(\n    template_volume: Optional[Union[torch.Tensor, Any]] = None,\n    template_volume_path: Optional[Union[str, os.PathLike, Path]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Load and convert template volume to a torch.Tensor.\n\n    This function ensures that the template volume is a torch.Tensor.\n    If template_volume is None, it loads the volume from template_volume_path.\n    If template_volume is not a torch.Tensor, it converts it to one.\n\n    Parameters\n    ----------\n    template_volume : Optional[Union[torch.Tensor, Any]], optional\n        The template volume object, by default None\n    template_volume_path : Optional[Union[str, os.PathLike, Path]], optional\n        Path to the template volume file, by default None\n\n    Returns\n    -------\n    torch.Tensor\n        The template volume as a torch.Tensor\n\n    Raises\n    ------\n    ValueError\n        If both template_volume and template_volume_path are None\n    \"\"\"\n    if template_volume is None:\n        if template_volume_path is None:\n            raise ValueError(\"template_volume or template_volume_path must be provided\")\n        template_volume = load_mrc_volume(template_volume_path)\n\n    if not isinstance(template_volume, torch.Tensor):\n        template = torch.from_numpy(template_volume)\n    else:\n        template = template_volume\n\n    return template\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.read_mrc_to_numpy","title":"<code>read_mrc_to_numpy(mrc_path)</code>","text":"<p>Reads an MRC file and returns the data as a numpy array.</p> <p>Attributes:</p> Name Type Description <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The MRC data as a numpy array, copied.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def read_mrc_to_numpy(mrc_path: str | os.PathLike | Path) -&gt; np.ndarray:\n    \"\"\"Reads an MRC file and returns the data as a numpy array.\n\n    Attributes\n    ----------\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    np.ndarray\n        The MRC data as a numpy array, copied.\n    \"\"\"\n    with mrcfile.open(mrc_path) as mrc:\n        return mrc.data.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.read_mrc_to_tensor","title":"<code>read_mrc_to_tensor(mrc_path)</code>","text":"<p>Reads an MRC file and returns the data as a torch tensor.</p> <p>Attributes:</p> Name Type Description <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC data as a tensor, copied.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def read_mrc_to_tensor(mrc_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Reads an MRC file and returns the data as a torch tensor.\n\n    Attributes\n    ----------\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC data as a tensor, copied.\n    \"\"\"\n    return torch.tensor(read_mrc_to_numpy(mrc_path))\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.write_mrc_from_numpy","title":"<code>write_mrc_from_numpy(data, mrc_path, mrc_header=None, overwrite=False)</code>","text":"<p>Writes a numpy array to an MRC file.</p> <p>NOTE: Writing header information is not currently implemented.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>The data to write to the MRC file.</p> <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <code>mrc_header</code> <code>Optional[dict]</code> <p>Dictionary containing header information. Default is None.</p> <code>overwrite</code> <code>bool</code> <p>Overwrite argument passed to mrcfile.new. Default is False.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def write_mrc_from_numpy(\n    data: np.ndarray,\n    mrc_path: str | os.PathLike | Path,\n    mrc_header: Optional[dict] = None,\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Writes a numpy array to an MRC file.\n\n    NOTE: Writing header information is not currently implemented.\n\n    Attributes\n    ----------\n    data : np.ndarray\n        The data to write to the MRC file.\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n    mrc_header : Optional[dict]\n        Dictionary containing header information. Default is None.\n    overwrite : bool\n        Overwrite argument passed to mrcfile.new. Default is False.\n    \"\"\"\n    if mrc_header is not None:\n        raise NotImplementedError(\"Setting header info is not yet implemented.\")\n\n    with mrcfile.new(mrc_path, overwrite=overwrite) as mrc:\n        mrc.set_data(data)\n</code></pre>"},{"location":"autoapi/leopard_em/utils/#leopard_em.utils.write_mrc_from_tensor","title":"<code>write_mrc_from_tensor(data, mrc_path, mrc_header=None, overwrite=False)</code>","text":"<p>Writes a tensor array to an MRC file.</p> <p>NOTE: Not currently implemented.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>The data to write to the MRC file.</p> <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <code>mrc_header</code> <code>Optional[dict]</code> <p>Dictionary containing header information. Default is None.</p> <code>overwrite</code> <code>bool</code> <p>Overwrite argument passed to mrcfile.new. Default is False.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def write_mrc_from_tensor(\n    data: torch.Tensor,\n    mrc_path: str | os.PathLike | Path,\n    mrc_header: Optional[dict] = None,\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Writes a tensor array to an MRC file.\n\n    NOTE: Not currently implemented.\n\n    Attributes\n    ----------\n    data : np.ndarray\n        The data to write to the MRC file.\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n    mrc_header : Optional[dict]\n        Dictionary containing header information. Default is None.\n    overwrite : bool\n        Overwrite argument passed to mrcfile.new. Default is False.\n    \"\"\"\n    write_mrc_from_numpy(data.numpy(), mrc_path, mrc_header, overwrite)\n</code></pre>"},{"location":"autoapi/leopard_em/utils/cross_correlation/","title":"cross_correlation","text":"<p>Core cross-correlation methods for single and stacks of image/templates.</p>"},{"location":"autoapi/leopard_em/utils/cross_correlation/#leopard_em.utils.cross_correlation.handle_correlation_mode","title":"<code>handle_correlation_mode(cross_correlation, out_shape, mode)</code>","text":"<p>Handle cropping for cross correlation mode.</p> <p>NOTE: 'full' mode is not implemented.</p> <p>Parameters:</p> Name Type Description Default <code>cross_correlation</code> <code>Tensor</code> <p>The cross correlation result.</p> required <code>out_shape</code> <code>tuple[int, ...]</code> <p>The desired shape of the output.</p> required <code>mode</code> <code>Literal['valid', 'same']</code> <p>The mode of the cross correlation. Either 'valid' or 'same'. See numpy.correlate for more details.</p> required Source code in <code>src/leopard_em/utils/cross_correlation.py</code> <pre><code>def handle_correlation_mode(\n    cross_correlation: torch.Tensor,\n    out_shape: tuple[int, ...],\n    mode: Literal[\"valid\", \"same\"],\n) -&gt; torch.Tensor:\n    \"\"\"Handle cropping for cross correlation mode.\n\n     NOTE: 'full' mode is not implemented.\n\n    Parameters\n    ----------\n    cross_correlation : torch.Tensor\n        The cross correlation result.\n    out_shape : tuple[int, ...]\n        The desired shape of the output.\n    mode : Literal[\"valid\", \"same\"]\n        The mode of the cross correlation. Either 'valid' or 'same'. See\n        [numpy.correlate](https://numpy.org/doc/stable/reference/generated/\n        numpy.convolve.html#numpy.convolve)\n        for more details.\n    \"\"\"\n    # Crop the result to the valid bounds\n    if mode == \"valid\":\n        slices = [slice(0, _out_s) for _out_s in out_shape]\n        cross_correlation = cross_correlation[slices]\n    elif mode == \"same\":\n        pass\n    elif mode == \"full\":\n        raise NotImplementedError(\"Full mode not supported\")\n    else:\n        raise ValueError(f\"Invalid mode: {mode}\")\n\n    return cross_correlation\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/","title":"data_io","text":"<p>Utility functions dealing with basic data I/O operations.</p>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.load_mrc_image","title":"<code>load_mrc_image(file_path)</code>","text":"<p>Helper function for loading an two-dimensional MRC image into a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC image as a tensor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the MRC file is not two-dimensional.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_mrc_image(file_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Helper function for loading an two-dimensional MRC image into a tensor.\n\n    Parameters\n    ----------\n    file_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC image as a tensor.\n\n    Raises\n    ------\n    ValueError\n        If the MRC file is not two-dimensional.\n    \"\"\"\n    tensor = read_mrc_to_tensor(file_path)\n\n    # Check that tensor is 2D, squeezing if necessary\n    tensor = tensor.squeeze()\n    if len(tensor.shape) != 2:\n        raise ValueError(f\"MRC file is not two-dimensional. Got shape: {tensor.shape}\")\n\n    return tensor\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.load_mrc_volume","title":"<code>load_mrc_volume(file_path)</code>","text":"<p>Helper function for loading an three-dimensional MRC volume into a tensor.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC volume as a tensor.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the MRC file is not three-dimensional.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_mrc_volume(file_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Helper function for loading an three-dimensional MRC volume into a tensor.\n\n    Parameters\n    ----------\n    file_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC volume as a tensor.\n\n    Raises\n    ------\n    ValueError\n        If the MRC file is not three-dimensional.\n    \"\"\"\n    tensor = read_mrc_to_tensor(file_path)\n\n    # Check that tensor is 3D, squeezing if necessary\n    tensor = tensor.squeeze()\n    if len(tensor.shape) != 3:\n        raise ValueError(\n            f\"MRC file is not three-dimensional. Got shape: {tensor.shape}\"\n        )\n\n    return tensor\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.load_template_tensor","title":"<code>load_template_tensor(template_volume=None, template_volume_path=None)</code>","text":"<p>Load and convert template volume to a torch.Tensor.</p> <p>This function ensures that the template volume is a torch.Tensor. If template_volume is None, it loads the volume from template_volume_path. If template_volume is not a torch.Tensor, it converts it to one.</p> <p>Parameters:</p> Name Type Description Default <code>template_volume</code> <code>Optional[Union[Tensor, Any]]</code> <p>The template volume object, by default None</p> <code>None</code> <code>template_volume_path</code> <code>Optional[Union[str, PathLike, Path]]</code> <p>Path to the template volume file, by default None</p> <code>None</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The template volume as a torch.Tensor</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both template_volume and template_volume_path are None</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def load_template_tensor(\n    template_volume: Optional[Union[torch.Tensor, Any]] = None,\n    template_volume_path: Optional[Union[str, os.PathLike, Path]] = None,\n) -&gt; torch.Tensor:\n    \"\"\"Load and convert template volume to a torch.Tensor.\n\n    This function ensures that the template volume is a torch.Tensor.\n    If template_volume is None, it loads the volume from template_volume_path.\n    If template_volume is not a torch.Tensor, it converts it to one.\n\n    Parameters\n    ----------\n    template_volume : Optional[Union[torch.Tensor, Any]], optional\n        The template volume object, by default None\n    template_volume_path : Optional[Union[str, os.PathLike, Path]], optional\n        Path to the template volume file, by default None\n\n    Returns\n    -------\n    torch.Tensor\n        The template volume as a torch.Tensor\n\n    Raises\n    ------\n    ValueError\n        If both template_volume and template_volume_path are None\n    \"\"\"\n    if template_volume is None:\n        if template_volume_path is None:\n            raise ValueError(\"template_volume or template_volume_path must be provided\")\n        template_volume = load_mrc_volume(template_volume_path)\n\n    if not isinstance(template_volume, torch.Tensor):\n        template = torch.from_numpy(template_volume)\n    else:\n        template = template_volume\n\n    return template\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.read_mrc_to_numpy","title":"<code>read_mrc_to_numpy(mrc_path)</code>","text":"<p>Reads an MRC file and returns the data as a numpy array.</p> <p>Attributes:</p> Name Type Description <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>The MRC data as a numpy array, copied.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def read_mrc_to_numpy(mrc_path: str | os.PathLike | Path) -&gt; np.ndarray:\n    \"\"\"Reads an MRC file and returns the data as a numpy array.\n\n    Attributes\n    ----------\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    np.ndarray\n        The MRC data as a numpy array, copied.\n    \"\"\"\n    with mrcfile.open(mrc_path) as mrc:\n        return mrc.data.copy()\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.read_mrc_to_tensor","title":"<code>read_mrc_to_tensor(mrc_path)</code>","text":"<p>Reads an MRC file and returns the data as a torch tensor.</p> <p>Attributes:</p> Name Type Description <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <p>Returns:</p> Type Description <code>Tensor</code> <p>The MRC data as a tensor, copied.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def read_mrc_to_tensor(mrc_path: str | os.PathLike | Path) -&gt; torch.Tensor:\n    \"\"\"Reads an MRC file and returns the data as a torch tensor.\n\n    Attributes\n    ----------\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n\n    Returns\n    -------\n    torch.Tensor\n        The MRC data as a tensor, copied.\n    \"\"\"\n    return torch.tensor(read_mrc_to_numpy(mrc_path))\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.write_mrc_from_numpy","title":"<code>write_mrc_from_numpy(data, mrc_path, mrc_header=None, overwrite=False)</code>","text":"<p>Writes a numpy array to an MRC file.</p> <p>NOTE: Writing header information is not currently implemented.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>The data to write to the MRC file.</p> <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <code>mrc_header</code> <code>Optional[dict]</code> <p>Dictionary containing header information. Default is None.</p> <code>overwrite</code> <code>bool</code> <p>Overwrite argument passed to mrcfile.new. Default is False.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def write_mrc_from_numpy(\n    data: np.ndarray,\n    mrc_path: str | os.PathLike | Path,\n    mrc_header: Optional[dict] = None,\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Writes a numpy array to an MRC file.\n\n    NOTE: Writing header information is not currently implemented.\n\n    Attributes\n    ----------\n    data : np.ndarray\n        The data to write to the MRC file.\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n    mrc_header : Optional[dict]\n        Dictionary containing header information. Default is None.\n    overwrite : bool\n        Overwrite argument passed to mrcfile.new. Default is False.\n    \"\"\"\n    if mrc_header is not None:\n        raise NotImplementedError(\"Setting header info is not yet implemented.\")\n\n    with mrcfile.new(mrc_path, overwrite=overwrite) as mrc:\n        mrc.set_data(data)\n</code></pre>"},{"location":"autoapi/leopard_em/utils/data_io/#leopard_em.utils.data_io.write_mrc_from_tensor","title":"<code>write_mrc_from_tensor(data, mrc_path, mrc_header=None, overwrite=False)</code>","text":"<p>Writes a tensor array to an MRC file.</p> <p>NOTE: Not currently implemented.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>The data to write to the MRC file.</p> <code>mrc_path</code> <code>str | PathLike | Path</code> <p>Path to the MRC file.</p> <code>mrc_header</code> <code>Optional[dict]</code> <p>Dictionary containing header information. Default is None.</p> <code>overwrite</code> <code>bool</code> <p>Overwrite argument passed to mrcfile.new. Default is False.</p> Source code in <code>src/leopard_em/utils/data_io.py</code> <pre><code>def write_mrc_from_tensor(\n    data: torch.Tensor,\n    mrc_path: str | os.PathLike | Path,\n    mrc_header: Optional[dict] = None,\n    overwrite: bool = False,\n) -&gt; None:\n    \"\"\"Writes a tensor array to an MRC file.\n\n    NOTE: Not currently implemented.\n\n    Attributes\n    ----------\n    data : np.ndarray\n        The data to write to the MRC file.\n    mrc_path : str | os.PathLike | Path\n        Path to the MRC file.\n    mrc_header : Optional[dict]\n        Dictionary containing header information. Default is None.\n    overwrite : bool\n        Overwrite argument passed to mrcfile.new. Default is False.\n    \"\"\"\n    write_mrc_from_numpy(data.numpy(), mrc_path, mrc_header, overwrite)\n</code></pre>"},{"location":"autoapi/leopard_em/utils/fourier_slice/","title":"fourier_slice","text":"<p>Useful functions for extracting and filtering Fourier slices.</p>"},{"location":"autoapi/leopard_em/utils/fourier_slice/#leopard_em.utils.fourier_slice.get_real_space_projections_from_volume","title":"<code>get_real_space_projections_from_volume(volume, phi, theta, psi, degrees=True)</code>","text":"<p>Real-space projections of a 3D volume.</p> <p>Note that Euler angles are in 'ZYZ' convention.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Tensor</code> <p>The 3D volume to get projections from.</p> required <code>phi</code> <code>Tensor</code> <p>The phi Euler angle.</p> required <code>theta</code> <code>Tensor</code> <p>The theta Euler angle.</p> required <code>psi</code> <code>Tensor</code> <p>The psi Euler angle.</p> required <code>degrees</code> <code>bool</code> <p>True if Euler angles are in degrees, False if in radians.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The real-space projections.</p> Source code in <code>src/leopard_em/utils/fourier_slice.py</code> <pre><code>def get_real_space_projections_from_volume(\n    volume: torch.Tensor,\n    phi: torch.Tensor,\n    theta: torch.Tensor,\n    psi: torch.Tensor,\n    degrees: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Real-space projections of a 3D volume.\n\n    Note that Euler angles are in 'ZYZ' convention.\n\n    Parameters\n    ----------\n    volume : torch.Tensor\n        The 3D volume to get projections from.\n    phi : torch.Tensor\n        The phi Euler angle.\n    theta : torch.Tensor\n        The theta Euler angle.\n    psi : torch.Tensor\n        The psi Euler angle.\n    degrees : bool\n        True if Euler angles are in degrees, False if in radians.\n\n    Returns\n    -------\n    torch.Tensor\n        The real-space projections.\n    \"\"\"\n    fourier_slices = get_rfft_slices_from_volume(\n        volume=volume,\n        phi=phi,\n        theta=theta,\n        psi=psi,\n        degrees=degrees,\n    )\n    projections = _rfft_slices_to_real_projections(fourier_slices)\n\n    return projections\n</code></pre>"},{"location":"autoapi/leopard_em/utils/fourier_slice/#leopard_em.utils.fourier_slice.get_rfft_slices_from_volume","title":"<code>get_rfft_slices_from_volume(volume, phi, theta, psi, degrees=True)</code>","text":"<p>Helper function to get Fourier slices of a real-space volume.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Tensor</code> <p>The 3D volume to get Fourier slices from.</p> required <code>phi</code> <code>Tensor</code> <p>The phi Euler angle.</p> required <code>theta</code> <code>Tensor</code> <p>The theta Euler angle.</p> required <code>psi</code> <code>Tensor</code> <p>The psi Euler angle.</p> required <code>degrees</code> <code>bool</code> <p>True if Euler angles are in degrees, False if in radians.</p> <code>True</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>The Fourier slices of the volume.</p> Source code in <code>src/leopard_em/utils/fourier_slice.py</code> <pre><code>def get_rfft_slices_from_volume(\n    volume: torch.Tensor,\n    phi: torch.Tensor,\n    theta: torch.Tensor,\n    psi: torch.Tensor,\n    degrees: bool = True,\n) -&gt; torch.Tensor:\n    \"\"\"Helper function to get Fourier slices of a real-space volume.\n\n    Parameters\n    ----------\n    volume : torch.Tensor\n        The 3D volume to get Fourier slices from.\n    phi : torch.Tensor\n        The phi Euler angle.\n    theta : torch.Tensor\n        The theta Euler angle.\n    psi : torch.Tensor\n        The psi Euler angle.\n    degrees : bool\n        True if Euler angles are in degrees, False if in radians.\n\n    Returns\n    -------\n    torch.Tensor\n        The Fourier slices of the volume.\n\n    \"\"\"\n    shape = volume.shape\n    volume_rfft = torch.fft.fftshift(volume, dim=(-3, -2, -1))  # pylint: disable=not-callable\n    volume_rfft = torch.fft.fftn(volume_rfft, dim=(-3, -2, -1))  # pylint: disable=not-callable\n    volume_rfft = torch.fft.fftshift(volume_rfft, dim=(-3, -2))  # pylint: disable=not-callable\n\n    # Use roma to keep angles on same device\n    rot_matrix = roma.euler_to_rotmat(\"ZYZ\", (phi, theta, psi), degrees=degrees)\n\n    # Use torch_fourier_slice to take the Fourier slice\n    fourier_slices = extract_central_slices_rfft_3d(\n        volume_rfft=volume_rfft,\n        image_shape=shape,\n        rotation_matrices=rot_matrix,\n    )\n\n    # Invert contrast to match image\n    fourier_slices = -fourier_slices\n\n    return fourier_slices\n</code></pre>"},{"location":"examples/","title":"Leopard-EM Examples Gallery","text":"<p>A gallery of examples demonstrating how to process data using the Leopard-EM package, and some helpful notebooks for visualizing data and results.</p>"},{"location":"examples/01_basic_configuration/","title":"Configuring Pydantic models in Python","text":"In\u00a0[1]: Copied! <pre>\"\"\"Leopard-EM config objects in Python.\"\"\"\n\nfrom pprint import pprint\n\nfrom leopard_em.pydantic_models.config import (\n    ArbitraryCurveFilterConfig,\n    BandpassFilterConfig,\n    ComputationalConfig,\n    DefocusSearchConfig,\n    OrientationSearchConfig,\n    PhaseRandomizationFilterConfig,\n    PreprocessingFilters,\n    WhiteningFilterConfig,\n)\nfrom leopard_em.pydantic_models.data_structures import OpticsGroup\nfrom leopard_em.pydantic_models.managers import MatchTemplateManager\nfrom leopard_em.pydantic_models.results import MatchTemplateResult\n</pre> \"\"\"Leopard-EM config objects in Python.\"\"\"  from pprint import pprint  from leopard_em.pydantic_models.config import (     ArbitraryCurveFilterConfig,     BandpassFilterConfig,     ComputationalConfig,     DefocusSearchConfig,     OrientationSearchConfig,     PhaseRandomizationFilterConfig,     PreprocessingFilters,     WhiteningFilterConfig, ) from leopard_em.pydantic_models.data_structures import OpticsGroup from leopard_em.pydantic_models.managers import MatchTemplateManager from leopard_em.pydantic_models.results import MatchTemplateResult In\u00a0[2]: Copied! <pre>my_optics_group = OpticsGroup(\n    label=\"my_optics_group\",\n    pixel_size=1.06,\n    voltage=300.0,\n    spherical_aberration=2.7,  # default value\n    amplitude_contrast_ratio=0.07,  # default value\n    phase_shift=0.0,  # default value\n    defocus_u=5200.0,\n    defocus_v=4950.0,\n    astigmatism_angle=25.0,\n    ctf_B_factor=60.0,\n)\n</pre> my_optics_group = OpticsGroup(     label=\"my_optics_group\",     pixel_size=1.06,     voltage=300.0,     spherical_aberration=2.7,  # default value     amplitude_contrast_ratio=0.07,  # default value     phase_shift=0.0,  # default value     defocus_u=5200.0,     defocus_v=4950.0,     astigmatism_angle=25.0,     ctf_B_factor=60.0, ) <p>The Python variable <code>my_optics_group</code> is now an instance of the <code>OpticsGroup</code> model. Note that the model does do validation under-the-hood to ensure necessary fields are present and valid. Any invalid fields will raise a <code>ValidationError</code> when the model is created. Uncomment the following code block to see this in action.</p> In\u00a0[3]: Copied! <pre># bad_optics_group = OpticsGroup(\n#     label=\"bad_optics_group\",\n#     pixel_size=-1.0,  # &lt;--- Must be positive\n#     voltage=300.0,\n#     phase_shift=0.0,  # default value\n#     defocus_u=5200.0,\n#     defocus_v=4950.0,\n#     astigmatism_angle=25.0,\n# )\n</pre> # bad_optics_group = OpticsGroup( #     label=\"bad_optics_group\", #     pixel_size=-1.0,  # &lt;--- Must be positive #     voltage=300.0, #     phase_shift=0.0,  # default value #     defocus_u=5200.0, #     defocus_v=4950.0, #     astigmatism_angle=25.0, # ) In\u00a0[4]: Copied! <pre>optics_dict = my_optics_group.model_dump()\npprint(optics_dict)\n</pre> optics_dict = my_optics_group.model_dump() pprint(optics_dict) <pre>{'amplitude_contrast_ratio': 0.07,\n 'astigmatism_angle': 25.0,\n 'beam_tilt_x': None,\n 'beam_tilt_y': None,\n 'chromatic_aberration': 0.0,\n 'ctf_B_factor': 60.0,\n 'defocus_u': 5200.0,\n 'defocus_v': 4950.0,\n 'even_zernike': None,\n 'label': 'my_optics_group',\n 'mtf_reference': None,\n 'mtf_values': None,\n 'odd_zernike': None,\n 'phase_shift': 0.0,\n 'pixel_size': 1.06,\n 'spherical_aberration': 2.7,\n 'voltage': 300.0,\n 'zernike_moments': None}\n</pre> In\u00a0[5]: Copied! <pre>yaml_filepath = \"./optics_group_example.yaml\"\nmy_optics_group.to_yaml(yaml_filepath)\n</pre> yaml_filepath = \"./optics_group_example.yaml\" my_optics_group.to_yaml(yaml_filepath) <p>A new file called <code>optics_group_example.yaml</code> should now exist in the current working directory with the following contents:</p> <pre>amplitude_contrast_ratio: 0.07\nbeam_tilt_x: null\nbeam_tilt_y: null\nchromatic_aberration: 0.0\nctf_B_factor: 60.0\nastigmatism_angle: 25.0\ndefocus_u: 5200.0\ndefocus_v: 4950.0\neven_zernike: null\nlabel: my_optics_group\nmtf_reference: null\nmtf_values: null\nodd_zernike: null\nphase_shift: 0.0\npixel_size: 1.06\nspherical_aberration: 2.7\nvoltage: 300.0\nzernike_moments: null\n</pre> In\u00a0[6]: Copied! <pre>new_optics_group = OpticsGroup.from_yaml(yaml_filepath)\n\n# Check if the two OpticsGroup objects are equal\nif new_optics_group == my_optics_group:\n    print(\"OpticsGroup objects are equal.\")\nelse:\n    print(\"The two OpticsGroup are not equal!!!\")\n</pre> new_optics_group = OpticsGroup.from_yaml(yaml_filepath)  # Check if the two OpticsGroup objects are equal if new_optics_group == my_optics_group:     print(\"OpticsGroup objects are equal.\") else:     print(\"The two OpticsGroup are not equal!!!\") <pre>OpticsGroup objects are equal.\n</pre> <p>Now that we've covered the basics of creating, serializing, and deserializing the <code>OpticsGroup</code> model, we can move onto the next models without covering the (de)serialization and import/export steps in detail.</p> <p>Below, we create a new instance of the <code>OrientationSearchConfig</code> model with only the <code>psi_step</code> and <code>theta_step</code> attributes set to non-default values.</p> In\u00a0[7]: Copied! <pre>orientation_search_config = OrientationSearchConfig(\n    psi_step=4.0,\n    theta_step=4.0,\n)\n\n# print the model dictionary\norientation_search_config.model_dump()\n</pre> orientation_search_config = OrientationSearchConfig(     psi_step=4.0,     theta_step=4.0, )  # print the model dictionary orientation_search_config.model_dump() Out[7]: <pre>{'psi_step': 4.0,\n 'theta_step': 4.0,\n 'phi_min': None,\n 'phi_max': None,\n 'theta_min': None,\n 'theta_max': None,\n 'psi_min': None,\n 'psi_max': None,\n 'base_grid_method': 'uniform',\n 'symmetry': 'C1'}</pre> In\u00a0[8]: Copied! <pre># Searches defocus between -600 and 600 with a step of 200 Angstroms\ndefocus_search_config = DefocusSearchConfig(\n    enabled=True, defocus_min=-600, defocus_max=600, defocus_step=200\n)\n</pre> # Searches defocus between -600 and 600 with a step of 200 Angstroms defocus_search_config = DefocusSearchConfig(     enabled=True, defocus_min=-600, defocus_max=600, defocus_step=200 ) <p>The <code>defocus_min</code> and <code>defocus_max</code> should be set so that the range covers the thickness of the specimen.</p> In\u00a0[9]: Copied! <pre>defocus_search_config.defocus_values\n</pre> defocus_search_config.defocus_values Out[9]: <pre>tensor([-600., -400., -200.,    0.,  200.,  400.,  600.])</pre> In\u00a0[10]: Copied! <pre>whitening_filter_config = WhiteningFilterConfig()\n</pre> whitening_filter_config = WhiteningFilterConfig() In\u00a0[11]: Copied! <pre>bandpass_filter_config = BandpassFilterConfig()\n</pre> bandpass_filter_config = BandpassFilterConfig() In\u00a0[12]: Copied! <pre>phase_randomization_filter = PhaseRandomizationFilterConfig()\n</pre> phase_randomization_filter = PhaseRandomizationFilterConfig() In\u00a0[13]: Copied! <pre>arbitrary_curve_filter = ArbitraryCurveFilterConfig()\n</pre> arbitrary_curve_filter = ArbitraryCurveFilterConfig() In\u00a0[14]: Copied! <pre>preprocessing_filters = PreprocessingFilters(\n    whitening_filter=whitening_filter_config,\n    bandpass_filter=bandpass_filter_config,\n    phase_randomization_filter=phase_randomization_filter,\n    arbitrary_curve_filter=arbitrary_curve_filter,\n)\n</pre> preprocessing_filters = PreprocessingFilters(     whitening_filter=whitening_filter_config,     bandpass_filter=bandpass_filter_config,     phase_randomization_filter=phase_randomization_filter,     arbitrary_curve_filter=arbitrary_curve_filter, ) In\u00a0[15]: Copied! <pre>comp_config = ComputationalConfig()\ncomp_config\n</pre> comp_config = ComputationalConfig() comp_config Out[15]: <pre>ComputationalConfig(gpu_ids=[0], num_cpus=1)</pre> In\u00a0[16]: Copied! <pre>match_template_result = MatchTemplateResult(\n    allow_file_overwrite=True,\n    mip_path=\"./output_mip.mrc\",\n    scaled_mip_path=\"./output_scaled_mip.mrc\",\n    correlation_average_path=\"./output_correlation_average.mrc\",\n    correlation_variance_path=\"./output_correlation_variance.mrc\",\n    orientation_psi_path=\"./output_orientation_psi.mrc\",\n    orientation_theta_path=\"./output_orientation_theta.mrc\",\n    orientation_phi_path=\"./output_orientation_phi.mrc\",\n    relative_defocus_path=\"./output_relative_defocus.mrc\",\n)\n</pre> match_template_result = MatchTemplateResult(     allow_file_overwrite=True,     mip_path=\"./output_mip.mrc\",     scaled_mip_path=\"./output_scaled_mip.mrc\",     correlation_average_path=\"./output_correlation_average.mrc\",     correlation_variance_path=\"./output_correlation_variance.mrc\",     orientation_psi_path=\"./output_orientation_psi.mrc\",     orientation_theta_path=\"./output_orientation_theta.mrc\",     orientation_phi_path=\"./output_orientation_phi.mrc\",     relative_defocus_path=\"./output_relative_defocus.mrc\", ) In\u00a0[17]: Copied! <pre>match_template_manager = MatchTemplateManager(\n    micrograph_path=\"./dummy_micrograph.mrc\",\n    template_volume_path=\"./dummy_template_volume.mrc\",\n    optics_group=my_optics_group,\n    defocus_search_config=defocus_search_config,\n    orientation_search_config=orientation_search_config,\n    preprocessing_filters=preprocessing_filters,\n    match_template_result=match_template_result,\n    computational_config=comp_config,\n    preload_mrc_files=False,  # Don't try to read the MRC upon initialization\n)\n</pre> match_template_manager = MatchTemplateManager(     micrograph_path=\"./dummy_micrograph.mrc\",     template_volume_path=\"./dummy_template_volume.mrc\",     optics_group=my_optics_group,     defocus_search_config=defocus_search_config,     orientation_search_config=orientation_search_config,     preprocessing_filters=preprocessing_filters,     match_template_result=match_template_result,     computational_config=comp_config,     preload_mrc_files=False,  # Don't try to read the MRC upon initialization ) In\u00a0[18]: Copied! <pre>match_template_manager.to_yaml(\"./match_template_manager_example.yaml\")\n</pre> match_template_manager.to_yaml(\"./match_template_manager_example.yaml\") In\u00a0[19]: Copied! <pre>new_match_template_manager = MatchTemplateManager.from_yaml(\n    \"./match_template_manager_example.yaml\"\n)\n\nif new_match_template_manager == match_template_manager:\n    print(\"MatchTemplateManager objects are equal.\")\nelse:\n    print(\"The two MatchTemplateManager are not equal!!!\")\n</pre> new_match_template_manager = MatchTemplateManager.from_yaml(     \"./match_template_manager_example.yaml\" )  if new_match_template_manager == match_template_manager:     print(\"MatchTemplateManager objects are equal.\") else:     print(\"The two MatchTemplateManager are not equal!!!\") <pre>MatchTemplateManager objects are equal.\n</pre>"},{"location":"examples/01_basic_configuration/#configuring-pydantic-models-in-python","title":"Configuring Pydantic models in Python\u00b6","text":"<p>This example notebook outlines the steps necessary to generate, save, and load configurations for the <code>match_template</code> program through Python object and <code>yaml</code> files. Here, we focus on how to create and modify these configurations rather than the underlying code for parsing these configurations and running the program.</p> <p>Rationale for using YAML configurations</p> <p>While the <code>Leopard-EM</code> package provides an object-oriented Python API for extending template matching into more complex workflows, it is useful to have a human-readable, easily editable, and shareable configuration file because:</p> <ol> <li>It increases reproducibility by keeping a record of exact parameters used for a particular run,</li> <li>It can be quickly modified during development, debugging, and testing without changing underlying code, and</li> <li>It can be replicated across large datasets (e.g. multiple images with similar configurations) for execution on distributed clusters.</li> </ol> <p>We find that storing configurations in a structured file format strikes a good balance between user-friendliness and programmatic control.</p>"},{"location":"examples/01_basic_configuration/#importing-necessary-classes-and-functions","title":"Importing Necessary Classes and Functions\u00b6","text":"<p>We utilize Pydantic to create Python objects that parse, validate, and serialize configurations. These objects (called Pydantic models) are laid out in a hierarchial structure with a single root \"manager\" model. Below we import all the configuration classes (along with other libraries) we will detail usage of in this notebook.</p>"},{"location":"examples/01_basic_configuration/#the-opticsgroup-model","title":"The OpticsGroup Model\u00b6","text":"<p>The <code>OpticsGroup</code> model is a container for microscope imaging parameters necessary for calculating filters (e.g. contrast transfer functions). We follow the fields that are defined in RELION's optics group .star file, and the class has the following attributes:</p> <ul> <li><code>label</code>: A unique label for the optics group, usually contains some form of the micrograph name but can be any string.</li> <li><code>pixel_size</code>: Float value representing the pixel size of the image, in Angstroms.</li> <li><code>voltage</code>: The voltage of the microscope, in kV.</li> <li><code>spherical_aberration</code>: The spherical aberration of the microscope, in mm, with the default value of 2.7 mm.</li> <li><code>amplitude_contrast_ratio</code>: The amplitude contrast ratio (unitless) with the default value of 0.07.</li> <li><code>phase_shift</code>: Additional phase shift to apply across the CTF, in degrees, with the default value of 0.0.</li> <li><code>defocus_u</code>: Defocus of the micrograph along the major axis, in Angstroms.</li> <li><code>defocus_v</code>: Defocus of the micrograph along the minor axis, in Angstroms.</li> <li><code>astigmatism_angle</code>: Angle of the defocus astigmatism (relative to the x-axis), in degrees. The default value is 0.0.</li> <li><code>ctf_B_factor</code>: An additional b-factor to apply to the CTF, in Angstroms^2. The default value is 0.0.</li> </ul> <p>There are other unused fields in the class that are not detailed here. See the Pydantic model API documentation for more information.</p>"},{"location":"examples/01_basic_configuration/#creating-an-instance-of-the-opticsgroup-model","title":"Creating an instance of the OpticsGroup model\u00b6","text":"<p>Below, we create an instance of the <code>OpticsGroup</code> model with some made-up but nevertheless realistic values.</p>"},{"location":"examples/01_basic_configuration/#serializing-an-instance-of-the-opticsgroup-model","title":"Serializing an instance of the OpticsGroup model\u00b6","text":"<p>Pydantic has built-in functionality, namely the <code>model_dump()</code>, for generating a dictionary of key, value pairs from the model attributes and their values. Below, we create a dictionary from the <code>my_optics_group</code> instance and print it out. Note that extra, unused fields are still included in the dictionary.</p>"},{"location":"examples/01_basic_configuration/#exporting-configurations-to-a-yaml-file","title":"Exporting configurations to a YAML file\u00b6","text":"<p>YAML files are nothing more than a bunch of key-value pairs in a human-readable format. Like JSON, YAML has parser functions/libraries in most programming languages increasing their interoperability. We adopt the <code>.yaml</code> format (and actually the <code>.json</code> format too, but not detailed here) for our configuration files rather than less-common formats specific to a sub-field or program.</p> <p>The <code>OpticsGroup</code> model (and all the other Pydanic models discussed here) have a <code>to_yaml()</code> method that writes the model to a YAML file. Below, we first specify a path and then call the <code>to_yaml()</code> method on the <code>my_optics_group</code> instance to write the model to a file.</p>"},{"location":"examples/01_basic_configuration/#importing-configurations-from-a-yaml-file","title":"Importing configurations from a YAML file\u00b6","text":"<p>Each model also has the <code>from_yaml()</code> method which can be to instantiate the class from contents in a <code>.yaml</code> file. Below, we are creating a new instance of the <code>OpticsGroup</code> class from the <code>optics_group.yaml</code> file.</p>"},{"location":"examples/01_basic_configuration/#the-orientationsearchconfig-model","title":"The OrientationSearchConfig Model\u00b6","text":"<p>Two-dimensional template matching necessitates covering SO(3) orientation space to find the \"best\" orientation match for a particle. How points are sampled during the search process is handled by the <code>OrientationSearchConfig</code> model. This model effectively acts as an interface with the torch-so3 package, which provides the underlying functionality for generating uniform grids on SO(3).</p> <p>The class has the following attributes:</p> <ul> <li><code>psi_step</code>: The psi step size (in units of degrees) with a default value of 1.5 degrees.</li> <li><code>theta_step</code>: The theta step size (in units of degrees) with a default value of 2.5 degrees.</li> <li><code>phi_min</code>: The minimum value for the $\\phi$ Euler angle (in degrees) with a default value of 0.0.</li> <li><code>phi_max</code>: The maximum value for the $\\phi$ Euler angle (in degrees) with a default value of 360.0.</li> <li><code>theta_min</code>: The minimum value for the $\\theta$ Euler angle (in degrees) with a default value of 0.0.</li> <li><code>theta_max</code>: The maximum value for the $\\theta$ Euler angle (in degrees) with a default value of 180.0.</li> <li><code>psi_min</code>: The minimum value for the $\\psi$ Euler angle (in degrees) with a default value of 0.0.</li> <li><code>psi_max</code>: The maximum value for the $\\psi$ Euler angle (in degrees) with a default value of 360.0.</li> <li><code>base_grid_method</code>: The method used to generate the base S2 grid. Allowed values are <code>\"uniform\"</code> and <code>\"healpix\"</code>. The default value is <code>\"uniform\"</code>.</li> <li><code>symmetry</code>: Specify the template symmetry to automatically restrict the angular search space. Default <code>\"C1\"</code>. Note, this is ignored if manual angular ranges are given.</li> </ul> <p>Note that the default min/max values set the search space to cover SO(3) for a particle with <code>\"C1\"</code> symmetry.</p>"},{"location":"examples/01_basic_configuration/#the-defocussearchconfig-model","title":"The DefocusSearchConfig Model\u00b6","text":"<p>Two-dimensional template matching is also sensitive to the relative defocus of a particle allowing the estimation of the Z-height in a sample. The <code>DefocusSearchConfig</code> model handles which defocus planes are searched over (relative to the defocus parameters defined in the <code>OpticsGroup</code> model).</p> <p>The model has the following attributes:</p> <ul> <li><code>enabled</code>: A boolean value indicating whether defocus search is enabled. The default value is <code>True</code>. If <code>False</code>, then only the defocus value defined in the <code>OpticsGroup</code> model is used.</li> <li><code>defocus_min</code>: The minimum relative defocus value (in Angstroms) to search.</li> <li><code>defocus_max</code>: The maximum relative defocus value (in Angstroms) to search.</li> <li><code>defocus_step</code>: The increment between searched defocus planes (in Angstroms).</li> </ul> <p>These parameters will generate a set of relative defocus planes searched over according to $$[\\text{f}_\\text{min}, \\text{f}_\\text{min} + \\Delta\\text{f}, + \\text{f}_\\text{min} + 2\\Delta\\text{f}, \\dots, \\text{f}_\\text{max}]$$ which is effectively the following range object in Python:</p> <pre>range(defocus_min, defocus_max + defocus_step, defocus_step)\n</pre>"},{"location":"examples/01_basic_configuration/#the-defocussearchconfigdefocus_values-property","title":"The <code>DefocusSearchConfig.defocus_values</code> property\u00b6","text":"<p>Once a <code>DefocusSearchConfig</code> model is instantiated, there is the helpful <code>defocus_values</code> property that returns a list of relative defocus values to search over.</p>"},{"location":"examples/01_basic_configuration/#fourier-filters-in-the-preprocessingfilters-model","title":"Fourier filters in the PreprocessingFilters Model\u00b6","text":"<p>Template matching necessitates the use of Fourier filters to preprocess the input image (e.g. spectral whitening). The <code>PreprocessingFilters</code> model handles the configuration of the following filter types:</p> <ul> <li>Spectral whitening under the <code>whitening_filter</code> attribute</li> <li>Bandpass filtering, with the option for smooth transitions, under the <code>bandpass_filter</code> attribute.</li> <li>Phase randomization above a certain frequency using the <code>phase_randomization_filter</code> attribute.</li> <li>Options for a user-defined arbitrary curve filter under the <code>arbitrary_curve_filter</code> attribute.</li> </ul> <p>Together, all these filter types allow fine control over how an input image is preprocessed before template matching. Each filter type is itself a Pydantic model with its own set of attributes.</p>"},{"location":"examples/01_basic_configuration/#whiteningfilterconfig","title":"WhiteningFilterConfig\u00b6","text":"<p>The <code>WhiteningFilterConfig</code> model handles the configuration of the spectral whitening filter. When applied the image, the power spectral density should become flat and the noise distribution is white (i.e. uncorrelated).</p> <p>The whitening filter is enabled by default and has the following attributes:</p> <ul> <li><code>enabled</code>: A boolean value indicating whether the whitening filter is enabled.</li> <li><code>num_freq_bins</code>: An optional integer specifying the number of frequency bins used when calculating the power spectral density. This parameter is automatically calculated based on the input image size if not provided.</li> <li><code>max_freq</code>: An optional float specifying the maximum spatial frequency (in terms of Nyquist) to use when calculating the whitening filter. Frequencies above this value are set to <code>1.0</code>, that is, unscaled. The default value is <code>0.5</code> which corresponds to the Nyquist frequency.</li> <li><code>do_power_spectrum</code>: Boolean indicating weather the whitening filter should be calculated over the power spectrum or amplitude spectrum. The default value is <code>True</code> and the power spectrum is used.</li> </ul> <p>Below, we create a default instance of the <code>WhiteningFilterConfig</code> model.</p>"},{"location":"examples/01_basic_configuration/#bandpassfilterconfig","title":"BandpassFilterConfig\u00b6","text":"<p>The <code>BandpassFilterConfig</code> model handles the configuration of the bandpass filter.</p> <p>The bandpass filter is disabled by default and has the following attributes:</p> <ul> <li><code>enabled</code>: A boolean value indicating whether the bandpass filter is enabled.</li> <li><code>low_freq_cutoff</code>: The low-pass cutoff frequency (in terms of Nyquist) for the bandpass filter.</li> <li><code>high_freq_cutoff</code>: The high-pass cutoff frequency (in terms of Nyquist) for the bandpass filter.</li> <li><code>falloff</code>: The falloff factor (using a cosine function) for the bandpass filter. A value of <code>0.0</code> (default) corresponds to a hard cutoff with values in the range <code>(0.0, 0.1)</code> providing a smooth, but distinct, transition.</li> </ul> <p>When disabled, the bandpass filter is not applied to the input image. Nonetheless, we create a default instance of the <code>BandpassFilterConfig</code> model below.</p>"},{"location":"examples/01_basic_configuration/#phaserandomizationfilterconfig","title":"PhaseRandomizationFilterConfig\u00b6","text":"<p>The <code>PhaseRandomizationFilterConfig</code> model hold parameters defining a phase randomization filter. This filter keeps the amplitudes of Fourier components above a certain frequency the same, but randomizes their phases. This is useful for testing the robustness of template matching algorithms to noise.</p> <p>The model is disabled by default has the following attributes:</p> <ul> <li><code>enabled</code>: A boolean value indicating whether the phase randomization filter is enabled.</li> <li><code>cuton</code>: The cuton frequency (in terms of Nyquist) for the phase randomization filter. Frequencies above this value are randomized.</li> </ul> <p>Below, we create a default instance of the <code>PhaseRandomizationFilterConfig</code> model.</p>"},{"location":"examples/01_basic_configuration/#arbitrarycurvefilterconfig","title":"ArbitraryCurveFilterConfig\u00b6","text":"<p>We also provide a model for defining an arbitrary curve filter for preprocessing. This filter takes a set of spatial frequency values (in terms of Nyquist) and filter amplitudes at those frequencies to create a custom filter. Utilizing this filter allows for fine-grained control over how spatial frequencies should be weighted within the template matching package itself.</p> <p>The model is disabled by default has the following attributes:</p> <ul> <li><code>enabled</code>: A boolean value indicating whether the arbitrary curve filter is enabled.</li> <li><code>frequencies</code>: 1-dimensional list of floats representing the spatial frequencies (in terms of Nyquist). The list must be sorted in ascending order.</li> <li><code>amplitudes</code>: 1-dimensional list of floats representing the filter amplitudes at the corresponding frequencies. The list must be the same length as <code>frequencies</code>.</li> </ul> <p>Below, we create a default instance of the <code>ArbitraryCurveFilterConfig</code> mode; it is disabled and has no frequencies or amplitudes set.</p>"},{"location":"examples/01_basic_configuration/#putting-the-filters-together-in-the-preprocessingfilters-model","title":"Putting the filters together in the PreprocessingFilters Model\u00b6","text":"<p>We now construct the <code>PreprocessingFilters</code> model with the instances of the four filter models we created above.</p>"},{"location":"examples/01_basic_configuration/#computationalconfig","title":"ComputationalConfig\u00b6","text":"<p>The <code>ComputationalConfig</code> model handles the GPU ids to use for template matching as well as the number of streams to run concurrently on each device. The model has the following attributes:</p> <ul> <li><code>gpu_ids</code>: A list of integers representing the GPU ids to use for template matching. The default value is <code>[0]</code> which corresponds to the first GPU.</li> <li><code>num_cpus</code>: A positive integer corresponding to the number of streams to run concurrently on each device with a default of <code>1</code>.</li> </ul> <p>Below, we create a new instance of the <code>ComputationalConfig</code> model with the default GPU id list.</p>"},{"location":"examples/01_basic_configuration/#specifying-result-output-with-the-matchtemplateresult-model","title":"Specifying result output with the MatchTemplateResult Model\u00b6","text":"<p>We almost have a complete set of configurations for the <code>match-template</code> program, but we still need to specify where to save results after the program completes. The <code>MatchTemplateResult</code> model handles this by specifying output file paths. The model also has handy class methods for analyzing results and picking particles, but this is discussed elsewhere in the documentation.</p>"},{"location":"examples/01_basic_configuration/#user-definable-attributes","title":"User-definable attributes\u00b6","text":"<p>The model has the following user-definable attributes:</p> <ul> <li><code>allow_file_overwrite</code>: A boolean value indicating whether the program should be allowed to overwrite existing files. The default value is <code>False</code> and will raise an error if a file already exists.</li> <li><code>mip_path</code>: The path to save the maximum intensity projection (MIP) image.</li> <li><code>scaled_mip_path</code>: The path to save the scaled MIP (a.k.a z-score or SNR) image.</li> <li><code>correlation_average_path</code>: The path to save the average correlation value per pixel.</li> <li><code>correlation_variance_path</code>: The path to save the variance of the correlation value per pixel.</li> <li><code>orientation_psi_path</code>: The path to save the best $\\psi$ Euler angle map.</li> <li><code>orientation_theta_path</code>: The path to save the best $\\theta$ Euler angle map.</li> <li><code>orientation_phi_path</code>: The path to save the best $\\phi$ Euler angle map.</li> <li><code>relative_defocus_path</code>: The path to save the best relative defocus map.</li> </ul>"},{"location":"examples/01_basic_configuration/#attributes-updated-after-template-matching","title":"Attributes updated after template matching\u00b6","text":"<p>There are additional attributes in the model which automatically get updated after template matching is complete:</p> <ul> <li><code>total_projections</code>: The total number of projections (\\text{orientations} \\times \\text{defocus planes}) searched over.</li> <li><code>total_orientations</code>: The total number of orientations searched over.</li> <li><code>total_defocus</code>: The total number of defocus planes searched over.</li> </ul>"},{"location":"examples/01_basic_configuration/#creating-an-instance-of-the-matchtemplateresult-model","title":"Creating an instance of the MatchTemplateResult model\u00b6","text":"<p>Below, we specify the necessary output paths for the <code>MatchTemplateResult</code> model. Note that this configuration will output the images into thee current working directory. You will need to update these paths to whatever is appropriate for your system.</p>"},{"location":"examples/01_basic_configuration/#root-matchtemplateconfig-model","title":"Root MatchTemplateConfig Model\u00b6","text":"<p>Finally, we have all the components which go into the root <code>MatchTemplateConfig</code> model. This model is the top-level configuration object that contains all the other models as attributes along with <code>micrograph_path</code> and <code>template_volume_path</code> which point to the input micrograph and simulated reference template volume, respectfully.</p> <p>Below, we create our instance of the <code>MatchTemplateConfig</code> model. Note that you will need to supply the paths to the micrograph and template volume on your system; dummy paths are provided here so the code runs without error.</p>"},{"location":"examples/01_basic_configuration/#serializing-the-matchtemplateconfig-model","title":"Serializing the MatchTemplateConfig model\u00b6","text":"<p>Like discussed before, we can serialize and read the <code>MatchTemplateConfig</code> model to/from a YAML file. Below, we write the model to a file called <code>match_template_example.yaml</code>.</p>"},{"location":"examples/01_basic_configuration/#importing-the-matchtemplateconfig-model-from-a-yaml-file","title":"Importing the MatchTemplateConfig model from a YAML file\u00b6","text":"<p>Now, we re-import the configuration into a new model and check that they are the same.</p>"},{"location":"examples/01_basic_configuration/#conclusion","title":"Conclusion\u00b6","text":"<p>We have now covered the creation, serialization, and deserialization of all the configuration models necessary for the <code>match-template</code> program. This script will create the <code>match_template_example.yaml</code> file in the current working directory whose file contents should match what is listed below. Modifying this file and using it as input to the <code>match-template</code> program will allow you to run the program with the specified configurations. Note that a default YAML configuration can also be found in the GitHub page.</p> <pre>computational_config:\n  gpu_ids:\n  - 0\n  num_cpus: 1\ndefocus_search_config:\n  defocus_max: 600.0\n  defocus_min: -600.0\n  defocus_step: 200.0\n  enabled: true\nmatch_template_result:\n  allow_file_overwrite: true\n  correlation_average_path: ./output_correlation_average.mrc\n  correlation_variance_path: ./output_correlation_variance.mrc\n  mip_path: ./output_mip.mrc\n  orientation_phi_path: ./output_orientation_phi.mrc\n  orientation_psi_path: ./output_orientation_psi.mrc\n  orientation_theta_path: ./output_orientation_theta.mrc\n  relative_defocus_path: ./output_relative_defocus.mrc\n  scaled_mip_path: ./output_scaled_mip.mrc\n  total_defocus: 0\n  total_orientations: 0\n  total_projections: 0\nmicrograph_path: ./dummy_micrograph.mrc\noptics_group:\n  amplitude_contrast_ratio: 0.07\n  beam_tilt_x: null\n  beam_tilt_y: null\n  chromatic_aberration: 0.0\n  ctf_B_factor: 60.0\n  astigmatism_angle: 25.0\n  defocus_u: 5200.0\n  defocus_v: 4950.0\n  even_zernike: null\n  label: my_optics_group\n  mtf_reference: null\n  mtf_values: null\n  odd_zernike: null\n  phase_shift: 0.0\n  pixel_size: 1.06\n  spherical_aberration: 2.7\n  voltage: 300.0\n  zernike_moments: null\norientation_search_config:\n  base_grid_method: uniform\n  psi_step: 4.0\n  theta_step: 4.0\n  phi_max: 360.0\n  phi_min: 0.0\n  psi_max: 360.0\n  psi_min: 0.0\n  theta_max: 180.0\n  theta_min: 0.0\npreprocessing_filters:\n  arbitrary_curve_filter:\n    amplitudes: null\n    enabled: false\n    frequencies: null\n  bandpass_filter:\n    enabled: false\n    falloff: null\n    high_freq_cutoff: null\n    low_freq_cutoff: null\n  phase_randomization_filter:\n    cuton: null\n    enabled: false\n  whitening_filter:\n    do_power_spectrum: true\n    enabled: true\n    max_freq: 0.5\n    num_freq_bins: null\ntemplate_volume_path: ./dummy_template_volume.mrc\n</pre>"},{"location":"examples/02_extract_peak_info/","title":"Extracting results from the template matching search","text":"In\u00a0[1]: Copied! <pre>\"\"\"Extracting results to DataFrame.\"\"\"\n\nfrom leopard_em.pydantic_models.managers import MatchTemplateManager\n</pre> \"\"\"Extracting results to DataFrame.\"\"\"  from leopard_em.pydantic_models.managers import MatchTemplateManager In\u00a0[2]: Copied! <pre>!zenodo_get https://doi.org/10.5281/zenodo.15426374 \\\n--glob \"60S_map_px0.936_bscale0.5.mrc\" \\\n--glob \"xenon_216_000_0_output_mip.mrc\" \\\n--glob \"xenon_216_000_0_output_scaled_mip.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_phi.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_theta.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_psi.mrc\" \\\n--glob \"xenon_216_000_0_output_relative_defocus.mrc\" \\\n--glob \"xenon_216_000_0_output_correlation_average.mrc\" \\\n--glob \"xenon_216_000_0_output_correlation_variance.mrc\"\n</pre> !zenodo_get https://doi.org/10.5281/zenodo.15426374 \\ --glob \"60S_map_px0.936_bscale0.5.mrc\" \\ --glob \"xenon_216_000_0_output_mip.mrc\" \\ --glob \"xenon_216_000_0_output_scaled_mip.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_phi.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_theta.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_psi.mrc\" \\ --glob \"xenon_216_000_0_output_relative_defocus.mrc\" \\ --glob \"xenon_216_000_0_output_correlation_average.mrc\" \\ --glob \"xenon_216_000_0_output_correlation_variance.mrc\" <pre>Title: 2DTM inputs and program results from the Leopard-EM Python package\nKeywords: \nPublication date: 2025-05-15\nDOI: 10.5281/zenodo.15426374\nTotal size: 948.2 MB\n\nDownloading (1/9):\nFile: xenon_216_000_0_output_relative_defocus.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_relative_defocus.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_relative_defocus.mrc. (eb62fdd477b14f5b618f970fb635e7e8)\n\nDownloading (2/9):\nFile: 60S_map_px0.936_bscale0.5.mrc (536.9 MB)\nLink: https://zenodo.org/api/records/15426374/files/60S_map_px0.936_bscale0.5.mrc/content\n100% [..................................................] 536871936 / 536871936\nChecksum is correct for 60S_map_px0.936_bscale0.5.mrc. (4419d7ac93f5492b5f27a8a410b3d1fd)\n\nDownloading (3/9):\nFile: xenon_216_000_0_output_scaled_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_scaled_mip.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_scaled_mip.mrc. (20b1e6099fe4248fac106824d1aa65a5)\n\nDownloading (4/9):\nFile: xenon_216_000_0_output_orientation_psi.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_psi.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_orientation_psi.mrc. (65e8bf20a90f131ce86bf64c630ee5e1)\n\nDownloading (5/9):\nFile: xenon_216_000_0_output_orientation_phi.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_phi.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_orientation_phi.mrc. (6c51d9b315f2b59e930fbc54d3a4fcfd)\n\nDownloading (6/9):\nFile: xenon_216_000_0_output_correlation_average.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_correlation_average.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_correlation_average.mrc. (e0c1c298055f1d765b557ab3363e0d32)\n\nDownloading (7/9):\nFile: xenon_216_000_0_output_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_mip.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_mip.mrc. (e913d42e86d84d521746ae90eec9d6fe)\n\nDownloading (8/9):\nFile: xenon_216_000_0_output_orientation_theta.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_theta.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_orientation_theta.mrc. (8c852dce6182df6d2f7153d1c70cce98)\n\nDownloading (9/9):\nFile: xenon_216_000_0_output_correlation_variance.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_correlation_variance.mrc/content\n100% [....................................................] 51409924 / 51409924\nChecksum is correct for xenon_216_000_0_output_correlation_variance.mrc. (2a7ffb937e05a6374f751cacb48e4908)\n\nAll specified files have been processed.\n</pre> In\u00a0[3]: Copied! <pre># Update this path based on which match template config you want to use\nyaml_path = \"02_extract_peak_info_config.yaml\"\n\n# Instantiate the MatchTemplateManager from the config and get the result object\nmt_manager = MatchTemplateManager.from_yaml(yaml_path)\nmt_result = mt_manager.match_template_result\nmt_result.load_tensors_from_paths()  # Needed to load results into memory\n</pre> # Update this path based on which match template config you want to use yaml_path = \"02_extract_peak_info_config.yaml\"  # Instantiate the MatchTemplateManager from the config and get the result object mt_manager = MatchTemplateManager.from_yaml(yaml_path) mt_result = mt_manager.match_template_result mt_result.load_tensors_from_paths()  # Needed to load results into memory In\u00a0[4]: Copied! <pre># Manually set the number of correlations; used for z-score cutoff determination\n# Is automatically calculated after an actual run\ntotal_corr = int(13 * 1.59e6)\nmt_result.total_projections = total_corr\n</pre> # Manually set the number of correlations; used for z-score cutoff determination # Is automatically calculated after an actual run total_corr = int(13 * 1.59e6) mt_result.total_projections = total_corr In\u00a0[5]: Copied! <pre>mt_result.locate_peaks()\ndf_peaks = mt_result.peaks_to_dataframe()\n\n# Print the columns in the DataFrame\nprint(\"Columns in the DataFrame:\")\nfor col in df_peaks.columns:\n    print(f\"  {col}\")\n\ndf_peaks\n</pre> mt_result.locate_peaks() df_peaks = mt_result.peaks_to_dataframe()  # Print the columns in the DataFrame print(\"Columns in the DataFrame:\") for col in df_peaks.columns:     print(f\"  {col}\")  df_peaks <pre>Columns in the DataFrame:\n  pos_y\n  pos_x\n  mip\n  scaled_mip\n  psi\n  theta\n  phi\n  relative_defocus\n  correlation_mean\n  correlation_variance\n  total_correlations\n</pre> Out[5]: pos_y pos_x mip scaled_mip psi theta phi relative_defocus correlation_mean correlation_variance total_correlations 0 3336 3470 11.810101 12.104484 301.5 90.0 302.500000 200.0 0.025537 0.973570 20670000 1 1945 3322 11.348068 11.758850 118.5 137.5 11.134021 600.0 0.130799 0.953943 20670000 2 3353 1842 11.823074 11.681293 19.5 22.5 111.272728 800.0 0.062959 1.006748 20670000 3 3452 133 11.246000 11.189375 166.5 65.0 296.793884 0.0 -0.028836 1.007638 20670000 4 3249 1811 11.394345 11.041210 243.0 130.0 52.363636 400.0 -0.032740 1.034949 20670000 ... ... ... ... ... ... ... ... ... ... ... ... 193 1733 2254 7.664472 7.848475 315.0 90.0 350.000000 -400.0 0.042711 0.971114 20670000 194 2300 1376 7.992585 7.818872 153.0 105.0 106.187050 -200.0 0.133709 1.005116 20670000 195 1819 1945 7.570004 7.792142 45.0 107.5 328.467163 200.0 0.016312 0.969399 20670000 196 2183 2747 7.620340 7.788315 255.0 82.5 234.125870 400.0 0.082988 0.967777 20670000 197 897 2553 7.862420 7.782097 7.5 142.5 0.000000 -1000.0 0.046521 1.004344 20670000 <p>198 rows \u00d7 11 columns</p> In\u00a0[6]: Copied! <pre>df_full = mt_manager.results_to_dataframe()\n\n# Print the columns in the DataFrame\nprint(\"Columns in the DataFrame:\")\nfor col in df_full.columns:\n    print(f\"  {col}\")\n\ndf_full\n</pre> df_full = mt_manager.results_to_dataframe()  # Print the columns in the DataFrame print(\"Columns in the DataFrame:\") for col in df_full.columns:     print(f\"  {col}\")  df_full <pre>Columns in the DataFrame:\n  particle_index\n  mip\n  scaled_mip\n  correlation_mean\n  correlation_variance\n  total_correlations\n  pos_x\n  pos_y\n  pos_x_img\n  pos_y_img\n  pos_x_img_angstrom\n  pos_y_img_angstrom\n  phi\n  theta\n  psi\n  relative_defocus\n  defocus_u\n  defocus_v\n  astigmatism_angle\n  pixel_size\n  refined_pixel_size\n  voltage\n  spherical_aberration\n  amplitude_contrast_ratio\n  phase_shift\n  ctf_B_factor\n  micrograph_path\n  template_path\n  mip_path\n  scaled_mip_path\n  psi_path\n  theta_path\n  phi_path\n  defocus_path\n  correlation_average_path\n  correlation_variance_path\n</pre> Out[6]: particle_index mip scaled_mip correlation_mean correlation_variance total_correlations pos_x pos_y pos_x_img pos_y_img ... micrograph_path template_path mip_path scaled_mip_path psi_path theta_path phi_path defocus_path correlation_average_path correlation_variance_path 0 0 11.810101 12.104484 0.025537 0.973570 20670000 3470 3336 3726 3592 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 1 1 11.348068 11.758850 0.130799 0.953943 20670000 3322 1945 3578 2201 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 2 2 11.823074 11.681293 0.062959 1.006748 20670000 1842 3353 2098 3609 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 3 3 11.246000 11.189375 -0.028836 1.007638 20670000 133 3452 389 3708 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 4 4 11.394345 11.041210 -0.032740 1.034949 20670000 1811 3249 2067 3505 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 193 193 7.664472 7.848475 0.042711 0.971114 20670000 2254 1733 2510 1989 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 194 194 7.992585 7.818872 0.133709 1.005116 20670000 1376 2300 1632 2556 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 195 195 7.570004 7.792142 0.016312 0.969399 20670000 1945 1819 2201 2075 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 196 196 7.620340 7.788315 0.082988 0.967777 20670000 2747 2183 3003 2439 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 197 197 7.862420 7.782097 0.046521 1.004344 20670000 2553 897 2809 1153 ... dummy_micrograph.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc <p>198 rows \u00d7 36 columns</p>"},{"location":"examples/02_extract_peak_info/#extracting-results-from-the-template-matching-search","title":"Extracting results from the template matching search\u00b6","text":"<p>After running through a template matching process, we have a set of location, correlation, and orientation statistics that need parsed. For example, peaks need to be picked from the z-score map, and the corresponding best orientations and defoci at those locations need to be read. While the necessary information can be grabbed from a configuration file and array-like objects, having a tabular data format is more flexible to work with. The default <code>match_template</code> program script does export a csv file with picked peaks by default, but you may want to go back and re-extract results in a different way.</p> <p>This example goes through the very basics of loading a manager object from a YAML config and then extracting the peak information from the results into a <code>pandas.DataFrame</code> object.</p>"},{"location":"examples/02_extract_peak_info/#downloading-example-data","title":"Downloading example data\u00b6","text":"<p>Run the following code cell to download pre-processed results into the current directory of the notebook. This is dependent on the <code>zenodo-get</code> package which should come pre-installed with Leopard-EM</p> <p>If you have an actual result already on your system, you can proceed with that configuration file.</p>"},{"location":"examples/02_extract_peak_info/#loading-a-configuration","title":"Loading a configuration\u00b6","text":"<p>Here, we use an example configuration file to demonstrate how to extract the relevant information. If you've already run template matching, then this information should already be present in the <code>MatchTemplateManager</code> instance. Or you can load your actual configuration file.</p>"},{"location":"examples/02_extract_peak_info/#extracting-minimal-peak-information","title":"Extracting minimal peak information\u00b6","text":"<p>Minimal information at the peaks (location, orientation, peak height) can be extracted from the <code>MatchTemplateResult</code> instance as either a <code>dict</code> or <code>pandas.DataFrame</code>. Here, we show how to extract the information as a <code>pandas.DataFrame</code>.</p>"},{"location":"examples/02_extract_peak_info/#converting-full-result-information-to-a-dataframe","title":"Converting full result information to a DataFrame\u00b6","text":"<p>The <code>MatchTemplateManager</code> class also has a method, <code>results_to_dataframe</code>, which populates a <code>pandas.DataFrame</code> with all necessary information for (most) downstream processing. The additional columns include paths to the result statistic maps, original micrograph, and the reference template used for the template matching process.</p>"},{"location":"examples/03_compare_scoring_metrics/","title":"Comparing 2DTM scoring metrics","text":"In\u00a0[1]: Copied! <pre>\"\"\"2DTM scoring metrics.\"\"\"\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport mrcfile\nimport numpy as np\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes\n\nfrom leopard_em.analysis.gev_fit_metric import fit_gev_to_zscore\nfrom leopard_em.analysis.pvalue_metric import (\n    _params_to_multivariate_normal,\n    fit_full_cov_gaussian_2d,\n    probit_transform,\n)\nfrom leopard_em.analysis.zscore_metric import gaussian_noise_zscore_cutoff\n\nplt.rcParams[\"figure.dpi\"] = 120  # Increase resolution of plots\n</pre> \"\"\"2DTM scoring metrics.\"\"\"  import matplotlib as mpl import matplotlib.pyplot as plt import mrcfile import numpy as np from mpl_toolkits.axes_grid1.inset_locator import inset_axes  from leopard_em.analysis.gev_fit_metric import fit_gev_to_zscore from leopard_em.analysis.pvalue_metric import (     _params_to_multivariate_normal,     fit_full_cov_gaussian_2d,     probit_transform, ) from leopard_em.analysis.zscore_metric import gaussian_noise_zscore_cutoff  plt.rcParams[\"figure.dpi\"] = 120  # Increase resolution of plots In\u00a0[2]: Copied! <pre>!zenodo_get https://doi.org/10.5281/zenodo.15426374 \\\n--glob \"xenon_216_000_0_output_mip.mrc\" \\\n--glob \"xenon_216_000_0_output_scaled_mip.mrc\"\n</pre> !zenodo_get https://doi.org/10.5281/zenodo.15426374 \\ --glob \"xenon_216_000_0_output_mip.mrc\" \\ --glob \"xenon_216_000_0_output_scaled_mip.mrc\" <pre>Title: 2DTM inputs and program results from the Leopard-EM Python package\nKeywords: \nPublication date: 2025-05-15\nDOI: 10.5281/zenodo.15426374\nTotal size: 102.8 MB\n\nDownloading (1/2):\nFile: xenon_216_000_0_output_scaled_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_scaled_mip.mrc/content\nxenon_216_000_0_output_scaled_mip.mrc is already downloaded correctly.\n\nDownloading (2/2):\nFile: xenon_216_000_0_output_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_mip.mrc/content\nxenon_216_000_0_output_mip.mrc is already downloaded correctly.\n\nAll specified files have been processed.\n</pre> In\u00a0[3]: Copied! <pre>mip = mrcfile.open(\"xenon_216_000_0_output_mip.mrc\", mode=\"r\").data.copy()\nscaled_mip = mrcfile.open(\"xenon_216_000_0_output_scaled_mip.mrc\", mode=\"r\").data.copy()\n</pre> mip = mrcfile.open(\"xenon_216_000_0_output_mip.mrc\", mode=\"r\").data.copy() scaled_mip = mrcfile.open(\"xenon_216_000_0_output_scaled_mip.mrc\", mode=\"r\").data.copy() In\u00a0[4]: Copied! <pre>num_orientations = 1584480\nnum_defocus = 13\ntotal_correlations = num_orientations * num_defocus\n</pre> num_orientations = 1584480 num_defocus = 13 total_correlations = num_orientations * num_defocus In\u00a0[5]: Copied! <pre># Calculating our z-score cutoff\napr_zscore_cutoff = gaussian_noise_zscore_cutoff(\n    total_correlations * mip.size, false_positives=1.0\n)\nprint(f\"A priori z-score cutoff: {apr_zscore_cutoff:.3f}\")\n</pre> # Calculating our z-score cutoff apr_zscore_cutoff = gaussian_noise_zscore_cutoff(     total_correlations * mip.size, false_positives=1.0 ) print(f\"A priori z-score cutoff: {apr_zscore_cutoff:.3f}\") <pre>A priori z-score cutoff: 7.775\n</pre> In\u00a0[6]: Copied! <pre># Create grid of number of pixels and search space size\nx = np.logspace(9, 12.5, num=32, base=2)  # Image width\ny = np.logspace(4, 8.5, num=32, base=10)  # Search space size\nxx, yy = np.meshgrid(x, y)\n\n# Calculate z-score cutoff for each pixel\nzscore_cutoffs = np.zeros_like(xx)\nfor i in range(xx.shape[0]):\n    for j in range(xx.shape[1]):\n        num_pixels = int(xx[i, j] ** 2)\n        search_space_size = int(yy[i, j])\n        zscore_cutoffs[i, j] = gaussian_noise_zscore_cutoff(\n            num_ccg=num_pixels * search_space_size,\n            false_positives=1.0,\n        )\n\n# Contour plot of z-score cutoff\nplt.figure(figsize=(8, 6))\nplt.contourf(xx, yy, zscore_cutoffs, levels=20, cmap=\"viridis\")\nplt.colorbar(label=\"Z-score cutoff\")\n\n# Lines corresponding to the results we are investigating\nplt.axvline(x=mip.size**0.5, color=\"k\", linestyle=\"--\", label=\"Our MIP width\")\nplt.axhline(y=total_correlations, color=\"k\", linestyle=\"--\", label=\"Total Correlations\")\nplt.scatter(\n    mip.size**0.5,\n    total_correlations,\n    color=\"red\",\n    marker=\"o\",\n    label=f\"cutoff: {apr_zscore_cutoff:.3f}\",\n)\n\nplt.xscale(\"log\", base=2)\nplt.xticks(\n    ticks=[2**i for i in range(9, 13)],\n    labels=[f\"{int(2**i)}\" for i in range(9, 13)],\n)\nplt.yscale(\"log\", base=10)\nplt.xlabel(\"Max intensity projection width (pixels, square)\")\nplt.ylabel(\"Search space size\")\nplt.title(\"A priori determined z-score cutoffs\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</pre> # Create grid of number of pixels and search space size x = np.logspace(9, 12.5, num=32, base=2)  # Image width y = np.logspace(4, 8.5, num=32, base=10)  # Search space size xx, yy = np.meshgrid(x, y)  # Calculate z-score cutoff for each pixel zscore_cutoffs = np.zeros_like(xx) for i in range(xx.shape[0]):     for j in range(xx.shape[1]):         num_pixels = int(xx[i, j] ** 2)         search_space_size = int(yy[i, j])         zscore_cutoffs[i, j] = gaussian_noise_zscore_cutoff(             num_ccg=num_pixels * search_space_size,             false_positives=1.0,         )  # Contour plot of z-score cutoff plt.figure(figsize=(8, 6)) plt.contourf(xx, yy, zscore_cutoffs, levels=20, cmap=\"viridis\") plt.colorbar(label=\"Z-score cutoff\")  # Lines corresponding to the results we are investigating plt.axvline(x=mip.size**0.5, color=\"k\", linestyle=\"--\", label=\"Our MIP width\") plt.axhline(y=total_correlations, color=\"k\", linestyle=\"--\", label=\"Total Correlations\") plt.scatter(     mip.size**0.5,     total_correlations,     color=\"red\",     marker=\"o\",     label=f\"cutoff: {apr_zscore_cutoff:.3f}\", )  plt.xscale(\"log\", base=2) plt.xticks(     ticks=[2**i for i in range(9, 13)],     labels=[f\"{int(2**i)}\" for i in range(9, 13)], ) plt.yscale(\"log\", base=10) plt.xlabel(\"Max intensity projection width (pixels, square)\") plt.ylabel(\"Search space size\") plt.title(\"A priori determined z-score cutoffs\") plt.legend() plt.tight_layout() plt.show() In\u00a0[7]: Copied! <pre># Fit a generalized extreme value (GEV) distribution to the z-scores\n# NOTE: this could take a while to run (1-3 mins), depending on the number of samples\ngev_opt, (shape, loc, scale) = fit_gev_to_zscore(\n    scaled_mip,\n    num_samples=1_000_000,\n    max_zscore_value=8.5,  # Prevent fitting to signal\n)\n</pre> # Fit a generalized extreme value (GEV) distribution to the z-scores # NOTE: this could take a while to run (1-3 mins), depending on the number of samples gev_opt, (shape, loc, scale) = fit_gev_to_zscore(     scaled_mip,     num_samples=1_000_000,     max_zscore_value=8.5,  # Prevent fitting to signal ) In\u00a0[8]: Copied! <pre>gev_zscore_cutoff_val = gev_opt.isf(1 / mip.size)\nprint(f\"GEV z-score cutoff: {gev_zscore_cutoff_val:.3f}\")\n</pre> gev_zscore_cutoff_val = gev_opt.isf(1 / mip.size) print(f\"GEV z-score cutoff: {gev_zscore_cutoff_val:.3f}\") <pre>GEV z-score cutoff: 7.760\n</pre> In\u00a0[9]: Copied! <pre># Create the main figure and axis\nfig, ax = plt.subplots(figsize=(8, 5))\n\n# Plot the full histogram and fitted GEV PDF on the main axis\ncounts, bins, _ = ax.hist(\n    scaled_mip.ravel(),\n    bins=64,\n    density=True,\n    label=\"Z-score histogram\",\n)\nx_vals = np.linspace(scaled_mip.min() * 0.8, scaled_mip.max() * 1.2, 500)\nax.plot(\n    x_vals,\n    gev_opt.pdf(x_vals),\n    color=\"red\",\n    label=\"GEV PDF\",\n    linestyle=\"--\",\n    alpha=0.8,\n)\nax.axvline(\n    gev_zscore_cutoff_val,\n    color=\"grey\",\n    linestyle=\":\",\n    label=f\"GEV cutoff: {gev_zscore_cutoff_val:.3f}\",\n)\nax.set_title(\"Histogram and GEV PDF\")\nax.set_xlabel(\"Z-score\")\nax.set_ylabel(\"Density\")\nax.grid()\n\n# Create an inset axis in the upper right corner (zoomed view)\naxins = inset_axes(ax, width=\"40%\", height=\"40%\", loc=\"center right\", borderpad=2)\n\naxins.hist(scaled_mip.ravel(), bins=64, density=True)\naxins.plot(x_vals, gev_opt.pdf(x_vals), color=\"red\", linestyle=\"--\", alpha=0.8)\naxins.axvline(gev_zscore_cutoff_val, color=\"grey\", linestyle=\":\")\naxins.set_xlim(6.6, 10.5)\naxins.set_ylim(0, 2e-3)  # Adjust y-limit as needed\naxins.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n\nax.legend(loc=\"upper right\")\nplt.show()\n</pre> # Create the main figure and axis fig, ax = plt.subplots(figsize=(8, 5))  # Plot the full histogram and fitted GEV PDF on the main axis counts, bins, _ = ax.hist(     scaled_mip.ravel(),     bins=64,     density=True,     label=\"Z-score histogram\", ) x_vals = np.linspace(scaled_mip.min() * 0.8, scaled_mip.max() * 1.2, 500) ax.plot(     x_vals,     gev_opt.pdf(x_vals),     color=\"red\",     label=\"GEV PDF\",     linestyle=\"--\",     alpha=0.8, ) ax.axvline(     gev_zscore_cutoff_val,     color=\"grey\",     linestyle=\":\",     label=f\"GEV cutoff: {gev_zscore_cutoff_val:.3f}\", ) ax.set_title(\"Histogram and GEV PDF\") ax.set_xlabel(\"Z-score\") ax.set_ylabel(\"Density\") ax.grid()  # Create an inset axis in the upper right corner (zoomed view) axins = inset_axes(ax, width=\"40%\", height=\"40%\", loc=\"center right\", borderpad=2)  axins.hist(scaled_mip.ravel(), bins=64, density=True) axins.plot(x_vals, gev_opt.pdf(x_vals), color=\"red\", linestyle=\"--\", alpha=0.8) axins.axvline(gev_zscore_cutoff_val, color=\"grey\", linestyle=\":\") axins.set_xlim(6.6, 10.5) axins.set_ylim(0, 2e-3)  # Adjust y-limit as needed axins.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))  ax.legend(loc=\"upper right\") plt.show() In\u00a0[10]: Copied! <pre>mip_flat = mip.ravel()\nscaled_mip_flat = scaled_mip.ravel()\n\n# 2D histogram of the flattened MIP and z-scores\nhist, xedges, yedges = np.histogram2d(\n    mip_flat,\n    scaled_mip_flat,\n    bins=100,\n    range=[(4, 14), (4, 14)],\n)\n\n# Apply a probit transform and recalculate the histogram\nmip_probit = probit_transform(mip_flat)\nscaled_mip_probit = probit_transform(scaled_mip_flat)\n\nhist_probit, xedges_probit, yedges_probit = np.histogram2d(\n    mip_probit,\n    scaled_mip_probit,\n    bins=100,\n    range=[(-6, 6), (-6, 6)],\n)\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 6))\n\n# Plot the original histogram\nc1 = ax[0].imshow(\n    hist.T,\n    origin=\"lower\",\n    extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],\n    aspect=\"auto\",\n    cmap=\"viridis\",\n    norm=mpl.colors.LogNorm(),\n)\ncbar1 = fig.colorbar(c1, ax=ax[0])\ncbar1.set_label(\"Counts\")\nax[0].set_title(\"2D Histogram of MIP and Z-score\")\nax[0].set_xlabel(\"MIP\")\nax[0].set_ylabel(\"Scaled MIP\")\n\n# Plot the probit-transformed histogram\nc2 = ax[1].imshow(\n    hist_probit.T,\n    origin=\"lower\",\n    extent=[xedges_probit[0], xedges_probit[-1], yedges_probit[0], yedges_probit[-1]],\n    aspect=\"auto\",\n    cmap=\"viridis\",\n    norm=mpl.colors.LogNorm(),\n)\ncbar2 = fig.colorbar(c2, ax=ax[1])\ncbar2.set_label(\"Counts\")\nax[1].set_title(\"2D Histogram of probit transformed MIP and Z-score\")\nax[1].set_xlabel(\"pro(MIP)\")\nax[1].set_ylabel(\"pro(z-score)\")\n\nplt.tight_layout()\nplt.show()\n</pre> mip_flat = mip.ravel() scaled_mip_flat = scaled_mip.ravel()  # 2D histogram of the flattened MIP and z-scores hist, xedges, yedges = np.histogram2d(     mip_flat,     scaled_mip_flat,     bins=100,     range=[(4, 14), (4, 14)], )  # Apply a probit transform and recalculate the histogram mip_probit = probit_transform(mip_flat) scaled_mip_probit = probit_transform(scaled_mip_flat)  hist_probit, xedges_probit, yedges_probit = np.histogram2d(     mip_probit,     scaled_mip_probit,     bins=100,     range=[(-6, 6), (-6, 6)], )  fig, ax = plt.subplots(1, 2, figsize=(12, 6))  # Plot the original histogram c1 = ax[0].imshow(     hist.T,     origin=\"lower\",     extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]],     aspect=\"auto\",     cmap=\"viridis\",     norm=mpl.colors.LogNorm(), ) cbar1 = fig.colorbar(c1, ax=ax[0]) cbar1.set_label(\"Counts\") ax[0].set_title(\"2D Histogram of MIP and Z-score\") ax[0].set_xlabel(\"MIP\") ax[0].set_ylabel(\"Scaled MIP\")  # Plot the probit-transformed histogram c2 = ax[1].imshow(     hist_probit.T,     origin=\"lower\",     extent=[xedges_probit[0], xedges_probit[-1], yedges_probit[0], yedges_probit[-1]],     aspect=\"auto\",     cmap=\"viridis\",     norm=mpl.colors.LogNorm(), ) cbar2 = fig.colorbar(c2, ax=ax[1]) cbar2.set_label(\"Counts\") ax[1].set_title(\"2D Histogram of probit transformed MIP and Z-score\") ax[1].set_xlabel(\"pro(MIP)\") ax[1].set_ylabel(\"pro(z-score)\")  plt.tight_layout() plt.show() In\u00a0[11]: Copied! <pre>x = (xedges_probit[:-1] + xedges_probit[1:]) / 2\ny = (yedges_probit[:-1] + yedges_probit[1:]) / 2\nresult = fit_full_cov_gaussian_2d(\n    data=hist_probit,\n    x_dim=x,\n    y_dim=y,\n)\nresult\n</pre> x = (xedges_probit[:-1] + xedges_probit[1:]) / 2 y = (yedges_probit[:-1] + yedges_probit[1:]) / 2 result = fit_full_cov_gaussian_2d(     data=hist_probit,     x_dim=x,     y_dim=y, ) result Out[11]: Fit Result <p>Model: Model(gaussian_pdf_2d)</p> Fit Statisticsfitting methodleastsq# function evals65# data points10000# variables6chi-square 5.0672e+09reduced chi-square 507023.580Akaike info crit. 131369.126Bayesian info crit. 131412.388R-squared 0.98158987Parametersnamevaluestandard errorrelative errorinitial valueminmaxvaryamplitude 184579.736 347.142509(0.19%)44988.0 0.00000000        infTruemu_x 0.03332879 0.00189181(5.68%)-9.769962616701378e-17       -inf        infTruemu_y 0.07231366 0.00188661(2.61%)-9.769962616701378e-17       -inf        infTruesigma_x 1.00589462 0.00189185(0.19%)1.0 0.00000000        infTruesigma_y 1.00314087 0.00188666(0.19%)1.0 0.00000000        infTruerho 0.75922226 0.00112660(0.15%)0.0-1.00000000 1.00000000TrueCorrelations (unreported values are &lt; 0.100)Parameter1Parameter 2Correlationmu_xmu_y+0.7592sigma_xsigma_y+0.5764sigma_yrho+0.5369sigma_xrho+0.5369amplitudesigma_y+0.5000amplitudesigma_x+0.5000 In\u00a0[12]: Copied! <pre># Create a 2D Gaussian random variable from the bes-fit parameters\nparams_opt = result.best_values\namplitude = params_opt.pop(\"amplitude\")\nnorm_opt = _params_to_multivariate_normal(**params_opt)\n</pre> # Create a 2D Gaussian random variable from the bes-fit parameters params_opt = result.best_values amplitude = params_opt.pop(\"amplitude\") norm_opt = _params_to_multivariate_normal(**params_opt) In\u00a0[13]: Copied! <pre># Plot the 2D Gaussian over the histogram\nfig, ax = plt.subplots(figsize=(8, 8))\nc = ax.imshow(\n    hist_probit.T,\n    origin=\"lower\",\n    extent=[xedges_probit[0], xedges_probit[-1], yedges_probit[0], yedges_probit[-1]],\n    aspect=\"auto\",\n    cmap=\"viridis\",\n    norm=mpl.colors.LogNorm(),\n)\ncbar = fig.colorbar(c, ax=ax)\ncbar.set_label(\"Counts\")\n\nz = norm_opt.pdf(np.dstack(np.meshgrid(x, y)).reshape(-1, 2))\nz = z.reshape(hist_probit.shape)\nlevels = np.logspace(-0.698, -2.5, num=5, base=10)\ncont = ax.contour(\n    x,\n    y,\n    z,\n    levels=levels[::-1],\n    colors=\"black\",\n    linestyles=\"--\",\n    linewidths=2,\n)\nax.clabel(cont, inline=True, fontsize=10, fmt=\"%.4f\")\nax.set_title(\"2D Gaussian fit to probit-transformed histogram\")\nax.set_xlabel(\"pro(MIP)\")\nax.set_ylabel(\"pro(z-score)\")\nplt.tight_layout()\nplt.show()\n</pre> # Plot the 2D Gaussian over the histogram fig, ax = plt.subplots(figsize=(8, 8)) c = ax.imshow(     hist_probit.T,     origin=\"lower\",     extent=[xedges_probit[0], xedges_probit[-1], yedges_probit[0], yedges_probit[-1]],     aspect=\"auto\",     cmap=\"viridis\",     norm=mpl.colors.LogNorm(), ) cbar = fig.colorbar(c, ax=ax) cbar.set_label(\"Counts\")  z = norm_opt.pdf(np.dstack(np.meshgrid(x, y)).reshape(-1, 2)) z = z.reshape(hist_probit.shape) levels = np.logspace(-0.698, -2.5, num=5, base=10) cont = ax.contour(     x,     y,     z,     levels=levels[::-1],     colors=\"black\",     linestyles=\"--\",     linewidths=2, ) ax.clabel(cont, inline=True, fontsize=10, fmt=\"%.4f\") ax.set_title(\"2D Gaussian fit to probit-transformed histogram\") ax.set_xlabel(\"pro(MIP)\") ax.set_ylabel(\"pro(z-score)\") plt.tight_layout() plt.show()"},{"location":"examples/03_compare_scoring_metrics/#comparing-2dtm-scoring-metrics","title":"Comparing 2DTM scoring metrics\u00b6","text":"<p>This notebook demonstrates how the three scoring metrics implemented in Leopard-EM work by visualizing the steps along each process. Data used in this notebook are hosted on Zenodo.</p>"},{"location":"examples/03_compare_scoring_metrics/#downloading-example-data","title":"Downloading Example Data\u00b6","text":"<p>Run the following code cell to download the results into the current directory of the notebook. Otherwise, place the downloaded data in the same directory as the notebook or adjust the paths in the following cell(s).</p>"},{"location":"examples/03_compare_scoring_metrics/#load-data-into-memory","title":"Load data into memory\u00b6","text":"<p>Using the <code>mrcfile</code> package to read each of the downloaded example files into a numpy array</p>"},{"location":"examples/03_compare_scoring_metrics/#known-parameters-from-2dtm-search","title":"Known parameters from 2DTM search\u00b6","text":"<p>Manually setting the number of orientations and defocus planes searched.</p>"},{"location":"examples/03_compare_scoring_metrics/#a-priori-z-score-cutoff","title":"A Priori z-score cutoff\u00b6","text":"<p>The distribution of cross-correlation values in 2DTM follows a standard normal distribution when the image contains only noise (no macromolecule of interest). Using the normal distribution assumption, we can construct the probability that a given maximum cross-correlation value corresponds to true signal rather than background noise. And by setting a value cutoff to n false-positive per image, we derive the ***A Priori* z-score cutoff**.</p> <p>The a priori z-score cutoff depends on the size of the 2DTM search space, number of pixels in the searched image, and desired number of false-positives.</p>"},{"location":"examples/03_compare_scoring_metrics/#fitted-extreme-value-distribution","title":"Fitted extreme value distribution\u00b6","text":"<p>Since 2DTM records the maximum cross-correlation value over a large search space, the background noise is distributed as a generalized extreme value distribution. We can fit our data to this distribution to capture slight deviations from idealized normal noise. Like before, a cutoff value can be derived for a given number of false positives.</p>"},{"location":"examples/03_compare_scoring_metrics/#using-the-p-value-metric","title":"Using the p-value metric\u00b6","text":"<p>The p-value metric, described in ((CITE)), fits a 2D Gaussian random variable to the probit transformed MIP and z-score map. Each pair of MIP and z-scores can then be transformed into a probability value given this fitted 2D Gaussian. Below, we step through this process but the Leopard-EM package performs all these steps automatically when given the MIP and z-score maps.</p>"},{"location":"examples/03_compare_scoring_metrics/#applying-the-probit-transformation","title":"Applying the probit transformation\u00b6","text":""},{"location":"examples/03_compare_scoring_metrics/#fitting-a-2d-gaussian-to-probit-transformed-data","title":"Fitting a 2D Gaussian to probit transformed data\u00b6","text":"<p>Fitted distribution has a full covariance matrix.</p>"},{"location":"examples/03_compare_scoring_metrics/#plot-of-the-p-value-fit","title":"Plot of the p-value fit\u00b6","text":""},{"location":"examples/04_plotting_2dtm_results/","title":"Visualizing 2DTM result","text":"In\u00a0[1]: Copied! <pre>import matplotlib.gridspec as gridspec\nimport matplotlib.pyplot as plt\nimport mrcfile\nimport numpy as np\n\nplt.rcParams[\"figure.dpi\"] = 120  # Increase resolution of plots\n</pre> import matplotlib.gridspec as gridspec import matplotlib.pyplot as plt import mrcfile import numpy as np  plt.rcParams[\"figure.dpi\"] = 120  # Increase resolution of plots In\u00a0[2]: Copied! <pre>!zenodo_get https://doi.org/10.5281/zenodo.15426374 \\\n--glob \"60S_map_px0.936_bscale0.5.mrc\" \\\n--glob \"xenon_216_000_0_output_mip.mrc\" \\\n--glob \"xenon_216_000_0_output_scaled_mip.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_phi.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_theta.mrc\" \\\n--glob \"xenon_216_000_0_output_orientation_psi.mrc\" \\\n--glob \"xenon_216_000_0_output_relative_defocus.mrc\" \\\n--glob \"xenon_216_000_0_output_correlation_average.mrc\" \\\n--glob \"xenon_216_000_0_output_correlation_variance.mrc\"\n</pre> !zenodo_get https://doi.org/10.5281/zenodo.15426374 \\ --glob \"60S_map_px0.936_bscale0.5.mrc\" \\ --glob \"xenon_216_000_0_output_mip.mrc\" \\ --glob \"xenon_216_000_0_output_scaled_mip.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_phi.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_theta.mrc\" \\ --glob \"xenon_216_000_0_output_orientation_psi.mrc\" \\ --glob \"xenon_216_000_0_output_relative_defocus.mrc\" \\ --glob \"xenon_216_000_0_output_correlation_average.mrc\" \\ --glob \"xenon_216_000_0_output_correlation_variance.mrc\" <pre>Title: 2DTM inputs and program results from the Leopard-EM Python package\nKeywords: \nPublication date: 2025-05-15\nDOI: 10.5281/zenodo.15426374\nTotal size: 948.2 MB\n\nDownloading (1/9):\nFile: xenon_216_000_0_output_relative_defocus.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_relative_defocus.mrc/content\nxenon_216_000_0_output_relative_defocus.mrc is already downloaded correctly.\n\nDownloading (2/9):\nFile: 60S_map_px0.936_bscale0.5.mrc (536.9 MB)\nLink: https://zenodo.org/api/records/15426374/files/60S_map_px0.936_bscale0.5.mrc/content\n60S_map_px0.936_bscale0.5.mrc is already downloaded correctly.\n\nDownloading (3/9):\nFile: xenon_216_000_0_output_scaled_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_scaled_mip.mrc/content\nxenon_216_000_0_output_scaled_mip.mrc is already downloaded correctly.\n\nDownloading (4/9):\nFile: xenon_216_000_0_output_orientation_psi.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_psi.mrc/content\nxenon_216_000_0_output_orientation_psi.mrc is already downloaded correctly.\n\nDownloading (5/9):\nFile: xenon_216_000_0_output_orientation_phi.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_phi.mrc/content\nxenon_216_000_0_output_orientation_phi.mrc is already downloaded correctly.\n\nDownloading (6/9):\nFile: xenon_216_000_0_output_correlation_average.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_correlation_average.mrc/content\nxenon_216_000_0_output_correlation_average.mrc is already downloaded correctly.\n\nDownloading (7/9):\nFile: xenon_216_000_0_output_mip.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_mip.mrc/content\nxenon_216_000_0_output_mip.mrc is already downloaded correctly.\n\nDownloading (8/9):\nFile: xenon_216_000_0_output_orientation_theta.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_orientation_theta.mrc/content\nxenon_216_000_0_output_orientation_theta.mrc is already downloaded correctly.\n\nDownloading (9/9):\nFile: xenon_216_000_0_output_correlation_variance.mrc (51.4 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0_output_correlation_variance.mrc/content\nxenon_216_000_0_output_correlation_variance.mrc is already downloaded correctly.\n\nAll specified files have been processed.\n</pre> In\u00a0[3]: Copied! <pre>mip = mrcfile.open(\"xenon_216_000_0_output_mip.mrc\", mode=\"r\").data.copy()\nscaled_mip = mrcfile.open(\"xenon_216_000_0_output_scaled_mip.mrc\", mode=\"r\").data.copy()\ncorrelation_average = mrcfile.open(\n    \"xenon_216_000_0_output_correlation_average.mrc\", mode=\"r\"\n).data.copy()\ncorrelation_variance = mrcfile.open(\n    \"xenon_216_000_0_output_correlation_variance.mrc\", mode=\"r\"\n).data.copy()\norientation_phi = mrcfile.open(\n    \"xenon_216_000_0_output_orientation_phi.mrc\", mode=\"r\"\n).data.copy()\norientation_theta = mrcfile.open(\n    \"xenon_216_000_0_output_orientation_theta.mrc\", mode=\"r\"\n).data.copy()\norientation_psi = mrcfile.open(\n    \"xenon_216_000_0_output_orientation_psi.mrc\", mode=\"r\"\n).data.copy()\n</pre> mip = mrcfile.open(\"xenon_216_000_0_output_mip.mrc\", mode=\"r\").data.copy() scaled_mip = mrcfile.open(\"xenon_216_000_0_output_scaled_mip.mrc\", mode=\"r\").data.copy() correlation_average = mrcfile.open(     \"xenon_216_000_0_output_correlation_average.mrc\", mode=\"r\" ).data.copy() correlation_variance = mrcfile.open(     \"xenon_216_000_0_output_correlation_variance.mrc\", mode=\"r\" ).data.copy() orientation_phi = mrcfile.open(     \"xenon_216_000_0_output_orientation_phi.mrc\", mode=\"r\" ).data.copy() orientation_theta = mrcfile.open(     \"xenon_216_000_0_output_orientation_theta.mrc\", mode=\"r\" ).data.copy() orientation_psi = mrcfile.open(     \"xenon_216_000_0_output_orientation_psi.mrc\", mode=\"r\" ).data.copy() In\u00a0[4]: Copied! <pre># Define the square region of interest to zoom in on\nregion_pos_x = 600\nregion_pos_y = 2300\nregion_width = 400\n\n# Extract the region of interest from the mip\nregion_mip = mip[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\n\n# Plot the full image and the zoomed-in region\nfig, ax = plt.subplots(\n    1, 2, figsize=(10, 5), gridspec_kw={\"width_ratios\": [0.55, 0.45]}\n)\n\n# Image of the entire MIP\nim = ax[0].imshow(mip, cmap=\"gray\")\ncbar = plt.colorbar(im, ax=ax[0], orientation=\"vertical\")\nax[0].set_title(\"Maximum Intensity Projection\")\nax[0].set_xlabel(\"x / pixels\")\nax[0].set_ylabel(\"y / pixels\")\n\n# box around the region of interest\nrect = plt.Rectangle(\n    (region_pos_x, region_pos_y),\n    region_width,\n    region_width,\n    linewidth=1,\n    edgecolor=\"r\",\n    facecolor=\"none\",\n)\nax[0].add_patch(rect)\n\nax[1].imshow(region_mip, cmap=\"gray\")\nax[1].set_title(\"Zoomed-in Region of Interest\")\nax[1].set_xlabel(\"x / pixels\")\nax[1].set_ylabel(\"y / pixels\")\n# Make the spines of the axes on the zoomed-in region red\nfor spine in ax[1].spines.values():\n    spine.set_edgecolor(\"red\")\n    spine.set_linewidth(1.5)\n\nplt.tight_layout()\nplt.show()\n</pre> # Define the square region of interest to zoom in on region_pos_x = 600 region_pos_y = 2300 region_width = 400  # Extract the region of interest from the mip region_mip = mip[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ]  # Plot the full image and the zoomed-in region fig, ax = plt.subplots(     1, 2, figsize=(10, 5), gridspec_kw={\"width_ratios\": [0.55, 0.45]} )  # Image of the entire MIP im = ax[0].imshow(mip, cmap=\"gray\") cbar = plt.colorbar(im, ax=ax[0], orientation=\"vertical\") ax[0].set_title(\"Maximum Intensity Projection\") ax[0].set_xlabel(\"x / pixels\") ax[0].set_ylabel(\"y / pixels\")  # box around the region of interest rect = plt.Rectangle(     (region_pos_x, region_pos_y),     region_width,     region_width,     linewidth=1,     edgecolor=\"r\",     facecolor=\"none\", ) ax[0].add_patch(rect)  ax[1].imshow(region_mip, cmap=\"gray\") ax[1].set_title(\"Zoomed-in Region of Interest\") ax[1].set_xlabel(\"x / pixels\") ax[1].set_ylabel(\"y / pixels\") # Make the spines of the axes on the zoomed-in region red for spine in ax[1].spines.values():     spine.set_edgecolor(\"red\")     spine.set_linewidth(1.5)  plt.tight_layout() plt.show() In\u00a0[5]: Copied! <pre># Define the region of interest to zoom in on\nregion_pos_x = 600\nregion_pos_y = 2300\nregion_width = 400\n\n# Extract the region of interest from the mip\nregion_scaled_mip = scaled_mip[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\n\n# Plot the full image and the zoomed-in region\nfig, ax = plt.subplots(\n    1, 2, figsize=(10, 5), gridspec_kw={\"width_ratios\": [0.55, 0.45]}\n)\n\n# Image of the entire MIP\nim = ax[0].imshow(scaled_mip, cmap=\"gray\")\ncbar = plt.colorbar(im, ax=ax[0], orientation=\"vertical\")\nax[0].set_title(\"Scaled MIP (Z-score)\")\nax[0].set_xlabel(\"x / pixels\")\nax[0].set_ylabel(\"y / pixels\")\n\n# box around the region of interest\nrect = plt.Rectangle(\n    (region_pos_x, region_pos_y),\n    region_width,\n    region_width,\n    linewidth=1,\n    edgecolor=\"r\",\n    facecolor=\"none\",\n)\nax[0].add_patch(rect)\n\nax[1].imshow(region_scaled_mip, cmap=\"gray\")\nax[1].set_title(\"Zoomed-in Region of Interest\")\nax[1].set_xlabel(\"x / pixels\")\nax[1].set_ylabel(\"y / pixels\")\n# Make the spines of the axes on the zoomed-in region red\nfor spine in ax[1].spines.values():\n    spine.set_edgecolor(\"red\")\n    spine.set_linewidth(1.5)\n\nplt.tight_layout()\nplt.show()\n</pre> # Define the region of interest to zoom in on region_pos_x = 600 region_pos_y = 2300 region_width = 400  # Extract the region of interest from the mip region_scaled_mip = scaled_mip[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ]  # Plot the full image and the zoomed-in region fig, ax = plt.subplots(     1, 2, figsize=(10, 5), gridspec_kw={\"width_ratios\": [0.55, 0.45]} )  # Image of the entire MIP im = ax[0].imshow(scaled_mip, cmap=\"gray\") cbar = plt.colorbar(im, ax=ax[0], orientation=\"vertical\") ax[0].set_title(\"Scaled MIP (Z-score)\") ax[0].set_xlabel(\"x / pixels\") ax[0].set_ylabel(\"y / pixels\")  # box around the region of interest rect = plt.Rectangle(     (region_pos_x, region_pos_y),     region_width,     region_width,     linewidth=1,     edgecolor=\"r\",     facecolor=\"none\", ) ax[0].add_patch(rect)  ax[1].imshow(region_scaled_mip, cmap=\"gray\") ax[1].set_title(\"Zoomed-in Region of Interest\") ax[1].set_xlabel(\"x / pixels\") ax[1].set_ylabel(\"y / pixels\") # Make the spines of the axes on the zoomed-in region red for spine in ax[1].spines.values():     spine.set_edgecolor(\"red\")     spine.set_linewidth(1.5)  plt.tight_layout() plt.show() In\u00a0[6]: Copied! <pre>bins = np.linspace(4, 13, 100)\n\nfig, ax = plt.subplots(1, 1, figsize=(5, 5))\n\n# Plot histogram of the MIP\nax.hist(\n    scaled_mip.flatten(),\n    bins=bins,\n    label=\"z-score histogram\",\n    density=False,\n)\n\nplt.xlabel(\"Z-score\")\nplt.ylabel(\"Counts\")\nplt.yscale(\"log\")\nplt.show()\n</pre> bins = np.linspace(4, 13, 100)  fig, ax = plt.subplots(1, 1, figsize=(5, 5))  # Plot histogram of the MIP ax.hist(     scaled_mip.flatten(),     bins=bins,     label=\"z-score histogram\",     density=False, )  plt.xlabel(\"Z-score\") plt.ylabel(\"Counts\") plt.yscale(\"log\") plt.show() In\u00a0[7]: Copied! <pre># Define the region of interest to zoom in on\nregion_correlation_mean = correlation_average[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\nregion_correlation_variance = correlation_variance[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\n\n# Create a 2x2 plot\nfig, ax = plt.subplots(2, 2, figsize=(12, 10))\n# Add a black box around the region of interest in the full images\nrect_mean = plt.Rectangle(\n    (region_pos_x, region_pos_y),\n    region_width,\n    region_width,\n    linewidth=1,\n    edgecolor=\"black\",\n    facecolor=\"none\",\n)\nax[0, 0].add_patch(rect_mean)\n\nrect_variance = plt.Rectangle(\n    (region_pos_x, region_pos_y),\n    region_width,\n    region_width,\n    linewidth=1,\n    edgecolor=\"black\",\n    facecolor=\"none\",\n)\nax[1, 0].add_patch(rect_variance)\n# Plot the full image of correlation mean\nim1 = ax[0, 0].imshow(correlation_average, cmap=\"magma\")\ncbar1 = plt.colorbar(im1, ax=ax[0, 0], orientation=\"vertical\")\nax[0, 0].set_title(\"Correlation Mean (Full Image)\")\nax[0, 0].set_xlabel(\"x / pixels\")\nax[0, 0].set_ylabel(\"y / pixels\")\n\n# Plot the zoomed-in region of correlation mean\nim2 = ax[0, 1].imshow(region_correlation_mean, cmap=\"magma\")\ncbar2 = plt.colorbar(im2, ax=ax[0, 1], orientation=\"vertical\")\nax[0, 1].set_title(\"Correlation Mean (Zoomed Region)\")\nax[0, 1].set_xlabel(\"x / pixels\")\nax[0, 1].set_ylabel(\"y / pixels\")\n\n# Plot the full image of correlation variance\nim3 = ax[1, 0].imshow(correlation_variance, cmap=\"magma\")\ncbar3 = plt.colorbar(im3, ax=ax[1, 0], orientation=\"vertical\")\nax[1, 0].set_title(\"Correlation Variance (Full Image)\")\nax[1, 0].set_xlabel(\"x / pixels\")\nax[1, 0].set_ylabel(\"y / pixels\")\n\n# Plot the zoomed-in region of correlation variance\nim4 = ax[1, 1].imshow(region_correlation_variance, cmap=\"magma\")\ncbar4 = plt.colorbar(im4, ax=ax[1, 1], orientation=\"vertical\")\nax[1, 1].set_title(\"Correlation Variance (Zoomed Region)\")\nax[1, 1].set_xlabel(\"x / pixels\")\nax[1, 1].set_ylabel(\"y / pixels\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Define the region of interest to zoom in on region_correlation_mean = correlation_average[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ] region_correlation_variance = correlation_variance[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ]  # Create a 2x2 plot fig, ax = plt.subplots(2, 2, figsize=(12, 10)) # Add a black box around the region of interest in the full images rect_mean = plt.Rectangle(     (region_pos_x, region_pos_y),     region_width,     region_width,     linewidth=1,     edgecolor=\"black\",     facecolor=\"none\", ) ax[0, 0].add_patch(rect_mean)  rect_variance = plt.Rectangle(     (region_pos_x, region_pos_y),     region_width,     region_width,     linewidth=1,     edgecolor=\"black\",     facecolor=\"none\", ) ax[1, 0].add_patch(rect_variance) # Plot the full image of correlation mean im1 = ax[0, 0].imshow(correlation_average, cmap=\"magma\") cbar1 = plt.colorbar(im1, ax=ax[0, 0], orientation=\"vertical\") ax[0, 0].set_title(\"Correlation Mean (Full Image)\") ax[0, 0].set_xlabel(\"x / pixels\") ax[0, 0].set_ylabel(\"y / pixels\")  # Plot the zoomed-in region of correlation mean im2 = ax[0, 1].imshow(region_correlation_mean, cmap=\"magma\") cbar2 = plt.colorbar(im2, ax=ax[0, 1], orientation=\"vertical\") ax[0, 1].set_title(\"Correlation Mean (Zoomed Region)\") ax[0, 1].set_xlabel(\"x / pixels\") ax[0, 1].set_ylabel(\"y / pixels\")  # Plot the full image of correlation variance im3 = ax[1, 0].imshow(correlation_variance, cmap=\"magma\") cbar3 = plt.colorbar(im3, ax=ax[1, 0], orientation=\"vertical\") ax[1, 0].set_title(\"Correlation Variance (Full Image)\") ax[1, 0].set_xlabel(\"x / pixels\") ax[1, 0].set_ylabel(\"y / pixels\")  # Plot the zoomed-in region of correlation variance im4 = ax[1, 1].imshow(region_correlation_variance, cmap=\"magma\") cbar4 = plt.colorbar(im4, ax=ax[1, 1], orientation=\"vertical\") ax[1, 1].set_title(\"Correlation Variance (Zoomed Region)\") ax[1, 1].set_xlabel(\"x / pixels\") ax[1, 1].set_ylabel(\"y / pixels\")  plt.tight_layout() plt.show() In\u00a0[8]: Copied! <pre>phi_region = orientation_phi[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\ntheta_region = orientation_theta[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\npsi_region = orientation_psi[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\n\n# Normalize the orientation data to the range [0, 1]\nphi_region = phi_region / 360\ntheta_region = theta_region / 180\npsi_region = psi_region / 360\norientation_rgb = np.stack((phi_region, theta_region, psi_region), axis=-1)\n\n# Add alpha channel based on scaled_mip\nalpha_channel = scaled_mip[\n    region_pos_y : region_pos_y + region_width,\n    region_pos_x : region_pos_x + region_width,\n]\nalpha_channel = (alpha_channel - np.min(alpha_channel)) / (\n    np.max(alpha_channel) - np.min(alpha_channel)\n)\norientation_rgba = np.zeros(\n    (orientation_rgb.shape[0], orientation_rgb.shape[1], 4), dtype=np.float32\n)\norientation_rgba[..., :3] = orientation_rgb\norientation_rgba[..., 3] = alpha_channel\n\n# Create a 2 by 2 grid, bottom row spans both columns\nfig = plt.figure(figsize=(8, 8))\ngs = gridspec.GridSpec(2, 2, figure=fig)\n\nax0 = fig.add_subplot(gs[0, 0])\nax1 = fig.add_subplot(gs[0, 1])\nax2 = fig.add_subplot(gs[1, :])  # spans both columns\n\n\nax0.imshow(orientation_rgb)\nax0.set_title(\"Best Orientation\\n(color-coded)\")\nax0.set_xlabel(\"x / pixels\")\nax0.set_ylabel(\"y / pixels\")\n\nax1.imshow(orientation_rgba)\nax1.set_title(\"Best Orientation\\n(z-score alpha channel)\")\nax1.set_xlabel(\"x / pixels\")\nax1.set_ylabel(\"y / pixels\")\n\nax2.imshow(region_scaled_mip, cmap=\"gray\")\nax2.set_title(\"Scaled MIP (z-score)\")\nax2.set_xlabel(\"x / pixels\")\nax2.set_ylabel(\"y / pixels\")\n\nplt.tight_layout()\nplt.show()\n</pre> phi_region = orientation_phi[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ] theta_region = orientation_theta[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ] psi_region = orientation_psi[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ]  # Normalize the orientation data to the range [0, 1] phi_region = phi_region / 360 theta_region = theta_region / 180 psi_region = psi_region / 360 orientation_rgb = np.stack((phi_region, theta_region, psi_region), axis=-1)  # Add alpha channel based on scaled_mip alpha_channel = scaled_mip[     region_pos_y : region_pos_y + region_width,     region_pos_x : region_pos_x + region_width, ] alpha_channel = (alpha_channel - np.min(alpha_channel)) / (     np.max(alpha_channel) - np.min(alpha_channel) ) orientation_rgba = np.zeros(     (orientation_rgb.shape[0], orientation_rgb.shape[1], 4), dtype=np.float32 ) orientation_rgba[..., :3] = orientation_rgb orientation_rgba[..., 3] = alpha_channel  # Create a 2 by 2 grid, bottom row spans both columns fig = plt.figure(figsize=(8, 8)) gs = gridspec.GridSpec(2, 2, figure=fig)  ax0 = fig.add_subplot(gs[0, 0]) ax1 = fig.add_subplot(gs[0, 1]) ax2 = fig.add_subplot(gs[1, :])  # spans both columns   ax0.imshow(orientation_rgb) ax0.set_title(\"Best Orientation\\n(color-coded)\") ax0.set_xlabel(\"x / pixels\") ax0.set_ylabel(\"y / pixels\")  ax1.imshow(orientation_rgba) ax1.set_title(\"Best Orientation\\n(z-score alpha channel)\") ax1.set_xlabel(\"x / pixels\") ax1.set_ylabel(\"y / pixels\")  ax2.imshow(region_scaled_mip, cmap=\"gray\") ax2.set_title(\"Scaled MIP (z-score)\") ax2.set_xlabel(\"x / pixels\") ax2.set_ylabel(\"y / pixels\")  plt.tight_layout() plt.show()"},{"location":"examples/04_plotting_2dtm_results/#visualizing-2dtm-result","title":"Visualizing 2DTM result\u00b6","text":"<p>This notebook demonstrates how to take the result files from a template matching run and plot those results. The data used in this notebook are hosted remotely on Zenodo and need downloaded beforehand. Alternately, you can replace these results with your actual data.</p>"},{"location":"examples/04_plotting_2dtm_results/#downloading-example-data","title":"Downloading Example Data\u00b6","text":"<p>Run the following code cell to download the results into the current directory of the notebook. Otherwise, place the downloaded data in the same directory as the notebook or adjust the paths in the following cell(s).</p>"},{"location":"examples/04_plotting_2dtm_results/#load-data-into-memory","title":"Load data into memory\u00b6","text":"<p>Using the <code>mrcfile</code> package to read each of the downloaded example files into a numpy array.</p>"},{"location":"examples/04_plotting_2dtm_results/#plot-of-the-maximum-intensity-projection-mip","title":"Plot of the Maximum Intensity Projection (MIP)\u00b6","text":"<p>The MIP is the maximum cross-correlation value attained in the template matching search for each location (pixel) in the image. Here, we are plotting the global MIP as well as a zoomed-in region of the MIP.</p>"},{"location":"examples/04_plotting_2dtm_results/#plot-of-the-scaled-mip-z-score-values","title":"Plot of the Scaled MIP (Z-score) values\u00b6","text":"<p>The Scaled MIP is the best per-pixel cross-correlation values scaled by the mean and variance of all cross-correlation values over the search space. If we could observe all cross-correlation values (~20 million points in this case), then after normalization each would be distributed $\\mathcal{N}(0, 1)$. However, we only observe the maxima (MIP), and after scaling these z-scores therefore represent how extreme that observation is relative to the background noise.</p>"},{"location":"examples/04_plotting_2dtm_results/#histogram-of-z-score-values","title":"Histogram of Z-score values\u00b6","text":"<p>The background z-score values follow a Generalized Extreme Value Distribution, and we can clearly see a shoulder deviating from this distribution starting around a z-score of 7.5 in the following histogram. Some of these pixels correspond to signal, that is, particles identified in our image.</p> <p>Note that this histogram is shown on a log-scale.</p>"},{"location":"examples/04_plotting_2dtm_results/#correlation-mean-and-variance","title":"Correlation Mean and Variance\u00b6","text":"<p>As a brief demonstration, we now show the mean and variance of the cross-correlation values over the 2DTM search space on a per-pixel basis. These are the \"images\" used to normalize the MIP into a z-score</p>"},{"location":"examples/04_plotting_2dtm_results/#best-orientations-represented-by-color","title":"Best orientations represented by color\u00b6","text":"<p>Here, we take the three Euler angles $(\\phi, \\theta, \\psi)$ defining the best orientation per-pixel and map them to an RGB image to plot the orientation information. Note that this coloring scheme does not account for the periodic nature of orientation space, and the relative color difference should only be used for visualization purposes.</p>"},{"location":"examples/05_structure_reprojection/","title":"Structure projections on an Image","text":"In\u00a0[1]: Copied! <pre>import os\n\nimport matplotlib.pyplot as plt\nimport mrcfile\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom scipy.signal import wiener\n\nfrom leopard_em.utils.fourier_slice import get_real_space_projections_from_volume\n\nplt.rcParams[\"figure.dpi\"] = 120\n</pre> import os  import matplotlib.pyplot as plt import mrcfile import numpy as np import pandas as pd import torch from scipy.signal import wiener  from leopard_em.utils.fourier_slice import get_real_space_projections_from_volume  plt.rcParams[\"figure.dpi\"] = 120 In\u00a0[2]: Copied! <pre>!zenodo_get https://doi.org/10.5281/zenodo.15426374 \\\n--glob \"60S_map_px0.936_bscale0.5.mrc\" \\\n--glob \"xenon_216_000_0.0_DWS.mrc\" \\\n--glob \"xenon_216_000_0.0_DWS_results.csv\"\n</pre> !zenodo_get https://doi.org/10.5281/zenodo.15426374 \\ --glob \"60S_map_px0.936_bscale0.5.mrc\" \\ --glob \"xenon_216_000_0.0_DWS.mrc\" \\ --glob \"xenon_216_000_0.0_DWS_results.csv\" <pre>Title: 2DTM inputs and program results from the Leopard-EM Python package\nKeywords: \nPublication date: 2025-05-15\nDOI: 10.5281/zenodo.15426374\nTotal size: 604.1 MB\n\nDownloading (1/3):\nFile: 60S_map_px0.936_bscale0.5.mrc (536.9 MB)\nLink: https://zenodo.org/api/records/15426374/files/60S_map_px0.936_bscale0.5.mrc/content\n60S_map_px0.936_bscale0.5.mrc is already downloaded correctly.\n\nDownloading (2/3):\nFile: xenon_216_000_0.0_DWS_results.csv (118.6 kB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0.0_DWS_results.csv/content\n100% [........................................................] 118621 / 118621\nChecksum is correct for xenon_216_000_0.0_DWS_results.csv. (7aae48e3ce68f41230b3e778089ed2a7)\n\nDownloading (3/3):\nFile: xenon_216_000_0.0_DWS.mrc (67.1 MB)\nLink: https://zenodo.org/api/records/15426374/files/xenon_216_000_0.0_DWS.mrc/content\n100% [....................................................] 67109888 / 67109888\nChecksum is correct for xenon_216_000_0.0_DWS.mrc. (a38451fabc9a2bdbdac3b83e39d5df6a)\n\nAll specified files have been processed.\n</pre> In\u00a0[3]: Copied! <pre>import requests\n\n\ndef download_zenodo_file(url: str) -&gt; str:\n    \"\"\"Downloads a zenodo file from the given URL. Returns the output filename.\"\"\"\n    output_filename = url.split(\"/\")[-1]\n\n    # Check if the file already exists\n    if os.path.exists(output_filename):\n        print(f\"File {output_filename} already exists. Skipping download.\")\n        return output_filename\n\n    response = requests.get(url, stream=True)\n    response.raise_for_status()  # Check for request errors\n\n    with open(output_filename, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n    return output_filename\n\n\n# NOTE: This may take a few seconds to few minutes, depending on internet connection\n# fmt: off\nfile_urls = [\n    \"https://zenodo.org/records/15426374/files/60S_map_px0.936_bscale0.5.mrc\",\n    \"https://zenodo.org/records/15426374/files/xenon_216_000_0.0_DWS.mrc\",\n    \"https://zenodo.org/records/15426374/files/xenon_216_000_0.0_DWS_results.csv\",\n]\n# fmt: on\n\nfor url in file_urls:\n    filename = download_zenodo_file(url)\n    print(f\"Downloaded {filename}\")\n</pre> import requests   def download_zenodo_file(url: str) -&gt; str:     \"\"\"Downloads a zenodo file from the given URL. Returns the output filename.\"\"\"     output_filename = url.split(\"/\")[-1]      # Check if the file already exists     if os.path.exists(output_filename):         print(f\"File {output_filename} already exists. Skipping download.\")         return output_filename      response = requests.get(url, stream=True)     response.raise_for_status()  # Check for request errors      with open(output_filename, \"wb\") as f:         for chunk in response.iter_content(chunk_size=8192):             f.write(chunk)      return output_filename   # NOTE: This may take a few seconds to few minutes, depending on internet connection # fmt: off file_urls = [     \"https://zenodo.org/records/15426374/files/60S_map_px0.936_bscale0.5.mrc\",     \"https://zenodo.org/records/15426374/files/xenon_216_000_0.0_DWS.mrc\",     \"https://zenodo.org/records/15426374/files/xenon_216_000_0.0_DWS_results.csv\", ] # fmt: on  for url in file_urls:     filename = download_zenodo_file(url)     print(f\"Downloaded {filename}\") <pre>File 60S_map_px0.936_bscale0.5.mrc already exists. Skipping download.\nDownloaded 60S_map_px0.936_bscale0.5.mrc\nFile xenon_216_000_0.0_DWS.mrc already exists. Skipping download.\nDownloaded xenon_216_000_0.0_DWS.mrc\nFile xenon_216_000_0.0_DWS_results.csv already exists. Skipping download.\nDownloaded xenon_216_000_0.0_DWS_results.csv\n</pre> In\u00a0[4]: Copied! <pre>micrograph_path = \"xenon_216_000_0.0_DWS.mrc\"\nmicrograph = mrcfile.open(micrograph_path, mode=\"r\").data.copy()\n\n# Show the micrograph\nplt.figure(figsize=(5, 5))\nplt.imshow(micrograph, cmap=\"gray\")\nplt.xlabel(\"x / pixels\")\nplt.ylabel(\"y / pixels\")\nplt.show()\n</pre> micrograph_path = \"xenon_216_000_0.0_DWS.mrc\" micrograph = mrcfile.open(micrograph_path, mode=\"r\").data.copy()  # Show the micrograph plt.figure(figsize=(5, 5)) plt.imshow(micrograph, cmap=\"gray\") plt.xlabel(\"x / pixels\") plt.ylabel(\"y / pixels\") plt.show() In\u00a0[5]: Copied! <pre>results_csv_path = \"xenon_216_000_0.0_DWS_results.csv\"\ndf = pd.read_csv(results_csv_path)\ndf\n</pre> results_csv_path = \"xenon_216_000_0.0_DWS_results.csv\" df = pd.read_csv(results_csv_path) df Out[5]: Unnamed: 0 particle_index mip scaled_mip correlation_mean correlation_variance total_correlations pos_x pos_y pos_x_img ... micrograph_path template_path mip_path scaled_mip_path psi_path theta_path phi_path defocus_path correlation_average_path correlation_variance_path 0 0 0 11.810101 12.104484 0.025537 0.973570 20598240 3470 3336 3726 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 1 1 1 11.348068 11.758850 0.130799 0.953943 20598240 3322 1945 3578 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 2 2 2 11.823074 11.681293 0.062959 1.006748 20598240 1842 3353 2098 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 3 3 3 11.246000 11.189375 -0.028836 1.007638 20598240 133 3452 389 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 4 4 4 11.394345 11.041210 -0.032740 1.034949 20598240 1811 3249 2067 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 193 193 193 7.664472 7.848475 0.042711 0.971114 20598240 2254 1733 2510 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 194 194 194 7.992585 7.818872 0.133709 1.005116 20598240 1376 2300 1632 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 195 195 195 7.570004 7.792142 0.016312 0.969399 20598240 1945 1819 2201 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 196 196 196 7.620340 7.788315 0.082988 0.967777 20598240 2747 2183 3003 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc 197 197 197 7.862420 7.782097 0.046521 1.004344 20598240 2553 897 2809 ... xenon_216_000_0.0_DWS.mrc 60S_map_px0.936_bscale0.5.mrc xenon_216_000_0_output_mip.mrc xenon_216_000_0_output_scaled_mip.mrc xenon_216_000_0_output_orientation_psi.mrc xenon_216_000_0_output_orientation_theta.mrc xenon_216_000_0_output_orientation_phi.mrc xenon_216_000_0_output_relative_defocus.mrc xenon_216_000_0_output_correlation_average.mrc xenon_216_000_0_output_correlation_variance.mrc <p>198 rows \u00d7 38 columns</p> In\u00a0[6]: Copied! <pre># Scatter plot of particle positions on top of the micrograph\nplt.figure(figsize=(5, 5))\n\n\n# Scatter plot of particle positions\nplt.imshow(micrograph, cmap=\"gray\")\nplt.scatter(\n    df[\"pos_x_img\"],\n    df[\"pos_y_img\"],\n    s=10,\n    color=\"red\",\n)\n\n# Set labels\nplt.xlabel(\"x / pixels\")\nplt.ylabel(\"y / pixels\")\nplt.title(\"Scatter Plot of Particle Positions on Micrograph\")\nplt.show()\n</pre> # Scatter plot of particle positions on top of the micrograph plt.figure(figsize=(5, 5))   # Scatter plot of particle positions plt.imshow(micrograph, cmap=\"gray\") plt.scatter(     df[\"pos_x_img\"],     df[\"pos_y_img\"],     s=10,     color=\"red\", )  # Set labels plt.xlabel(\"x / pixels\") plt.ylabel(\"y / pixels\") plt.title(\"Scatter Plot of Particle Positions on Micrograph\") plt.show() In\u00a0[7]: Copied! <pre>template_volume_path = \"60S_map_px0.936_bscale0.5.mrc\"\ntemplate_volume = mrcfile.open(template_volume_path, mode=\"r\").data.copy()\ntemplate_volume = torch.from_numpy(template_volume)\ntemplate_volume.shape\n</pre> template_volume_path = \"60S_map_px0.936_bscale0.5.mrc\" template_volume = mrcfile.open(template_volume_path, mode=\"r\").data.copy() template_volume = torch.from_numpy(template_volume) template_volume.shape Out[7]: <pre>torch.Size([512, 512, 512])</pre> In\u00a0[8]: Copied! <pre># Generating the projections\nprojections = get_real_space_projections_from_volume(\n    volume=template_volume,\n    phi=torch.from_numpy(df[\"phi\"].values).float(),\n    theta=torch.from_numpy(df[\"theta\"].values).float(),\n    psi=torch.from_numpy(df[\"psi\"].values).float(),\n    degrees=True,\n)\nprojections.shape\n</pre> # Generating the projections projections = get_real_space_projections_from_volume(     volume=template_volume,     phi=torch.from_numpy(df[\"phi\"].values).float(),     theta=torch.from_numpy(df[\"theta\"].values).float(),     psi=torch.from_numpy(df[\"psi\"].values).float(),     degrees=True, ) projections.shape Out[8]: <pre>torch.Size([198, 512, 512])</pre> In\u00a0[9]: Copied! <pre>pixel_size = df.iloc[0][\"pixel_size\"].item()  # Angstroms / pixel\nprint(f\"Pixel size (\u00c5): {pixel_size}\")\n\n# Optionally apply a Wiener filter to image (params here are arbitrary)\napply_wiener = True\nimg = wiener(micrograph, mysize=20) if not apply_wiener else micrograph.copy()\nprint(f\"Wiener filter applied: {apply_wiener}\")\n</pre> pixel_size = df.iloc[0][\"pixel_size\"].item()  # Angstroms / pixel print(f\"Pixel size (\u00c5): {pixel_size}\")  # Optionally apply a Wiener filter to image (params here are arbitrary) apply_wiener = True img = wiener(micrograph, mysize=20) if not apply_wiener else micrograph.copy() print(f\"Wiener filter applied: {apply_wiener}\") <pre>Pixel size (\u00c5): 0.936\nWiener filter applied: True\n</pre> In\u00a0[10]: Copied! <pre>fig, ax = plt.subplots(figsize=(10, 10))\nax.imshow(\n    img,\n    cmap=\"gray\",\n    extent=(0, img.shape[1] * pixel_size, img.shape[0] * pixel_size, 0),\n)\n\n# Iterate over each of the particle projections\nfor i, projection in enumerate(projections):\n    projection = projection.numpy()\n\n    # Get the position of the particle\n    dx = df[\"pos_x_img_angstrom\"].iloc[i]\n    dy = df[\"pos_y_img_angstrom\"].iloc[i]\n    extent = [\n        dx - (projection.shape[1] // 2 * pixel_size),\n        dx + (projection.shape[1] // 2 * pixel_size),\n        dy - (projection.shape[0] // 2 * pixel_size),\n        dy + (projection.shape[0] // 2 * pixel_size),\n    ]\n\n    # Apply a circular mask to the projection\n    mask = np.zeros_like(projection)\n    h, w = mask.shape\n    y, x = np.ogrid[:h, :w]\n    r = np.sqrt((x - w // 2) ** 2 + (y - h // 2) ** 2)\n    mask_area = r &lt; 0.33 * min(h, w)\n    mask[mask_area] = 1\n\n    # Do normalization and coloring for projections\n    projection = projection - projection.min()\n    projection = projection / projection.max()\n    normed_projection = 1 - projection\n    projection = plt.cm.Blues(projection)\n    projection[..., 3] = normed_projection * 0.8  # set alpha channel\n\n    # Overlay the projection on the micrograph\n    ax.imshow(\n        projection * mask[..., None],\n        extent=extent,\n    )\n\n# Manually setting the limits, otherwise the extent of the last projection is used\nax.set_xlim(0, img.shape[1] * pixel_size)\nax.set_ylim(0, img.shape[0] * pixel_size)\nax.invert_yaxis()\n\nplt.xlabel(\"x / Angstrom\")\nplt.ylabel(\"y / Angstrom\")\nplt.title(\"Projections of Particles on Micrograph\")\n\nplt.tight_layout()\nplt.show()\n</pre> fig, ax = plt.subplots(figsize=(10, 10)) ax.imshow(     img,     cmap=\"gray\",     extent=(0, img.shape[1] * pixel_size, img.shape[0] * pixel_size, 0), )  # Iterate over each of the particle projections for i, projection in enumerate(projections):     projection = projection.numpy()      # Get the position of the particle     dx = df[\"pos_x_img_angstrom\"].iloc[i]     dy = df[\"pos_y_img_angstrom\"].iloc[i]     extent = [         dx - (projection.shape[1] // 2 * pixel_size),         dx + (projection.shape[1] // 2 * pixel_size),         dy - (projection.shape[0] // 2 * pixel_size),         dy + (projection.shape[0] // 2 * pixel_size),     ]      # Apply a circular mask to the projection     mask = np.zeros_like(projection)     h, w = mask.shape     y, x = np.ogrid[:h, :w]     r = np.sqrt((x - w // 2) ** 2 + (y - h // 2) ** 2)     mask_area = r &lt; 0.33 * min(h, w)     mask[mask_area] = 1      # Do normalization and coloring for projections     projection = projection - projection.min()     projection = projection / projection.max()     normed_projection = 1 - projection     projection = plt.cm.Blues(projection)     projection[..., 3] = normed_projection * 0.8  # set alpha channel      # Overlay the projection on the micrograph     ax.imshow(         projection * mask[..., None],         extent=extent,     )  # Manually setting the limits, otherwise the extent of the last projection is used ax.set_xlim(0, img.shape[1] * pixel_size) ax.set_ylim(0, img.shape[0] * pixel_size) ax.invert_yaxis()  plt.xlabel(\"x / Angstrom\") plt.ylabel(\"y / Angstrom\") plt.title(\"Projections of Particles on Micrograph\")  plt.tight_layout() plt.show()"},{"location":"examples/05_structure_reprojection/#structure-projections-on-an-image","title":"Structure projections on an Image\u00b6","text":"<p>Once particle locations and orientations have been identified, we can go back and plot the projections of the template structure back onto the original micrograph. This example goes through and generates this plot on a set of already template matched data.</p>"},{"location":"examples/05_structure_reprojection/#downloading-example-data","title":"Downloading Example Data\u00b6","text":"<p>Run the following code cell to download the results into the current directory of the notebook. Otherwise, place the downloaded data in the same directory as the notebook or adjust the paths in the following cell(s).</p>"},{"location":"examples/05_structure_reprojection/#loading-in-micrograph","title":"Loading in micrograph\u00b6","text":"<p>Read in the micrograph mrc file into a numpy array visualize it using <code>matplotlib</code>.</p>"},{"location":"examples/05_structure_reprojection/#loading-in-picked-particle-results-to-dataframe","title":"Loading in picked particle results to DataFrame\u00b6","text":"<p>We downloaded the identified particles csv from the <code>match_template</code> program which contain the location and orientation of each particle. These data will be used to generate and plot the structure re-projections later.</p>"},{"location":"examples/05_structure_reprojection/#first-scatter-plot","title":"First scatter plot\u00b6","text":"<p>Just for quick visualization purposes, we generate a quick scatter plot of the identified particle positions on top of the micrograph.</p>"},{"location":"examples/05_structure_reprojection/#projections-from-simulated-volume","title":"Projections from simulated volume\u00b6","text":"<p>To generate projections of a structure, we first need a simulated structure. Leopard-EM includes a nice helper function to generate projections from a simulated volume from some set of orientations (angles in ZYZ Euler format).</p>"},{"location":"examples/05_structure_reprojection/#some-light-pre-processing","title":"Some light pre-processing\u00b6","text":"<p>Plot will have spatial units of Angstroms (not pixels), and Wiener filter can optionally be applied to the micrograph.</p>"},{"location":"programs/constrained_search/","title":"The constrained search program","text":"<p>The constrained search program takes in locations and orientations for one particle and searches for another particle based on these locations and orientations. This allows us to perform for fewer cross correlations, reducing the noise and thus increasing our sensitivity. This increased sensitivity is incredibly useful when searching for smaller proteins which may associate with a larger complex but otherwise fall below the noise floor of full-orientation 2DTM.</p>"},{"location":"programs/constrained_search/#configuration-options","title":"Configuration options","text":"<p>A default config file for the constrained search program is available here on the GitHub page. This file is separated into multiple \"blocks\" each configuring distinct portions of the program discussed briefly below.</p>"},{"location":"programs/constrained_search/#top-level-template-paths","title":"Top-level template paths","text":"<p>The first field in the configuration file is the path to the simulated 3D map of the constrained particle we want to search for. Note this is not the the 3D map used in either of the match template or refine template steps.</p> <pre><code>template_volume_path: /some/path/to/template.mrc\n</code></pre>"},{"location":"programs/constrained_search/#center-vector-between-the-structures","title":"Center vector between the structures","text":"<p>The center vector is the vector that points from the reference particle to the constrained particle when all Euler angles are 0 (default orientation). We include the script get_center_vector.py to calculate this based on two aligned (relative to each other) PDB files.</p> <p>The following example is specific to the constrained 40S ribosome search.</p> <pre><code>center_vector: [53.65, 82.58, 47.17]\n</code></pre>"},{"location":"programs/constrained_search/#particle-stacks-for-the-reference-and-constrained-particle","title":"Particle stacks for the reference and constrained particle","text":"<p>You must provide particle stacks for the constrained particle as well as the reference particle. The euler angles and locations are taken from the reference particle stack, and the mean and variance are taken from the constrained particle stack input, allowing us to accurately calculate a z-score. The extracted box size determines how many pixels will be searched over and is calculated as . Since we want as few cross-correlations as possible, the additional extracted pixels should be kept as low as possible while still allowing for some variability in the (x, y) position.</p> <pre><code>particle_stack_reference:  # This is from the reference particles\n  df_path: /some/path/to/particles.csv\n  extracted_box_size: [520, 520]\n  original_template_size: [512, 512]\nparticle_stack_constrained:  # This is from the constrained particles\n  df_path: /some/path/to/particles.csv\n  extracted_box_size: [520, 520]\n  original_template_size: [512, 512]\n</code></pre>"},{"location":"programs/constrained_search/#orientation-refinement-configuration","title":"Orientation refinement configuration","text":"<p>We must specify what angular space to perform the orientation search over. The first thing we must specify is the primary rotation axis, which we set as the Z axis. If unknown, this can be calculated using two PDB models (one rotated and one unrotated) using the script get_rot_axis.py.</p> <p>As well as searching over one rotation axis, we can search over a second axis, which by default is the y axis. This can be changed to any axis orthogonal to the primary axis by specifying a <code>roll_axis</code> and using the <code>base_grid_method: roll</code>. If a second axis is not known, a roll axis search can be performed (<code>search_roll_axis: true</code>) with a specified <code>roll_step</code>.</p> <p>The most important parameters to specify is the range and step size for the psi and theta searches. The psi angles are rotations around the Z-axis, and theta rotations around the orthogonal axis. Since psi and phi are redundant for small angular searches, we usually do not need to search over phi.</p> <pre><code>orientation_refinement_config:\n  enabled: true\n  rotation_axis_euler_angles: [0.0, 0.0, 0.0] # This is the rotation axis\n  base_grid_method: uniform\n  psi_step: 1.0   # psi in degrees\n  theta_step: 1.0   # theta and phi in degrees\n  phi_min: -0.0\n  phi_max: 0.0\n  theta_min: -8.0\n  theta_max: 2.0\n  psi_min: -13.0\n  psi_max: 2.0\n  search_roll_axis: false\n  roll_axis: [0,1] # [x,y] This defines the roll axis (orthogonal to the rotation axis).\n  roll_step: 2.0 \n</code></pre>"},{"location":"programs/constrained_search/#pre-processing-filters-and-computational-config","title":"Pre-processing filters and computational config","text":"<p>These should be the same as for Match Template.</p>"},{"location":"programs/match_template/","title":"The match template program","text":"<p>The match template program takes in a micrograph and a simulated reference structure along with search parameters to find locations in the micrograph which agree with expected 2D projections of this reference structure. Notably, the match template program simultaneously finds the location and orientations of these particles as well as the depth of the particle within the sample.</p> <p>GPU usage with match template</p> <p>The match template program is GPU-intensive, and there is the <code>ORIENTATION_BATCH_SIZE</code> parameter within the <code>run_match_template.py</code> script to help manage GPU resources. If you encounter a CUDA out of memory error try decreasing the <code>ORIENTATION_BATCH_SIZE</code> parameter.</p>"},{"location":"programs/match_template/#configuration-options","title":"Configuration options","text":"<p>A default config file for the match template program is available here on the GitHub page. This file is separated into multiple \"blocks\" each configuring distinct portions of the program discussed briefly below.</p>"},{"location":"programs/match_template/#top-level-micrograph-and-template-paths","title":"Top-level micrograph and template paths","text":"<p>The first two fields in the configuration are define where the simulated 3D reference template and 2D micrograph files are located. These are both saved in the mrc file format, and the paths need to be updated to match your system and experiment. Configurations are made on a per-micrograph basis, that is, a new configuration file should be made for each micrograph in your dataset.</p> <pre><code>template_volume_path: /some/path/to/template.mrc\nmicrograph_path:      /some/path/to/micrograph.mrc\n</code></pre> <p>Note</p> <p>The reference template should be simulated under the same conditions as the experimental micrograph (pixel size, cumulative electron exposure, etc.). A 3D volume can be simulated from a PDB structure using the TeamTomo ttsim3d Python package.</p>"},{"location":"programs/match_template/#output-result-files","title":"Output result files","text":"<p>The next block is the <code>match_template_result</code> configuration which defines where to save match template results to disk Note that these paths need to be writable by the user executing the program, and the <code>match_template_result.allow_file_overwrite</code> field needs to be set to <code>true</code> if you are overwriting pre-existing result files. Otherwise the match template program will not proceed if the files already exist.</p> <pre><code>match_template_result:\n  allow_file_overwrite: true\n  mip_path:                   /some/path/to/output_mip.mrc\n  scaled_mip_path:            /some/path/to/output_scaled_mip.mrc\n  orientation_psi_path:       /some/path/to/output_orientation_psi.mrc\n  orientation_theta_path:     /some/path/to/output_orientation_theta.mrc\n  orientation_phi_path:       /some/path/to/output_orientation_phi.mrc\n  relative_defocus_path:      /some/path/to/output_relative_defocus.mrc\n  correlation_average_path:   /some/path/to/output_correlation_average.mrc\n  correlation_variance_path:  /some/path/to/output_correlation_variance.mrc\n</code></pre> <p>Results are saved as MRC files with positions  corresponding to positions in the image. See Data Formats for more information.</p>"},{"location":"programs/match_template/#optics-group-for-micrograph-parameters","title":"Optics group for micrograph parameters","text":"<p>Constructing the appropriate projective filters requires the microscope parameters used to collect the micrograph, namely the defocus of the image. These microscope parameters are collected under the <code>optics_group</code> block with the most commonly modified parameters listed below.</p> <pre><code>optics_group:\n  label: some_label\n  voltage: 300.0\n  pixel_size: 1.06   # in Angstroms\n  defocus_u: 5200.0  # in Angstroms\n  defocus_v: 4950.0  # in Angstroms\n  astigmatism_angle: 25.0  # in degrees\n  spherical_aberration: 2.7  # in millimeters\n  amplitude_contrast_ratio: 0.07\n  ctf_B_factor: 60.0  # in Angstroms^2\n</code></pre> <p>Note</p> <p>The <code>label</code> field is currently unused and can be set to any string, but may be integrated into other workflows in the future to differentiate between multiple micrograph and/or refined optical parameters.</p>"},{"location":"programs/match_template/#defocus-search-space-configuration","title":"Defocus search space configuration","text":"<p>Defining the defocus search space is configured using the <code>defocus_search_config</code> block which defines the exact relative defocus values searched over in units of Angstroms. For example, to search defocus values ranging across -120 to +120 nm relative to the fitted CTF defocus values in <code>optics_group</code>, use the following configuration.</p> <pre><code>defocus_search_config:\n  defocus_max:  1200.0  # in Angstroms, relative to the defocus_u and defocus_v values\n  defocus_min: -1200.0  # in Angstroms, relative to the defocus_u and defocus_v values\n  defocus_step: 200.0   # in Angstroms\n  enabled: true\n</code></pre> <p>Note</p> <p>The defocus search can be turned off by changed the <code>enabled</code> field from <code>true</code> to <code>false</code>. This will run the 2DTM search at a single defocus plane corresponding to the fitted CTF defocus values.</p>"},{"location":"programs/match_template/#orientation-search-space-configuration","title":"Orientation search space configuration","text":"<p>How points in orientation space (SO(3) space) are sampled is configured using the the <code>orientation_search_config</code> block. At its most basic, only three parameters need considered: <code>base_grid_method</code>, <code>psi_step</code>, and <code>theta_step</code>. The <code>uniform</code> grid sampling method uses the Hopf Fibration from the torch-so3 package to generate a uniformly distributed set of points across SO(3) space and should be the first method you try when running a 2DTM search. There is also <code>healpix</code> option which uses a HEALPix discretization of the sphere to sample orientation space.</p> <p>The other two fields define how finely orientation space is sampled with lower angular values corresponding to a larger number of samples. The <code>psi_step</code> field controls how many degrees are between two consecutive in-plane rotations while <code>theta_step</code> corresponds to the step size for out-of-plane rotations.</p> A note on default angular sampling parameters <p>We have empirically found an angular sampling of <code>psi_step: 1.5</code> and <code>theta_step: 2.5</code> works well for maximizing 60S ribosomal subunit detections in situ. These values do not come from some underlying theory. Increasing angular sampling from these parameters in the 60S case does not lead to more particle detections, but it does raise the computational cost and 2DTM noise floor. Decreasing angular sampling leads to particle \"misses\" which is undesirable.</p> <p>If you are searching for a structure other than the 60S ribosome, then an alternate set of angular sampling parameters may work better. Finding these parameters may require some trial and error, and the search parameters must also strike a balance between computational cost, minimizing the noise floor, and maximizing sensitivity.</p> <p>Below, we show the <code>orientation_search_config</code> with the above parameters</p> <pre><code>orientation_search_config:\n  base_grid_method: uniform\n  psi_step: 1.5    # in degrees\n  theta_step: 2.5  # in degrees\n</code></pre>"},{"location":"programs/match_template/#configuring-the-pre-processing-filters","title":"Configuring the pre-processing filters","text":"<p>Pre-processing filters are applied to both the image and template in Fourier space. Below, we briefly discuss the parameter choices for the whitening and band-pass filters, the two most commonly used 2DTM filters. There are two additional pre-processing filters, phase-randomization &amp; arbitrary curve, whose configuration is discussed here. In most cases, the default values should suffice, but nevertheless the knobs to tweak how calculations are performed are included for completeness' sake.</p>"},{"location":"programs/match_template/#whitening-filter","title":"Whitening filter","text":"<p>The whitening filter, with parameters defined under <code>preprocessing_filters.whitening_filter</code>, flattens the 1D power spectrum of the image so each frequency component contributes equally to the cross-corelation; the same filter is applied to template projections. The whitening filter is enabled by default and necessary to compensate for the the strong low-frequency components of in situ cryo-EM images,<sup>1</sup> but the filter can be disabled by changing <code>enabled: true</code> to <code>enabled: false</code>. Changing the <code>do_power_spectrum</code> to <code>false</code> will calculate the whitening filter based on the amplitude spectrum instead of the power spectrum, but we don't observe a major difference when swapping this parameter.</p> <p>The <code>whitening_filter.max_freq</code> field defines the maximum spatial frequency considered (in terms of Nyquist) when calculating the whitening filter; the default of <code>0.5</code> should perform well in most cases. Similarly, keeping the default <code>num_freq_bins: null</code> will choose the number of frequency bins automatically based on input image shape. Values between 500-2,000 are generally good for typical cryo-EM images with ~4,000 pixels along each dimension.</p>"},{"location":"programs/match_template/#bandpass-filter","title":"Bandpass filter","text":"<p>Bandpass filtering is disabled by default but can be turned on by changing <code>enabled: false</code> to <code>enabled: true</code>. Note that the <code>high_freq_cutoff</code> and <code>low_freq_cutoff</code> fields are both defined in terms of the Nyquist frequency with values of <code>null</code> corresponding to no cutoff. For example, <code>high_freq_cutoff: 0.5</code> and <code>low_freq_cutoff: null</code> would correspond to a low-pass filter to the Nyquist frequency of the image. Filtering to a specific resolution in terms of Angstroms means doing some math before populating the fields.</p> <pre><code>preprocessing_filters:\n  whitening_filter:\n    enabled: true\n    do_power_spectrum: true\n    max_freq: 0.5  # In terms of Nyquist frequency\n    num_freq_bins: null\n  bandpass_filter:\n    enabled: false\n    falloff: null\n    high_freq_cutoff: null  # Both high/low in terms of Nyquist frequency\n    low_freq_cutoff: null   # e.g. low-pass to 3 \u00c5 @ 1.06 \u00c5/px would be 1.06/3 = 0.353\n</code></pre>"},{"location":"programs/match_template/#configuring-gpus-for-a-match-template-run","title":"Configuring GPUs for a match template run","text":"<p>The final block of the match template configuration file is used to choose which GPUs will run on. The <code>num_cpus</code> field is used to control how many concurrent streams the <code>match_template</code> program will run on for each device. Values between 1 and 8 are generally advised, but mileage may vary on your system. The <code>gpu_ids</code> field is a list of integers defining which GPU device index(s) the program will target. A value of <code>gpu_ids: \"all\"</code> is a special case which will target all GPUs on the machine (note that only single-node execution is currently supported). The example below will distribute work equally between the zeroth and first GPU device which need discoverable by PyTorch.</p> <pre><code>computational_config:\n  gpu_ids:\n  - 0\n  - 1\n  num_cpus: 4  # 4 streams x 2 devices = 8 total streams\n</code></pre> <p>RuntimeError: CUDA error: invalid device ordinal</p> <p>If you encounter the error <code>RuntimeError: CUDA error: invalid device ordinal</code>, then you've probably listed more GPU devices than are on your machine! Check how many GPUs you have (for example with <code>nvidia-smi</code>) and update the <code>gpu_ids</code> field accordingly.</p>"},{"location":"programs/match_template/#running-the-match-template-program","title":"Running the match template program","text":"<p>Once you've configured a YAML file, running the match template program is fairly simple. We have an example script, <code>Leopard-EM/programs/run_match_template.py</code>, which processes a single micrograph against a single reference template. In addition to the YAML configuration path, there are the additional constant variables <code>DATAFRAME_OUTPUT_PATH</code> and <code>ORIENTATION_BATCH_SIZE</code> listed near the top of the Python script. The latter variable should be adjusted based on available GPU memory while the former defines where an output csv file containing located particles should be saved.</p> <p>We have not specified any arguments in the line 54 of this script: <code>df = mt_manager.results_to_dataframe()</code>. You can have more control over the peak extraction by specifying a <code>locate_peak_kwargs</code> dictionary which can control the desired number of false positives in the search or pick particles given a pre-defined z-score cutoff. For example,</p> <pre><code># Select peaks bases on a number of false positives\ndf = mt_manager.results_to_dataframe(locate_peaks_kwargs={\"false_positives\": 1.0})\n\n\n# Uses a pre-defined z-score cutoff for peak calling\ndf = mt_manager.results_to_dataframe(locate_peaks_kwargs={\"z_score_cutoff\": 7.8})\n</code></pre> <p>Currently, Leopard-EM uses a false-positive rate of 1 per micrograph by default to differentiate between true particles and background.</p>"},{"location":"programs/match_template/#match-template-output-files","title":"Match template output files","text":"<p>The provided program script will output the statistics maps over the image for the search as well as a Pandas DataFrame with compacted information on found particles. These data can be passed onto downstream analysis, for example the refine template program. More detail about these data and their formats is on the Leopard-EM data formats page.</p>"},{"location":"programs/match_template/#mathematical-description","title":"Mathematical description","text":"<p>Described succinctly using mathematics, the match template constructs the orientational search space, , and relative defocus search space, , to generate the CTF-convolved projections of a reference template:</p> <p> </p> <p>The \"best\" projection, based on cross-correlation with the cryo-EM image  (which is the same shape as the projection), is found,</p> <p> </p> <p>where the indexes  and  correspond to the orientation and relative defocus which generated the \"best\" projection. Orientations of the best projection are returned as Euler angles  in the ZYZ format. Note that in practice, this search is done simultaneous for all positions, , within an image much larger than the projection using the convolution theorem, but here we focus on a single location in the image.</p> <p>The match template program also returns the Maximum Intensity Projection (MIP) which is the cross-correlation score of the best projection as well as a z-score (also called \"scaled mip\") on a per-pixel level.</p> <p> </p> <p>There are other steps, namely Fourier filtering, which will be discussed in a later theory section of the documentation.</p> <ol> <li> <p>J Peter Rickgauer, Nikolaus Grigorieff, Winfried Denk (2017) Single-protein detection in crowded molecular environments in cryo-EM images eLife 6:e25648, https://doi.org/10.7554/eLife.25648\u00a0\u21a9</p> </li> </ol>"},{"location":"programs/optimize_template/","title":"The optimize template program","text":"<p>The optimize template program takes in a particle stack of known particle locations and orientations and adjusts the pixel size of the template to maximize the 2DTM SNR values. The SNRs from 2DTM are extremely sensitive to the pixel size used to simulate the map. As a result, we suggest running optimize template early on in data processing to maximize the SNRs.</p>"},{"location":"programs/optimize_template/#configuration-options","title":"Configuration options","text":"<p>A default config file for the optimize template program is available here on the GitHub page. This file is separated into multiple \"blocks\" each configuring distinct portions of the program discussed briefly below.</p>"},{"location":"programs/optimize_template/#particle-stack","title":"Particle stack","text":"<p>The first field we specify is the particle stack to optimize the pixel size with. With this you must specify the path to the particle stack dataframe (as output from match or refine template), the original template box size in pixels, and the box size to extract the particle with. This extracted box size must be even, but the absolute values are not important, although they are the same for Refine Template.</p> <pre><code>particle_stack:\n  df_path: results/results_goodModel.csv  # Needs to be readable by pandas\n  extracted_box_size: [528, 528]\n  original_template_size: [512, 512]\n</code></pre>"},{"location":"programs/optimize_template/#simulator-configuration","title":"Simulator configuration","text":"<p>The optimize template program uses the TeamTomo ttsim3d Python package to simulate maps with different pixel sizes. Detailed configuration information is described on the above page, but the following is the simulator configuration in brief.</p> <p>Note</p> <p>The pixel size specified for the simulator used will be the starting pixel size used for the search.</p> <pre><code>simulator:\n  simulator_config:\n    voltage: 300.0\n    apply_dose_weighting: true\n    dose_start: 0.0\n    dose_end: 50.0\n    dose_filter_modify_signal: \"rel_diff\"\n    upsampling: -1  \n    mtf_reference: \"falcon4EC_300kv\"\n  pdb_filepath: \"parsed_6Q8Y_whole_LSU_match3.pdb\"\n  volume_shape: [512, 512, 512]\n  b_factor_scaling: 0.5\n  additional_b_factor: 0\n  pixel_spacing: 0.95\n</code></pre>"},{"location":"programs/optimize_template/#specifying-pixel-size-search-range-and-steps","title":"Specifying pixel size search range and steps","text":"<p>The program works in two stages, a coarse and a fine pixel size search. We first do a coarse search with a larger range and step size, and then use the best pixel size from that search to do localized, fine-grain search. Note that the min/max values are relative to the pixel size in the simulator configuration.</p> <pre><code>pixel_size_coarse_search:\n  enabled: true\n  pixel_size_min: -0.05\n  pixel_size_max: 0.05\n  pixel_size_step: 0.01\npixel_size_fine_search:\n  enabled: true\n  pixel_size_min: -0.008\n  pixel_size_max: 0.008\n  pixel_size_step: 0.001\n</code></pre> <p>This will first search between 0.90 and 1.00 in 0.01 Angstrom steps, before searching with finer steps around the best value.</p>"},{"location":"programs/optimize_template/#pre-processing-filters-and-computational-config","title":"Pre-processing filters and computational config","text":"<p>These should be the same as for Match Template run to identify the particles.</p>"},{"location":"programs/overview/","title":"Programs at a glance","text":"<p>The Leopard-EM package currently has five main programs which are easily user-configurable through YAML files and are runnable from Python scripts. These five programs encompass a variety of 2DTM data processing workflows. Here, we provide a brief overview of each program's functionality and the necessary input data for that program. Detailed information on configuring and running each program can be found on their respective pages, linked below.</p> <p>Note</p> <p>The functionality of Leopard-EM extends beyond just these five programs. We encourage users to leverage the modular Pydantic models and backend functions to build more complex cryo-EM workflows.</p>"},{"location":"programs/overview/#match-template","title":"Match Template","text":"<p>The <code>match_template</code> program searches for regions in a 2D micrograph containing a macromolecule using a simulated reference structure. The configuration parameters define how the search space (orientation &amp; defocus) is sampled, what pre-processing filters to apply, and where to save the result files from the program. The match template program details contains further information on configuring the program.</p> <p>The required inputs (besides config fields) for <code>match_template</code> are:</p> <ul> <li>A processed 2D micrograph (aligned and summed),</li> <li>The estimated CTF defocus parameters for that micrograph, and</li> <li>A simulated 3D reference template (see package ttsim3d for simulating reference templates).</li> </ul>"},{"location":"programs/overview/#refine-template","title":"Refine Template","text":"<p>After the <code>match_template</code> program identifies particles from a \"coarse\" search, the <code>refine_template</code> program locally refines the orientation, location, and defocus parameters on a per-particle basis. The desired degree of angular &amp; defocus accuracy are configurable parameters, and many of the other fields should be copied directly from the <code>match_template</code> config. The refine template program details has further information on configuring the program.</p> <p>The required inputs for <code>refine_template</code> are:</p> <ul> <li>A simulated 3D reference template (see package ttsim3d for simulating reference templates), and</li> <li>The csv file of particle locations and orientations output from the <code>match_template</code> program.</li> </ul>"},{"location":"programs/overview/#optimize-template","title":"Optimize Template","text":"<p>The 2DTM SNR is extremely sensitive to incorrect pixel size in the reference template structure. Since not all deposited structures have accurate pixel sizes, we include the <code>optimize_template</code> program to maximize 2DTM SNR values by varying the pixel size of the map. A set of pre-identified particles are used (rather than doing a full-image search) for computational efficiency. The optimize template program details contains further information on configuring the program.</p> <p>The required inputs for <code>optimize_template</code> are:</p> <ul> <li>Simulation configuration for the ttsim3d package including the reference structure, and</li> <li>The csv file of particle locations and orientations output from either the <code>match_template</code> or <code>refine_template</code> program.</li> </ul>"},{"location":"programs/overview/#constrained-search","title":"Constrained Search","text":"<p>The <code>constrained_search</code> program uses pre-identified locations and orientations of a reference particle (lets call it particle A) to constrain the search space for another particle (called particle B); constraining the search space increases the sensitivity of 2DTM. This is useful when particle A is easier to identify with 2DTM and when prior knowledge about the spatial relationship between particles A and B is available.</p> <p>The constrained search program details contains further information on configuration the program.</p> <p>The required inputs for <code>constrained_search</code> are:</p> <ul> <li>A simulated 3D reference template (see package ttsim3d) of the constrained particle to search for,</li> <li>The relative position, (x, y, z), and relative orientation between the reference and constrained particle,</li> <li>A particle stack csv (from <code>match_template</code> or <code>refine_template</code>) for the reference particle,</li> <li>A particle stack csv (from <code>match_template</code>) for the constrained particle, and</li> <li>Estimates on the relative position &amp; orientation as well as flexibility of the constrained particle.</li> </ul>"},{"location":"programs/overview/#optimize-b-factor-script","title":"Optimize B-Factor script","text":"<p>In addition to the four larger programs, we have a script, optimize_b_factor.py, which varies the B-factor applied across a model to maximize one of four SNR metrics. This ad hoc B-factor can help account for increased sample structural heterogeneity which is not captured in the input model, or it can help select for particles which closely match the reference template model.</p> <p>The script uses <code>match_template</code> under-the-hood to re-calculate the 2DTM SNR of particles over a variety of CTF B-factors. In addition to parameters modifiable within the script, the program inputs are the same as the match template program.</p>"},{"location":"programs/refine_template/","title":"The refine template program","text":"<p>Although the match template program samples millions of points across orientation space, this can be considered relatively coarse search compared to the theoretical angular accuracy. To achieve an even higher angular accuracy, we finely sample SO(3) space locally for each match template identified particle using the <code>refine_template</code> program. A defocus refinement is also included in the <code>refine_template</code> program  whose relative sampling is another configurable parameter.</p> <p>Refine template does not find additional particles</p> <p>Refine template uses pre-identified particle locations and orientations from the <code>match_template</code> program to refine particle parameters. This will increase the 2DTM SNR values of these already identified particles, but this will not find any additional peaks by bringing them above the cutoff threshold.</p>"},{"location":"programs/refine_template/#configuration-options","title":"Configuration options","text":"<p>A default config file for the match template program is available here on the GitHub page. This file is separated into multiple \"blocks\" each configuring distinct portions of the program briefly discussed below.</p>"},{"location":"programs/refine_template/#template-volume-path","title":"Template volume path","text":"<p>The first field in the example configuration file is <code>template_volume_path</code> which is a path to the simulated 3D reference template. If you are running <code>refine_template</code> directly after <code>match_template</code>, then this field should be copied directly from your match template configuration YAML.</p> <pre><code>template_volume_path: /some/path/to/template.mrc\n</code></pre>"},{"location":"programs/refine_template/#particle-stack-of-particles-to-refine","title":"Particle stack of particles to refine","text":"<p>The next portion of the example configuration is the <code>particle_stack</code> block which is used to extract information from the original micrograph and template matching results. Within this block, we have the <code>df_path</code> field which is a csv file path which contains a complete set of information for particle locations, orientations, paths to 2DTM result files, and more. This csv file is written when running the match template program, and the output path can be directly copied into this configuration field.</p> <p>Refining results from <code>refine_template</code></p> <p>The refine template program writes an updated csv file with refined particle parameters to disk which itself can be fed back into the refinement step. That is, the csv file for <code>df_path</code> does not need to come from match template. Running multiple refinement can be useful to compare between similar reference structures using 2DTM.</p> <p>The next two fields are <code>extracted_box_size</code> and <code>original_template_size</code> which together are used to extract regions in the image and statistics maps around a particle. Set the <code>original_template_size</code> field to the same shape as the simulated volume, that is if the 3D mrc file for the reference template is of shape , then this filed should be <code>original_template_size: [512, 512]</code>.</p> <p>We use <code>extracted_box_size</code> to allow for some padding around the particle which permits some flexibility in particle location during the refinement step. Note that the extracted box shape must be larger than the original template size and an even integer. Values around 4-24 pixels larger than the original template size are advised, and going larger can start to slow down computation without providing any sensitivity benefit.</p> <p>The particle stack block should look something like the following.</p> <pre><code>particle_stack:\n  df_path: /some/path/to/particles.csv\n  extracted_box_size: [528, 528]\n  original_template_size: [512, 512]\n</code></pre>"},{"location":"programs/refine_template/#configuring-the-defocus-refinement-search","title":"Configuring the defocus refinement search","text":"<p>2DTM is highly sensitive to particle defocus, and particle refinement can localize a particle to a higher accuracy than the initial full-orientation search. The <code>defocus_refinement_config</code> block defines what defocus values are searched over relative to the previous best particle defocus.</p> <p>Accuracy of defocus refinement</p> <p>Obtaining highly-accurate per-particle defocus values is dependent on accurate orientation estimations and the quality of experimental data. You may find different search parameters work better depending on the sample and reference template structure.</p> <p>The following configuration will search 100 Angstroms above and below the best particle defocus value in 20 Angstrom increments.</p> <pre><code>defocus_refinement_config:\n  enabled: true\n  defocus_max:  100.0  # in Angstroms, relative to \"best\" defocus value in particle stack dataframe\n  defocus_min: -100.0  # in Angstroms, relative to \"best\" defocus value in particle stack dataframe\n  defocus_step: 20.0   # in Angstroms\n</code></pre> <p>Defocus refinement can be turned off by setting <code>enabled: false</code>, but is enabled by default.</p>"},{"location":"programs/refine_template/#sampling-orientation-space-locally","title":"Sampling orientation space locally","text":"<p>Orientation space is sampled in fine increments during the refinement step, and this sampling is configured with the <code>orientation_refinement_config</code> block. Here, the in-plane rotation sampling increment is controlled by the <code>psi_step_fine</code> field, and the range of in-plane rotations is defined by <code>psi_step_coarse</code>. In the configuration example below, the relative searched relative in-plane rotations would be  in units of degrees. The same applies for the out-of-plane rotations controlled by the <code>theta_step_coarse</code> and <code>theta_step_fine</code> fields.</p> <pre><code>orientation_refinement_config:\n  enabled: true\n  psi_step_coarse:   1.5   # in degrees\n  psi_step_fine:     0.15  # in degrees\n  theta_step_coarse: 2.5   # in degrees\n  theta_step_fine:   0.25  # in degrees\n</code></pre> <p>A good way of choosing these parameters is setting the coarse angular step size to the step size used in <code>match_template</code> while the fine angular step size is a free parameter to choose based on desired accuracy. Also, like the defocus refinement search, orientation refinement can be disabled by setting <code>enabled: false</code>, but it is enabled by default.</p>"},{"location":"programs/refine_template/#varying-pixel-size-during-refinement","title":"Varying pixel size during refinement","text":"<p>Since 2DTM is sensitive to accurate pixel sizes, we include a final search space configuration block called <code>pixel_size_refinement_config</code>. Like orientation and defocus refinement, this searches over a uniform grid of pixel sizes relative to the original pixel size (defined in the particle stack csv). However, pixel size refinement is turned off by default and can be enabled by setting <code>enabled: true</code>.</p> <p>Pixel size refinement vs the <code>optimize_template</code> program</p> <p>Pixel size refinement happens on a per-particle basis in the <code>refine_template</code> program whereas the <code>optimize_template</code> program finds the \"best\" global pixel size for a reference structure across all particles. If you are doubtful of a deposited model's pixel size accuracy (or the relative pixel size of your micrograph), run the <code>optimize_template</code> program rather than using template refinement to identify the correct pixel size.</p> <p>The following is the default pixel size refinement configuration.</p> <pre><code>pixel_size_refinement_config:\n  enabled: false\n  pixel_size_min: -0.005\n  pixel_size_max:  0.005\n  pixel_size_step: 0.001\n</code></pre>"},{"location":"programs/refine_template/#pre-processing-filters-applied-before-search","title":"Pre-processing filters applied before search","text":"<p>The <code>preprocessing_filters</code> block should be copied directly from the original <code>match_template</code> program configuration. All these parameters are discussed in more detail on the match template program page.</p>"},{"location":"programs/refine_template/#configuring-gpus-for-a-match-template-run","title":"Configuring GPUs for a match template run","text":"<p>The refine template program parallelizes across multiple GPUs by splitting which particles are refined across the configured list of GPU devices. The <code>num_cpus</code> field controls how many concurrent streams of work are being submitted to each GPUs; in most cases, a value of <code>1</code> or <code>2</code> will saturate the GPU and give the best performance, although your mileage may vary. Like configuring GPUs for a match template run, GPUs are targeted by their device index or the special string <code>\"all\"</code> The following configuration will run <code>refine_template</code> on GPU zero.</p> <pre><code>computational_config:\n  gpu_ids: 0\n  num_cpus: 1\n</code></pre> <p>The following configuration will run <code>refine_template</code> on all available GPUs with two streams per GPU.</p> <pre><code>computational_config:\n  gpu_ids: \"all\"\n  num_cpus: 2\n</code></pre>"},{"location":"programs/refine_template/#running-the-refine-template-program","title":"Running the refine template program","text":"<p>Once you've configured a YAML file, running the refine template program is fairly simple. We have an example script, <code>Leopard-EM/programs/run_refine_template.py</code>, which processes single particle stack against a single reference template. In addition to the YAML configuration path, there are the additional variables <code>DATAFRAME_OUTPUT_PATH</code> and <code>PARTICLE_BATCH_SIZE</code> near the top of the Python script. The latter variable is used to process multiple particles at once since we want to maximize hardware utilization. But this parameter also needs to balance available GPU memory.</p> <p>The former variable, <code>DATAFRAME_OUTPUT_PATH</code>, will write a new particle stack csv file with new columns corresponding to the refined position, orientation, defocus, and pixel size on a per-particle basis. More details on the particle stack csv format can be found on the Leopard-EM data formats page.</p>"},{"location":"tutorials/batch_processing/","title":"Processing batches of micrographs with Leopard-EM","text":"<p>Often times cryo-EM users may want to process tens to hundreds of micrographs with 2DTM using the same search parameters, reference template, etc. Using batch processing scripts to run through a large set of micrographs is extremely useful, especially when compared to running each 2DTM search manually. In this tutorial, we walk through a basic example of doing batch processing with Leopard-EM on a cluster with SLURM scheduling.</p> <p>The pre-requisites for this tutorial are:</p> <ol> <li>Multiple aligned and summed micrographs as MRC files.</li> <li>A single simulated reference template in MRC format.</li> <li>CTF estimations for each micrograph (tutorial assumes CTFFIND5 was used).</li> <li>A cluster with SLURM scheduling and GPU nodes available.</li> <li>Leopard-EM installed in the current Python environment.</li> </ol> Why Leopard-EM doesn't handle batch processing internally <p>Leopard-EM is designed to be a flexible and modular Python package for 2DTM, and as such we focus on providing the core functionality for 2DTM workflows. Reproducibility is another key aspect of Leopard-EM, and we encourage users to have a one-to-one mapping between input configuration files and 2DTM results. This means that Leopard-EM does not inherently handle batch processing, but instead provides a simple interface for users to write their own 2DTM workflows specific to their computing environments and project needs.</p>"},{"location":"tutorials/batch_processing/#pre-requisite-data-layout","title":"Pre-requisite data layout","text":"<p>This tutorial assumes you are working within a directory with already processed micrographs and associated CTF estimations as well as a simulated reference volume named <code>ref_template.mrc</code>. Each micrograph has a unique name, and these micrographs are stored under the <code>micrographs/</code> directory. The CTF estimations share the same prefix as the micrograph names, and are stored under the <code>ctf_estimations/</code> directory. Below is an example of the directory structure where we have 100 micrographs:</p> <pre><code>/some/path/to/my_project/\n\u251c\u2500\u2500 ref_template.mrc\n\u251c\u2500\u2500 micrographs/\n\u2502   \u251c\u2500\u2500 micrograph_0.mrc\n\u2502   \u251c\u2500\u2500 micrograph_1.mrc\n\u2502   \u251c\u2500\u2500 micrograph_2.mrc\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99.mrc\n\u251c\u2500\u2500 ctf_estimations/\n\u2502   \u251c\u2500\u2500 micrograph_0_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_1_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_2_diagnostic.txt\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99_diagnostic.txt\n</code></pre> <p>An example of the CTF estimation diagnostic file is shown below:</p> <pre><code># Output from CTFFind version 5.0.2, run on 2025-02-13 21:14:21\n# Input file: /some/path/to/my_project/micrograph_1.mrc ; Number of micrographs: 1\n# Pixel size: 0.930 Angstroms ; acceleration voltage: 300.0 keV ; spherical aberration: 2.70 mm ; amplitude contrast: 0.07\n# Box size: 512 pixels ; min. res.: 30.0 Angstroms ; max. res.: 3.5 Angstroms ; min. def.: 0.0 um; max. def. 50000.0 um\n# Columns: #1 - micrograph number; #2 - defocus 1 [Angstroms]; #3 - defocus 2; #4 - azimuth of astigmatism; #5 - additional phase shift [radians]; #6 - cross correlation; #7 - spacing (in Angstroms) up to which CTF rings were fit successfully; #8 - Estimated tilt axis angle; #9 - Estimated tilt angle ; #10 Estimated sample thickness (in Angstroms)\n1.000000 8984.742188 8709.236328 45.948771 0.000000 0.446317 3.720000 221.912292 12.251187 1619.773438\n</code></pre> <p>We will later write a Python function which reads in this diagnostic data and extracts the relevant defocus parameters for each micrograph.</p>"},{"location":"tutorials/batch_processing/#base-yaml-configuration-file","title":"Base YAML configuration file","text":"<p>Next, we need to create a base YAML configuration file. Most of these fields will be the same for each micrograph, but other like the CTF defocus parameters need populated for each micrograph. See the Match Template program page for information on each of the configuration fields which will be specific to your cryo-EM imaging setup. We enclose the populated fields in double curly braces <code>{{...}}</code> which are used for string replacement in the later Python script.</p> <p>This file should be saved as <code>base_match_template_config.yaml</code> in the project directory root.</p> <p>Code copy button (top-left)</p> <p>This tutorial includes a lot of code snippets. There is a copy button in the top-left corner of each code block which will copy the entire code block to your clipboard.</p> <pre><code># base_match_template_config.yaml\ntemplate_volume_path: \"/some/path/to/my_project/ref_template.mrc\"\nmicrograph_path:      \"/some/path/to/my_project/micrographs/{{ micrograph_path }}\"\nmatch_template_result:\n  allow_file_overwrite: true\n  mip_path:                   \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_mip.mrc\"\n  scaled_mip_path:            \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_scaled_mip.mrc\"\n  orientation_psi_path:       \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_orientation_psi.mrc\"\n  orientation_theta_path:     \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_orientation_theta.mrc\"\n  orientation_phi_path:       \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_orientation_phi.mrc\"\n  relative_defocus_path:      \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_relative_defocus.mrc\"\n  correlation_average_path:   \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_correlation_average.mrc\"\n  correlation_variance_path:  \"/some/path/to/my_project/match_template_results/{{ micrograph_name }}_output_correlation_variance.mrc\"\noptics_group:\n  label: my_optics_group\n  voltage: 300.0\n  pixel_size: 0.936   # in Angstroms\n  defocus_u: \"{{ defocus_u_value }}\"  # in Angstroms\n  defocus_v: \"{{ defocus_v_value }}\"  # in Angstroms\n  astigmatism_angle: \"{{ astigmatism_angle_value }}\"\n  spherical_aberration: 2.7  # in millimeters\n  amplitude_contrast_ratio: 0.07\n  phase_shift: 0.0\n  ctf_B_factor: 0.0\ndefocus_search_config:\n  defocus_min: -1000.0  # in Angstroms, relative to defocus_{u,v}\n  defocus_max: 1000.0   # in Angstroms, relative to defocus_{u,v}\n  defocus_step: 200.0   # in Angstroms\norientation_search_config:\n  base_grid_method: uniform\n  psi_step: 1.5    # in degrees\n  theta_step: 2.5  # in degrees\npreprocessing_filters:\n  whitening_filter:\n    enabled: true\n    do_power_spectrum: true\n    max_freq: 0.5  # In terms of Nyquist frequency\n    num_freq_bins: null\n  bandpass_filter:\n    enabled: false\ncomputational_config:\n  gpu_ids: \"all\"\n  num_cpus: 8\n</code></pre>"},{"location":"tutorials/batch_processing/#populating-the-yaml-configuration-file","title":"Populating the YAML configuration file","text":"<p>Now that we have a YAML configuration file to build off of, we next write a Python script to populate the necessary fields for each micrograph. This script is basic expecting an exact correspondence between the micrograph names and the CTF estimation diagnostic files and that the diagnostics are from CTFFIND5. However, this script is easily extensible to handle more complex cases.</p> <p>After creating a new file with the following code and saving it as <code>populate_match_template_config.py</code>, our project directory structure should look like this:</p> <pre><code>/some/path/to/my_project/\n\u251c\u2500\u2500 ref_template.mrc\n\u251c\u2500\u2500 micrographs/\n\u2502   \u251c\u2500\u2500 micrograph_0.mrc\n\u2502   \u251c\u2500\u2500 micrograph_1.mrc\n\u2502   \u251c\u2500\u2500 micrograph_2.mrc\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99.mrc\n\u251c\u2500\u2500 ctf_estimations/\n\u2502   \u251c\u2500\u2500 micrograph_0_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_1_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_2_diagnostic.txt\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99_diagnostic.txt\n\u2502\n\u251c\u2500\u2500 base_match_template_config.yaml    &lt;-- New (contents above)\n\u2514\u2500\u2500 populate_match_template_config.py  &lt;-- New (contents below)\n</code></pre> <pre><code>\"\"\"Script to populate the base YAML configuration file for each micrograph.\"\"\"\n\nimport os\nimport yaml\nimport glob\nimport re\n\n\n# Path constants which are updatable\nINPUT_MICROGRAPHS_DIR = \"/some/path/to/my_project/micrographs/\"\nCTF_DIAGNOSTICS_DIR = \"/some/path/to/my_project/ctf_estimations/\"\nBASE_CONFIG_PATH = \"/some/path/to/my_project/base_match_template_config.yaml\"\nOUTPUT_DIR = \"/some/path/to/my_project/match_template_results/\"\n\n\ndef parse_ctffind5_result(diagnostic_path: str) -&gt; tuple[float, float, float]:\n    \"\"\"Parse the CTFFIND5 diagnostic file to extract defocus parameters.\n\n    Parameters\n    ----------\n    diagnostic_path : str\n        Path to the CTFFIND5 diagnostic file.\n    Returns\n    -------\n    tuple[float, float, float]\n        A tuple containing defocus values\n        (defocus_u, defocus_v, astigmatism_angle).\n    \"\"\"\n    with open(diagnostic_path, \"r\") as f:\n        lines = f.readlines()\n\n    # Assuming first non-comment line contains all info\n    for line in lines:\n        if not line.startswith(\"#\"):\n            parts = line.split()\n            defocus_u = float(parts[1])\n            defocus_v = float(parts[2])\n            astigmatism_angle = float(parts[3])\n            return defocus_u, defocus_v, astigmatism_angle\n\n\ndef populate_single_config(\n    base_config_dict: dict, micrograph_path: str, ctf_diagnostic_path: str\n) -&gt; dict:\n    \"\"\"Populates a single configuration dictionary.\n\n    Parameters\n    ----------\n    base_config_dict : dict\n        The base configuration dictionary to populate.\n    micrograph_path : str\n        The path to the micrograph file.\n\n    Returns\n    -------\n    dict\n        The populated configuration dictionary.\n    \"\"\"\n\n    # Populate the micrograph path and results fields\n    base_config_dict[\"micrograph_path\"] = micrograph_path\n\n    # Replace all \"{{ micrograph_name }}\" placeholders in match_template_result paths\n    basename = os.path.basename(micrograph_path)\n    basename = os.path.splitext(basename)[0]\n    for result_key, result_path in base_config_dict[\"match_template_result\"].items():\n        if isinstance(result_path, str) and \"{{ micrograph_name }}\" in result_path:\n            updated_path = result_path.replace(\"{{ micrograph_name }}\", basename)\n            base_config_dict[\"match_template_result\"][result_key] = updated_path\n\n    # Get the defocus parameters and populate the optics group\n    defocus_u, defocus_v, astigmatism_angle = parse_ctffind5_result(ctf_diagnostic_path)\n    base_config_dict[\"optics_group\"][\"defocus_u\"] = defocus_u\n    base_config_dict[\"optics_group\"][\"defocus_v\"] = defocus_v\n    base_config_dict[\"optics_group\"][\"astigmatism_angle\"] = astigmatism_angle\n\n    return base_config_dict\n\n\ndef create_micrograph_pairs(micrograph_paths, ctf_diagnostic_paths):\n    \"\"\"Create pairs of micrograph and CTF diagnostic files.\"\"\"\n    # Create dictionaries mapping index to file path\n    micrographs = {}\n    diagnostics = {}\n\n    # Extract indices from micrograph files\n    for path in micrograph_paths:\n        match = re.search(r\"micrograph_(\\d+)\\.mrc$\", os.path.basename(path))\n        if match:\n            index = int(match.group(1))\n            micrographs[index] = path\n\n    # Extract indices from diagnostic files\n    for path in ctf_diagnostic_paths:\n        match = re.search(r\"micrograph_(\\d+)_diagnostic\\.txt$\", os.path.basename(path))\n        if match:\n            index = int(match.group(1))\n            diagnostics[index] = path\n\n    # Create pairs for matching indices\n    pairs = []\n    for index in sorted(micrographs.keys()):\n        if index in diagnostics:\n            pairs.append((micrographs[index], diagnostics[index]))\n\n    return pairs\n\n\ndef main():\n    \"\"\"Main function to loop through all micrographs.\"\"\"\n    # Find all micrographs and CTF diagnostics\n    micrograph_paths = glob.glob(os.path.join(INPUT_MICROGRAPHS_DIR, \"*.mrc\"))\n    ctf_diagnostic_paths = glob.glob(\n        os.path.join(CTF_DIAGNOSTICS_DIR, \"*_diagnostic.txt\")\n    )\n\n    # Create pairs based on filename indices\n    pairs = create_micrograph_pairs(micrograph_paths, ctf_diagnostic_paths)\n\n    # Load base configuration\n    with open(BASE_CONFIG_PATH, \"r\") as f:\n        base_config_dict = yaml.safe_load(f)\n\n    # Process each pair\n    for i, (micrograph_path, ctf_diagnostic_path) in enumerate(pairs):\n        populated_config = populate_single_config(\n            base_config_dict.copy(), micrograph_path, ctf_diagnostic_path\n        )\n\n        # Create output directory and save configuration\n        os.makedirs(OUTPUT_DIR, exist_ok=True)\n        output_filename = os.path.join(\n            OUTPUT_DIR,\n            f\"{os.path.basename(micrograph_path).replace('.mrc', '')}_match_template_config.yaml\",\n        )\n        with open(output_filename, \"w\") as out_f:\n            yaml.dump(populated_config, out_f)\n\n        print(f\"Finished processing {output_filename} ({i + 1}/{len(pairs)})\")\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Now run the above script which will generate all the necessary YAML configurations.</p> <pre><code>python populate_match_template_config.py\n</code></pre> <p>Our project directory structure should now look like this:</p> <pre><code>/some/path/to/my_project/\n\u251c\u2500\u2500 ref_template.mrc\n\u251c\u2500\u2500 micrographs/\n\u2502   \u251c\u2500\u2500 micrograph_0.mrc\n\u2502   \u251c\u2500\u2500 micrograph_1.mrc\n\u2502   \u251c\u2500\u2500 micrograph_2.mrc\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99.mrc\n\u251c\u2500\u2500 ctf_estimations/\n\u2502   \u251c\u2500\u2500 micrograph_0_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_1_diagnostic.txt\n\u2502   \u251c\u2500\u2500 micrograph_2_diagnostic.txt\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99_diagnostic.txt\n\u251c\u2500\u2500 match_template_results/                       &lt;-- New\n\u2502   \u251c\u2500\u2500 micrograph_0_match_template_config.yaml   &lt;-- New\n\u2502   \u251c\u2500\u2500 micrograph_1_match_template_config.yaml   &lt;-- New\n\u2502   \u251c\u2500\u2500 micrograph_2_match_template_config.yaml   &lt;-- New\n\u2502   \u251c\u2500\u2500 ...\n\u2502   \u251c\u2500\u2500 micrograph_99_match_template_config.yaml  &lt;-- New\n\u251c\u2500\u2500 base_match_template_config.yaml\n\u2514\u2500\u2500 populate_match_template_config.py\n</code></pre> <p>Batch processing in Leopard-EM not depend on CTFFIND5</p> <p>This tutorial assumes outputs from the CTFFIND5 program each in their own diagnostic file, but the above script can be adapted to any number of CTF estimation outputs. As long as you can uniquely map each micrograph to a set of defocus parameters (presumably in a Python function), the above population of the configuration will be straightforward.</p>"},{"location":"tutorials/batch_processing/#setting-up-the-leopard-em-2dtm-script","title":"Setting up the Leopard-EM 2DTM script","text":"<p>The final step before job submission is to create a Python script for running the <code>match_template</code> program. We adapt the included Python script from the <code>programs/</code> directory to accept a YAML file as an argument; the program is completely configured through the YAML file, so this is the only argument which changes between different 2DTM runs. Copy the following code into a new file named <code>run_match_template.py</code> in the project directory root.</p> <pre><code>\"\"\"Program for running whole-orientation search using 2D template matching.\"\"\"\n\nimport sys\n\nfrom leopard_em.pydantic_models.managers import MatchTemplateManager\n\n# Change batch size based on available GPU memory\nORIENTATION_BATCH_SIZE = 8\n\n\ndef main() -&gt; None:\n    yaml_config_path = sys.argv[1]\n    dataframe_output_path = yaml_config_path.replace(\"config.yaml\", \"results.csv\")\n    mt_manager = MatchTemplateManager.from_yaml(yaml_config_path)\n\n    print(\"Loaded configuration.\\nRunning match_template...\")\n\n    mt_manager.run_match_template(\n        orientation_batch_size=ORIENTATION_BATCH_SIZE,\n        do_result_export=True,  # Saves the statistics immediately upon completion\n    )\n\n    print(\"Finished core match_template call.\\nExporting results...\")\n\n    df = mt_manager.results_to_dataframe()\n    df.to_csv(dataframe_output_path, index=True)\n\n    print(\"Done!\")\n\n\n# NOTE: Invoking  program under `if __name__ == \"__main__\"`\n# necessary for multiprocesing\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Thats it! From the project directory root, we can now initiate a 2DTM run through the following command for a particular configuration:</p> <pre><code>python run_match_template.py match_template_results/micrograph_0_match_template_config.yaml\n</code></pre>"},{"location":"tutorials/batch_processing/#wrapping-the-runs-into-a-slurm-array-job","title":"Wrapping the runs into a SLURM array job","text":"<p>Rather than running each 2DTM search manually, we can use an included SLURM job scheduler to process all of the data. Here, we choose to use a SLURM array job since we have a large number of micrographs to process and the computational needs don't change between runs.</p> <p>Adapting to your SLURM environment</p> <p>Different computing environments have different SLURM configurations including how to request GPU resources, constraints on job allocations, and how to record allocations to a computing account. We cannot possibly enumerate all possible configurations, but the following script is a good starting point. You will need to adapt the SLURM job script below to your specific computing environment, but the principles of running N independent searches across N micrographs remains the same.</p> <p>Create a new file named <code>run_match_template_slurm.sh</code> in the project directory root with the following code:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=batch_2dtm_example\n#SBATCH --account=&lt;&lt;&lt;YOUR_ACCOUNT&gt;&gt;&gt;\n#SBATCH --partition=&lt;&lt;&lt;YOUR_PARTITION&gt;&gt;&gt;\n#SBATCH --qos=&lt;&lt;&lt;YOUR_QOS&gt;&gt;&gt;\n#SBATCH --ntasks=1\n#SBATCH --cpus-per-task=8  # &lt;------ Match with 'num_cpus' in YAML\n#SBATCH --gres=gpu:L40:1  # &lt;------- Adjust based on GPU/node configuration\n#SBATCH --time=10:00:00\n#SBATCH --array=0-99  # &lt;----------- Adjust based on number of micrographs\n#SBATCH --output=batch_2dtm_example_%A_task_%a.out\n#SBATCH --error=batch_2dtm_example_%A_task_%a.err\n\n#####################################\n### Load modules and activate     ###\n### Leopard-EM Python environment ###\n#####################################\n# NOTE: You will need to adjust these lines!\nml anaconda3\nconda activate leopard-em\n\n#######################################################\n### Decode config file based on SLURM_ARRAY_TASK_ID ###\n#######################################################\n# NOTE: You will also need to adjust the CONFIG_DIRECTORY variable below\nCONFIG_DIRECTORY=\"/some/path/to/my_project/match_template_results\"\n\n# Find all YAML files in the directory, sort them, and select the one corresponding to the current task ID.\n# NOTE: Does not depend on naming scheme and should work for any set of YAML configurations.\nCONFIG_FILE=$(ls \"${CONFIG_DIRECTORY}\"/*.yaml | sort | sed -n \"$((SLURM_ARRAY_TASK_ID + 1))p\")\n\n# Check if the config file exists\nif [ -z \"$CONFIG_FILE\" ]; then\n    echo \"Error: No config file found for task ID $SLURM_ARRAY_TASK_ID.\"\n    exit 1\nfi\n\n# Run the match_template script with the selected config file\necho \"Running match_template with config file: $CONFIG_FILE\"\npython run_match_template.py $CONFIG_FILE\n</code></pre>"},{"location":"tutorials/batch_processing/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we walked through how to set up batch processing of micrographs with Leopard-EM using a SLURM array job. Many components of this tutorial will need to be adapted to your specific use-case, like the naming convention for micrographs, how the CTF estimations are mapped to each micrograph, and your particular SLURM environment. However, the principles of creating a single YAML configuration for each template matching run and then executing each run independently remain the same.</p> <p>In short, batch processing with Leopard-EM follows these steps: 1. Placing micrographs and CTF estimations in a known directory structure, 2. Creating a base YAML configuration file with placeholders for micrograph-specific parameters, 3. Populating the YAML configuration file for each micrograph, and 4. Running the <code>match_template</code> program for each of the populated YAML configuration files.</p>"},{"location":"tutorials/match_template_intro/","title":"Introduction to 2DTM with Leopard-EM","text":"<p>This introductory tutorial goes through the basics of running the <code>match_template</code> and <code>refine_template</code> programs using a 60S large ribosomal subunit (LSU) template with a micrograph of a yeast lamella. Here, we focus on understanding the basics of 2DTM which serves as the foundation for building more complex cryo-EM template matching workflows.</p>"},{"location":"tutorials/match_template_intro/#whats-covered-in-this-tutorial","title":"What's covered in this tutorial","text":"<p>In this tutorial we will cover:</p> <ol> <li>Simulate reference volume from PDB files - We  download a prepared 60S LSU structure and demonstrate how to simulate realistic cryo-EM reference volumes. These steps are similar for any other PDB structure.</li> <li>Configure template matching runs - How to define orientation and defocus search parameters as well as running the <code>match_template</code> program.</li> <li>Optimize 2DTM parameters (pixel size) - By using initial results, we can optimize parameters for later 2DTM searches to increase SNR and identify more particles.</li> <li>Running full 2DTM with Leopard-EM - Initial Particle locations and orientations are found using the <code>match_template</code> program.</li> <li>Refining particle parameters post-search - Particle orientation and defocus values (initially identified with <code>match_template</code>) are locally refined using the <code>refine_template</code> program.</li> </ol> <p>Code copy button (top-left)</p> <p>This tutorial includes a lot of code snippets. There is a copy button in the top-left corner of each code block which will copy the entire code block to your clipboard.</p>"},{"location":"tutorials/match_template_intro/#data-and-computation-pre-requisites","title":"Data and computation pre-requisites","text":""},{"location":"tutorials/match_template_intro/#computational-resources","title":"Computational resources","text":"<p>The <code>match_template</code> program requires a GPU for accelerated computation, and Leopard-EM only supports Linux operating systems. This tutorial also assumes you have Leopard-EM installed on your system. Please refer to the installation instructions for more further details, but Leopard-EM should be installable via:</p> <pre><code>pip install leopard-em\n</code></pre>"},{"location":"tutorials/match_template_intro/#data","title":"Data","text":"<p>Data used in this tutorial are hosted in this Zenodo record. Download the following files into some project directory on your machine:</p> <ul> <li><code>60S_aligned.pdb</code> - LSU structure processed from PDB 6Q8Y.</li> <li><code>xenon_131_000_0.0_DWS.mrc</code> - Full micrograph (4k by 4k) to search over</li> <li><code>xenon_131_000_0.0_DWS_cropped_4.mrc</code> - Cropped portion of micrograph (1k by 1k) to run optimizations on.</li> </ul> <p>This can be accomplished via the following command</p> <pre><code>zenodo_get https://zenodo.org/records/16423583 --glob 60S_aligned.pdb --glob xenon_131_000_0.0_DWS.mrc --glob xenon_131_000_0.0_DWS_cropped_4.mrc\n</code></pre> <p>Your project directory should now look like this:</p> <pre><code>leopardEM_intro/\n\u251c\u2500\u2500 60S_aligned.pdb\n\u251c\u2500\u2500 xenon_131_000_0.0_DWS_cropped_4.mrc\n\u2514\u2500\u2500 xenon_131_000_0.0_DWS.mrc\n</code></pre>"},{"location":"tutorials/match_template_intro/#inspecting-the-micrograph","title":"Inspecting the micrograph","text":"<p>The micrograph of yeast cytoplasm contains ribosomes in various orientations and has typical features of cryo-EM data. Notably, the edge of the lamella is visible in the top right corner of the micrograph which we will revisit later in this tutorial to make sure this artifact does not cause spurious detections.</p> <p></p>"},{"location":"tutorials/match_template_intro/#step-1-reference-template-simulation","title":"Step 1: Reference template simulation","text":"<p>Our objective is to generate a realistic 3D cyro-EM density map from the provided LSU PDB structure. This volume is needed for the 2D template match process.</p>"},{"location":"tutorials/match_template_intro/#template-simulation-process","title":"Template simulation process","text":"<p>We will use the TeamTomo package <code>ttsim3d</code> to simulate realistic cryo-EM conditions including:</p> <ul> <li>Electron dose weighting - accounts for radiation damage during exposure</li> <li>Modulation Transfer Function (MTF) - simulates detector response characteristics  </li> <li>B-factor scaling - accounts for structural flexibility and motion blur</li> </ul> <p>This simulation transforms our atomic PDB model into a realistic density map that matches what we expect to see in actual cryo-EM data.</p>"},{"location":"tutorials/match_template_intro/#python-script-for-template-simulation","title":"Python script for template simulation","text":"<p>Create a new Python script <code>simulate_template.py</code> in your project directory with the following contents:</p> <pre><code>from ttsim3d.models import Simulator, SimulatorConfig\n\n# Instantiate the configuration object\nsim_conf = SimulatorConfig(\n    voltage=300.0,  # in keV\n    apply_dose_weighting=True,\n    dose_start=0.0,  # in e-/A^2\n    dose_end=50.0,  # in e-/A^2\n    dose_filter_modify_signal=\"rel_diff\",\n    upsampling=-1,  # auto\n    mtf_reference=\"falcon4EC_300kv\",\n)\n\n# Instantiate the simulator\nsim = Simulator(\n    pdb_filepath=\"60S_aligned.pdb\",\n    pixel_spacing=0.95,  # Angstroms\n    volume_shape=(512, 512, 512),\n    center_atoms=True,\n    remove_hydrogens=True,\n    b_factor_scaling=0.5,\n    additional_b_factor=0,\n    simulator_config=sim_conf,\n)\n\n# Run the simulation and save to disk\nmrc_filepath = \"60S_map_px0.95_bscale0.5_intro.mrc\"\nsim.export_to_mrc(mrc_filepath)\n</code></pre> <p>Then, run the Python script:</p> <pre><code>python simulate_template.py\n</code></pre> <p>A new file should appear in your project directory.</p> <pre><code>leopardEM_intro/\n\u251c\u2500\u2500 60S_aligned.pdb\n\u251c\u2500\u2500 60S_map_px0.95_bscale0.5_intro.mrc  &lt;-- New\n\u251c\u2500\u2500 simulate_template.py\n\u251c\u2500\u2500 xenon_131_000_0.0_DWS_cropped_4.mrc\n\u2514\u2500\u2500 xenon_131_000_0.0_DWS.mrc\n</code></pre>"},{"location":"tutorials/match_template_intro/#step-2-initial-template-matching-process","title":"Step 2: Initial template matching process","text":"<p>During the initial template matching process, we begin by performing a test run on a smaller region of the image rather than the entire micrograph. This approach helps us validate that our program is functioning as expected and the high-confidence peaks identified in this initial search can be used for further optimization, such as pixel size, before processing many micrographs.</p> <p>Cropping the micrograph to its central region and reducing its size by a factor of four in each dimension (4,096 --&gt; 1,024 pixels) makes this initial search much faster thus making the optimization and debugging steps much faster.</p>"},{"location":"tutorials/match_template_intro/#optional-crop-the-micrograph-to-smaller-size","title":"(Optional) Crop the micrograph to smaller size","text":"<p>The cropped micrograph <code>xenon_131_000_0.0_DWS_cropped_4.mrc</code> should already be downloaded in your project directory, but for completeness, here is a Python script that performs the cropping:</p> Micrograph cropping script <pre><code>import mrcfile\nimport numpy as np\n\n# Crop center of micrograph by division factor\nINPUT_FILE = \"xenon_131_000_0.0_DWS.mrc\"\nDIVISION_FACTOR = 4\n\nif __name__ == \"__main__\":\n    with mrcfile.open(INPUT_FILE, permissive=True) as mrc:\n        data = mrc.data[0] if len(mrc.data.shape) &gt; 2 else mrc.data\n\n        # Crop square in center of image\n        h, w = data.shape\n        new_h, new_w = h // DIVISION_FACTOR, w // DIVISION_FACTOR\n        start_h, start_w = h // 2 - new_h // 2, w // 2 - new_w // 2\n\n        cropped = data[start_h:start_h + new_h, start_w:start_w + new_w]\n\n    # Save cropped image\n    output_file = INPUT_FILE.replace(\".mrc\", f\"_cropped_{DIVISION_FACTOR}.mrc\")\n    with mrcfile.new(output_file, overwrite=True) as mrc_new:\n        mrc_new.set_data(cropped.astype(np.float32))\n\n    print(f\"Cropped {data.shape} to {cropped.shape} -&gt; {output_file}\")\n</code></pre>"},{"location":"tutorials/match_template_intro/#configure-the-template-matching-run","title":"Configure the template matching run","text":"<p>Now we'll set up template matching run on the cropped image. We use a YAML configuration file to organize all the parameters in a clean, readable format rather than specifying them directly in Python code or passing them as command line arguments. Some benefits of using configuration files over large numbers of command line arguments are:</p> <ul> <li>Reproducibility - exact parameters are saved and can be shared</li> <li>Clarity - all settings are visible and easy to modify</li> <li>Organization - complex parameter sets are well-structured</li> </ul> <p>Example YAML configurations for all programs can be found under the <code>programs/</code> directory on the GitHub page, and detailed documentation for each program is available on the Program Documentation Overview page. The template matching configuration for this tutorial is shown below; copy its contents into a new file <code>match_template_config_crop_intro.yaml</code>.</p> <p>CTF estimations for match template</p> <p>Defocus estimations per micrograph are necessary for running 2DTM, and we have previously run CTFFIND5 to obtain the <code>optics_group.astigmatism_angle</code>, <code>optics_group.defocus_u</code>, and <code>optics_group.defocus_v</code> parameters. Using a different micrograph with this tutorial will require you to replace these values (along with any other optics changes) in the configuration file.</p> <pre><code>micrograph_path: xenon_131_000_0.0_DWS_cropped_4.mrc\ntemplate_volume_path: 60S_map_px0.95_bscale0.5_intro.mrc\ncomputational_config:\n  gpu_ids: \"all\"  # Use all available GPUs\n  num_cpus: 4     # 4 CPUs per GPU\ndefocus_search_config:\n  enabled: true\n  defocus_max: 1200.0\n  defocus_min: -1200.0\n  defocus_step: 200.0\nmatch_template_result:\n  allow_file_overwrite: true\n  correlation_average_path:  cropped_correlation_average_intro.mrc\n  correlation_variance_path: cropped_correlation_variance_intro.mrc\n  mip_path:                  cropped_mip_intro.mrc\n  orientation_phi_path:      cropped_orientation_phi_intro.mrc\n  orientation_psi_path:      cropped_orientation_psi_intro.mrc\n  orientation_theta_path:    cropped_orientation_theta_intro.mrc\n  relative_defocus_path:     cropped_relative_defocus_intro.mrc\n  scaled_mip_path:           cropped_scaled_mip_intro.mrc\noptics_group:\n  label: micrograph_1\n  amplitude_contrast_ratio: 0.07\n  ctf_B_factor: 0.0\n  astigmatism_angle: 39.417260\n  defocus_u: 5978.758301\n  defocus_v: 5617.462402\n  phase_shift: 0.0\n  pixel_size: 0.95\n  spherical_aberration: 2.7\n  voltage: 300.0\norientation_search_config:\n  base_grid_method: uniform\n  psi_step: 1.5    # in degrees\n  theta_step: 2.5  # in degrees\npreprocessing_filters:\n  whitening_filter:\n    enabled: true\n    do_power_spectrum: true\n    max_freq: 1.0\n</code></pre> <p>In terms of configuration, that's it! We can move onto running the <code>match_template</code> program.</p>"},{"location":"tutorials/match_template_intro/#running-template-matching","title":"Running template matching","text":"<p>Now, we move onto executing the template matching program based on the blueprint <code>run_match_template.py</code> script. Create a new file <code>run_match_template.py</code> in your project directory with the following contents:</p> <pre><code>from leopard_em.pydantic_models.managers import MatchTemplateManager\n\nYAML_CONFIG_PATH = \"match_template_config_crop_intro.yaml\"\nORIENTATION_BATCH_SIZE = 8  # larger values may run faster\n\n\ndef main():\n    \"\"\"Main function to run the match template program.\"\"\"\n    mt_manager = MatchTemplateManager.from_yaml(YAML_CONFIG_PATH)\n    mt_manager.run_match_template(ORIENTATION_BATCH_SIZE)\n    df = mt_manager.results_to_dataframe(locate_peaks_kwargs={\"false_positives\": 1.0})\n    df.to_csv(\"results_match_template_crop_intro.csv\")\n\n\n# NOTE: invoking from `if __name__ == \"__main__\"` is necessary\n# for proper multiprocessing/GPU-distribution behavior\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Now, run the script:</p> <pre><code>python run_match_template.py\n</code></pre> <p>After the program completes, a new CSV file along with several output MRC files should appear in the <code>results/</code> directory. Looking at the results CSV file, we've found 14 peaks above the statistical threshold. While this is a modest number for the cropped region, these high-confidence detections provide valuable data for optimizing our template parameters.</p> <pre><code>leopardEM_intro/\n\u251c\u2500\u2500 60S_aligned.pdb\n\u251c\u2500\u2500 60S_map_px0.95_bscale0.5_intro.mrc\n\u251c\u2500\u2500 cropped_correlation_average_intro.mrc   &lt;-- New\n\u251c\u2500\u2500 cropped_correlation_variance_intro.mrc  &lt;-- New\n\u251c\u2500\u2500 cropped_mip_intro.mrc                   &lt;-- New\n\u251c\u2500\u2500 cropped_orientation_phi_intro.mrc       &lt;-- New\n\u251c\u2500\u2500 cropped_orientation_psi_intro.mrc       &lt;-- New\n\u251c\u2500\u2500 cropped_orientation_theta_intro.mrc     &lt;-- New\n\u251c\u2500\u2500 cropped_relative_defocus_intro.mrc      &lt;-- New\n\u251c\u2500\u2500 cropped_scaled_mip_intro.mrc            &lt;-- New\n\u251c\u2500\u2500 match_template_config_crop_intro.yaml\n\u251c\u2500\u2500 results_match_template_crop_intro.csv   &lt;-- New\n\u251c\u2500\u2500 run_match_template.py\n\u251c\u2500\u2500 simulate_template.py\n\u251c\u2500\u2500 xenon_131_000_0.0_DWS.mrc\n\u2514\u2500\u2500 xenon_131_000_0.0_DWS_cropped_4.mrc\n</code></pre>"},{"location":"tutorials/match_template_intro/#step-3-template-optimization","title":"Step 3: Template optimization","text":"<p>Using the initial template matching results, we optimize critical parameters to improve 2DTM detections and sensitivity. Even small errors in parameters can significantly reduce 2DTM sensitivity. The most critical parameter to optimize is the pixel size used for template simulation, and the <code>optimize_template</code> program iteratively refines the pixel size.</p> Template optimization good practices <p>The common sources of pixel size errors are:</p> <ul> <li>PDB models built with incorrect pixel size calibration (\u00b11-3% for cryo-EM maps)</li> <li>Inaccurate microscope magnification calibration</li> </ul> <p>Even small misalignments in the relative pixel size between the micrograph and model structure used for 2DTM can cause ~10-20% decrease in sensitivity. We highly recommend re-running this pixel size optimization procedure for each new combination of template structure and dataset. Who knows, you may find more peaks with higher confidences!</p>"},{"location":"tutorials/match_template_intro/#optimize-template-configuration","title":"Optimize template configuration","text":"<p>Let's create the optimization configuration (create <code>optimize_template_config_intro.yaml</code> in your project directory).</p> <pre><code>particle_stack:\n  df_path: results_match_template_crop_intro.csv\n  extracted_box_size: [528, 528]\n  original_template_size: [512, 512]\npixel_size_coarse_search:\n  enabled: true\n  pixel_size_min: -0.05\n  pixel_size_max: 0.05\n  pixel_size_step: 0.01\npixel_size_fine_search:\n  enabled: true\n  pixel_size_min: -0.008\n  pixel_size_max: 0.008\n  pixel_size_step: 0.001\npreprocessing_filters:\n  whitening_filter:\n    do_power_spectrum: true\n    enabled: true\n    max_freq: 1.0\n    num_freq_bins: null\ncomputational_config:\n  gpu_ids: 0\n  num_cpus: 2\nsimulator:\n  simulator_config:\n    voltage: 300.0\n    apply_dose_weighting: true\n    dose_start: 0.0\n    dose_end: 50.0\n    dose_filter_modify_signal: \"rel_diff\"\n    upsampling: -1  \n    mtf_reference: \"falcon4EC_300kv\"\n  pdb_filepath: \"60S_aligned.pdb\"\n  volume_shape: [512, 512, 512]\n  b_factor_scaling: 0.5\n  additional_b_factor: 0\n  pixel_spacing: 0.95\n  center_atoms: true\n  remove_hydrogens: true\n</code></pre>"},{"location":"tutorials/match_template_intro/#running-the-optimize-template-program","title":"Running the optimize template program","text":"<p>The <code>optimize_template</code> program is executed in much the same way as the <code>match_template</code> program. Create a new Python script <code>run_optimize_template.py</code> with the following contents</p> <pre><code>from leopard_em.pydantic_models.managers import OptimizeTemplateManager\n\nOPTIMIZE_YAML_PATH = \"optimize_template_config_intro.yaml\"\n\n\ndef main() -&gt; None:\n    \"\"\"Main function to run the optimize template program.\"\"\"\n    otm = OptimizeTemplateManager.from_yaml(OPTIMIZE_YAML_PATH)\n    otm.run_optimize_template(\n        output_text_path=\"optimize_template_results_intro.txt\"\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Then again run the script.</p> <pre><code>python run_optimize_template.py\n</code></pre>"},{"location":"tutorials/match_template_intro/#optimization-results","title":"Optimization results","text":"<p>Inspecting the new results file <code>optimize_template_results_intro.txt</code> we see the pixel size optimization determined that 0.936 \u00c5/pixel provides the best match to our experimental data (results may vary by \u00b10.002 \u00c5). This represents a ~1.5% correction from our initial estimate of 0.95 \u00c5/pixel - a small but important improvement.</p>"},{"location":"tutorials/match_template_intro/#re-generating-optimized-templates","title":"Re-generating Optimized Templates","text":"<p>Now we'll regenerate our 60S template using the optimized pixel size. This updated template should provide better correlation scores and more reliable particle detection in the full template matching run.</p> <p>Create a new file <code>simulate_optimized_template.py</code> and run it like before.</p> <pre><code># Re-simulate 60S map with optimized pixel size\nfrom ttsim3d.models import Simulator, SimulatorConfig\n\n# Instantiate the configuration object\nsim_conf = SimulatorConfig(\n    voltage=300.0,  # in keV\n    apply_dose_weighting=True,\n    dose_start=0.0,  # in e-/A^2\n    dose_end=50.0,  # in e-/A^2\n    dose_filter_modify_signal=\"rel_diff\",\n    upsampling=-1,  # auto\n    mtf_reference=\"falcon4EC_300kv\",\n)\n\n# Instantiate the simulator for 60S\nsim = Simulator(\n    pdb_filepath=\"60S_aligned.pdb\",\n    pixel_spacing=0.936,  # Optimized (Angstroms)\n    volume_shape=(512, 512, 512),\n    center_atoms=False,\n    remove_hydrogens=True,\n    b_factor_scaling=0.5,\n    additional_b_factor=0,\n    simulator_config=sim_conf,\n)\n\n# Run the simulation\nmrc_filepath = \"60S_map_px0.936_bscale0.5_intro.mrc\"\nsim.export_to_mrc(mrc_filepath)\n</code></pre> <p>We will now use the new <code>60S_map_px0.936_bscale0.5_intro.mrc</code> template in the full template matching process.</p>"},{"location":"tutorials/match_template_intro/#step-4-full-template-matching-run","title":"Step 4: Full template matching run","text":"<p>With our optimized 60S template in hand, we're ready to move on to running template matching on the entire micrograph to locate and orient 60S ribosomes within our image. The full search is computationally intensive taking ~8 hours on an RTX A6000 ada GPU and parallelizes across multi-GPU systems.</p>"},{"location":"tutorials/match_template_intro/#full-match-template-configuration","title":"Full match template configuration","text":"<p>The full match template configuration is is nearly identical to the previous cropped configuration, but this time we point it towards the full 4k by 4k micrograph. Create a new file <code>match_template_config_60S_intro.yaml</code> with the following contents.</p> <pre><code>micrograph_path: xenon_131_000_0.0_DWS.mrc\ntemplate_volume_path: 60S_map_px0.936_bscale0.5_intro.mrc\ncomputational_config:\n  gpu_ids: \"all\"  # Use all available GPUs\n  num_cpus: 4     # 4 CPUs per GPU\ndefocus_search_config:\n  enabled: true\n  defocus_max: 1200.0\n  defocus_min: -1200.0\n  defocus_step: 200.0\nmatch_template_result:\n  allow_file_overwrite: true\n  correlation_average_path:  output_correlation_average_intro.mrc\n  correlation_variance_path: output_correlation_variance_intro.mrc\n  mip_path:                  output_mip_intro.mrc\n  orientation_phi_path:      output_orientation_phi_intro.mrc\n  orientation_psi_path:      output_orientation_psi_intro.mrc\n  orientation_theta_path:    output_orientation_theta_intro.mrc\n  relative_defocus_path:     output_relative_defocus_intro.mrc\n  scaled_mip_path:           output_scaled_mip_intro.mrc\noptics_group:\n  label: micrograph_1\n  amplitude_contrast_ratio: 0.07\n  ctf_B_factor: 0.0\n  astigmatism_angle: 39.417260\n  defocus_u: 5978.758301\n  defocus_v: 5617.462402\n  phase_shift: 0.0\n  pixel_size: 0.936  # Optimized pixel size\n  spherical_aberration: 2.7\n  voltage: 300.0\norientation_search_config:\n  base_grid_method: uniform\n  psi_step: 1.5    # in degrees\n  theta_step: 2.5  # in degrees\npreprocessing_filters:\n  whitening_filter:\n    enabled: true\n    do_power_spectrum: true\n    max_freq: 1.0\n</code></pre>"},{"location":"tutorials/match_template_intro/#running-the-search","title":"Running the search","text":"<p>We will use the same <code>run_match_template.py</code> file, but we need to update which YAML configuration file the script reads and the output CSV file. Change the following lines in the script</p> <pre><code>YAML_CONFIG_PATH = \"match_template_config_60S_intro.yaml\"  # line 3\n...\ndf.to_csv(\"results/results_match_template_60S_intro.csv\")  # line 12\n</code></pre> <p>and run the Python script again</p> <pre><code>python run_match_template.py\n</code></pre> Encountering CUDA Out of Memory Error <p>On GPUs with lower amounts of VRAM, you may encounter an out-of-memory error. Decrease the batch size to a lower value (e.g., <code>ORIENTATION_BATCH_SIZE = 4</code>) and try re-running the script.</p>"},{"location":"tutorials/match_template_intro/#results","title":"Results","text":"<p>Excellent! Once the template matching process finishes, there should be the following new files in the project directory.</p> <pre><code>leopardEM_intro/\n60S_aligned.pdb\n...\noutput_correlation_average_intro.mrc    &lt;-- New\noutput_correlation_variance_intro.mrc   &lt;-- New\noutput_mip_intro.mrc                    &lt;-- New\noutput_orientation_phi_intro.mrc        &lt;-- New\noutput_orientation_psi_intro.mrc        &lt;-- New\noutput_orientation_theta_intro.mrc      &lt;-- New\noutput_relative_defocus_intro.mrc       &lt;-- New\noutput_scaled_mip_intro.mrc             &lt;-- New\nresults_match_template_60S_intro.csv    &lt;-- New\nresults_match_template_crop_intro.csv\nrun_match_template.py\n...\nxenon_131_000_0.0_DWS.mrc\n</code></pre> <p>Their exact contents and visualizing the results are discussed elsewhere in the documentation, and what we're most interested in is the <code>results_match_template_60S_intro.csv</code> file which contains all the information about our 407 identified peaks above the statistical threshold.</p>"},{"location":"tutorials/match_template_intro/#step-5-data-inspection-step","title":"Step 5: Data inspection step","text":"<p>Re-referencing the micrograph, we can clearly see the dark lamella edge is visible in the top-right corner. It is good practice to make sure artifacts in your micrographs are not causing spurious detections and apply a filtering strategy if necessary. In this case, we don't see any ribosome detections within the dark region or along its boundary.</p> <p></p> <p>Since we are confident in our detections, we can move onto the template refinement process.</p> Python script for generating above plot images <p>The following is a very simple plotting script using matplotlib to visualize the distribution of particles. Note, you may need to install matplotlib via <code>pip install matplotlib</code> before running the script.</p> <pre><code>import mrcfile\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load data\nimg = mrcfile.read(\"xenon_131_000_0.0_DWS.mrc\")\ndf = pd.read_csv(\"results_match_template_60S_intro.csv\")\n\n# Plot 1: Only unfiltered data\nplt.figure(figsize=(8, 8))\nplt.imshow(img, cmap=\"gray\")\nplt.scatter(\n    df[\"pos_x_img\"], df[\"pos_y_img\"], c=\"red\", s=30, label=\"All\", alpha=0.4, marker=\"x\"\n)\nplt.axis(\"off\")\nplt.legend()\nplt.savefig(\"match_template_intro_all_locations.png\", dpi=200, bbox_inches=\"tight\")\nplt.close()\n\nprint(\"Plots saved successfully!\")\n</code></pre>"},{"location":"tutorials/match_template_intro/#step-6-template-refinement","title":"Step 6: Template refinement","text":"<p>Our objective now is to improve the accuracy of particle location and orientation estimates through local refinement. This is accomplished using the <code>refine_template</code> program which performs a local search around the initial estimates from <code>match_template</code>. Key difference between <code>match_template</code> and <code>refine_template</code> are:</p> <ul> <li><code>match_template</code> performs a global search over the entire micrograph and orientation space which is computationally expensive.</li> <li><code>refine_template</code> performs a local search around known particles with finer angular and defocus sampling. Local searches are much faster.</li> </ul>"},{"location":"tutorials/match_template_intro/#refinement-configuration","title":"Refinement configuration","text":"<p>At its most basic, the refinement configuration tells the program where particles are located in the micrograph, how to extract their particle images, and what orientation and defocus values to sample locally. Our original template volume produces projections of 512 by 512 pixels, so we'll set the extracted box size to 518 by 518 pixels to provide some small margin of movement during refinement. Generally, the extracted box size should be 4-24 pixels larger than the template projection size.</p> <p>Create a new file <code>refine_template_config_60S_intro.yaml</code> with the following contents.</p> <pre><code>template_volume_path: 60S_map_px0.936_bscale0.5_intro.mrc\nparticle_stack:\n  df_path: results_match_template_60S_intro.csv\n  extracted_box_size: [518, 518]\n  original_template_size: [512, 512]\ndefocus_refinement_config:\n  enabled: true\n\n  defocus_max:  100.0  # in Angstroms, relative to \"best\" particle defocus value\n  defocus_min: -100.0  # in Angstroms, relative to \"best\" particle defocus value\n  defocus_step: 20.0   # in Angstroms\norientation_refinement_config:\n  enabled: true\n  psi_step_coarse:     1.5  # in degrees\n  psi_step_fine:       0.1  # in degrees\n  theta_step_coarse:   2.5  # in degrees\n  theta_step_fine:     0.1  # in degrees\npixel_size_refinement_config:\n  enabled: false\npreprocessing_filters:\n  whitening_filter:\n    do_power_spectrum: true\n    enabled: true\n    max_freq: 1.0\n    num_freq_bins: null\ncomputational_config:\n  gpu_ids: \"all\"\n  num_cpus: 1  # 1 CPU per GPU\n</code></pre>"},{"location":"tutorials/match_template_intro/#running-the-refinement","title":"Running the refinement","text":"<p>The refinement program is executed in a similar manner to the previous programs. Again, we use the included blueprint script <code>run_refine_template.py</code> from the GitHub repository. Create a new Python script <code>run_refine_template.py</code> with the following contents:</p> <pre><code>from leopard_em.pydantic_models.managers import RefineTemplateManager\n\nYAML_CONFIG_PATH = \"refine_template_config_60S_intro.yaml\"\nDATAFRAME_OUTPUT_PATH = \"results_refine_template_60S_intro.csv\"\nPARTICLE_BATCH_SIZE = 64  # Tune this values based on GPU memory\n\ndef main() -&gt; None:\n    rt_manager = RefineTemplateManager.from_yaml(YAML_CONFIG_PATH)\n    rt_manager.run_refine_template(DATAFRAME_OUTPUT_PATH, PARTICLE_BATCH_SIZE)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Then run the script:</p> <pre><code>python run_refine_template.py\n</code></pre>"},{"location":"tutorials/match_template_intro/#refinement-results","title":"Refinement results","text":"<p>We now have a set of particle locations and orientations with improved orientation and defocus estimates along with improved z-scores. These results are saved in an updated CSV file <code>results_refine_template_60S_intro.csv</code>.</p> <p>The introductory tutorial is now complete, and you should now have solid understanding of the standard 2DTM workflow using Leopard-EM. Feel free to explore other parts of the documentation to learn more about how you can use these refined results to visualize particles, such as with Visualizing 2DTM Results, or the exact data formats which Leopard-EM uses.</p>"},{"location":"tutorials/match_template_intro/#tutorial-summary","title":"Tutorial summary","text":"<p>Throughout this tutorial, we've covered the essential steps in the \"standard 2DTM workflow\" by identifying 60S ribosomes using Leopard-EM. You've learned how to</p> <ol> <li>Simulate reference volumes from PDB structures using <code>ttsim3d</code>.</li> <li>Configure and run 2DTM searches with the <code>match_template</code> program in Leopard-EM.</li> <li>(once per dataset) Optimize the pixel size using the <code>optimize_template</code> program.</li> <li>Perform a full 2DTM search on a micrograph to identify particle locations and orientations.</li> <li>Inspect results on top of the micrograph to ensure they make contextual sense (no spurious detections).</li> <li>Refine particle parameters using the <code>refine_template</code> program for improved accuracy.</li> </ol>"}]}